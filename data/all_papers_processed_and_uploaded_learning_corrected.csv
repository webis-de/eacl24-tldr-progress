id,title,venue,year,authors,abstract,tldr,purpose,paper_type,pipeline_components,datasets,metrics,manual_evaluation,code_url,paper_url,problems_with_solutions,learning,domains,challenge_type
SP:a27498a61940383cc38672d70c7181ea3727c8e6,Unsupervised Class-Specific Abstractive Summarization of Customer Reviews,ACL,2021,"['Thi Nhat', 'Anh Nguyen', 'Mingwei Shen', 'Karen Hovsepian']","Large-scale unsupervised abstractive summarization is sorely needed to automatically scan millions of customer reviews in today’s fastpaced e-commerce landscape. We address a key challenge in unsupervised abstractive summarization – reducing generic and uninformative content and producing useful information that relates to specific product aspects. To do so, we propose to model reviews in the context of some topical classes of interest. In particular, for any arbitrary set of topical classes of interest, the proposed model can learn to generate a set of class-specific summaries from multiple reviews of each product without ground-truth summaries, and the only required signal is class probabilities or class label for each review. The model combines a generative variational autoencoder, with an integrated class-correlation gating mechanism and a hierarchical structure capturing dependence among products, reviews and classes. Human evaluation shows that generated summaries are highly relevant, fluent, and representative. Evaluation using a reference dataset shows that our model outperforms state-of-theart abstractive and extractive baselines.","

System: The paper proposes a model for large-scale unsupervised abstractive summarization of customer reviews in e-commerce. The model addresses the challenge of reducing generic and uninformative content and producing useful information related to specific product aspects by modeling reviews in the context of topical classes of interest. The proposed model can generate class-specific summaries from multiple reviews of each product without ground-truth summaries, using only class probabilities or labels. The model combines a generative variational autoencoder with a class-correlation gating mechanism and a hierarchical structure. Human evaluation shows that the generated summaries are relevant, fluent, and representative, and evaluation using a reference dataset shows that the model outperforms state-of-the-art abstractive and extractive baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of product reviews to improve products and streamline defect discovery, trend analysis, and product development.', 'Who is the target audience?': 'The summaries are for both sellers and customers who manually sift through hundreds of reviews across competing products to decipher systemic or trending concerns from isolated or irrelevant issues.', 'How will the summaries be used?': 'The summaries will be used to provide informative and fluent insights to improve products and make review summaries more useful to users.'}",['method'],['Input Encoding'],['Amazon Product Reviews'],['ROUGE'],"['Informativeness', 'Conciseness', 'Non-redundancy', 'Content Support', 'Opinion Consensus', 'Fluency', 'Overall Quality']",,https://aclanthology.org/2021.ecnlp-1.11,"{'Current state-of-the-art methods for abstractive summarization rely on large amounts of human-written ground-truth summaries, which are expensive to obtain.': 'The authors propose an unsupervised abstractive summarization model that can generate class-specific summaries from multiple reviews of each product, without using any ground-truth summaries. The only additional signal required for the model is the class probabilities or class label for each review generated by an independent black-box classifier, or provided by annotators.', 'Summaries generated by unsupervised models are often generic and uninformative, and do not provide useful information about different aspects of the product.': 'The authors propose a class-specific unsupervised abstractive summarization model that can generate informative and fluent summaries according to any predefined set of topical classes of interest for the users. The proposed model combines a generative variational autoencoder (VAE) model with a hierarchical structure that captures dependence among products, reviews and classes, allowing the representation of class-specific information through class latent variables.', 'Existing opinion summarization models require either a large training set of ground-truth summaries per class or a complicated and costly training set comprising multiple types of manual annotations.': 'The proposed model only needs review-class label pairs. The authors also propose an integrated two-layer filter mechanism consisting of a class-correlation gate and a set of class-specific importance coefficients which focus on class-related words, and thus reduce irrelevant or generic information and increase informativeness with respect to each class of interest.', 'There is a need to evaluate the proposed model against state-of-the-art baselines.': 'The authors conducted human evaluation and experiments with a reference dataset, which showed that the proposed model outperforms state-of-the-art baselines in a wide range of evaluation metrics.'}",unsupervised,['Reviews'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:d058a625b73f4f625b40a60837e81490a9113e69,Unsupervised Abstractive Opinion Summarization by Generating Sentences with Tree-Structured Topic Guidance,TACL,2021,"['Masaru Isonuma', 'Junichiro Mori', 'Danushka Bollegala', 'Ichiro Sakata']","This paper presents a novel unsupervised abstractive summarization method for opinionated texts. While the basic variational autoencoder-based models assume a unimodal Gaussian prior for the latent code of sentences, we alternate it with a recursive Gaussian mixture, where each mixture component corresponds to the latent code of a topic sentence and is mixed by a tree-structured topic distribution. By decoding each Gaussian component, we generate sentences with tree-structured topic guidance, where the root sentence conveys generic content, and the leaf sentences describe specific topics. Experimental results demonstrate that the generated topic sentences are appropriate as a summary of opinionated texts, which are more informative and cover more input contents than those generated by the recent unsupervised summarization model (Bražinskas et al., 2020). Furthermore, we demonstrate that the variance of latent Gaussians represents the granularity of sentences, analogous to Gaussian word embedding (Vilnis and McCallum, 2015).","The paper presents a new method for summarizing opinionated texts using a recursive Gaussian mixture model. The model generates sentences with tree-structured topic guidance, where the root sentence conveys generic content, and the leaf sentences describe specific topics. Experimental results show that the generated topic sentences are more informative and cover more input contents than those generated by recent unsupervised summarization models. The paper also demonstrates that the variance of latent Gaussians represents the granularity of sentences, similar to Gaussian word embedding.","{'What is the purpose of the summaries?': 'The authors are generating summaries of opinionated texts, such as product reviews and online posts on Web sites, to provide an overview of the documents and to capture the topictree structure of reviews.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the content of opinionated texts, such as consumers who want to make informed purchasing decisions based on product reviews.', 'How will the summaries be used?': 'The summaries can be used to provide a quick overview of the content of opinionated texts, to identify the main topics and details discussed in the texts, and to compare and contrast different opinions on the same topic.'}",['method'],['Objective Function'],"['Amazon Product Reviews', 'Yelp Reviews']",['ROUGE'],"['Fluency', 'Coherence', 'Informativeness', 'Redundancy']",,https://aclanthology.org/2021.tacl-1.56,"{'Extractive approaches to document summarization often fail to provide an overview of opinionated texts.': 'Abstractive summarization can overcome this challenge by paraphrasing and generalizing an entire document.', 'Supervised approaches to abstractive summarization are limited to specific domains where a large number of gold summaries are available.': 'The authors propose an unsupervised abstractive summarization method for opinionated texts.', 'Previous unsupervised summarization methods for opinionated texts lack topics and granularity.': ""The authors' proposed method generates more informative summaries that cover more input content than previous unsupervised summarization methods."", 'Generating sentences with tree-structured topic guidance is difficult due to controlling the granularity of topic sentences.': 'The authors model the sentence granularity by the variance size of the latent code and represent the latent code of topic sentences with Gaussian distributions.', 'Previous methods for generating sentences with designated topic guidance do not model the sentence granularity in a latent space to generate topic sentences with multiple granularities.': 'The authors introduce a recursive Gaussian mixture prior to modeling the latent code of input sentences in reviews to model the sentence granularity and generate topic sentences with multiple granularities.'}",unsupervised,['Reviews'],"['information-loss-and-incoherence-in-extractive-summarization', 'lack-of-suitable-training-data']"
SP:5fa8171880191dfb5e9df2112b9587df1af6fcca,Unsupervised Single Document Abstractive Summarization using Semantic Units,AACL,2022,"['Jhen-Yi Wu', 'Ying-Jia Lin', 'Hung-Yu Kao']","In this work, we study the importance of content frequency on abstractive summarization, where we define the content as ""semantic units."" We propose a two-stage training framework to let the model automatically learn the frequency of each semantic unit in the source text. Our model is trained in an unsupervised manner since the frequency information can be inferred from source text only. During inference, our model identifies sentences with highfrequency semantic units and utilizes frequency information to generate summaries from the filtered sentences. Our model performance on the CNN/Daily Mail summarization task outperforms the other unsupervised methods under the same settings. Furthermore, we achieve competitive ROUGE scores with far fewer model parameters compared to several large-scale pre-trained models. Our model can be trained under low-resource language settings and thus can serve as a potential solution for real-world applications where pre-trained models are not applicable.",The paper discusses the importance of content frequency in abstractive summarization and proposes a two-stage training framework for the model to learn the frequency of each semantic unit in the source text. The model is trained in an unsupervised manner and identifies sentences with high-frequency semantic units during inference to generate summaries. The model outperforms other unsupervised methods on the CNN/Daily Mail summarization task and achieves competitive ROUGE scores with fewer parameters than pre-trained models. It can be trained under low-resource language settings and is a potential solution for real-world applications where pre-trained models are not applicable.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress longer texts into shorter versions while preserving the salient information in the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer text.', 'How will the summaries be used?': 'The summaries can be used in real-world applications where human-written summaries are rarely accessible, and can be generated automatically using the proposed approach by the authors.'}",['method'],"['Input Encoding', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],[''],https://github.com/IKMLab/UASSU,https://aclanthology.org/2022.aacl-main.69,"{'Lack of sufficient training pairs is a common issue in real-world applications of supervised summarization models.': 'The authors propose an unsupervised summarization method that utilizes the frequency of contents in the source text to automatically learn semantic unit frequency and discriminate salient parts in source documents for abstractive summarization.', 'Large pre-trained models for language generation or summarization may require less data for fine-tuning, but they are often trained on English corpus only and thus are not suitable for low-resource languages.': 'The authors propose an unsupervised summarization method that does not rely on pre-trained models and can be applied to any language.', 'Creating high-quality training pairs for supervised summarization models can be costly.': 'The authors propose an unsupervised summarization method that does not require any human-written summaries during training or inference, making it suitable for real-world applications where human-written summaries are rarely accessible.', 'It is difficult to identify the most salient information in a source text for summarization.': 'The authors propose dividing and enumerating all text spans with a fixed-size sliding window to create ""semantic units"" (SUs) that contain brief semantic concepts. They argue that a refined summary should at least contain the semantic units frequently occurring in the original articles since the high-frequency semantic units should be the topic or contain key descriptions.', 'It is difficult to retrieve frequency information from source documents only.': 'The authors propose a model that automatically learns semantic unit frequency and uses the learned frequency information to filter the sentences in the source text and generate a summary.', 'It is difficult to decide how much to focus on each semantic unit when generating text.': 'The authors propose using the attention mechanism to obtain semantic unit frequency in the inference stage, which helps the model decide how much to focus on each semantic unit when generating text. The recorded attention weights are used to assign weights to the semantic units, which are considered the semantic unit frequency.'}",unsupervised,['News'],['lack-of-suitable-training-data']
SP:01581253892aee772f6defcc087fa9f97e0ec201,BottleSum: Unsupervised and Self-supervised Sentence Summarization using the Information Bottleneck Principle,EMNLP,2019,"['Peter West', 'Ari Holtzman', 'Jan Buys', 'Yejin Choi']","The principle of the Information Bottleneck (Tishby et al., 1999) is to produce a summary of information X optimized to predict some other relevant information Y . In this paper, we propose a novel approach to unsupervised sentence summarization by mapping the Information Bottleneck principle to a conditional language modelling objective: given a sentence, our approach seeks a compressed sentence that can best predict the next sentence. Our iterative algorithm under the Information Bottleneck objective searches gradually shorter subsequences of the given sentence while maximizing the probability of the next sentence conditioned on the summary. Using only pretrained language models with no direct supervision, our approach can efficiently perform extractive sentence summarization over a large corpus. Building on our unsupervised extractive summarization (BottleSum), we then present a new approach to self-supervised abstractive summarization (BottleSum ), where a transformer-based language model is trained on the output summaries of our unsupervised method. Empirical results demonstrate that our extractive method outperforms other unsupervised models on multiple automatic metrics. In addition, we find that our selfsupervised abstractive model outperforms unsupervised baselines (including our own) by human evaluation along multiple attributes.","The paper proposes a new approach to unsupervised sentence summarization using the Information Bottleneck principle. The approach seeks a compressed sentence that can best predict the next sentence, using an iterative algorithm that gradually searches shorter subsequences of the given sentence. The method can efficiently perform extractive sentence summarization over a large corpus using only pretrained language models with no direct supervision. The paper also presents a new approach to self-supervised abstractive summarization, where a transformer-based language model is trained on the output summaries of the unsupervised method. Empirical results show that the extractive method outperforms other unsupervised models on multiple automatic metrics, and the self-supervised abstractive model outperforms unsupervised baselines by human evaluation along multiple attributes.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to bring significant advancements for both extractive and abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding large amounts of text, and can be particularly useful in fields such as journalism and research.'}",['method'],['Objective Function'],"['DUC 2003', 'DUC 2004']","['ROUGE', 'Compression Rate']","['Coherence', 'Conciseness', 'Agrement', 'Overall Quality']",,https://aclanthology.org/D19-1389/,"{'The success of recent neural network-based approaches for summarization relies on large-scale parallel corpora of input text and output summaries for direct supervision, which are costly to create.': 'The authors propose unsupervised or self-supervised alternatives to overcome the sample inefficiency of current neural approaches, such as their novel approaches BottleSumEx and BottleSum.', 'Existing large-scale datasets for summarization are based on naturally occurring pairs of summary-like text paired with source text, which must already exist in-domain, limiting their applicability to different tasks and domains.': 'The authors propose their novel approaches BottleSumEx and BottleSum, which do not rely on pre-existing pairs of summary-like text and source text, making them more applicable to different tasks and domains.'}",unsupervised,['News'],"['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:a9d2bc33f49110c0b6736b768b40b15a36ab048b,Simple Unsupervised Summarization by Contextual Matching,ACL,2019,"['Jiawei Zhou', 'Alexander M. Rush']","We propose an unsupervised method for sentence summarization using only language modeling. The approach employs two language models, one that is generic (i.e. pretrained), and the other that is specific to the target domain. We show that by using a productof-experts criteria these are enough for maintaining continuous contextual matching while maintaining output fluency. Experiments on both abstractive and extractive sentence summarization data sets show promising results of our method without being exposed to any paired data.","System: The paper proposes an unsupervised method for sentence summarization using language modeling. The approach uses two language models, one generic and one specific to the target domain, and employs a product-of-experts criteria to maintain contextual matching and output fluency. The experiments show promising results for both abstractive and extractive summarization without the need for paired data.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to formulate a shorter output text than the original while capturing its core meaning.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Objective Function'],['Gigaword'],['ROUGE'],[''],https://github.com/jzhou316/Unsupervised-Sentence-Summarization,https://aclanthology.org/P19-1503,"{'Unsupervised sentence summarization with no paired examples is a challenging task.': 'The authors propose a simple approach that does not require any joint training. They utilize a generic pretrained language model to enforce contextual matching between sentence prefixes. They then use a smoothed problem specific target language model to guide the fluency of the generation process. They combine these two models in a product-of-experts objective.', 'Data-driven approaches for unsupervised sentence summarization require a large amount of parallel data for supervision to do well.': 'The unsupervised approach proposed by the authors reduces the human effort for collecting and annotating large amounts of paired training data.', 'Existing unsupervised sentence summarization methods use parameterized unsupervised learning methods to induce a latent variable model.': 'The authors propose a method that does not use any task-specific training and instead relies on a pretrained language model for unsupervised contextual matching, i.e. unsupervised paraphrasing.', 'Some existing unsupervised sentence summarization methods only work for extractive summarization.': 'The proposed method works for both extractive and abstractive summarization and produces qualitatively fluent outputs.'}",unsupervised,['News'],['lack-of-suitable-training-data']
SP:49568c9ec0c0b75710bdbb34b8687d8e01434f92,Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking,ACL,2019,"['Masaru Isonuma', 'Junichiro Mori', 'Ichiro Sakata']","This paper focuses on the end-to-end abstractive summarization of a single product review without supervision. We assume that a review can be described as a discourse tree, in which the summary is the root, and the child sentences explain their parent in detail. By recursively estimating a parent from its children, our model learns the latent discourse tree without an external parser and generates a concise summary. We also introduce an architecture that ranks the importance of each sentence on the tree to support summary generation focusing on the main review point. The experimental results demonstrate that our model is competitive with or outperforms other unsupervised approaches. In particular, for relatively long reviews, it achieves a competitive or better performance than supervised models. The induced tree shows that the child sentences provide additional information about their parent, and the generated summary abstracts the entire review.","The paper presents a model for end-to-end abstractive summarization of product reviews without supervision. The model uses a discourse tree to represent the review, with the summary as the root and child sentences providing detailed explanations. The model recursively estimates parents from their children to learn the discourse tree and generate a concise summary. An architecture is introduced to rank the importance of each sentence on the tree and focus on the main review point. Experimental results show that the model outperforms other unsupervised approaches and achieves competitive performance with supervised models for long reviews. The induced tree demonstrates that child sentences provide additional information about their parent, and the generated summary abstracts the entire review.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the need for automatic document summarization due to the vast amounts of online textual data that continue to grow.', 'Who is the target audience?': 'The summaries are for both customers and manufacturers of E-commerce websites to obtain large numbers of opinions on product reviews.', 'How will the summaries be used?': 'The summaries will be used to provide a concise overview of product reviews, allowing customers and manufacturers to quickly and easily understand the opinions of others.'}",['method'],['Input Encoding'],['Amazon Product Reviews'],['ROUGE'],[''],https://github.com/misonuma/strsum,https://aclanthology.org/P19-1206,"{'The need for automatic document summarization is increasing due to the vast amounts of online textual data that continue to grow, but supervised neural network models trained on reference summaries cannot be adopted in other domains, as salient phrases are not common across domains, and it requires a significant cost to prepare large volumes of references for each domain.': 'The authors propose an unsupervised approach to abstractive summarization of a single-review without supervision.', 'The difficulties of unsupervised abstractive summarization are two-fold: obtaining the representation of the summaries, and learning a language model to decode them.': 'The authors apply the discourse tree framework to overcome these problems and propose a novel architecture called StrSum, which reconstructs a parent from its children recursively and induces a latent discourse tree without a parser.', 'Extractive summarization and document classification techniques sometimes use a discourse parser to gain a concise representation of documents, but there are limitations to using external discourse parsers.': 'The authors propose a framework to induce a latent discourse tree without a parser by identifying and reconstructing a parent sentence from its children.', 'Extractive approaches often fail to provide an overview of the reviews, while abstractive ones successfully condense an entire review via paraphrasing and generalization.': 'The authors focus on the one-sentence abstractive summarization of a single-review without supervision and propose a novel unsupervised end-to-end model to generate an abstractive summary of a single product review while inducing a latent discourse tree.', ""Chu and Liu's unsupervised approach for multiple reviews cannot be extended to a single review directly because it also condenses including trivial or redundant sentences."": 'The authors propose a novel architecture called StrSum, which reconstructs a parent from its children recursively and induces a latent discourse tree without a parser, to generate a summary from the surrounding sentences of the root while learning a language model through reconstruction in an end-to-end manner.', 'It is difficult to generate a summary that focuses on the main review point.': 'The authors introduce DiscourseRank, which ranks the importance of each sentence in terms of the number of descendants, to support StrSum to generate a summary that focuses on the main review point.'}",unsupervised,['Reviews'],['identifying-important-contents-from-the-document']
SP:faed159cb039d3521635b64d6e489c0e5f25675e,Unsupervised Opinion Summarization as Copycat-Review Generation,ACL,2020,"['Arthur Bražinskas', 'Mirella Lapata', 'Ivan Titov']","Opinion summarization is the task of automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While the majority of previous work has focused on the extractive setting, i.e., selecting fragments from input reviews to produce a summary, we let the model generate novel sentences and hence produce abstractive summaries. Recent progress in summarization has seen the development of supervised models which rely on large quantities of document-summary pairs. Since such training data is expensive to acquire, we instead consider the unsupervised setting, in other words, we do not use any summaries in training. We define a generative model for a review collection which capitalizes on the intuition that when generating a new review given a set of other reviews of a product, we should be able to control the “amount of novelty” going into the new review or, equivalently, vary the extent to which it deviates from the input. At test time, when generating summaries, we force the novelty to be minimal, and produce a text reflecting consensus opinions. We capture this intuition by defining a hierarchical variational autoencoder model. Both individual reviews and the products they correspond to are associated with stochastic latent codes, and the review generator (“decoder”) has direct access to the text of input reviews through the pointergenerator mechanism. Experiments on Amazon and Yelp datasets, show that setting at test time the review’s latent code to its mean, allows the model to produce fluent and coherent summaries reflecting common opinions.","The paper discusses the task of opinion summarization, which involves automatically creating summaries that reflect subjective information expressed in multiple documents, such as product reviews. While previous work has focused on selecting fragments from input reviews to produce a summary, the authors propose a generative model that can produce abstractive summaries by generating novel sentences. They consider the unsupervised setting, where no summaries are used in training, and define a hierarchical variational autoencoder model that can control the ""amount of novelty"" in new reviews. At test time, the model produces summaries that reflect consensus opinions by forcing the novelty to be minimal. Experiments on Amazon and Yelp datasets show that setting the review's latent code to its mean allows the model to produce fluent and coherent summaries.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to extract user opinions expressed in online resources, such as blogs, reviews, social media, or internet forums, for various information access applications, such as creating digests, search, and report generation.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly get an overall feel for a product or business, and for making quick decisions.', 'How will the summaries be used?': 'The summaries will be used for various information access applications, such as creating digests, search, and report generation. They can also be used for making quick decisions and getting an overall feel for a product or business.'}",['method'],"['Input Encoding', 'Controlled Generation']","['Amazon Product Reviews', 'Yelp Reviews']",['ROUGE'],"['Fluency', 'Coherence', 'Non-redundancy', 'Opinion Consensus', 'Overall Quality']",https://github.com/ixlan/Copycat-abstractive-opinion-summarizer,https://aclanthology.org/2020.acl-main.461,"{'Modern deep learning methods rely on large amounts of annotated data that are not readily available in the opinion-summarization domain and expensive to produce.': 'The authors propose to use unsupervised and weakly-supervised methods for opinion summarization, which do not require annotated data.', 'Previous unsupervised and weakly-supervised methods for opinion summarization have primarily focused on extractive summarization, i.e., producing summaries by copying parts of the input reviews.': 'The authors propose to consider abstractive summarization, which involves generating new phrases, possibly rephrasing or using words that were not in the original text.', 'Online reviews are inherently multi-domain and summarization systems are highly domain-sensitive.': 'The authors propose to generate summaries that represent consensus opinions, which can be useful for quick decision making and to get an overall feel for a product or business.', 'It is challenging to control the “amount of novelty” going into the new review or vary the extent to which it deviates from the input.': 'The authors propose to define a hierarchical variational autoencoder (VAE) model that can control the “amount of novelty” going into the new review.', 'Copycat reviews differ in writing style from a typical review and do not contain irrelevant details that are common in customer reviews.': 'The authors propose to encourage the summaries to include specific details by giving the review generator (‘decoder’) direct access to the text of input reviews through the pointer-generator mechanism.', 'Using discrete latent sequences makes optimization challenging for generating consensus summaries.': 'The authors propose to use continuous latent representations instead of discrete latent sequences for generating consensus summaries.'}",unsupervised,['Reviews'],['lack-of-suitable-training-data']
SP:69fb382a6fb28122de5709b8e83331ddb5150942,TED: A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising,EMNLP,2020,"['Ziyi Yang', 'Chenguang Zhu', 'Robert Gmyr', 'Michael Zeng', 'Xuedong Huang', 'Eric Darve']","Text summarization aims to extract essential information from a piece of text and transform the text into a concise version. Existing unsupervised abstractive summarization models leverage recurrent neural networks framework while the recently proposed transformer exhibits much more capability. Moreover, most of previous summarization models ignore abundant unlabeled corpora resources available for pretraining. In order to address these issues, we propose TED, a transformerbased unsupervised abstractive summarization system with pretraining on large-scale data. We first leverage the lead bias in news articles to pretrain the model on millions of unlabeled corpora. Next, we finetune TED on target domains through theme modeling and a denoising autoencoder to enhance the quality of generated summaries. Notably, TED outperforms all unsupervised abstractive baselines on NYT, CNN/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by TED are highly abstractive, and each component in the objective function of TED is highly effective.",The paper proposes a transformer-based unsupervised abstractive summarization system called TED that pretrains on large-scale data using the lead bias in news articles. The system is then fine-tuned on target domains through theme modeling and a denoising autoencoder to enhance the quality of generated summaries. TED outperforms all unsupervised abstractive baselines on various datasets and the summaries generated by TED are highly abstractive. Each component in the objective function of TED is highly effective.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to condense them into shorter versions without losing key information.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they can potentially be used for various applications such as news article summarization, document summarization, and more.'}",['method'],"['External Knowledge', 'Auxiliary Tasks']","['CNN/DailyMail', 'NYT', 'Gigaword']","['ROUGE', 'New Words']",[''],,https://aclanthology.org/2020.findings-emnlp.168.pdf,"{'Lack of high-quality paired data for supervised summarization approaches.': 'Propose unsupervised summarization approaches that do not require reference summaries for the target domain.', 'Most unsupervised summarization models are only tested on datasets with considerably small article/summary length.': 'Develop a transformer-based encoder-decoder structure for unsupervised abstractive summarization that leverages pretraining language models and SentencePiece tokenization to generate summaries for longer articles.', 'Difficulty in making generated summaries semantically close to the article.': 'Finetune the unsupervised summarization model with a theme modeling loss and a denoising autoencoder to extract salient information from corrupted text and make the generated summary semantically close to the article.', 'Inability of unsupervised abstractive models to generate novel words and phrases in summaries.': 'Pretrain the unsupervised summarization model on a large-scale corpus with 21.4M news articles using the lead bias in news articles to predict the leading sentences as the target summary during pretraining. This allows the model to generate novel words and phrases in summaries and be highly abstractive even compared with supervised systems.'}",unsupervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:0ca4551c4c9d1e2d090e87c6d7129a8f8ef253b8,Q-learning with Language Model for Edit-based Unsupervised Summarization,EMNLP,2020,"['Ryosuke Kohita', 'Akifumi Wachi', 'Yang Zhao', 'Ryuki Tachibana']","Unsupervised methods are promising for abstractive textsummarization in that the parallel corpora is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on Q-learning with an edit-based summarization. The method combines two key modules to form an Editorial Agent and Language Model converter (EALM). The agent predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Qlearning is leveraged to train the agent to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoderdecoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as Q-learning enables us not only to develop a competitive method but also to make the latest techniques in reinforcement learning available for unsupervised summarization. We also conduct qualitative analysis, providing insights into future study on unsupervised summarizers.1","The paper proposes a new approach for unsupervised text summarization using Q-learning with an edit-based summarization. The method combines two modules to form an Editorial Agent and Language Model converter (EALM), where the agent predicts edit actions and the LM converter generates a summary based on the action signals. Q-learning is used to train the agent to produce proper edit actions. Experimental results show that EALM performs competitively compared to previous methods, even with no validation set. The approach also allows for the use of reinforcement learning techniques in unsupervised summarization. Qualitative analysis is conducted to provide insights for future research in unsupervised summarizers.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to help humans grasp the content of the documents effortlessly.', 'Who is the target audience?': 'The summaries are for humans.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Objective Function'],['Gigaword'],['ROUGE'],[''],https://github.com/kohilin/ealm,https://aclanthology.org/2020.emnlp-main.34/,"{'Unsupervised text summarization is currently behind state-of-the-art supervised models.': 'The authors propose an unsupervised approach based on Q-learning and edit-based summarization to achieve competitive performance with supervised models.', 'Unsupervised methods for text summarization require costly parallel corpora.': 'The authors propose an unsupervised approach that does not require paired data, leveraging Q-learning and a language model.', 'RL techniques for unsupervised text summarization require a value function that represents the goodness of an action on a given state.': 'The authors utilize the compression-reconstruction (CR) learning paradigm to define the value function and make the latest value-based approaches available for unsupervised text summarization.', 'A vast action space causing sparsity in reward is generally difficult to be learned in RL.': 'The authors mitigate this issue by using fewer edit actions and the deterministic decoding of a language model in their edit-based summarization approach.', 'Current unsupervised models for text summarization are missing certain aspects.': 'The authors provide qualitative analysis to identify what current unsupervised models are missing and propose their unsupervised edit-based summarization approach as a potential solution.'}",reinforced,['News'],['lack-of-suitable-training-data']
SP:b531e19376b7c0c08f9c8c0ea2df216c2a2573b0,Unsupervised document summarization using pre-trained sentence embeddings and graph centrality,NAACL,2021,"['Juan Ramirez-Orta', 'Evangelos Milios']","This paper describes our submission for the LongSumm task in SDP 2021. We propose a method for incorporating sentence embeddings produced by deep language models into extractive summarization techniques based on graph centrality in an unsupervised manner. The proposed method is simple, fast, can summarize any document of any size and can satisfy any length constraints for the summaries produced. The method offers competitive performance to more sophisticated supervised methods and can serve as a proxy for abstractive summarization techniques.",System: The paper proposes a simple and fast method for summarizing any document of any size using sentence embeddings produced by deep language models. This method is based on graph centrality and can satisfy any length constraints for the summaries produced. The proposed method offers competitive performance to more sophisticated supervised methods and can serve as a proxy for abstractive summarization techniques.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce a shorter text with maximum information content, fluency, and coherence.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used as a proxy for more advanced summarization methods, can easily scale to arbitrarily large amounts of text, are fast and easy to implement, and can fit any length requirements for the production of summaries.'}",['method'],"['Input Encoding', 'External Knowledge']",['TalkSumm'],['ROUGE'],[''],,https://aclanthology.org/2021.sdp-1.14,"{'The task of automatic text summarization is important but challenging due to the ever-increasing size of collections of text.': 'The authors propose an unsupervised approach that leverages sentence embeddings produced by pre-trained language models to create extractive summaries using graphs.', 'Extractive summarization involves selecting passages from the original document, while abstractive summarization involves generating new text not present in the original document.': 'The authors focus on extractive summarization using graphs, which involves creating a graph where the nodes represent text units and the links represent some measure of semantic similarity.', 'The sentence embeddings produced by SBERT are not well suited for clustering algorithms like Hierarchical Clustering or DBSCAN.': 'The authors propose to use graph centrality methods along with SBERT embeddings to create extractive summaries.', 'The current state of the art in automatic summarization with graphs is mainly based on algorithms like PageRank or Graph Neural Networks.': 'The authors propose a new approach that is fast, easy to implement, and can fit any length requirements for the production of summaries.', 'The previous Scholarly Document Processing workshop held in 2020 only had two systems based on graphs.': 'The authors contribute to the field by proposing a new approach to extractive summarization using graphs and SBERT embeddings.'}",unsupervised,['Scholarly Documents'],[]
SP:83fe62fe0f07bc61862c4c2bb98dc1bc2f8fbeab,GenCompareSum: a hybrid unsupervised summarization method using salience,ACL,2022,"['Jennifer A Bishop', 'Qianqian Xie', 'Sophia Ananiadou']","Text summarization (TS) is an important NLP task. Pre-trained Language Models (PLMs) have been used to improve the performance of TS. However, PLMs are limited by their need of labelled training data and by their attention mechanism, which often makes them unsuitable for use on long documents. To this end, we propose a hybrid, unsupervised, abstractive-extractive approach, in which we walk through a document, generating salient textual fragments representing its key points. We then select the most important sentences of the document by choosing the most similar sentences to the generated texts, calculated using BERTScore. We evaluate the efficacy of generating and using salient textual fragments to guide extractive summarization on documents from the biomedical and general scientific domains. We compare the performance between long and short documents using different generative text models, which are finetuned to generate relevant queries or document titles. We show that our hybrid approach out-performs existing unsupervised methods, as well as state-of-the-art supervised methods, despite not needing a vast amount of labelled training data.","The paper proposes a hybrid, unsupervised, abstractive-extractive approach for text summarization (TS) that generates salient textual fragments representing key points in a document and selects the most important sentences using BERTScore. The approach is evaluated on documents from the biomedical and general scientific domains and compared to existing unsupervised and supervised methods. The authors show that their approach out-performs existing methods despite not needing a vast amount of labelled training data.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the challenges of summarizing long documents, which often require truncation due to the limitations of transformer-based architectures.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, particularly in the biomedical and scientific domains.', 'How will the summaries be used?': ""The summaries can be used to save time and resources by providing a concise overview of a document's content, without the need to read the entire document. They can also be used to identify relevant information for further analysis or to inform decision-making.""}",['method'],['Unit Selection'],"['CORD-19', 'PubMed', 'arXiv', 'S2ORC']",['ROUGE'],[''],https://github.com/jbshp/GenCompareSum,https://aclanthology.org/2022.bionlp-1.22/,"{'Transformer-based architectures have limitations in processing long documents, resulting in truncated analysis for text summarization.': 'The authors adopt a hybrid unsupervised approach, where the PLMs are required only to act on short sections of the document at any time, meaning that their method can be extended to any document length.', 'Supervised methods for long document summarization require large amounts of labelled training data, which are often unavailable or time-consuming and costly to produce.': 'The authors address the challenges of supervised methods by adopting a hybrid unsupervised approach, which does not require manually labelled training data for the extractive summarization task.', 'Earlier unsupervised, graph-based methods have been criticised in their ability to effectively represent documents which present multiple facts.': 'The authors address this by generating multiple salient texts per document, thus enabling it to represent multiple facts per document.', 'Abstractive summarization cannot be trusted to be factually consistent, making it unsuitable in many practical applications.': 'The authors choose to opt for a hybrid approach, using transformer-based models for the generation of salient points, but ultimately generating an extractive summarization to ensure factual consistency.', 'Existing unsupervised methods for text summarization have generally used graph-based methods.': 'The authors differ from these previous approaches by evaluating the effectiveness of a novel approach – generating and using salient textual fragments to guide the extractive summarization.', 'The authors aim to achieve a summary which harnesses the semantic knowledge of transformer-based models, whilst being extendable to any length document, without requiring a large corpus of training data.': 'The authors fuse state-of-the-art PLMs with unsupervised approaches to achieve their goal.', 'The authors aim to outperform both existing unsupervised methods and state-of-the-art supervised methods, both on long and short documents.': 'The authors evaluate their approach on short and long versions of data sets from the biomedical and scientific domains and demonstrate that their hybrid method outperforms both existing unsupervised methods and state-of-the-art supervised methods.'}",unsupervised,['Scholarly Documents'],['efficient-encoding-of-long-documents']
SP:f4b1c63af0607c3919645f5d88e0c22f934b7875,Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization,ACL,2022,"['Puyuan Liu', 'Chenyang Huang', 'Lili Mou']","Text summarization aims to generate a short summary for an input text. In this work, we propose a Non-Autoregressive Unsupervised Summarization (NAUS) approach, which does not require parallel data for training. Our NAUS first performs edit-based search towards a heuristically defined score, and generates a summary as pseudo-groundtruth. Then, we train an encoder-only non-autoregressive Transformer based on the search result. We also propose a dynamic programming approach for length-control decoding, which is important for the summarization task. Experiments on two datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization, yet largely improving inference efficiency. Further, our algorithm is able to perform explicit length-transfer summary generation.1","The paper proposes a Non-Autoregressive Unsupervised Summarization (NAUS) approach for generating short summaries without the need for parallel data. The approach involves edit-based search and training an encoder-only non-autoregressive Transformer based on the search result. The paper also introduces a dynamic programming approach for length-control decoding, which is important for the summarization task. Experiments on two datasets show that NAUS achieves state-of-the-art performance for unsupervised summarization and improves inference efficiency. Additionally, the algorithm is able to perform explicit length-transfer summary generation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to perform text summarization, which is an important natural language processing task that aims to generate concise summaries for given texts while preserving the key information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long text, such as journalists, researchers, or students.', 'How will the summaries be used?': 'The summaries can be used for various real-world applications, such as headline generation, and can be generated through supervised or unsupervised methods. The proposed approach by the authors, Non-Autoregressive approach to Unsupervised Summarization (NAUS), aims to improve the efficiency and quality of unsupervised summarization.'}",['method'],"['Controlled Generation', 'Objective Function']","['Gigaword', 'DUC 2004']",['ROUGE'],"['Overall Quality', 'Fluency']",https://github.com/MANGA-UOFA/NAUS,https://aclanthology.org/2022.acl-long.545,"{'State-of-the-art text summarization models are typically trained in a supervised way with large training corpora, comprising pairs of long texts and their summaries. However, such parallel data are expensive to obtain, preventing the applications to less popular domains and less spoken languages.': 'The authors propose an unsupervised approach to text summarization that does not require parallel data for training.', 'One widely used unsupervised approach is to compress a long text into a short one, and to reconstruct it to the long text by a cycle consistency loss. However, such an approach requires reinforcement learning (or its variants), which makes the training difficult.': 'The authors propose a Non-Autoregressive approach to Unsupervised Summarization (NAUS) that utilizes non-autoregressive decoders, which generate all output tokens in parallel. This approach does not require reinforcement learning and is faster than autoregressive generation.', 'Recently, Schumann et al. propose an edit-based approach for unsupervised summarization. However, the search approach is slow in inference because hundreds of search steps are needed for each data sample. Moreover, their approach can only select words from the input sentence with the word order preserved. Thus, it is restricted and may generate noisy summaries due to the local optimality of search algorithms.': 'The authors propose to perform search as in Schumann et al. and to train a machine learning model to smooth out the noise and to speed up the inference process. They also propose a length-control algorithm based on dynamic programming to satisfy the constraint of output lengths, which is typical in summarization applications but cannot be easily achieved with autoregressive models.', 'Autoregressive models are slow and cannot easily achieve length control.': 'The authors propose to utilize non-autoregressive models, which are faster and can achieve length control with dynamic programming.', 'The proposed approach may generate noisy summaries due to the local optimality of search algorithms.': 'The authors propose to train a machine learning model to smooth out the noise and to improve the quality of the generated summaries.'}",unsupervised,['News'],['lack-of-suitable-training-data']
SP:8f23231a730861bb3341e74225bc88a1c54eadc7,Zero-Shot Aspect-Based Scientific Document Summarization using Self-Supervised Pre-training,ACL,2022,"['Amir Soleimani', 'Vassilina Nikoulina', 'Benoit Favre', 'Salah Ait-Mokhtar']","We study the zero-shot setting for the aspectbased scientific document summarization task. Summarizing scientific documents with respect to an aspect can remarkably improve document assistance systems and readers experience. However, existing large-scale datasets contain a limited variety of aspects, causing summarization models to over-fit to a small set of aspects and a specific domain. We establish baseline results in zero-shot performance (over unseen aspects and the presence of domain shift), paraphrasing, leave-one-out, and limited supervised samples experimental setups. We propose a self-supervised pre-training approach to enhance the zero-shot performance. We leverage the PubMed structured abstracts to create a biomedical aspect-based summarization dataset. Experimental results on the PubMed and FacetSum aspect-based datasets show promising performance when the model is pre-trained using unlabelled in-domain data.1","The paper explores the zero-shot setting for aspect-based scientific document summarization, which can improve document assistance systems and reader experience. However, current datasets have limited aspects, causing models to over-fit to specific domains. The authors establish baseline results for zero-shot performance and propose a self-supervised pre-training approach to enhance it. They create a biomedical aspect-based summarization dataset using PubMed structured abstracts and show promising results when pre-trained with unlabelled in-domain data.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific documents to facilitate document assistance systems and to help readers explore articles quickly.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the content of a scientific paper.', 'How will the summaries be used?': 'The summaries will be used to assist readers in quickly understanding the content of a scientific paper and to facilitate document assistance systems.'}",['method'],"['Controlled Generation', 'Objective Function']","['PubMed', 'FacetSum']","['ROUGE', 'BERTScore']",[''],https://github.com/asoleimanib/ZeroShotAspectBased,https://aclanthology.org/2022.bionlp-1.5,"{'Little research has been conducted on aspect-based scientific document summarization.': 'The authors propose to focus on zero-shot aspect-based summarization of scientific literature, leveraging pre-trained models and semantic representations to establish a connection between the aspect and the summary.', 'The data for aspect-based summarization of scientific papers is scarce, and most existing methods rely on pre-defined aspects.': 'The authors propose to use large pre-trained models such as BERT and BART, and to continue the pre-training task with domain-related or target datasets to improve performance on low-resource domains. They also propose an additional pre-training procedure to reinforce the semantic connection between aspect and summary.', 'Readers may be interested in new aspects beyond proposed annotations or new domains, particularly in the biomedical area.': 'The authors propose to establish baselines for aspect-based summarization using two datasets from different domains, biomedical and management, and to analyze the zero-shot capabilities of those models on unseen aspects.', 'Such approaches only cover limited aspects.': 'The authors propose to leverage the semantic representations emerging during LM pre-training to allow the model to establish a semantic connection between the aspect and the summary, and to propose self-supervised pre-training to boost the zero-shot capability of the model.', 'It is unclear how different models behave as the amount of supervision decreases.': 'The authors analyze how different models behave as the amount of supervision decreases.'}",supervised,['Scholarly Documents'],['lack-of-suitable-training-data']
SP:aa862b705c2e29c909b11f18dfa819ba8ab67e5b,An Efficient Coarse-to-Fine Facet-Aware Unsupervised Summarization Framework Based on Semantic Blocks,COLING,2022,"['Xinnian Liang', 'Jing Li', 'Shuangzhi Wu', 'Jiali Zeng', 'Yufan Jiang', 'Mu Li', 'Zhoujun Li']","Unsupervised summarization methods have achieved remarkable results by incorporating representations from pre-trained language models. However, existing methods fail to consider efficiency and effectiveness at the same time when the input document is extremely long. To tackle this problem, in this paper, we proposed an efficient Coarse-to-Fine Facet-Aware Ranking (C2F-FAR) framework for unsupervised long document summarization, which is based on the semantic block. The semantic block refers to continuous sentences in the document that describe the same facet. Specifically, we address this problem by converting the one-step ranking method into the hierarchical multi-granularity two-stage ranking. In the coarse-level stage, we propose a new segment algorithm to split the document into facetaware semantic blocks and then filter insignificant blocks. In the fine-level stage, we select salient sentences in each block and then extract the final summary from selected sentences. We evaluate our framework on four long document summarization datasets: Gov-Report, BillSum, arXiv, and PubMed. Our C2F-FAR can achieve new state-of-the-art unsupervised summarization results on Gov-Report and BillSum. In addition, our method speeds up 4-28 times more than previous methods.1","The paper proposes an efficient Coarse-to-Fine Facet-Aware Ranking (C2F-FAR) framework for unsupervised long document summarization, which is based on the semantic block. The framework addresses the problem of existing methods failing to consider efficiency and effectiveness at the same time when the input document is extremely long. The proposed method converts the one-step ranking method into the hierarchical multi-granularity two-stage ranking, where the coarse-level stage splits the document into facet-aware semantic blocks and filters insignificant blocks, and the fine-level stage selects salient sentences in each block and extracts the final summary from selected sentences. The framework achieves new state-of-the-art unsupervised summarization results on Gov-Report and BillSum and speeds up 4-28 times more than previous methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense a document or a set of documents into several sentences while keeping the primary information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, such as researchers, policymakers, or students.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, to quickly identify the main points and key information, and to make informed decisions based on the summarized content.'}",['method'],['Input Encoding'],"['GovReport', 'BillSum', 'arXiv', 'PubMed']","['ROUGE', 'Word Overlap']","['Facet Coverage', 'Overall Quality']",https://github.com/xnliang98/c2f-far,https://aclanthology.org/2022.coling-1.558,"{'As the input length increases, the document will have more noise and insignificant facets. The relevance computation between the candidate summary and the document may cause the facet-aware ranking to be influenced by insignificant facets.': 'The authors propose a Coarse-to-Fine Facet-Aware Ranking (C2F-FAR) Framework based on semantic blocks, which consists of two stages with different granularities: semantic blocks and sentences. The coarse-level stage aims to filter insignificant facets via a coarse-level centrality estimator to measure the salience of blocks.', 'The running time of FAR will rise rapidly as the number of extracted sentences increases. Due to FAR needs to compute the relevance score number of combinations Ckm times, where k is the number of extracted summary sentences and m is the number of candidate salient sentences.': 'The authors propose a fine-level stage that can reduce the influence of facets with many sentences by only selecting several related sentences for the final ranking. This framework with a hierarchical coarse-to-fine structure can guarantee effective and efficient long document summarization.'}",unsupervised,"['Scholarly Documents', 'Legislative Bills', 'Govt. Reports']","['information-loss-and-incoherence-in-extractive-summarization', 'exploiting-the-structure-of-long-documents']"
SP:c2e031707dc3ec35e14d3bed794729979ca3014f,A Neural Attention Model for Abstractive Sentence Summarization,EMNLP,2015,"['Alexander M. Rush', 'Sumit Chopra']","Summarization based on text extraction is inherently limited, but generation-style abstractive methods have proven challenging to build. In this work, we propose a fully data-driven approach to abstractive sentence summarization. Our method utilizes a local attention-based model that generates each word of the summary conditioned on the input sentence. While the model is structurally simple, it can easily be trained end-to-end and scales to a large amount of training data. The model shows significant performance gains on the DUC-2004 shared task compared with several strong baselines.","System: The paper proposes a new approach to abstractive sentence summarization using a fully data-driven method. The method utilizes a local attention-based model that generates each word of the summary based on the input sentence. The model is simple in structure, but can be trained end-to-end and scaled to a large amount of training data. The model shows significant performance gains on the DUC-2004 shared task compared to other strong baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries to produce a condensed representation of an input text that captures the core meaning of the original.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but the authors test the effectiveness of their approach by comparing it to multiple abstractive and extractive baselines.'}",['method'],['Objective Function'],['Gigaword'],"['ROUGE', 'Perplexity']",[''],,https://aclanthology.org/D15-1044,"{'Summarization is a challenge of natural language understanding, and the aim is to produce a condensed representation of an input text that captures the core meaning of the original.': 'The authors propose a fully data-driven approach for generating abstractive summaries, which combines a neural language model with a contextual input encoder.', 'Most successful summarization systems utilize extractive approaches that crop out and stitch together portions of the text to produce a condensed version.': 'The authors propose an abstractive summarization approach that attempts to produce a bottom-up summary, aspects of which may not appear as part of the original.', 'Studies of human summarizers show that it is common to apply various other operations while condensing, such as paraphrasing, generalization, and reordering.': 'The authors model this abstractive summarization problem using a fully data-driven approach that incorporates less linguistic structure than comparable abstractive summarization approaches.', 'Past work has modeled this abstractive summarization problem either using linguistically-inspired constraints or with syntactic transformations of the input text.': 'The authors propose a fully data-driven approach that combines a neural language model with a contextual input encoder, which is modeled off of the attention-based encoder of Bahdanau et al. (2014) in that it learns a latent soft alignment over the input text to help inform the summary.', 'The authors want to test the effectiveness of their approach and compare it with multiple abstractive and extractive baselines.': 'The authors run extensive comparisons with traditional syntax-based systems, integer linear program-constrained systems, information-retrieval style approaches, as well as statistical phrase-based machine translation. Their approach outperforms a machine translation system trained on the same large-scale dataset and yields a large improvement over the highest scoring system in the DUC-2004 competition.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:cc8e43c61ce99a0e481bc3e2d3d086fa30275226,Abstractive Sentence Summarization with Attentive Recurrent Neural Networks,NAACL,2016,"['Sumit Chopra', 'Michael Auli', 'Alexander M. Rush']",Abstractive Sentence Summarization generates a shorter version of a given sentence while attempting to preserve its meaning. We introduce a conditional recurrent neural network (RNN) which generates a summary of an input sentence. The conditioning is provided by a novel convolutional attention-based encoder which ensures that the decoder focuses on the appropriate input words at each step of generation. Our model relies only on learned features and is easy to train in an end-to-end fashion on large data sets. Our experiments show that the model significantly outperforms the recently proposed state-of-the-art method on the Gigaword corpus while performing competitively on the DUC-2004 shared task.ive Sentence Summarization generates a shorter version of a given sentence while attempting to preserve its meaning. We introduce a conditional recurrent neural network (RNN) which generates a summary of an input sentence. The conditioning is provided by a novel convolutional attention-based encoder which ensures that the decoder focuses on the appropriate input words at each step of generation. Our model relies only on learned features and is easy to train in an end-to-end fashion on large data sets. Our experiments show that the model significantly outperforms the recently proposed state-of-the-art method on the Gigaword corpus while performing competitively on the DUC-2004 shared task.,"The paper discusses a new method for Abstractive Sentence Summarization, which generates a shorter version of a given sentence while preserving its meaning. The method uses a conditional recurrent neural network (RNN) with a novel convolutional attention-based encoder to ensure that the decoder focuses on the appropriate input words. The model relies on learned features and is easy to train on large data sets. The experiments show that the model outperforms the state-of-the-art method on the Gigaword corpus and performs competitively on the DUC-2004 shared task.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to tackle the task of text summarization, which is an important step towards natural language understanding.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be particularly useful for tasks such as information retrieval and document categorization.'}",['method'],"['Input Encoding', 'Objective Function']","['Gigaword', 'DUC 2004']","['ROUGE', 'Pyramid']",[''],https://github.com/facebook/namas,https://aclanthology.org/N16-1012,"{'Generating a condensed version of a passage while preserving its meaning is a challenging task in natural language understanding.': 'The authors propose a novel convolutional attention-based conditional recurrent neural network model for abstractive sentence summarization.', 'Extractive and abstractive models are two broad categories of summarization systems.': 'The authors focus on abstractive models and propose a recurrent neural network as a decoder to generate summaries from scratch without being constrained to reuse phrases from the original text.', 'Rush et al. (2015) proposed a model for abstractive sentence summarization, but it uses a feed-forward neural language model for generation and a less sophisticated encoder.': ""The authors propose an extension of Rush et al.'s model with a more advanced encoder that explicitly encodes the position information of input words and uses a convolutional network to encode them."", ""The state-of-the-art systems for abstractive sentence summarization, including Rush et al.'s model, have limitations in performance."": 'The authors show empirically that their proposed model outperforms the state-of-the-art systems on multiple datasets, including the Gigaword dataset and the DUC-2004 task.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:ba0b3075dd04e8a06b216b2405db0efdca9a5d9c,Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond,CONLL,2016,"['Ramesh Nallapati', 'Bowen Zhou', 'Cicero dos Santos', 'Bing Xiang']",ive Text Summarization using Sequence-to-sequence RNNs and Beyond Ramesh Nallapati IBM Watson nallapati@us.ibm.com Bowen Zhou IBM Watson zhou@us.ibm.com Cicero dos Santos IBM Watson,"

The paper discusses the use of sequence-to-sequence recurrent neural networks (RNNs) for text summarization. It also explores various techniques for improving the performance of these models, such as attention mechanisms and pointer networks. The authors present experimental results on several benchmark datasets, demonstrating the effectiveness of their approach. They also discuss potential future directions for research in this area.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to capture the salient ideas of an article or passage in a compressed paraphrasing of the main contents of the document.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the key concepts of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main ideas of a document, to decide whether to read the full text, or to provide a brief overview of the document to others.'}","['corpus', 'method']","['Input Encoding', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/K16-1028/,"{'Abstractive summarization is a very different problem from machine translation, as the target summary is typically very short and does not depend very much on the length of the source document.': 'The authors propose to apply the off-the-shelf attentional encoder-decoder RNN that was originally developed for machine translation to summarization, and show that it already outperforms state-of-the-art systems on two different English corpora.', 'A key challenge in summarization is to optimally compress the original document in a lossy manner such that the key concepts in the original document are preserved, whereas in machine translation, the translation is expected to be loss-less.': 'The authors propose novel models that address concrete problems in summarization that are not sufficiently addressed by the machine translation based model, and show that they provide additional improvement in performance.', 'In summarization, there is less obvious one-to-one word-level alignment between source and target compared to machine translation.': 'The authors propose a new dataset for the task of abstractive summarization of a document into multiple sentences and establish benchmarks.'}",supervised,['News'],[]
SP:73e231d6b40cac379060f13d4d82a8417332d14b,Diversity driven Attention Model for Query-based Abstractive Summarization,ACL,2017,"['Preksha Nema', 'Mitesh M. Khapra', 'Anirban Laha', 'Balaraman Ravindran']","Abstractive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion. On the other hand, query-based summarization highlights those points that are relevant in the context of a given query. The encodeattend-decode paradigm has achieved notable success in machine translation, extractive summarization, dialog systems, etc. But it suffers from the drawback of generation of repeated phrases. In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) a new diversity based attention model which aims to alleviate the problem of repeating phrases in the summary. In order to enable the testing of this model we introduce a new query-based summarization dataset building on debatepedia. Our experiments show that with these two additions the proposed model clearly outperforms vanilla encode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.ive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion. On the other hand, query-based summarization highlights those points that are relevant in the context of a given query. The encodeattend-decode paradigm has achieved notable success in machine translation, extractive summarization, dialog systems, etc. But it suffers from the drawback of generation of repeated phrases. In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) a new diversity based attention model which aims to alleviate the problem of repeating phrases in the summary. In order to enable the testing of this model we introduce a new query-based summarization dataset building on debatepedia. Our experiments show that with these two additions the proposed model clearly outperforms vanilla encode-attend-decode models with a gain of 28% (absolute) in ROUGE-L scores.",The paper proposes a model for query-based summarization that addresses the problem of repeated phrases in the summary. The model is based on the encode-attend-decode paradigm and includes a query attention model and a diversity-based attention model. The authors introduce a new query-based summarization dataset and show that their model outperforms vanilla encode-attend-decode models with a gain of 28% in ROUGE-L scores.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for query-based abstractive text summarization, where the aim is to generate a summary of a document in the context of a query.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the salient points of a document in the context of a specific query.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a document in the context of a specific query, without having to read the entire document. They can be used in various natural language generation tasks such as machine translation, abstractive summarization, and dialog.'}","['corpus', 'method']",['Objective Function'],['Debatepedia'],['ROUGE'],[''],,https://aclanthology.org/P17-1098,"{'The summaries produced by models based on the encode-attend-decode paradigm contain repeated phrases.': 'The authors propose a model that ensures successive context vectors are orthogonal to each other by subtracting out any component that the current context vector has in the direction of the previous context vector. They also propose an extension of this idea where they pass the sequence of context vectors through a LSTM and ensure that the current state produced by the LSTM is orthogonal to the history.', 'Lack of attention to query-based abstractive text summarization.': 'The authors propose a new dataset for query-based abstractive summarization and evaluate encode-attend-decode models on this dataset.', 'Previous work on query-based summarization has focused on extractive summarization.': 'The authors create a new dataset for abstractive summarization, where each summary is abstractive and not extractive in the sense that the summary does not necessarily comprise of a sentence which is simply copied from the original document.', 'Difficulty in generating summaries that are relevant to the query.': 'The authors propose a query-focused summarization approach that highlights those points that are relevant in the context of the query.'}",supervised,['Arguments'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:e96ab75d230d748703c9d2f380cfe4a820041173,Selective Encoding for Abstractive Sentence Summarization,ACL,2017,"['Qingyu Zhou', 'Nan Yang', 'Furu Wei', 'Ming Zhou']","We propose a selective encoding model to extend the sequence-to-sequence framework for abstractive sentence summarization. It consists of a sentence encoder, a selective gate network, and an attention equipped decoder. The sentence encoder and decoder are built with recurrent neural networks. The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder. The second level representation is tailored for sentence summarization task, which leads to better performance. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. The experimental results show that the proposed selective encoding model outperforms the state-ofthe-art baseline models.","The paper proposes a selective encoding model for abstractive sentence summarization, which includes a sentence encoder, a selective gate network, and an attention equipped decoder. The model uses recurrent neural networks and constructs a second level sentence representation for better performance. The model was evaluated on multiple datasets and outperformed state-of-the-art baseline models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to shorten given sentences and produce brief summaries of them.', 'Who is the target audience?': 'The intended audience for these summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Input Encoding'],"['Gigaword', 'DUC 2004', 'MSR-ATC']","['ROUGE', 'BLEU']",[''],https://github.com/magic282/SEASS,https://aclanthology.org/P17-1101,"{'Extractive methods are not effective for sentence summarization.': 'Rule-based methods, syntactic tree pruning methods, statistical machine translation techniques, and neural network models have been proposed for abstractive sentence summarization.', 'Existing neural network models for sentence summarization fall into the encoding-decoding paradigm, which does not explicitly model the selection process.': 'The authors propose a three-phase approach for sentence summarization: encoding, selection, and decoding. They introduce a selective gate network to control the information flow from encoder to decoder and improve encoding effectiveness.', 'Abstractive sentence summarization requires selecting the highlights while filtering out secondary information in the input.': 'The proposed SEASS model explicitly models the selection process and uses a selective gate network to select the important information from the encoded sentence. The attention-equipped decoder then generates the summary using the selected information.', 'The performance of existing methods for sentence summarization is not satisfactory.': 'The SEASS model achieves better performance compared to state-of-the-art methods on English Gigaword, DUC 2004, and Microsoft Research Abstractive Text Compression test sets.'}",supervised,"['News', 'Web Documents']",[]
SP:f164356a881ee784106869fefe0a8f563776ebdd,Deep Recurrent Generative Decoder for Abstractive Text Summarization,EMNLP,2017,"['Piji Li', 'Wai Lam', 'Lidong Bing', 'Zihao Wang']",We propose a new framework for abstractive text summarization based on a sequence-to-sequence oriented encoderdecoder model equipped with a deep recurrent generative decoder (DRGN). Latent structure information implied in the target summaries is learned based on a recurrent latent random model for improving the summarization quality. Neural variational inference is employed to address the intractable posterior inference for the recurrent latent variables. Abstractive summaries are generated based on both the generative latent variables and the discriminative deterministic states. Extensive experiments on some benchmark datasets in different languages show that DRGN achieves improvements over the state-ofthe-art methods.,The paper proposes a new framework for abstractive text summarization using a sequence-to-sequence oriented encoder-decoder model with a deep recurrent generative decoder. The model learns latent structure information from target summaries using a recurrent latent random model and neural variational inference. Abstractive summaries are generated using both generative latent variables and discriminative deterministic states. The model outperforms state-of-the-art methods on benchmark datasets in different languages.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically generate a summary that retains the most important content of the original text document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to improve the focus of a summary, reduce redundancy, and keep a good compression rate. They can also be used to improve the quality of generated summaries by incorporating latent structure information.'}",['method'],['Objective Function'],"['Gigaword', 'DUC 2004']",['ROUGE'],[''],,https://aclanthology.org/D17-1222,"{'Existing abstractive summarization models do not consider the latent structure information of summaries, which can improve the quality of generated summaries.': 'The authors propose a new framework based on a sequence-to-sequence oriented encoder-decoder model equipped with a deep recurrent generative decoder (DRGD) to model and learn the latent structure information implied in the target summaries of the training data. They employ Variational Auto-Encoders (VAEs) as the base model for their generative framework, which can handle the inference problem associated with complex generative modeling. They integrate the standard discriminative deterministic decoder and the recurrent generative decoder into a unified decoding framework, where the target summaries are decoded based on both the generative latent structural information and the discriminative deterministic variables.', 'Existing seq2seq models for abstractive summarization have limited representation ability for latent structure information due to their entirely deterministic transformations.': 'The authors propose a deep recurrent generative decoder (DRGD) for latent structure modeling, which adds historical dependencies on the latent variables of VAEs. This allows for better representation ability for latent structure information.', 'The standard framework of VAEs is not designed for sequence modeling related tasks.': 'The authors are inspired by Chung et al. (2015) and propose a VAE-based framework that can handle sequence modeling related tasks. They employ neural variational inference to address the intractable posterior inference for the recurrent latent variables.', 'Existing generative models for abstractive summarization do not consider recurrent dependencies, leading to limited representation ability.': 'The authors propose a deep recurrent generative decoder (DRGD) for latent structure modeling that considers recurrent dependencies, leading to better representation ability.', 'The proposed framework has not been evaluated on benchmark datasets in different languages.': 'The authors evaluate their framework on benchmark datasets in different languages and show that it achieves better performance than state-of-the-art models.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:a49afe35be38647f4b7953fe1b96f6e5e142f489,A Pilot Study of Domain Adaptation Effect for Neural Abstractive Summarization,EMNLP,2017,"['Xinyu Hua', 'Lu Wang']","We study the problem of domain adaptation for neural abstractive summarization. We make initial efforts in investigating what information can be transferred to a new domain. Experimental results on news stories and opinion articles indicate that neural summarization model benefits from pre-training based on extractive summaries. We also find that the combination of in-domain and out-of-domain setup yields better summaries when in-domain data is insufficient. Further analysis shows that, the model is capable to select salient content even trained on out-of-domain data, but requires in-domain data to capture the style for a target domain.","System: The paper explores domain adaptation for neural abstractive summarization and investigates what information can be transferred to a new domain. The study finds that pre-training based on extractive summaries benefits the neural summarization model and that a combination of in-domain and out-of-domain setup yields better summaries when in-domain data is insufficient. The model is capable of selecting salient content even when trained on out-of-domain data, but requires in-domain data to capture the style for a target domain.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce more concise and abstractive summaries that emulate the human summarization process.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of the documents without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding the content of the documents, especially in domains where training data is scarce and expensive to acquire.'}",['analysis'],['External Knowledge'],['NYT'],['Accuracy'],[''],,https://aclanthology.org/W17-4513,"{'Training summarization systems requires large amounts of labeled data, which is a big hurdle for new domains where training data is scarce and expensive to acquire.': 'Investigate the feasibility of leveraging available out-of-domain abstracts or extractive summaries to help train a neural summarization system for a new domain.', 'Understanding what information is transferable and what are the limitations when adapting a neural summarization model to a new domain.': 'Investigate neural summarization on two types of documents with major differences: news stories and opinion articles from The New York Times Annotated Corpus. Treat news stories as the source domain and opinion articles as the target domain, and make initial tries for understanding the feasibility of domain adaptation.', 'The model trained on out-of-domain data may not match the generation style in the target domain.': 'Interpret the learned model to understand what information is transferred to a new domain. The model trained on out-of-domain data can learn to detect summary-worthy content, but may not match the generation style in the target domain.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:1a6833f9b81ec10dd3308fde68bdb972a3d39ed7,Abstractive Document Summarization with a Graph-Based Attentional Neural Model,ACL,2017,"['Jiwei Tan', 'Xiaojun Wan', 'Jianguo Xiao']","Abstractive summarization is the ultimate goal of document summarization research, but previously it is less investigated due to the immaturity of text generation techniques. Recently impressive progress has been made to abstractive sentence summarization using neural models. Unfortunately, attempts on abstractive document summarization are still in a primitive stage, and the evaluation results are worse than extractive methods on benchmark datasets. In this paper, we review the difficulties of neural abstractive document summarization, and propose a novel graph-based attention mechanism in the sequence-to-sequence framework. The intuition is to address the saliency factor of summarization, which has been overlooked by prior works. Experimental results demonstrate our model is able to achieve considerable improvement over previous neural abstractive models. The data-driven neural abstractive method is also competitive with state-of-the-art extractive methods.ive summarization is the ultimate goal of document summarization research, but previously it is less investigated due to the immaturity of text generation techniques. Recently impressive progress has been made to abstractive sentence summarization using neural models. Unfortunately, attempts on abstractive document summarization are still in a primitive stage, and the evaluation results are worse than extractive methods on benchmark datasets. In this paper, we review the difficulties of neural abstractive document summarization, and propose a novel graph-based attention mechanism in the sequence-to-sequence framework. The intuition is to address the saliency factor of summarization, which has been overlooked by prior works. Experimental results demonstrate our model is able to achieve considerable improvement over previous neural abstractive models. The data-driven neural abstractive method is also competitive with state-of-the-art extractive methods.",The paper discusses the challenges of abstractive document summarization and proposes a novel graph-based attention mechanism in the sequence-to-sequence framework to address the saliency factor of summarization. The experimental results show that the proposed model achieves considerable improvement over previous neural abstractive models and is competitive with state-of-the-art extractive methods.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to alleviate the information overload people are facing today.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important information in a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and to quickly get an overview of the main points.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Conciseness', 'Coherence', 'Fluency']",,https://aclanthology.org/P17-1108,"{'Extractive methods for document summarization face the drawbacks of information redundancy and incoherence between sentences, which is far from the way humans write summaries.': 'The authors propose abstractive methods for document summarization, which are able to generate better summaries with the use of arbitrary words and expressions.', 'Abstractive summarization involves sophisticated techniques including meaning representation, content organization, and surface realization, which have large space to be improved.': 'The authors propose a novel graph-based attention mechanism in the encoder-decoder framework to discover the salient information of a document.', 'Recent abstractive document summarization models are yet not able to achieve convincing performance, with a considerable gap from extractive methods.': 'The authors propose a new hierarchical decoding algorithm with a reference mechanism to generate the abstractive summaries, which is able to tackle the constraints of saliency, nonredundancy, information correctness, and fluency under a unified framework.', 'Saliency has not been addressed by existing neural abstractive models, despite its importance for summary generation.': 'The authors study how neural summarization models can discover the salient information of a document and propose a method to address this issue.', 'The other factors of document summarization, such as coherence and novelty, are less considered in previous neural abstractive models.': 'The authors propose a distraction mechanism to avoid redundancy and consider the factor of novelty in their proposed method.', 'Encoding and decoding for a long sequence of multiple sentences currently lack satisfactory solutions.': 'The authors investigate the challenges of accepting and generating long sequences for sequence-to-sequence (seq2seq) models and propose a new hierarchical decoding algorithm to address this issue.', 'The proposed abstractive summarization method needs to be evaluated and compared with existing methods.': 'The authors conduct experiments on two large-scale corpora with human-generated summaries and demonstrate that their approach consistently outperforms previous neural abstractive summarization models and is also competitive with state-of-the-art extractive methods.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:9c9c4dd3506e5920e48bbff2aee50bda0b914066,Faithful to the Original: Fact-Aware Neural Abstractive Summarization,AAAI,2018,"['Ziqiang Cao', 'Furu Wei', 'Wenjie Li', 'Sujian Li']","Unlike extractive summarization, abstractive summarization has to fuse different parts of the source text, which inclines to create fake facts. Our preliminary study reveals nearly 30% of the outputs from a state-of-the-art neural summarization system suffer from this problem. While previous abstractive summarization approaches usually focus on the improvement of informativeness, we argue that faithfulness is also a vital prerequisite for a practical abstractive summarization system. To avoid generating fake facts in a summary, we leverage open information extraction and dependency parse technologies to extract actual fact descriptions from the source text. The dual-attention sequence-to-sequence framework is then proposed to force the generation conditioned on both the source text and the extracted fact descriptions. Experiments on the Gigaword benchmark dataset demonstrate that our model can greatly reduce fake summaries by 80%. Notably, the fact descriptions also bring significant improvement on informativeness since they often condense the meaning of the source text.","The paper discusses the problem of fake facts in abstractive summarization, where different parts of the source text are fused together. The authors propose a solution that leverages open information extraction and dependency parse technologies to extract actual fact descriptions from the source text, and a dual-attention sequence-to-sequence framework to generate summaries conditioned on both the source text and the extracted fact descriptions. Experiments show that their model can reduce fake summaries by 80%, while also improving informativeness.","{'What is the purpose of the summaries?': 'The exponentially growing online information has necessitated the development of effective automatic summarization systems.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading through large amounts of text, and to quickly identify the main points and key information of a document.'}",['method'],"['External Knowledge', 'Objective Function']",['Gigaword'],"['ROUGE', 'Cosine Similarity']",['Faithfulness'],https://github.com/facebook/NAMAS,https://web.archive.org/web/*/https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16121,"{'Abstractive sentence summarization often generates fake facts that do not match the original relations expressed in the source sentence.': 'The authors propose encoding existing facts into the summarization system to avoid fake generation. They extract facts from the source sentence using Open Information Extraction (OpenIE) and a dependency parser, and represent them as fact descriptions. Fact descriptions are incorporated as an additional input source text in their model, which uses two Recurrent Neural Network (RNN) encoders to read the sentence and fact descriptions in parallel. With respective attention mechanisms, the model computes the sentence and fact context vectors, merges them according to their relative reliabilities, and generates the summary word-by-word. The authors call their summarization system FTSum.', 'Relation triples are not always extractable from the source sentence, e.g., from imperative sentences.': 'The authors supplement relation triples with (subject; predicate) and (predicate; object) tuples identified from the parse tree of the sentence. They represent a fact through merging words in a triple or tuples to form a short sentence, defined as a fact description. Fact descriptions provide the right guidance for summarization and are 40% more likely to be included in the actual summaries than the entire words in the source sentences.', 'Previous researches on sentence summarization are usually devoted to increasing summary informativeness, but not summary faithfulness.': 'The authors propose a dual-attention s2s model to push the generation to follow the original facts and enhance summary faithfulness. They conduct extensive experiments on the Gigaword sentence summarization benchmark dataset and show that their model greatly reduces the fake summaries by 80% compared to the state-of-the-art s2s framework. The use of fact descriptions also brings significant improvement in terms of automatic informativeness evaluation.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:8f12e6e1f7f66fbb5c841ff953636a89fac0e3db,Generative Adversarial Network for Abstractive Text Summarization,AAAI,2018,"['Linqing Liu', 'Yao Lu', 'Min Yang', 'Qiang Qu', 'Jia Zhu', 'Hongyan Li']","In this paper, we propose an adversarial process for abstractive text summarization, in which we simultaneously train a generative model G and a discriminative model D. In particular, we build the generator G as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization. We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary. Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset. Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries.","The paper proposes an adversarial process for abstractive text summarization, where a generative model and a discriminative model are simultaneously trained. The generator is built as an agent of reinforcement learning, while the discriminator attempts to distinguish the generated summary from the ground truth summary. The model achieves competitive ROUGE scores with state-of-the-art methods on the CNN/Daily Mail dataset and is able to generate more abstractive, readable, and diverse summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries to capture the salient ideas of the source text in a short and concise manner.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the generated summaries will be used.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],[''],,https://ojs.aaai.org/index.php/AAAI/article/view/12141,"{'Neural sequence-to-sequence models tend to generate trivial and generic summary, often involving high-frequency phrases.': 'The authors propose an adversarial framework to jointly train a generative model G and a discriminative model D. The generator G takes the original text as input and generates the summary. The discriminator D tries to distinguish the ground truth summaries from the generated summaries by the generator G. This adversarial process can eventually adjust G to generate plausible and high-quality abstractive summaries.', 'The generated summaries have limited grammaticality and readability.': 'The authors propose using reinforcement learning (i.e., policy gradient) to optimize G for a highly rewarded summary. This effectively bypasses exposure bias and non-differentiable task metrics issues.', 'In most previous work, the standard sequence-to-sequence models are trained to predict the next word in summary using the maximum likelihood estimation (MLE) objective function. However, this strategy has two major shortcomings. First, the evaluation metric is different from the training loss. Second, the input of the decoder in each time step is often from the true summary during the training. Nevertheless, in the testing phase, the input of the next time step is the previous word generated by the decoder. This exposure bias leads to error accumulation at test time.': 'The authors propose using an adversarial framework to train the generative model G and the discriminative model D. The generator G and the discriminator D are optimized with a minimax two-player game. The training procedure of generator G is to maximize the probability of D making a mistake. This approach effectively bypasses the exposure bias issue.'}",reinforced,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:58d85716fad40cbb4a2eb050c70d7962d6fe2027,Controlling Length in Abstractive Summarization Using a Convolutional Neural Network,EMNLP,2018,"['Yizhu Liu', 'Zhiyi Luo', 'Kenny Q. Zhu']","Convolutional neural networks (CNNs) have met great success in abstractive summarization, but they cannot effectively generate summaries of desired lengths. Because generated summaries are used in difference scenarios which may have space or length constraints, the ability to control the summary length in abstractive summarization is an important problem. In this paper, we propose an approach to constrain the summary length by extending a convolutional sequence to sequence model. The results show that this approach generates high-quality summaries with user defined length, and outperforms the baselines consistently in terms of ROUGE score, length variations and semantic similarity.","The paper discusses the limitations of convolutional neural networks (CNNs) in generating summaries of desired lengths for different scenarios with space or length constraints. To address this problem, the authors propose an approach to constrain the summary length by extending a convolutional sequence to sequence model. The results show that this approach generates high-quality summaries with user-defined length and outperforms baselines in terms of ROUGE score, length variations, and semantic similarity.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for abstractive summarization.', 'Who is the target audience?': 'The summaries are for display on mobile devices or within a fixed area of advertisement slot on a website.', 'How will the summaries be used?': 'The summaries will be used to provide a shorter version of the document for readers who do not have the time or inclination to read the entire document.'}",['method'],['Controlled Generation'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/D18-1444,"{'Existing abstractive summarization models are not trained to react to summary length constraints, leading to incomplete or incoherent summaries.': 'The authors propose a method to control the length of summarization by adding a length constraint to each convolutional block of the initial layer of the model, allowing for the generation of summaries with arbitrary desired length.', 'Previous research on controlling length of abstractive summary has been scarce.': 'The authors extend the convolutional sequence to sequence model by controlling the length of summarization, proposing a new approach to generate summaries with arbitrary desired length.', 'Fan et al. (2017) proposed a method to control length by converting length range into special markers, but this approach can only generate summaries in predefined ranges of length.': 'The authors propose a new method that can generate summaries of any desired number of tokens, outperforming previous methods by all evaluation metrics, including ROUGE scores, length variation, and semantic similarity.', 'Truncation is a crude way of controlling summary length, leaving incomplete or incoherent summaries.': ""The authors' method adds a length constraint to each convolutional block of the initial layer of the model, allowing for more natural and complete summaries, especially when the desired length is short.""}",supervised,['News'],[]
SP:b9eedff87a3cccc6c902f1d0e3007f7d1347173b,Improving Neural Abstractive Document Summarization with Structural Regularization,EMNLP,2018,"['Wei Li', 'Xinyan Xiao', 'Yajuan Lyu', 'Yuanzhuo Wang']","Recent neural sequence-to-sequence models have shown significant progress on short text summarization. However, for document summarization, they fail to capture the longterm structure of both documents and multisentence summaries, resulting in information loss and repetitions. In this paper, we propose to leverage the structural information of both documents and multi-sentence summaries to improve the document summarization performance. Specifically, we import both structural-compression and structuralcoverage regularization into the summarization process in order to capture the information compression and information coverage properties, which are the two most important structural properties of document summarization. Experimental results demonstrate that the structural regularization improves the document summarization performance significantly, which enables our model to generate more informative and concise summaries, and thus significantly outperforms state-of-the-art neural abstractive methods.",The paper discusses the limitations of current neural sequence-to-sequence models in document summarization and proposes a solution that leverages the structural information of both documents and multi-sentence summaries to improve performance. The proposed method involves incorporating structural-compression and structural-coverage regularization to capture the information compression and coverage properties of document summarization. Experimental results show that the proposed method significantly improves the performance of document summarization and outperforms current state-of-the-art neural abstractive methods.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a fluent and condensed summary while retaining the gist information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and can be particularly useful for tasks such as document classification and information retrieval.'}",['method'],['Objective Function'],['CNN/DailyMail'],"['ROUGE', 'METEOR']","['Informativeness', 'Conciseness', 'Coherence', 'Fluency']",,https://aclanthology.org/D18-1441,"{'Seq2seq models are not able to achieve convincing performance in encoding and decoding for a long sequence of multiple sentences.': 'The authors propose to import both structural-compression and structural-coverage regularizations into the document summarization process based on a hierarchical encoder-decoder with hybrid sentence-word attention model.', 'The summary generated by the seq2seq models usually loses salient information of the original document or even contains repetitions.': 'The authors propose to explicitly model the structural-compression and structural-coverage properties of document summarization process, so as to generate more informative and concise summaries.', 'The basic hierarchical encoder-decoder model is not yet able to capture the structural properties of both document and summary.': 'The authors propose to use a hierarchical encoder-decoder with hybrid sentence-word attention model to capture the hierarchical structure of document and summary.', 'Few work makes use of the hierarchical structure of document and multi-sentence summary in document summarization.': 'The authors propose to realize information compression and information coverage at the sentence-level based on the hierarchical structure of document and summary.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:1e09d782e3535f2b6ee306aff2b245d0190c12ab,Controllable Abstractive Summarization,ACL,2018,"['Angela Fan', 'David Grangier', 'Michael Auli']","Current models for document summarization disregard user preferences such as the desired length, style, the entities that the user might be interested in, or how much of the document the user has already read. We present a neural summarization model with a simple but effective mechanism to enable users to specify these high level attributes in order to control the shape of the final summaries to better suit their needs. With user input, our system can produce high quality summaries that follow user preferences. Without user input, we set the control variables automatically – on the full text CNN-Dailymail dataset, we outperform state of the art abstractive systems (both in terms of F1-ROUGE1 40.38 vs. 39.53 F1-ROUGE and human evaluation).","The paper discusses how current document summarization models do not take into account user preferences such as desired length, style, entities of interest, and how much of the document has been read. The authors propose a neural summarization model that allows users to specify these preferences, resulting in high quality summaries tailored to their needs. The system can also automatically set control variables and outperforms state of the art abstractive systems on the CNN-Dailymail dataset.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to condense them into a short paragraph or a single sentence while retaining core information.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used to provide personalized generation and fully leverage that automatic summaries are generated at the reader’s request. They can be used to guide the learning process and improve generation even when they are set automatically during inference.'}",['method'],['Controlled Generation'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/W18-2706,"{'Lack of control over important aspects of generated summary.': 'Introduce mechanisms that enable the reader to control the length, focus on entities, style, and portion of the article to be summarized.', 'Inability to generate personalized summaries.': ""Introduce a controllable summarization model that enables personalized generation and fully leverages automatic summaries generated at the reader's request."", 'Difficulty in improving generation even when control variables are set automatically during inference.': 'Show that control variables guide the learning process and improve generation even when set automatically during inference.', 'Inability to outperform state-of-the-art models on standard CNN/DailyMail benchmark.': 'Demonstrate that the proposed approach outperforms previous pointer-based models trained with maximum likelihood on both entity-anonymized and full text versions of the dataset.', 'Lack of evidence that the proposed model generates summaries preferred by human readers.': 'Conduct a blind human evaluation study to demonstrate that the proposed model generates summaries preferred by human readers.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:606ba3737b74c59c6d0449a92c576360a0290954,Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting,ACL,2018,"['Yen-Chun Chen', 'Mohit Bansal']","Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the nondifferentiable computation between these two neural networks in a hierarchical way, while maintaining language fluency. Empirically, we achieve the new state-of-theart on all metrics (including human evaluation) on the CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our model on the test-only DUC2002 dataset, where we achieve higher scores than a state-of-the-art model.","The paper proposes a summarization model that selects important sentences and rewrites them to create a concise summary. They use a new sentence-level policy gradient method to bridge the gap between two neural networks and achieve higher scores on all metrics, including human evaluation, on the CNN/Daily Mail dataset. The model also enables faster inference and training convergence than previous models. The model is also demonstrated to perform well on the DUC2002 dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the quality, speed, and stability of the summarization process.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and improve efficiency in tasks such as research, decision-making, and information gathering.'}",['method'],"['Input Encoding', 'Unit Selection', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],"['Relevance', 'Readability']",https://github.com/ChenRocks/fast_abs_rl,https://aclanthology.org/P18-1063,"{'Abstractive models suffer from slow and inaccurate encoding of very long documents, with the attention model being required to look at all encoded words (in long paragraphs) for decoding each generated summary word (slow, one by one sequentially).': 'The authors propose a hybrid extractive-abstractive architecture, with policy-based reinforcement learning (RL) to bridge together the two networks. The model first uses an extractor agent to select salient sentences or highlights, and then employs an abstractor network to rewrite (i.e., compress and paraphrase) each of these extracted sentences. This avoids the need for the attention model to look at all encoded words in long paragraphs.', 'Abstractive models suffer from redundancy (repetitions), especially when generating multi-sentence summary.': 'The proposed model adopts intermediate extractive behavior to improve the overall model’s quality, speed, and stability. Instead of encoding and attending to every word in the long input document sequentially, the model adopts a human-inspired coarse-to-fine approach that first extracts all the salient sentences and then decodes (rewrites) them (in parallel). This also avoids almost all redundancy issues because the model has already chosen non-redundant salient sentences to abstractively summarize.', 'The non-differentiable behavior of the extractor makes it difficult to train on available document-summary pairs without saliency label.': 'The authors use actor-critic policy gradient with sentence-level metric rewards to connect the two neural networks and to learn sentence saliency. This takes into account the word-sentence hierarchy, which better models the language structure and makes parallelization possible.', 'Abstractive models suffer from common language fluency issues.': 'The authors prevent the policy gradients from affecting the abstractive summarizer’s word-level training, which is supported by their human evaluation study. This ensures that the model maintains the same level of fluency as a conventional RNN-based model.', 'Abstractive models have slower training and inference times compared to extractive models.': ""The proposed model's training is 4x and inference is more than 20x faster than the previous state-of-the-art. The optional final reranker gives further improvements while maintaining a 7x speedup.""}",reinforced,['News'],['efficient-encoding-of-long-documents']
SP:a151d4a40aff966edda65cbaf93f8b56fbeef852,Global Encoding for Abstractive Summarization,ACL,2018,"['Junyang Lin', 'Xu Sun', 'Shuming Ma', 'Qi Su']","In neural abstractive summarization, the conventional sequence-to-sequence (seq2seq) model often suffers from repetition and semantic irrelevance. To tackle the problem, we propose a global encoding framework, which controls the information flow from the encoder to the decoder based on the global information of the source context. It consists of a convolutional gated unit to perform global encoding to improve the representations of the source-side information. Evaluations on the LCSTS and the English Gigaword both demonstrate that our model outperforms the baseline models, and the analysis shows that our model is capable of generating summary of higher quality and reducing repetition1.","The paper proposes a new global encoding framework to improve the conventional sequence-to-sequence model in neural abstractive summarization, which often suffers from repetition and semantic irrelevance. The framework controls the information flow from the encoder to the decoder based on the global information of the source context, using a convolutional gated unit to perform global encoding and improve the representations of the source-side information. Evaluations on two datasets show that the proposed model outperforms baseline models and is capable of generating higher quality summaries with reduced repetition.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs a condensed version of the source text.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main idea of the source text without having to read the entire document.'}",['method'],['Input Encoding'],['Gigaword'],['ROUGE'],[''],https://www.github.com/lancopku/Global-Encoding,https://aclanthology.org/P18-2027,"{'Attention mechanism in seq2seq models for abstractive summarization can suffer from repetition and semantic irrelevance, causing grammatical errors and insufficient reflection of the main idea of the source text.': 'The authors propose a model of global encoding for abstractive summarization, which uses a convolutional gated unit to perform global encoding on the source context. The gate based on convolutional neural network (CNN) filters each encoder output based on the global context due to the parameter sharing, so that the representations at each time step are refined with consideration of the global context.', 'Recent studies show that there is no obvious alignment relationship between the source text and the target summary, and the encoder outputs contain noise for the attention.': 'The proposed global encoding model addresses this problem by using a convolutional gated unit to perform global encoding on the source context, which refines the representations at each time step with consideration of the global context.', 'Attention-based seq2seq models for abstractive summarization can suffer from repetition, as the attention mechanism still attends to the word with high attention score.': 'The proposed global encoding model is capable of reducing repetition compared with the seq2seq model, as shown by the analysis conducted on the benchmark datasets for sentence summarization.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:a2436ef46c7201bc80102067ce6286dd6793d0d3,Structure-Infused Copy Mechanisms for Abstractive Summarization,COLING,2018,"['Kaiqiang Song', 'Lin Zhao', 'Fei Liu']","Seq2seq learning has produced promising results on summarization. However, in many cases, system summaries still struggle to keep the meaning of the original intact. They may miss out important words or relations that play critical roles in the syntactic structure of source sentences. In this paper, we present structure-infused copy mechanisms to facilitate copying important words and relations from the source sentence to summary sentence. The approach naturally combines source dependency structure with the copy mechanism of an abstractive sentence summarizer. Experimental results demonstrate the effectiveness of incorporating source-side syntactic information in the system, and our proposed approach compares favorably to state-of-the-art methods.",The paper discusses the limitations of current summarization systems and proposes a new approach that incorporates source-side syntactic information to improve the quality of summaries. The approach uses structure-infused copy mechanisms to copy important words and relations from the source sentence to the summary sentence. Experimental results show that this approach is effective and outperforms state-of-the-art methods.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to condense source texts to summaries that are concise, grammatical, and preserve the important meaning of the original texts.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Objective Function'],['Gigaword'],['ROUGE'],"['Informativeness', 'Fluency', 'Faithfulness']",https://github.com/KaiQiangSong/struct_infused_summ,https://aclanthology.org/C18-1146,"{'Rare syntactic constructions of the source can pose problems for neural summarization systems, possibly for two reasons. First, certain syntactic constructions do not occur frequently enough in the training data to allow the system to learn the patterns. Second, neural summarization systems are not explicitly informed of the syntactic structure of the source sentences and they tend to bias towards sequential recency.': 'Incorporate source syntactic structure in neural sentence summarization to help the system identify summary-worthy content and compose summaries that preserve the important meaning of the source texts. Present structure-infused copy mechanisms to facilitate copying source words and relations to the summary based on their semantic and structural importance in the source sentences.', 'Individual system summaries can appear unreliable and fail to preserve the meaning of the source texts.': 'Introduce novel neural architectures that encourage salient source words/relations to be preserved in summaries. The framework naturally combines the dependency parse tree structure with the copy mechanism of an abstractive summarization system.', 'The system fails to identify the main verb in rare syntactic constructions of the source sentences.': 'Strive to preserve important parts of the source syntactic structure, such as a dependency edge from the main verb to the subject, in the summary using the structure-infused copy mechanisms.', 'Lack of effectiveness in incorporating syntactic information in neural sentence summarization.': 'Study the effectiveness of several important components, including the vocabulary size, a coverage-based regularizer, and a beam search with reference mechanism. Through extensive experiments, demonstrate that incorporating syntactic information in neural sentence summarization is effective and surpasses state-of-the-art published systems on the benchmark dataset.'}",supervised,['News'],[]
SP:481b4b8d5704c34246deaf2adfff858cb647b80a,Cross-domain Aspect/Sentiment-aware Abstractive Review Summarization,CIKM,2018,"['Min Yang', 'Qiang Qu', 'Jia Zhu', 'Ying Shen', 'Zhou Zhao']","This study takes the lead to study the aspect/sentiment-aware abstractive review summarization in domain adaptation scenario. The proposed model CASAS (neural attentive model for Cross-domain Aspect/Sentiment-aware Abstractive review Summarization) leverages domain classification task, working on datasets of both source and target domains, to recognize the domain information of texts and transfer knowledge from source domains to target domains. The extensive experiments on Amazon reviews demonstrate that CASAS outperforms the compared methods in both out-of-domain and in-domain setups.",System: The paper proposes a model called CASAS for aspect/sentiment-aware abstractive review summarization in a domain adaptation scenario. The model leverages a domain classification task to recognize the domain information of texts and transfer knowledge from source domains to target domains. The experiments conducted on Amazon reviews show that CASAS outperforms other methods in both out-of-domain and in-domain setups.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of user reviews on products to help e-commerce platforms automatically generate coherent and concise summaries for business organizations to improve their products and for individual consumers to make informed decisions.', 'Who is the target audience?': 'The summaries are for business organizations to improve their products and for individual consumers to make informed decisions.', 'How will the summaries be used?': 'The summaries will be used by e-commerce platforms to help business organizations improve their products and by individual consumers to make informed decisions.'}",['method'],['Auxiliary Tasks'],['Amazon Product Reviews'],['ROUGE'],['Readability'],,https://dl.acm.org/doi/pdf/10.1145/3269206.3269273,"{'Prior summarization models usually require a large number of labeled data. Annotating sufficient data is labor-intensive and time-consuming, establishing significant barriers for adapting the summarization systems to new domains which have limited labeled data.': 'The authors propose a multi-task system called ""CASAS"" that leverages text classification to learn better review representation and transfer knowledge from the source domain to the target domain. A weakly supervised LDA model (wsLDA) is proposed to learn domain-specific aspect and sentiment lexicon representations which are then used to calculate the aspect/sentiment-aware review representations via a soft attention mechanism.', 'Neural sequence-to-sequence models tend to generate trivial and generic summary, often involving high-frequency phrases. These summaries cannot capture the aspect and sentiment information from the product reviews which play a vital role in helping customers to make quick and informed decisions on certain products.': 'The authors propose a neural attentive model for cross-domain aspect/sentiment-aware abstractive review summarization. The abstractive review summarizer shares the document modeling module with the domain classifier. The learned aspect/lexicon-aware review representations are fed into a pointer-generator network to generate aspect/sentiment-aware abstractive summaries of given reviews.', 'Generating aspect/sentiment-aware summaries of product reviews remains a challenge.': 'The authors propose a multi-task system called ""CASAS"" that integrates the supervised deep learning system with the unsupervised probabilistic generative model to strengthen the representation learning via an attention mechanism. The learned representation is expected to capture aspect and sentiment knowledge.', 'There is a need for automatically generating the coherent and concise summaries of user reviews for e-commerce platforms.': 'The authors propose a neural attentive model for cross-domain aspect/sentiment-aware abstractive review summarization called ""CASAS"" that can automatically generate aspect/sentiment-aware abstractive summaries of given reviews. The experimental results show that their model outperforms the competitors from both quantitative and qualitative perspectives.'}",supervised,['Reviews'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data']"
SP:680282bbaca79641039acbed87e63ebbe60f80d7,A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss,ACL,2018,"['Wan-Ting Hsu', 'Chieh-Kai Lin', 'Ming-Ying Lee', 'Kerui Min', 'Jing Tang', 'Min Sun']","We propose a unified model combining the strength of extractive and abstractive summarization. On the one hand, a simple extractive model can obtain sentence-level attention with high ROUGE scores but less readable. On the other hand, a more complicated abstractive model can obtain word-level dynamic attention to generate a more readable paragraph. In our model, sentence-level attention is used to modulate the word-level attention such that words in less attended sentences are less likely to be generated. Moreover, a novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions. By end-to-end training our model with the inconsistency loss and original losses of extractive and abstractive models, we achieve state-of-theart ROUGE scores while being the most informative and readable summarization on the CNN/Daily Mail dataset in a solid human evaluation.","The paper proposes a unified model that combines the strengths of extractive and abstractive summarization. The model uses sentence-level attention to modulate word-level attention, resulting in a more readable paragraph. The model also introduces a novel inconsistency loss function to penalize the inconsistency between two levels of attentions. By end-to-end training, the model achieves state-of-the-art ROUGE scores and is the most informative and readable summarization on the CNN/Daily Mail dataset according to a human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically condense a piece of text to a shorter version while maintaining the important points.', 'Who is the target audience?': 'The summaries can aid many applications such as creating news digests, presenting search results, and generating reports.', 'How will the summaries be used?': 'The summaries can be used to provide concise and coherent information to users in various applications.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Conciseness', 'Readability']",,https://aclanthology.org/P18-1013,"{'Extractive and abstractive summarization approaches have their own strengths and weaknesses.': 'The authors propose a unified model that combines sentence-level and word-level attentions to take advantage of both extractive and abstractive summarization approaches.', 'Abstractive summarization suffers from inaccurately reproducing factual details and an inability to deal with out-of-vocabulary (OOV) words.': 'The authors modulate the word-level dynamic attention from the abstractive model with sentence-level attention such that words in less attended sentences are less likely to be generated. This way, extractive summarization mostly benefits abstractive summarization by mitigating spurious word-level attention.', 'There is a lack of consistency between the two levels of attentions in the unified model.': 'The authors introduce a novel inconsistency loss function to encourage the consistency between two levels of attentions. The loss function can be computed without additional human annotation and has shown to ensure the unified model to be mutually beneficial to both extractive and abstractive summarization.', 'The quality of the unified model needs to be evaluated.': 'The authors conduct a solid human evaluation and confirm that their method significantly outperforms recent state-of-the-art methods in informativity and readability.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:3e04d9d9399662b840a2b1a65dd25761c7595ab8,Aspect and Sentiment Aware Abstractive Review Summarization,COLING,2018,"['Min Yang', 'Qiang Qu', 'Ying Shen', 'Qiao Liu', 'Wei Zhao', 'Jia Zhu']","Review text has been widely studied in traditional tasks such as sentiment analysis and aspect extraction. However, to date, no work is towards the end-to-end abstractive review summarization that is essential for business organizations and individual consumers to make informed decisions. This work takes the lead to study the aspect/sentiment-aware abstractive review summarization in an end-to-end manner without hand-crafted features and templates by exploring the encoder-decoder framework and multi-factor attentions. Specifically, we propose a mutual attention mechanism to interactively learns the representations of context words, sentiment words and aspect words within the reviews, acted as an encoder. The learned sentiment and aspect representations are incorporated into the decoder to generate aspect/sentiment-aware review summaries via an attention fusion network. In addition, the abstractive summarizer is jointly trained with the text categorization task, which helps learn a category-specific text encoder, locating salient aspect information and exploring the variations of style and wording of content with respect to different text categories. The experimental results on a real-life dataset demonstrate that our model achieves impressive results compared to other strong competitors.","The paper discusses the lack of research on end-to-end abstractive review summarization, which is important for businesses and consumers to make informed decisions. The authors propose a mutual attention mechanism that learns the representations of context, sentiment, and aspect words within reviews, acting as an encoder. The learned representations are incorporated into the decoder to generate aspect/sentiment-aware review summaries via an attention fusion network. The abstractive summarizer is jointly trained with the text categorization task, which helps learn a category-specific text encoder. The experimental results on a real-life dataset show that their model outperforms other strong competitors.","{'What is the purpose of the summaries?': 'The authors are generating summaries of user-generated product reviews to provide coherent and concise summaries that capture the salient ideas of the source text.', 'Who is the target audience?': 'The summaries are valuable to business organizations for improving their products and to individual consumers for making informed decisions.', 'How will the summaries be used?': 'The summaries will be used to help customers make quick and informed decisions on certain products and to help business organizations improve their products based on customer feedback.'}",['method'],['Objective Function'],['Amazon Product Reviews'],['ROUGE'],['Readability'],,https://aclanthology.org/C18-1095,"{'Neural sequence-to-sequence models tend to generate trivial and generic summaries that cannot capture the aspect and sentiment information from product reviews.': 'The authors propose a Multi-factor attention fusion network for aspect/sentiment-aware Abstractive Review Summarization (MARS) that uses a mutual attention mechanism to capture the correlation of context words, sentiment words, and aspect words. This mechanism generates representations for contexts, sentiments, and aspects separately, allowing the model to learn aspect/sentiment-aware review summaries.', 'Summary styles and words in different categories can significantly vary, but existing methods apply a uniform model to generate text summaries for different categories, which easily miss or under represent salient aspects of the documents.': 'The authors leverage a text categorization task to learn better category-specific review representation for summarization. They explore the variation of style and wording of summaries with respect to different text categorization.', 'There is a need to selectively attend to the context information when decoding summaries.': 'The authors explore three kinds of attentions (i.e., semantic attention, sentiment attention, and aspect attention) to selectively attend to the context information when decoding summaries.', 'The exposure bias issue needs to be addressed.': 'The authors employ a reinforcement learning technique (i.e., policy gradient) to directly optimize the model with respect to the non-differentiable ROUGE scores, moderating the exposure bias issue.'}",supervised,['Reviews'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:9c2d72c2a198d8eeefac1898f68be354f632e6d1,Entity Commonsense Representation for Neural Abstractive Summarization,NAACL,2018,"['Reinald Kim Amplayo', 'Seung-won Hwang']","A major proportion of a text summary includes important entities found in the original text. These entities build up the topic of the summary. Moreover, they hold commonsense information once they are linked to a knowledge base. Based on these observations, this paper investigates the usage of linked entities to guide the decoder of a neural text summarizer to generate concise and better summaries. To this end, we leverage on an off-the-shelf entity linking system (ELS) to extract linked entities and propose Entity2Topic (E2T), a module easily attachable to a sequence-to-sequence model that transforms a list of entities into a vector representation of the topic of the summary. Current available ELS’s are still not sufficiently effective, possibly introducing unresolved ambiguities and irrelevant entities. We resolve the imperfections of the ELS by (a) encoding entities with selective disambiguation, and (b) pooling entity vectors using firm attention. By applying E2T to a simple sequenceto-sequence model with attention mechanism as base model, we see significant improvements of the performance in the Gigaword (sentence to title) and CNN (long document to multi-sentence highlights) summarization datasets by at least 2 ROUGE points.","The paper explores the use of linked entities to improve the performance of a neural text summarizer. The authors propose a module called Entity2Topic (E2T) that transforms a list of entities into a vector representation of the summary's topic. They use an off-the-shelf entity linking system (ELS) to extract linked entities, but resolve imperfections in the ELS by encoding entities with selective disambiguation and pooling entity vectors using firm attention. Applying E2T to a simple sequence-to-sequence model with attention mechanism results in significant improvements in the performance of the summarizer in the Gigaword and CNN datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create a shorter and concise version of the text while preserving the meaning of the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading longer texts, and to quickly understand the main topics and ideas presented in the original text.'}",['method'],"['Input Encoding', 'Input Encoding']","['Gigaword', 'CNN/DailyMail']",['ROUGE'],"['Relevance', 'Fluency']",https://github.com/rktamplayo/Entity2Topic,https://aclanthology.org/N18-1064,"{'Sequence-to-sequence models tend to include all information, relevant or not, when generating summaries, resulting in unconcise summaries that concentrate on irrelevant topics, especially when summarizing longer texts.': 'Use entities found in the original text to infer the summary topic, mitigating the aforementioned problem. Specifically, leverage on linked entities extracted by employing a readily available entity linking system.', 'Due to the imperfections of current ELS’s, the extracted linked entities may be too ambiguous and coarse to be considered relevant to the summary.': 'Solve this issue by using entity encoders with selective disambiguation and by constructing topic vectors using firm attention.', 'Difficulty in determining the main topic and sifting out unnecessary information that can be omitted when generating summaries.': 'Present a method to effectively apply linked entities in sequence-to-sequence models, called Entity2Topic (E2T). E2T is a module that can be easily attached to any sequence-to-sequence based summarization model. The module encodes the entities extracted from the original text by an entity linking system (ELS), constructs a vector representing the topic of the summary to be generated, and informs the decoder about the constructed topic vector.', 'Lack of analysis on how the model effectively uses the extracted linked entities to produce concise and better summaries.': 'Provide analysis on how the model effectively uses the extracted linked entities to produce concise and better summaries.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:ff6ceeff1e235b4b0c2ec43bddc20a259c006a46,A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents,NAACL,2018,"['Arman Cohan', 'Franck Dernoncourt', 'Doo Soon Kim', 'Trung Bui', 'Seokhwan Kim', 'Walter Chang', 'Nazli Goharian']","Neural abstractive summarization models have led to promising results in summarizing relatively short documents. We propose the first model for abstractive summarization of single, longer-form documents (e.g., research papers). Our approach consists of a new hierarchical encoder that models the discourse structure of a document, and an attentive discourse-aware decoder to generate the summary. Empirical results on two large-scale datasets of scientific papers show that our model significantly outperforms state-of-the-art models.","System: The paper proposes a new model for abstractive summarization of longer-form documents, such as research papers. The model uses a hierarchical encoder to model the discourse structure of the document and an attentive discourse-aware decoder to generate the summary. Empirical results on two large-scale datasets of scientific papers show that the proposed model outperforms state-of-the-art models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long-form structured documents, specifically scientific papers, to provide a more efficient way of conveying important information to readers.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a scientific paper without having to read the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort for researchers, students, and other readers who need to quickly understand the content of a scientific paper. They can also be used to help identify relevant papers for further research.'}","['corpus', 'method']",['Input Encoding'],"['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/acohan/long-summarization,https://aclanthology.org/N18-2097,"{'Existing large-scale summarization datasets consist of relatively short documents, and existing neural summarization models have focused on summarizing sentences and short documents.': 'The authors propose a model for effective abstractive summarization of longer documents, specifically scientific papers, which are significantly longer than news articles.', 'Most summarization works in the literature focus on extractive summarization.': 'The authors propose an alternative approach of abstractive summarization, which generates a summary that may contain novel words and phrases and is more similar to how humans summarize documents.', 'Seq2seq models tend to struggle with longer sequences because the decoder needs to learn to construct a context vector capturing relevant information from all the tokens in the source sequence.': 'The authors introduce a hierarchical encoder that captures the discourse structure of the document and a discourse-aware decoder that attends to different discourse sections, allowing the model to more accurately represent important information from the source resulting in a better context vector.', 'There is a lack of large-scale datasets of long and structured scientific papers for training and evaluating models on the task of long document summarization.': 'The authors introduce two large-scale datasets of long and structured scientific papers obtained from arXiv and PubMed to support both training and evaluating models on the task of long document summarization.'}",supervised,['Scholarly Documents'],"['efficient-encoding-of-long-documents', 'exploiting-the-structure-of-long-documents', 'lack-of-suitable-training-data']"
SP:3373e86667d488086739ed58fc35021f30fdada1,Deep Communicating Agents for Abstractive Summarization,NAACL,2018,"['Asli Celikyilmaz', 'Antoine Bosselut', 'Xiaodong He', 'Yejin Choi']","We present deep communicating agents in an encoder-decoder architecture to address the challenges of representing a long document for abstractive summarization. With deep communicating agents, the task of encoding a long text is divided across multiple collaborating agents, each in charge of a subsection of the input text. These encoders are connected to a single decoder, trained end-to-end using reinforcement learning to generate a focused and coherent summary. Empirical results demonstrate that multiple communicating encoders lead to a higher quality summary compared to several strong baselines, including those based on a single encoder or multiple non-communicating encoders.","System: The paper proposes a new approach to abstractive summarization using deep communicating agents in an encoder-decoder architecture. The task of encoding a long text is divided across multiple collaborating agents, each responsible for a subsection of the input text. These encoders are connected to a single decoder, trained using reinforcement learning to generate a focused and coherent summary. Empirical results show that this approach leads to higher quality summaries compared to several strong baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to provide a coherent and concise summary of the salient facts.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the key information.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'NYT']",['ROUGE'],"['Non-redundancy', 'Coherence', 'Focus', 'Overall Quality']",,https://aclanthology.org/N18-1150,"{'Neural models have strong performance at encoding short text but do not generalize well to long text.': 'The authors propose to dynamically attend to different parts of the input to capture salient facts. They also use improved attention models, pointer networks with coverage mechanisms, and coherence-focused training objectives to address this issue.', 'An effective mechanism for representing a long document remains a challenge in summarization.': 'The authors propose to divide the task of encoding a long text across multiple collaborating encoder agents, each in charge of a different subsection of the text. They use a novel contextual agent attention to integrate information from multiple agents smoothly at each decoding step.', 'Common mistakes such as missing key facts, repeating the same content, or including unnecessary details occur in summarization.': 'The authors propose to use multiple communicating encoders to gather salient information from multiple areas of the document and communicate their information with one another. They also train the network using self-critical reinforcement learning to generate focused and coherent summaries.'}",reinforced,['News'],"['efficient-encoding-of-long-documents', 'exploiting-the-structure-of-long-documents']"
SP:1749e78de5a055f3729b36a077018e6d327bd173,Guiding Generation for Abstractive Text Summarization Based on Key Information Guide Network,NAACL,2018,"['Chenliang Li', 'Weiran Xu', 'Sheng Gao']","Neural network models, based on the attentional encoder-decoder model, have good capability in abstractive text summarization. However, these models are hard to be controlled in the process of generation, which leads to a lack of key information. We propose a guiding generation model that combines the extractive method and the abstractive method. Firstly, we obtain keywords from the text by a extractive model. Then, we introduce a Key Information Guide Network (KIGN), which encodes the keywords to the key information representation, to guide the process of generation. In addition, we use a prediction-guide mechanism, which can obtain the long-term value for future decoding, to further guide the summary generation. We evaluate our model on the CNN/Daily Mail dataset. The experimental results show that our model leads to significant improvements.","The paper proposes a guiding generation model that combines extractive and abstractive methods for text summarization. The model uses a Key Information Guide Network (KIGN) to encode keywords and guide the generation process, and a prediction-guide mechanism to obtain long-term value for future decoding. The model is evaluated on the CNN/Daily Mail dataset and shows significant improvements compared to previous models.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide a brief summary while retaining the key information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key information in a document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the key information in a document without having to read the entire document.'}",['method'],"['Input Encoding', 'Controlled Generation', 'Unit Selection']",['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/N18-2009,"{'Abstractive summarization models are hard to control in the process of generation, leading to a lack of key information in the summary.': 'The authors propose a guiding generation model that combines an extractive method to obtain keywords as guidance for the abstractive model. They introduce a Key Information Guide Network (KIGN) to encode the keywords to the key information representation and integrate it into the abstractive model to guide the process of generation.', 'The selective gate network proposed by Zhou et al. controls the information flow from encoder to decoder for just once, making it hard for some key information to appear in the summary.': 'The authors propose a guiding generation model that uses the attention mechanism and the pointer mechanism to guide the process of generation. The attention mechanism helps the model focus on the important parts of the input text, while the pointer mechanism copies words from the input text to deal with out-of-vocabulary (OOV) words.', 'Without external guidance, it is hard for the pointer mechanism to identify keywords.': 'The authors propose a guiding generation model that combines an extractive method to obtain keywords as guidance for the abstractive model. They introduce a Key Information Guide Network (KIGN) to encode the keywords to the key information representation and integrate it into the abstractive model to guide the process of generation.', 'It is hard to predict the extent of key information covered in the final summary.': 'The authors propose a novel prediction-guide mechanism based on He et al. (2017), which predicts the extent of key information covered in the final summary, to further guide the summary generation.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:fce933d025eeeec5e22701d647ab9377dd121a24,Frustratingly Easy Model Ensemble for Abstractive Summarization,EMNLP,2018,['Hayato Kobayashi'],"Ensemble methods, which combine multiple models at decoding time, are now widely known to be effective for text-generation tasks. However, they generally increase computational costs, and thus, there have been many studies on compressing or distilling ensemble models. In this paper, we propose an alternative, simple but effective unsupervised ensemble method, post-ensemble, that combines multiple models by selecting a majority-like output in post-processing. We theoretically prove that our method is closely related to kernel density estimation based on the von MisesFisher kernel. Experimental results on a newsheadline-generation task show that the proposed method performs better than the current ensemble methods.","System: The paper discusses the effectiveness of ensemble methods for text-generation tasks, but notes that they often come with increased computational costs. The authors propose an alternative unsupervised ensemble method called post-ensemble, which selects a majority-like output in post-processing. The method is theoretically related to kernel density estimation based on the von MisesFisher kernel. Experimental results on a news headline-generation task show that the proposed method outperforms current ensemble methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of various text-generation tasks, such as translation, summarization, question-answering, and dialogue response generation.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of natural language processing who are interested in improving the performance of text-generation models.', 'How will the summaries be used?': 'The summaries will be used to inform researchers and practitioners about recent developments in deep learning, especially encoder-decoder models, and the effectiveness of ensemble methods for text-generation tasks. They may also be used to inspire new research directions in model ensemble and hypotheses reranking.'}",['method'],['Input Encoding'],['Gigaword'],['ROUGE'],[''],https://summary-wg.east.edge.storage-yahoo.jp/opendata/emnlp2018/post-ensemble_dataset.zip,https://aclanthology.org/D18-1449,"{'Ensemble methods for text-generation tasks increase computational costs due to the need to average the word-prediction probabilities of all models in each decoding step.': 'The authors propose an alternative method for model ensemble inspired by the majority vote in classification tasks, which involves selecting a majority-like output from the generated outputs of multiple text-generation models in post-processing instead of averaging models at decoding time. They also propose an unsupervised method for selecting a majority-like output close to the other outputs by using cosine similarity.', 'Majority output may not exist since each output will be basically different from other outputs, which are generated from different models.': 'The authors propose an unsupervised method for selecting a majority-like output close to the other outputs by using cosine similarity.', 'Output selection as typified by majority vote has received less attention in text generation studies.': 'The authors suggest a new category of ensemble algorithms that corresponds to the output selection in classification tasks and propose their method as a simple and effective approach.', 'In hypotheses reranking for a text-generation model, a reranking method based on a language model is frequently used assuming the model can generate good outputs.': 'The authors suggest a new category of reranking tasks, where they need to select the best output from the generated outputs of multiple models, instead of the N-best hypotheses of a single model. They propose their method as a way to consider all outputs to decide the goodness of an output because a fluent output is not always appropriate in this task.', 'Finding the maximum density point by kernel density estimation based on the von MisesFisher kernel is computationally expensive.': 'The authors prove that their method is an approximation of finding the maximum density point by kernel density estimation based on the von MisesFisher kernel and derive a formula of the error bound of this approximation.', 'Lack of datasets to improve ensemble methods.': 'The authors will release the 128 prepared models used in this paper, each of which was trained for more than two days, as a new dataset to improve ensemble methods.'}",unsupervised,['News'],[]
SP:e27f685974d2ca9dee3bf3aa3ba48baf06265177,A DEEP REINFORCED MODEL FOR ABSTRACTIVE SUMMARIZATION,ICLR,2018,"['Romain Paulus', 'Caiming Xiong', 'Richard Socher']","Attentional, RNN-based encoder-decoder models for abstractive summarization have achieved good performance on short input and output sequences. For longer documents and summaries however these models often include repetitive and incoherent phrases. We introduce a neural network model with a novel intraattention that attends over the input and continuously generated output separately, and a new training method that combines standard supervised word prediction and reinforcement learning (RL). Models trained only with supervised learning often exhibit “exposure bias” – they assume ground truth is provided at each step during training. However, when standard word prediction is combined with the global sequence prediction training of RL the resulting summaries become more readable. We evaluate this model on the CNN/Daily Mail and New York Times datasets. Our model obtains a 41.16 ROUGE-1 score on the CNN/Daily Mail dataset, an improvement over previous state-of-the-art models. Human evaluation also shows that our model produces higher quality summaries.","The paper discusses the limitations of current attentional, RNN-based encoder-decoder models for abstractive summarization on longer documents and introduces a new neural network model with a novel intraattention and a training method that combines supervised word prediction and reinforcement learning. The resulting summaries are more readable and the model achieves an improved ROUGE-1 score on the CNN/Daily Mail dataset compared to previous state-of-the-art models. Human evaluation also shows that the model produces higher quality summaries.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to aid downstream applications such as creating news digests, search, and report generation.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various downstream applications such as creating news digests, search, and report generation.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'NYT']",['ROUGE'],"['Readability', 'Relevance']",,https://arxiv.org/abs/1705.04304,"{'Attentional encoder-decoder models often generate unnatural summaries consisting of repeated phrases.': 'The authors introduce a key attention mechanism and a new learning objective to address the repeating phrase problem. They use an intra-temporal attention in the encoder that records previous attention weights for each of the input tokens while a sequential intra-attention model in the decoder takes into account which words have already been generated by the decoder.', 'Abstractive summarization systems have typically been used for summarizing short input sequences (one or two sentences) to generate even shorter summaries.': 'The authors present a new abstractive summarization model that achieves state-of-the-art results on the CNN/Daily Mail and similarly good results on the New York Times dataset (NYT) (Sandhaus, 2008). To our knowledge, this is the first end-to-end model for abstractive summarization on the NYT dataset.', 'Exposure bias in maximum-likelihood cross-entropy loss used in prior work.': 'The authors propose a new objective function by combining the maximum-likelihood cross-entropy loss used in prior work with rewards from policy gradient reinforcement learning to reduce exposure bias.', 'Generating readable summaries compared to other abstractive approaches.': 'The authors show, through human evaluation of generated outputs, that their model generates more readable summaries compared to other abstractive approaches.'}",reinforced,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:64a994d58e7df999c798c211f72fb86095522f09,Improving Neural Abstractive Document Summarization with Explicit Information Selection Modeling,EMNLP,2018,"['Wei Li', 'Xinyan Xiao', 'Yajuan Lyu', 'Yuanzhuo Wang']","Information selection is the most important component in document summarization task. In this paper, we propose to extend the basic neural encoding-decoding framework with an information selection layer to explicitly model and optimize the information selection process in abstractive document summarization. Specifically, our information selection layer consists of two parts: gated global information filtering and local sentence selection. Unnecessary information in the original document is first globally filtered, then salient sentences are selected locally while generating each summary sentence sequentially. To optimize the information selection process directly, distantly-supervised training guided by the golden summary is also imported. Experimental results demonstrate that the explicit modeling and optimizing of the information selection process improves document summarization performance significantly, which enables our model to generate more informative and concise summaries, and thus significantly outperform state-of-the-art neural abstractive methods.",The paper proposes a new approach to document summarization that explicitly models and optimizes the information selection process. This is achieved through an information selection layer that includes global information filtering and local sentence selection. The approach is trained using distantly-supervised training guided by a golden summary. Experimental results show that this approach significantly improves document summarization performance and outperforms state-of-the-art neural abstractive methods.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a condensed version of the document while retaining the essential information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be particularly useful for tasks such as information retrieval and decision-making.'}",['method'],"['Input Encoding', 'Unit Selection']",['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Conciseness', 'Coherence', 'Fluency']",,https://aclanthology.org/D18-1205,"{'The performance of current neural abstractive methods in document summarization has a considerable gap from extractive methods.': 'The authors propose to extend the encoding-decoding framework to model the information selection process explicitly, by treating document summarization as a three-phase task: document encoding, information selection, and summary decoding. They propose a model with three layers: a document encoder layer, an information selection layer, and a summary decoder layer. The information selection layer consists of two parts: gated global information filtering and local sentence selection. They also propose to optimize the information selection process with distantly-supervised training.', 'Document summarization requires proper modeling of both global document information and local inter-sentence relations in the information selection process.': 'The authors propose to process both the document and summary sentence by sentence, to better capture the inter-sentence relations. They also propose a model with an information selection layer that consists of two parts: gated global information filtering and local sentence selection.', 'Abstractive document summarization shall benefit from explicitly modeling and optimizing the information selection process.': 'The authors propose to extend the encoding-decoding framework to model the information selection process explicitly, and to optimize it with distantly-supervised training. They argue that this approach combines the strengths of extractive methods and abstractive methods, and is able to tackle the factors of saliency, non-redundancy, coherence, and fluency under a unified framework.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:ef2e4a483caa02779bc245c8999cc9f3b42a712b,Bottom-Up Abstractive Summarization,EMNLP,2018,"['Sebastian Gehrmann', 'Yuntian Deng', 'Alexander M. Rush']","Neural network-based methods for abstractive summarization produce outputs that are more fluent than other techniques, but perform poorly at content selection. This work proposes a simple technique for addressing this issue: use a data-efficient content selector to over-determine phrases in a source document that should be part of the summary. We use this selector as a bottom-up attention step to constrain the model to likely phrases. We show that this approach improves the ability to compress text, while still generating fluent summaries. This two-step process is both simpler and higher performing than other end-toend content selection models, leading to significant improvements on ROUGE for both the CNN-DM and NYT corpus. Furthermore, the content selector can be trained with as little as 1,000 sentences, making it easy to transfer a trained summarizer to a new domain.","The paper proposes a technique to improve the content selection of neural network-based methods for abstractive summarization. The technique involves using a data-efficient content selector to identify phrases in the source document that should be included in the summary. This selector is used as a bottom-up attention step to constrain the model to likely phrases, resulting in improved text compression and fluent summaries. The approach is simpler and higher performing than other end-to-end content selection models, and can be trained with as little as 1,000 sentences, making it easy to transfer to a new domain. The technique was shown to significantly improve ROUGE scores for both the CNN-DM and NYT corpus.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress the information in a longer text.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not explicitly state how the summaries will be used, but they may be useful for quickly understanding the main points of a longer text.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],[''],https://github.com/sebastianGehrmann/bottom-up-summary,https://aclanthology.org/D18-1443,"{'End-to-end neural abstractive summarization models have had mixed success in content selection compared to fully extractive models.': 'The authors propose a bottom-up attention approach that first selects a selection mask for the source document and then constrains a standard neural model by this mask. This approach can better decide which phrases a model should include in a summary, without sacrificing the fluency advantages of neural abstractive summarizers.', 'There is evidence that when summarizing, people follow a two-step approach of first selecting important phrases and then paraphrasing them.': 'The authors incorporate a separate content selection system to decide on relevant aspects of the source document. They frame this selection task as a sequence-tagging problem, with the objective of identifying tokens from a document that are part of its summary.', 'The content selection model requires a large amount of training data.': 'The authors show that a content selection model that builds on contextual word embeddings can identify correct tokens with a recall of over 60%, and a precision of over 50%, and can be trained with less than 1% of the original training data. This provides opportunities for domain-transfer and low-resource summarization.', 'It is challenging to incorporate bottom-up attention into more complex end-to-end abstractive summarization models.': 'The authors experiment with multiple methods to incorporate similar constraints into the training process of more complex end-to-end abstractive summarization models, either through multi-task learning or through directly incorporating a fully differentiable mask.'}",supervised,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:16c5649b3dabc946f6aa6dd06318b39d8c2bcbf5,Ensure the Correctness of the Summary: Incorporate Entailment Knowledge into Abstractive Sentence Summarization,COLING,2018,"['Haoran Li', 'Junnan Zhu', 'Jiajun Zhang', 'Chengqing Zong']","In this paper, we investigate the sentence summarization task that produces a summary from a source sentence. Neural sequence-to-sequence models have gained considerable success for this task, while most existing approaches only focus on improving word overlap between the generated summary and the reference, which ignore the correctness, i.e., the summary should not contain error messages with respect to the source sentence. We argue that correctness is an essential requirement for summarization systems. Considering a correct summary is semantically entailed by the source sentence, we incorporate entailment knowledge into abstractive summarization models. We propose an entailment-aware encoder under multi-task framework (i.e., summarization generation and entailment recognition) and an entailment-aware decoder by entailment Reward Augmented Maximum Likelihood (RAML) training. Experimental results demonstrate that our models significantly outperform baselines from the aspects of informativeness and correctness.",The paper discusses the importance of correctness in sentence summarization and proposes a new approach that incorporates entailment knowledge into abstractive summarization models. The authors argue that a correct summary should not contain error messages with respect to the source sentence. They propose an entailment-aware encoder and decoder and use entailment Reward Augmented Maximum Likelihood (RAML) training. Experimental results show that their models outperform baselines in terms of informativeness and correctness.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create a condensed version of a long source sentence.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the source sentence.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly grasp the main ideas and information conveyed in the source sentence.'}",['method'],"['Auxiliary Tasks', 'Objective Function']","['Gigaword', 'DUC 2004']",['ROUGE'],['Correctness'],https://github.com/hrlinlp/entail_sum,https://aclanthology.org/C18-1121,"{'Most existing sentence summarization systems aim to improve word overlap between the generated summary and the references, which cannot guarantee the semantic correctness of the summary as a whole.': 'The authors propose to incorporate entailment knowledge into abstractive summarization models to avoid producing contradictory or unrelated information in the summary.', 'Existing summarization systems ignore the essential requirement of correctness in the summary.': 'The authors propose to use entailment knowledge to ensure that a correct summary is semantically entailed by the source sentence.', 'Some summaries generated by state-of-the-art seq2seq systems contain critical error messages, leading to incorrect information with respect to the source sentence.': 'The authors propose an entailment-aware encoder and an entailment-aware decoder to incorporate entailment knowledge into the summarization model, which significantly outperforms some solid baselines on objective evaluation for informativeness and manual evaluation for correctness.', 'The summarization model may produce unrelated information with respect to the source sentence.': 'The authors propose to share the encoder of the summarization generation system with the entailment recognition system, so that the encoder can grasp both the gist of the source sentence and be aware of entailment relationships.', 'The decoder of the summarization system may not produce summary entailed by the source.': 'The authors propose an entailment Reward Augmented Maximum Likelihood (RAML) training that encourages the decoder of the summarization system to produce summary entailed by the source.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:5158417739c053051029a5dbad0333b7ec21ea4b,A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization,IJCAI,2018,"['Li Wang', 'Junlin Yao', 'Yunzhe Tao', 'Li Zhong', 'Wei Liu', 'Qiang Du']","In this paper, we propose a deep learning approach to tackle the automatic summarization tasks by incorporating topic information into the convolutional sequence-to-sequence (ConvS2S) model and using self-critical sequence training (SCST) for optimization. Through jointly attending to topics and word-level alignment, our approach can improve coherence, diversity, and informativeness of generated summaries via a biased probability generation mechanism. On the other hand, reinforcement training, like SCST, directly optimizes the proposed model with respect to the non-differentiable metric ROUGE, which also avoids the exposure bias during inference. We carry out the experimental evaluation with state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets. The empirical results demonstrate the superiority of our proposed method in the abstractive summarization.","The paper proposes a deep learning approach to automatic summarization that incorporates topic information into the ConvS2S model and uses SCST for optimization. The approach improves coherence, diversity, and informativeness of generated summaries through a biased probability generation mechanism. Reinforcement training optimizes the model with respect to the non-differentiable metric ROUGE and avoids exposure bias during inference. The method is evaluated on three datasets and shows superior performance in abstractive summarization.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to produce informative and representative natural language summaries that retain the main ideas of source articles.', 'Who is the target audience?': 'The summaries are for natural language processing (NLP) applications, such as news headlines generation and feeds stream digests.', 'How will the summaries be used?': 'The summaries will be used to efficiently filter redundant contents and properly aggregate related segments, making human-readable summaries.'}",['method'],['Objective Function'],"['Gigaword', 'DUC 2004']",['ROUGE'],[''],,https://arxiv.org/abs/1805.03616,"{'The key challenges in automatic text summarization are correctly evaluating and selecting important information, efficiently filtering redundant contents, and properly aggregating related segments and making human-readable summaries.': 'The authors propose a new approach based on the convolutional sequence-to-sequence (ConvS2S) framework jointly with a topic-aware attention mechanism to incorporate contextual information and generate more coherent summaries with increased diversity.', 'Compared to other NLP tasks, automatic summarization has its own difficulties, such as input and output sequences greatly imbalanced and less obvious word-level alignment between them.': 'The authors propose using the ConvS2S framework, which is less prone to gradient vanishing and allows for parallelization over the elements of a sequence, making the training more efficient.', 'Abstractive summarization methods should be able to properly rewrite the core ideas of the source document and assure that the generated summaries are grammatically correct and human-readable.': 'The authors propose a joint attention and biased probability generation mechanism to incorporate the topic information into an automatic summarization model, which introduces contextual information to help the model generate more coherent summaries with increased diversity.', 'The exposure bias issue in training models for automatic summarization.': 'The authors employ the self-critical sequence training technique in ConvS2S to directly optimize the model with respect to the non-differentiable summarization metric ROUGE, which also remedies the exposure bias issue.', 'Lack of topic information in automatic abstractive summarization models.': 'The authors propose incorporating topic information into the model, which can provide themed and contextual alignment information into deep learning architectures. This is the first work for automatic abstractive summarization that incorporates topic information.', 'Advancing the state-of-the-art methods for abstractive summarization.': 'The authors demonstrate through extensive experimental results on three datasets that their proposed model, which fully exploits the power of the ConvS2S architecture enhanced by topic embedding and SCST, yields high accuracy for abstractive summarization, advancing the state-of-the-art methods.'}",reinforced,['News'],[]
SP:70c5f7bbc7d6b03fa9d9c2f9c636fa838fd94d7b,Exploring Human-Like Reading Strategy for Abstractive Text Summarization,AAAI,2019,"['Min Yang', 'Qiang Qu', 'Wenting Tu', 'Ying Shen', 'Zhou Zhao', 'Xiaojun Chen']","The recent artificial intelligence studies have witnessed great interest in abstractive text summarization. Although remarkable progress has been made by deep neural network based methods, generating plausible and high-quality abstractive summaries remains a challenging task. The human-like reading strategy is rarely explored in abstractive text summarization, which however is able to improve the effectiveness of the summarization by considering the process of reading comprehension and logical thinking. Motivated by the humanlike reading strategy that follows a hierarchical routine, we propose a novel Hybrid learning model for Abstractive Text Summarization (HATS). The model consists of three major components, a knowledge-based attention network, a multitask encoder-decoder network, and a generative adversarial network, which are consistent with the different stages of the human-like reading strategy. To verify the effectiveness of HATS, we conduct extensive experiments on two real-life datasets, CNN/Daily Mail and Gigaword datasets. The experimental results demonstrate that HATS achieves impressive results on both datasets.","The paper discusses the challenges of generating high-quality abstractive summaries using deep neural network based methods and proposes a novel Hybrid learning model for Abstractive Text Summarization (HATS) that follows a hierarchical routine similar to human-like reading strategy. HATS consists of three major components, a knowledge-based attention network, a multitask encoder-decoder network, and a generative adversarial network, which are consistent with the different stages of the human-like reading strategy. The experimental results on two real-life datasets, CNN/Daily Mail and Gigaword, demonstrate that HATS achieves impressive results.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create condensed and concise summaries that retain the salient information and overall meaning of the source articles.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for a variety of purposes, such as research, news, and information gathering. They can also be used to improve natural language processing applications.'}",['method'],"['External Knowledge', 'Auxiliary Tasks', 'Objective Function']","['Gigaword', 'CNN/DailyMail']","['ROUGE', 'METEOR']","['Informativeness', 'Fluency']",,https://ojs.aaai.org/index.php/AAAI/article/view/4724,"{'Generating plausible and high-quality abstractive summaries remains a challenging task in practice, because computers lack human knowledge as well as language capability to understand the entire text and then write a summary highlighting its main points.': 'The authors propose a novel Hybrid learning model for Abstractive Text Summarization (HATS), which mimics the process of how humans write a summary for a piece of text. HATS consists of three components corresponding to the hierarchical stages of the human-like reading strategy.', 'To date, no attempt has been devoted to exploring the human-like reading strategy in abstractive text summarization (i.e., how humans summarize an article).': 'The authors explore the human-like reading strategy in abstractive text summarization and propose a model that mimics this strategy.', 'Humans first set the purpose of reading and pre-view the text quickly with prior (background) knowledge to get a general understanding of the document.': 'The authors design a knowledge-attention network to get the general understanding of the document, which leverages the commonsense knowledge from the knowledge base (KB) as prior knowledge to distinguish the important information from the input text and determine the focus of the summary.', 'To construct the meaning of a text, readers have to go beyond literal information through the generation of inferences.': 'The authors propose a multi-task learning system to jointly train the task of abstractive summarization and two other related tasks: text categorization and syntax annotation. Specifically, text categorization improves the quality of locating salient information of the text and syntax annotation exploits word-level syntax to generate high-quality summaries from the language modeling perspective.', 'The generated summary usually needs to be edited for accuracy and fluency by adding further information and rephrasing the generated words when necessary.': 'The authors employ a generative adversarial network (GAN) to further refine the performance of abstractive text summarization by using a discriminative model to guide the training of the generative model in an adversarial process. This adversarial process can eventually adjust the generative model to generate human-like and high-quality abstractive summaries.', 'Generating plausible and high-quality abstractive summaries remains a challenging task in practice.': 'Extensive experiments are conducted to show that HATS achieves substantial improvements over the compared methods on the widely used CNN/Daily Mail and Gigaword datasets.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'identifying-important-contents-from-the-document']"
SP:a01673ca035b52622eb3c7da35c02c3b81d3ebad,An Entity-Driven Framework for Abstractive Summarization,EMNLP,2019,"['Eva Sharma', 'Luyang Huang', 'Zhe Hu', 'Lu Wang']","Abstractive summarization systems aim to produce more coherent and concise summaries than their extractive counterparts. Popular neural models have achieved impressive results for single-document summarization, yet their outputs are often incoherent and unfaithful to the input. In this paper, we introduce SENECA, a novel System for ENtitydrivEn Coherent Abstractive summarization framework that leverages entity information to generate informative and coherent abstracts. Our framework takes a two-step approach: (1) an entity-aware content selection module first identifies salient sentences from the input, then (2) an abstract generation module conducts cross-sentence information compression and abstraction to generate the final summary, which is trained with rewards to promote coherence, conciseness, and clarity. The two components are further connected using reinforcement learning. Automatic evaluation shows that our model significantly outperforms previous state-of-the-art on ROUGE and our proposed coherence measures on New York Times and CNN/Daily Mail datasets. Human judges further rate our system summaries as more informative and coherent than those by popular summarization models.ive summarization systems aim to produce more coherent and concise summaries than their extractive counterparts. Popular neural models have achieved impressive results for single-document summarization, yet their outputs are often incoherent and unfaithful to the input. In this paper, we introduce SENECA, a novel System for ENtitydrivEn Coherent Abstractive summarization framework that leverages entity information to generate informative and coherent abstracts. Our framework takes a two-step approach: (1) an entity-aware content selection module first identifies salient sentences from the input, then (2) an abstract generation module conducts cross-sentence information compression and abstraction to generate the final summary, which is trained with rewards to promote coherence, conciseness, and clarity. The two components are further connected using reinforcement learning. Automatic evaluation shows that our model significantly outperforms previous state-of-the-art on ROUGE and our proposed coherence measures on New York Times and CNN/Daily Mail datasets. Human judges further rate our system summaries as more informative and coherent than those by popular summarization models.","The paper introduces SENECA, a new system for entity-driven coherent abstractive summarization that uses entity information to generate informative and coherent abstracts. The framework takes a two-step approach, with an entity-aware content selection module identifying salient sentences and an abstract generation module conducting cross-sentence information compression and abstraction. The model is trained with rewards to promote coherence, conciseness, and clarity, and is further connected using reinforcement learning. Automatic evaluation shows that SENECA outperforms previous state-of-the-art on ROUGE and coherence measures on New York Times and CNN/Daily Mail datasets, and human judges rate its summaries as more informative and coherent than those by popular summarization models.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to facilitate quick information consumption.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they are intended to be concise and coherent for easy consumption of information.'}",['method'],"['Unit Selection', 'Objective Function', 'Input Encoding']","['CNN/DailyMail', 'NYT']",['ROUGE'],"['Informativeness', 'Grammaticality', 'Coherence']",https://evasharma.github.io/SENECA,https://aclanthology.org/D19-1323,"{'Existing methods have difficulty in identifying salient entities and related events in the article.': 'The authors propose an entity-based modeling approach that underscores the salient content of the article by frequently mentioning entities from the input, along with their contextual information.', 'Existing methods lack inter-sentence coherence.': 'The authors propose a two-step neural abstractive summarization framework that conducts cross-sentence information ordering, compression, and revision to produce coherent summaries.', 'Existing model training objectives fail to guide the generation of coherent summaries.': 'The authors train their abstract generator using reinforcement learning with rewards that promote informativeness and optionally boost coherence, conciseness, and clarity of the summary.'}",reinforced,['News'],['controlled-and-tailored-summarization']
SP:9ae35466cd73e1143aae996cdd269248ff2cac18,Attention Optimization for Abstractive Document Summarization,EMNLP,2019,"['Min Gui', 'Junfeng Tian', 'Rui Wang', 'Zhenglu Yang']","Attention plays a key role in the improvement of sequence-to-sequence-based document summarization models. To obtain a powerful attention helping with reproducing the most salient information and avoiding repetitions, we augment the vanilla attention model from both local and global aspects. We propose an attention refinement unit paired with local variance loss to impose supervision on the attention model at each decoding step, and a global variance loss to optimize the attention distributions of all decoding steps from the global perspective. The performances on the CNN/Daily Mail dataset verify the effectiveness of our methods.",System: The paper discusses the importance of attention in improving document summarization models. The authors propose an attention refinement unit that uses both local and global variance loss to supervise the attention model at each decoding step and optimize the attention distributions from a global perspective. The effectiveness of the proposed methods is verified through experiments on the CNN/Daily Mail dataset.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce a condensed representation of the most salient information of the document, aspects of which may not appear as parts of the original input text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding longer documents, and can be applied in various fields such as news articles, research papers, and legal documents.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],"['Relevance', 'Readability']",,https://aclanthology.org/D19-1117,"{'Basic attention mechanism may lead to distraction and fail to attend to the relatively salient parts of longer documents.': 'Design various attentions to tackle this issue, such as the proposed attention refinement unit (ARU) that retains attention on salient parts but weakens attention on irrelevant parts of input.', 'Difficulty in deciding which exact part of the source document should be emphasized for the next word (the output of the decoder).': 'Design ARU as an update unit based on current decoding state, which adjusts the concentrated content by reconsidering the current state of what has been summarized already.', 'Soft attention assigns attention weights to all input encoder states, while hard attention on exact one input state is conducive to more accurate results.': 'Introduce a local variance loss to encourage the model to put most of the attention on just a few parts of input states at each decoding step, and a global variance loss to directly optimize the attention from the global perspective by preventing assigning high weights to the same locations multiple times.', 'Repetition problem in the coverage mechanism that hinders the correct assignment of attention in later steps.': 'Propose a global variance loss that is somewhat similar to the coverage mechanism but does not hinder the correct assignment of attention in later steps.', 'Lack of explicit loss functions to optimize the attention.': 'Introduce explicit loss functions to optimize the attention, which is a novel contribution of the proposed model.', 'Need for exploration of the proposed idea to improve other attention-based models.': 'Leave the exploration of the proposed idea to improve other attention-based models for future work.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:815c4d94f30615949e397834f6987e68be6a1e4b,Contrastive Attention Mechanism for Abstractive Sentence Summarization,EMNLP,2019,"['Xiangyu Duan', 'Hongfei Yu', 'Mingming Yin', 'Min Zhang', 'Weihua Luo', 'Yue Zhang']","We propose a contrastive attention mechanism to extend the sequence-to-sequence framework for abstractive sentence summarization task, which aims to generate a brief summary of a given source sentence. The proposed contrastive attention mechanism accommodates two categories of attention: one is the conventional attention that attends to relevant parts of the source sentence, the other is the opponent attention that attends to irrelevant or less relevant parts of the source sentence. Both attentions are trained in an opposite way so that the contribution from the conventional attention is encouraged and the contribution from the opponent attention is discouraged through a novel softmax and softmin functionality. Experiments on benchmark datasets show that, the proposed contrastive attention mechanism is more focused on the relevant parts for the summary than the conventional attention mechanism, and greatly advances the stateof-the-art performance on the abstractive sentence summarization task. We release the code at https://github.com/travel-go/ Abstractive-Text-Summarization.","The paper proposes a contrastive attention mechanism for abstractive sentence summarization, which includes both conventional attention that focuses on relevant parts of the source sentence and opponent attention that focuses on irrelevant or less relevant parts. The mechanism is trained in an opposite way to encourage the contribution from conventional attention and discourage the contribution from opponent attention. Experiments show that the proposed mechanism is more focused on relevant parts and greatly improves the state-of-the-art performance on the task. The code is available on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide concise and informative summaries based on the core meaning of source sentences.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Objective Function'],"['Gigaword', 'DUC 2004']",['ROUGE'],[''],https://github.com/travel-go/Abstractive-Text-Summarization,https://aclanthology.org/D19-1301,"{'Abstractive sentence summarization using traditional methods such as rule-based or statistical models trained on small scale training corpora have limitations in generating concise and informative summaries based on the core meaning of source sentences.': 'The authors propose using the sequence-to-sequence framework with large-scale sentence summary corpora to obtain better performance. They also enhance the target-to-source attention using a contrastive mechanism that encourages the contribution from the conventional attention that attends to relevant parts of the source sentence, while penalizing the contribution from an opponent attention that attends to irrelevant or less relevant parts.', 'The negative influence of redundant parts in the source sequence can affect the selection of the most salient words for a short summary in abstractive sentence summarization.': 'The authors propose using attention mechanisms to filter the negative influence of redundant parts and select the most salient words for a short summary. They also enhance the attention mechanism using a contrastive attention mechanism that discourages contributions from irrelevant or less relevant words.', 'The authors aim to investigate the use of Transformer as a sequence to sequence summarizer.': 'The authors use Transformer as the baseline summarization model and enhance it with a proponent attention module and an opponent attention module. The former acts as the conventional attention mechanism, while the latter can be regarded as a dual module to the former, with similar weight calculation structure, but using a novel softmin function to discourage contributions from irrelevant or less relevant words.', 'The authors aim to achieve better performance in abstractive sentence summarization.': 'The authors use the proposed contrastive attention mechanism to enhance the Transformer model and achieve the best reported results on all data. The visualization of attentions shows that through using the contrastive attention mechanism, the attention is more focused on relevant parts than the baseline. They also release their code for others to use.'}",supervised,['News'],[]
SP:c953185cf5226f499c3678e872080df11294f928,Aspect and Opinion Aware Abstractive Review Summarization with Reinforced Hard Typed Decoder,CIKM,2019,"['Yufei Tian', 'Jianfei Yu', 'Jing Jiang']","In this paper, we study abstractive review summarization. Observing that review summaries often consist of aspect words, opinion words and context words, we propose a two-stage reinforcement learning approach, which first predicts the output word type from the three types, and then leverages the predicted word type to generate the final word distribution. Experimental results on two Amazon product review datasets demonstrate that our method can consistently outperform several strong baseline approaches based on ROUGE scores.",System: The paper discusses a two-stage reinforcement learning approach for abstractive review summarization. The approach predicts the output word type and then generates the final word distribution based on the predicted word type. The method outperforms several strong baseline approaches based on ROUGE scores in experimental results on two Amazon product review datasets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of product reviews posted on e-commerce platforms by online shoppers to improve product quality and keep track of customer preferences.', 'Who is the target audience?': 'The summaries are for businesses to help them improve product quality and keep track of customer preferences.', 'How will the summaries be used?': 'The summaries will be used to automatically generate concise and readable summaries for product reviews, which is often referred to as review summarization.'}",['method'],['Objective Function'],['Amazon Product Reviews'],['ROUGE'],[''],,https://arxiv.org/abs/2004.05755,"{'It is impractical to manually read through each review, especially when they are lengthy and have low readability, given the large amount of product reviews in real scenarios.': 'Design a robust model to automatically generate concise and readable summaries for product reviews, which is often referred to as review summarization.', 'Existing approaches to review summarization generally belong to two groups: extractive summarization and abstractive summarization.': 'Develop an effective model that can generate a concise summary for a single input review.', 'Current representative encoder-decoder frameworks tend to produce generic summaries with high-frequency phrases, which often fail to include those less frequent aspect or opinion words that are also essential to review summaries.': 'Propose a two-stage Reinforced Hard Typed Decoder (RHTD) that explicitly controls word types when generating the review summary, classifying all the vocabulary words into three types: aspect words, opinion words, and context words.'}",reinforced,['Reviews'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:dbe688ab041544756e1c8d1af494ec0e58580e09,Concept Pointer Network for Abstractive Summarization,EMNLP,2019,"['Wang Wenbo', 'Gao Yang', 'Zhou Yuxiang']","A quality abstractive summary should not only copy salient source texts as summaries but should also tend to generate new conceptual words to express concrete details. Inspired by the popular pointer generator sequence-tosequence model, this paper presents a concept pointer network for improving these aspects of abstractive summarization. The network leverages knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts. The model then points to the most appropriate choice using both the concept set and original source text. This joint approach generates abstractive summaries with higher-level semantic concepts. The training model is also optimized in a way that adapts to different data, which is based on a novel method of distantly-supervised learning guided by reference summaries and testing set. Overall, the proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC2004 and Gigaword datasets. A human evaluation of the model’s abstractive abilities also supports the quality of the summaries produced within this framework.","The paper proposes a concept pointer network for improving abstractive summarization by generating new conceptual words to express concrete details. The network uses knowledge-based, context-aware conceptualizations to derive an extended set of candidate concepts and points to the most appropriate choice using both the concept set and original source text. The training model is optimized using a novel method of distantly-supervised learning guided by reference summaries and testing set. The proposed approach provides statistically significant improvements over several state-of-the-art models on both the DUC2004 and Gigaword datasets, and a human evaluation supports the quality of the summaries produced within this framework.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide informative and abstract-oriented summaries that reflect high-level semantics.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, as well as to provide a quick overview of the main points for decision-making or further research.'}",['method'],"['External Knowledge', 'Objective Function']","['Gigaword', 'DUC 2004']",['ROUGE'],"['Abstraction', 'Overall Quality']",https://github.com/wprojectsn/codes,https://aclanthology.org/D19-1304,"{'Abstractive summarization models often fail to generate abstract and conceptual words, relying instead on copying verbatim words from the source text.': 'The authors propose a novel model based on a concept pointer generator that encourages the generation of conceptual and abstract words. The model uses a pointer network to capture salient information from the source text and employs another pointer to generalize detailed words according to their upper level of expressions. The learned concept pointer points to the most suitable and expressive concepts or words.', 'Pointer generator networks that solely consider the source material to generate a summary do not adequately satisfy the needs of high-quality abstractive summarization.': 'The authors argue that concepts from world knowledge have a greater ability to express deeper meanings than verbatim words. Their proposed model not only points to informative source texts but also leverages conceptual words from human knowledge in the summaries it generates.', 'Out-of-vocabulary (OOV) words are a problem associated with generative-based models.': 'The authors use a pointer mechanism to determine the probability of generating a word from both a vocabulary distribution and the source text, which alleviates the OOV problem.', 'The optimization function needs to be adaptive to cater for different datasets with distantly-supervised training.': 'The authors propose a novel distant supervision training strategy that favors model adaptation and generalization, which results in performance that outperforms the well-accepted evaluation-based reinforcement learning optimization on a test-only dataset in terms of ROUGE metrics.', 'The proposed model needs to be evaluated against several state-of-the-art models to show its promising performance.': 'The authors conduct a statistical analysis of quantitative results and human evaluations from comparative experiments with several state-of-the-art models that shows the proposed method provides promising performance.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:841ad2ced4db8b4542749164a1775e04cf5a247d,How to Write Summaries with Patterns? Learning towards Abstractive Summarization through Prototype Editing,EMNLP,2019,"['Shen Gao', 'Xiuying Chen', 'Piji Li', 'Zhangming Chan', 'Dongyan Zhao', 'Rui Yan']","Under special circumstances, summaries should conform to a particular style with patterns, such as court judgments and abstracts in academic papers. To this end, the prototype document-summary pairs can be utilized to generate better summaries. There are two main challenges in this task: (1) the model needs to incorporate learned patterns from the prototype, but (2) should avoid copying contents other than the patternized words— such as irrelevant facts—into the generated summaries. To tackle these challenges, we design a model named Prototype Editing based Summary Generator (PESG). PESG first learns summary patterns and prototype facts by analyzing the correlation between a prototype document and its summary. Prototype facts are then utilized to help extract facts from the input document. Next, an editing generator generates new summary based on the summary pattern or extracted facts. Finally, to address the second challenge, a fact checker is used to estimate mutual information between the input document and generated summary, providing an additional signal for the generator. Extensive experiments conducted on a large-scale real-world text summarization dataset1 show that PESG achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations.","The paper introduces a model called Prototype Editing based Summary Generator (PESG) that utilizes prototype document-summary pairs to generate better summaries that conform to a particular style with patterns. The model addresses two challenges: incorporating learned patterns from the prototype while avoiding copying irrelevant facts, and generating new summaries based on the summary pattern or extracted facts. A fact checker is used to estimate mutual information between the input document and generated summary, resulting in state-of-the-art performance in both automatic metrics and human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve summarization performance when generating summaries with a specific pattern, such as court judgments, diagnosis certificates, abstracts in academic papers, etc.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, such as judges, doctors, researchers, etc.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the main points of a long document, without having to read the entire document. They can be used to make decisions, provide diagnoses, or understand the main findings of a research paper.'}","['corpus', 'method']","['Unit Selection', 'External Knowledge']",['Court Judgment Summarization Corpus'],"['ROUGE', 'BERTScore']","['Fluency', 'Consistency']",https://github.com/gsh199449/proto-summ,https://aclanthology.org/D19-1388,"{'Existing prototype based generation models are not suitable for long document summarization tasks.': 'The authors propose a summarization framework named Prototype Editing based Summary Generator (PESG) that incorporates prototype document-summary pairs to improve summarization performance when generating summaries with pattern.', 'Template-based methods are too rigid for patternized summary generation tasks.': 'The authors propose to calculate the cross dependency between the prototype document-summary pair to obtain a summary pattern and prototype facts. Then, they extract facts from the input document with the help of the prototype facts.', 'The generator may copy irrelevant facts from the prototype.': 'The authors design a fact checker to provide mutual information between the generated summary and the input document to prevent the generator from copying irrelevant facts from the prototype.', 'Lack of a large-scale prototype based summarization dataset.': 'The authors collect a large-scale court judgment dataset, where each judgment is a summary of the case description with a patternized style. They release this dataset to benefit the community.'}",supervised,['Legal Proceedings'],"['exploiting-the-structure-of-long-documents', 'hallucinations-in-the-generated-summaries']"
SP:73d9ecd090a666d1b7dfb736223cc8f5451d4748,Summary Level Training of Sentence Rewriting for Abstractive Summarization,EMNLP,2019,"['Sanghwan Bae', 'Taeuk Kim', 'Jihoon Kim', 'Sang-goo Lee']","As an attempt to combine extractive and abstractive summarization, Sentence Rewriting models adopt the strategy of extracting salient sentences from a document first and then paraphrasing the selected ones to generate a summary. However, the existing models in this framework mostly rely on sentence-level rewards or suboptimal labels, causing a mismatch between a training objective and evaluation metric. In this paper, we present a novel training signal that directly maximizes summary-level ROUGE scores through reinforcement learning. In addition, we incorporate BERT into our model, making good use of its ability on natural language understanding. In extensive experiments, we show that a combination of our proposed model and training procedure obtains new state-of-the-art performance on both CNN/Daily Mail and New York Times datasets. We also demonstrate that it generalizes better on DUC-2002 test set.","The paper proposes a new approach to combining extractive and abstractive summarization using Sentence Rewriting models. The existing models in this framework rely on suboptimal labels, causing a mismatch between the training objective and evaluation metric. The authors present a novel training signal that directly maximizes summary-level ROUGE scores through reinforcement learning and incorporate BERT into their model. They show that their proposed model and training procedure obtain new state-of-the-art performance on both CNN/Daily Mail and New York Times datasets and generalize better on DUC-2002 test set.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress the text into a shorter highlight while retaining important information.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they may be useful for quickly understanding the main points of a document without having to read the entire text.'}",['method'],"['Objective Function', 'Unit Selection']","['CNN/DailyMail', 'NYT', 'DUC 2002']",['ROUGE'],"['Relevance', 'Readability']",,https://aclanthology.org/D19-5402,"{'The performance improvement from pretrained language models (LMs) is relatively small in case of abstractive summarization.': 'The authors propose a novel neural extractor that exploits pre-trained LMs (BERT in this work) to improve the performance of abstractive summarization models.', 'There is a mismatch between the training objective and evaluation metric in previous work on abstractive summarization.': 'The authors propose to directly use summary-level ROUGE scores as an objective instead of sentence-level scores. They also use reward shaping to alleviate the sparsity of training signals.', 'The existing extractor in the Reinforce-Selected Sentence Rewriting model has a bottleneck and its performance as an independent summarization model is no better than solid baselines.': 'The authors present a novel neural extractor that exploits pre-trained LMs to improve the performance of the extractor in the Reinforce-Selected Sentence Rewriting model. They also fine-tune the extractor with rewards derived from sentence-level ROUGE scores of the summary generated from the abstractor.'}",reinforced,['News'],['robust-evaluation-methods']
SP:e87d5a1c56324f4687ddb7fa2fb4d4889f30a645,Deep Reinforcement Learning with Distributional Semantic Rewards for Abstractive Summarization,EMNLP,2019,"['Siyao Li', 'Deren Lei', 'Pengda Qin', 'William Yang Wang']","Deep reinforcement learning (RL) has been a commonly-used strategy for the abstractive summarization task to address both the exposure bias and non-differentiable task issues. However, the conventional reward ROUGE-L simply looks for exact n-grams matches between candidates and annotated references, which inevitably makes the generated sentences repetitive and incoherent. In this paper, instead of ROUGE-L, we explore the practicability of utilizing the distributional semantics to measure the matching degrees. With distributional semantics, sentence-level evaluation can be obtained, and semantically-correct phrases can also be generated without being limited to the surface form of the reference sentences. Human judgments on Gigaword and CNN/Daily Mail datasets show that our proposed distributional semantics reward (DSR) has distinct superiority in capturing the lexical and compositional diversity of natural language.","The paper discusses the limitations of using conventional reward measures for deep reinforcement learning in abstractive summarization tasks, which can result in repetitive and incoherent sentences. Instead, the authors propose using distributional semantics to measure the matching degrees, allowing for sentence-level evaluation and the generation of semantically-correct phrases. The proposed distributional semantics reward (DSR) is shown to have superior performance in capturing the lexical and compositional diversity of natural language, based on human judgments on Gigaword and CNN/Daily Mail datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long articles to paraphrase them with fewer words.', 'Who is the target audience?': 'The target audience for these summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not mention how the generated summaries will be used.'}",['method'],['Objective Function'],"['Gigaword', 'CNN/DailyMail']","['ROUGE', 'BERTScore']","['Coherence', 'Fluency']",,https://aclanthology.org/D19-1623,"{'Long sentence generation suffers from exposure bias as the error accumulates during the decoding process.': 'The authors propose using innovative deep RL methods that provide sentence-level feedback after generating a complete sentence, in addition to optimal transport usage, to alleviate the issue.', 'Commonly used automatic evaluation metrics for generating sentence-level rewards count exact n-grams matches and are not robust to different words that share similar meanings since the semantic level reward is deficient.': 'The authors propose using distributional semantic reward (DSR) to boost the RL-based abstractive summarization system. They argue that contextualized word representations have a powerful capacity of reflecting distributional semantic.', 'The conventional objectives used in abstractive summarization do not improve sentence fluency.': 'The authors design several novel objective functions that outperform the conventional objectives while increasing the sentence fluency. They claim that DSR improves generated tokens’ diversity and fluency while avoiding unnecessary repetitions.', 'ROUGE relies on crossentropy loss (XENT) to produce readable phrases, which introduces exposure bias.': 'Unlike ROUGE, DSR does not rely on XENT to produce readable phrases, thus avoiding exposure bias.'}",reinforced,['News'],[]
SP:e7e17fefd63b42fcc3d922cbdbfbcb7852adf4a6,Improving Abstractive Document Summarization with Salient Information Modeling,ACL,2019,"['Yongjian You', 'Weijia Jia', 'Tianyi Liu', 'Wenmian Yang']","Comprehensive document encoding and salient information selection are two major difficulties for generating summaries with adequate salient information. To tackle the above difficulties, we propose a Transformerbased encoder-decoder framework with two novel extensions for abstractive document summarization. Specifically, (1) to encode the documents comprehensively, we design a focus-attention mechanism and incorporate it into the encoder. This mechanism models a Gaussian focal bias on attention scores to enhance the perception of local context, which contributes to producing salient and informative summaries. (2) To distinguish salient information precisely, we design an independent saliency-selection network which manages the information flow from encoder to decoder. This network effectively reduces the influences of secondary information on the generated summaries. Experimental results on the popular CNN/Daily Mail benchmark demonstrate that our model outperforms other state-of-the-art baselines on the ROUGE metrics.","The paper proposes a Transformer-based encoder-decoder framework with two novel extensions for abstractive document summarization. The first extension is a focus-attention mechanism that models a Gaussian focal bias on attention scores to enhance the perception of local context, contributing to producing salient and informative summaries. The second extension is an independent saliency-selection network that manages the information flow from encoder to decoder, effectively reducing the influences of secondary information on the generated summaries. Experimental results on the CNN/Daily Mail benchmark show that the proposed model outperforms other state-of-the-art baselines on the ROUGE metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the given documents and generate fluent summaries with salient information automatically.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be used in various applications such as news article summarization, legal document summarization, and scientific paper summarization.'}",['method'],['Objective Function'],['CNN/DailyMail'],"['ROUGE', 'Sentence Coverage', 'Jaccard Similarity', 'Novel BiGram Repetition']",[''],,https://aclanthology.org/P19-1205,"{'Traditional seq2seq encoders are deficient in modeling dependencies among distant segments, which leads to generating incomplete summaries.': 'The authors propose the Extended Transformer model for Abstractive Document Summarization (ETADS) which employs a focus-attention mechanism to encode documents comprehensively. This mechanism uses a learnable Gaussian focal bias as a regularization term on attention scores to implicitly aggregate attention on local continuous scopes and emphasize the corresponding part of the document.', 'Naive seq2seq models find it laborious to distinguish important information from much secondary information in long documents, leading to loss of salient information or even repetitions in the generated summaries.': 'The authors propose an independent saliency-selection network to manage the information flow from encoder to decoder explicitly. This network employs a gate mechanism to assign a salient score for each token in source documents according to their encoded representations. The lower-score tokens are considered relatively insignificant and their likelihood of appearing in final summaries is reduced.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:c3721991bde908de556b733ba9d9880a90d7c51a,In Conclusion Not Repetition: Comprehensive Abstractive Summarization With Diversified Attention Based On Determinantal Point Processes,CONLL,2019,"['Lei Li', 'Wei Liu', 'Marina Litvak', 'Natalia Vanetik', 'Zuying Huang']","Various Seq2Seq learning models designed for machine translation were applied for abstractive summarization task recently. Despite these models provide high ROUGE scores, they are limited to generate comprehensive summaries with a high level of abstraction due to its degenerated attention distribution. We introduce Diverse Convolutional Seq2Seq Model(DivCNN Seq2Seq) using Determinantal Point Processes methods(Micro DPPs and Macro DPPs) to produce attention distribution considering both quality and diversity. Without breaking the end to end architecture, DivCNN Seq2Seq achieves a higher level of comprehensiveness compared to vanilla models and strong baselines. All the reproducible codes and datasets are available online1.",The paper discusses the limitations of existing Seq2Seq models for abstractive summarization and introduces a new model called DivCNN Seq2Seq that uses Determinantal Point Processes methods to produce attention distribution that considers both quality and diversity. The new model achieves a higher level of comprehensiveness compared to existing models and strong baselines without breaking the end-to-end architecture. The reproducible codes and datasets are available online.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for abstractive summarization, which aims to generate short sentences covering the main idea of the original article.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the main idea of a document without reading the entire article.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main idea of a document, to decide whether to read the full article, or to provide a brief overview of the article to others.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'Newsroom', 'TLDR', 'BigPatent', 'WikiHow']",['ROUGE'],[''],https://github.com/thinkwee/DPP_CNN_Summarization,https://aclanthology.org/K19-1077,"{'Attention in summarization may be over concentrated, causing problems like generating duplicate words or sentences.': 'Introduce various attention structures, including local attention, hierarchical attention, distraction attention, and coverage mechanism.', 'Original Text Repetition problem in abstractive summarization caused by degenerated attention distributions.': 'Introduce DPPs into deep neural network (DNN) attention adjustment and propose DivCNN Seq2Seq. Introduce two kinds of methods: Micro DPPs and Macro DPPs.', 'Lack of attention to both quality and diversity in adjusting attention distributions.': 'Adjust attention distributions considering both quality and diversity using DPPs.', 'Inadequate evaluation of models on open datasets.': 'Evaluate models on six open datasets and show their superiority in improving the comprehensiveness of generated summaries without losing much training and inference speed.'}",supervised,"['News', 'Social Media', 'Scholarly Documents', 'CQA']",[]
SP:6418fbc4e07157b90abfa3f2081fa62321d99373,Abstractive Summarization of Reddit Posts with Multi-level Memory Networks,NAACL,2019,"['Byeongchang Kim', 'Hyunwoo Kim', 'Gunhee Kim']","ive Summarization of Reddit Posts with Multi-level Memory Networks Byeongchang Kim Hyunwoo Kim Gunhee Kim Department of Computer Science and Engineering & Center for Superintelligence Seoul National University, Seoul, Korea {byeongchang.kim,hyunwoo.kim}@vision.snu.ac.kr gunhee@snu.ac.kr http://vision.snu.ac.kr/projects/reddit-tifu","

System: The paper discusses a method for summarizing Reddit posts using multi-level memory networks. The authors propose a model that can capture the important information in a post and generate a summary that accurately reflects the content. The model uses both word-level and sentence-level representations to capture the meaning of the post and the relationships between different parts of the text. The authors evaluate their model on a dataset of TIFU (Today I Fucked Up) posts from Reddit and show that it outperforms several baseline methods in terms of ROUGE scores.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization methods.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to provide a quick overview of the main points of the document.'}","['corpus', 'method']",['Input Encoding'],['Reddit-TIFU'],['ROUGE'],['Relevance'],http://vision.snu.ac.kr/projects/reddit-tifu,https://aclanthology.org/N19-1260/,"{'Abstractive summarization methods often suffer from inferior performance compared to extractive methods due to biases in existing summarization datasets.': 'The authors propose to alleviate this bias issue by changing the source of summarization dataset to user-generated posts from the online discussion forum Reddit, especially TIFU subreddit, which are more casual and conversational than news articles.', 'Abstractive methods trained on existing datasets may not show much abstraction because they are implicitly forced to learn structural patterns.': 'The authors propose to use the new Reddit TIFU dataset, which disallows models to simply rely on locational biases for summarization and contains passages that rarely contain sentences that are nearly identical to the gold summary.', 'RNNs accumulate information in a few fixed-length memories at every step regardless of the length of an input sequence, and thus may fail to utilize far-distant information due to vanishing gradient.': 'The authors propose a novel memory network model named multilevel memory networks (MMN) that explicitly captures long-term information and exploits a set of convolution operations with different receptive fields to build representations of not only multiple levels but also multiple ranges (e.g. sentences, paragraphs, and the whole document).', 'RNNs cannot build representations of different ranges, since hidden states are sequentially connected over the whole sequence.': 'The proposed MMN model can build representations of not only multiple levels but also multiple ranges (e.g. sentences, paragraphs, and the whole document).', 'Existing abstractive summarization methods with seq2seq architecture may not perform well on long input sequences.': 'The proposed MMN model improves abstractive summarization performance on both the new Reddit TIFU and existing Newsroom-Abs and XSum datasets and outperforms several state-of-the-art abstractive models with seq2seq architecture.'}",supervised,['Social Media'],[]
SP:5572934118c928383f97634ad5cac8651b7ffdbe,Abstractive Text Summarization Based on Deep Learning and Semantic Content Generalization,ACL,2019,"['Panagiotis Kouris', 'Georgios Alexandridis', 'Andreas Stafylopatis']","This work proposes a novel framework for enhancing abstractive text summarization based on the combination of deep learning techniques along with semantic data transformations. Initially, a theoretical model for semantic-based text generalization is introduced and used in conjunction with a deep encoder-decoder architecture in order to produce a summary in generalized form. Subsequently, a methodology is proposed which transforms the aforementioned generalized summary into human-readable form, retaining at the same time important informational aspects of the original text and addressing the problem of out-of-vocabulary or rare words. The overall approach is evaluated on two popular datasets with encouraging results.",The paper presents a new method for improving abstractive text summarization using deep learning and semantic data transformations. The method involves using a theoretical model for semantic-based text generalization along with a deep encoder-decoder architecture to produce a summary in generalized form. The summary is then transformed into a human-readable form while retaining important information and addressing the problem of out-of-vocabulary or rare words. The approach is evaluated on two datasets with positive results.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide a concise version of the original text while retaining its salient information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key information of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding documents, especially in cases where manual summarization is time-consuming and laborious.'}",['method'],"['Objective Function', 'Post Processing']","['Gigaword', 'DUC 2004']","['ROUGE', 'nDCG']",[''],https://github.com/pkouris/abtextsum,https://aclanthology.org/P19-1501,"{'Manual text summarization is a demanding, time-consuming, and laborious task.': 'Automatic text summarization is gaining popularity and is a strong motivation for further research.', 'Current efforts in automatic text summarization mainly focus on summarizing single and multi-documents while preserving key informational elements and the meaning of content.': 'The authors propose a novel abstractive text summarization technique that combines deep learning models of encoder-decoder architecture and semantic-based data transformations.', 'Abstractive text summarization is a more challenging task than extractive text summarization.': 'The proposed approach introduces a framework that combines the potential of machine learning with the importance of semantics to bridge the gap between the two approaches.', 'The majority of literature in abstractive text summarization focuses on either the theoretical model or the deep learning network.': 'The proposed framework comprises three components, including a methodology of transforming the ""generalized"" summary into a human-readable form, containing salient information of the original document.', 'Out-of-vocabulary (OOV) words or words of limited occurrences pose a problem in achieving semantic content generalization.': 'The proposed framework is capable of coping with the problem of OOV words, thereby achieving semantic content generalization.', 'The effectiveness of the proposed framework is unknown.': 'The overall architecture is evaluated on Gigaword and Duc 2004, two popular datasets used in text summarization tasks, with the obtained results being promising and outperforming the current state-of-the-art.'}",supervised,['News'],[]
SP:6886de04449362649602767de8e5b3ec71fbaad3,Scoring Sentence Singletons and Pairs for Abstractive Summarization,ACL,2019,"['Logan Lebanoff', 'Kaiqiang Song', 'Franck Dernoncourt', 'Doo Soon Kim', 'Seokhwan Kim', 'Walter Chang', 'Fei Liu']","When writing a summary, humans tend to choose content from one or two sentences and merge them into a single summary sentence. However, the mechanisms behind the selection of one or multiple source sentences remain poorly understood. Sentence fusion assumes multi-sentence input; yet sentence selection methods only work with single sentences and not combinations of them. There is thus a crucial gap between sentence selection and fusion to support summarizing by both compressing single sentences and fusing pairs. This paper attempts to bridge the gap by ranking sentence singletons and pairs together in a unified space. Our proposed framework attempts to model human methodology by selecting either a single sentence or a pair of sentences, then compressing or fusing the sentence(s) to produce a summary sentence. We conduct extensive experiments on both singleand multidocument summarization datasets and report findings on sentence selection and abstraction.","The paper discusses the challenge of summarizing text by both compressing single sentences and fusing pairs, as sentence selection methods only work with single sentences and not combinations of them. The authors propose a framework that ranks sentence singletons and pairs together in a unified space, modeling human methodology by selecting either a single sentence or a pair of sentences and compressing or fusing them to produce a summary sentence. The framework was tested on both single and multidocument summarization datasets, with findings reported on sentence selection and abstraction.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to present the main points of an article in a succinct and coherent manner.', 'Who is the target audience?': 'The target audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but the authors propose a method to learn to select sentence singletons and pairs, which then serve as the basis for an abstractive summarizer to compose a summary sentence-by-sentence, where singletons are shortened (i.e., compressed) and pairs are merged (i.e., fused).'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'XSum', 'DUC 2004']",['ROUGE'],[''],https://github.com/ucfnlp/summarization-sing-pair-mix,https://aclanthology.org/P19-1209,"{'There is a gap between sentence selection and fusion to support summarizing by both compressing single sentences and fusing pairs.': 'The authors propose to bridge the gap by ranking singletons and pairs together by their likelihoods of producing summary sentences.', 'System summaries can sometimes contain erroneous details and forged content.': 'The authors propose to separate the tasks of content selection and summary generation to closely examine the compressing and fusing mechanisms of an abstractive summarizer.', 'There lacks a mechanism to weigh sentence singletons and pairs in a unified space.': 'The authors propose a method to learn to select sentence singletons and pairs, which then serve as the basis for an abstractive summarizer to compose a summary sentence-by-sentence, where singletons are shortened (i.e., compressed) and pairs are merged (i.e., fused).', 'There is a need to investigate the factors involved in representing sentence singletons and pairs.': 'The authors investigate the factors involved in representing sentence singletons and pairs and perform extensive experiments to report findings on sentence selection and abstraction.'}",supervised,['News'],[]
SP:a2fce770da379f54aedff59af29a8f2adbf92db5,BiSET: Bi-directional Selective Encoding with Template for Abstractive Summarization,ACL,2019,"['Kai Wang', 'Xiaojun Quan', 'Rui Wang']","The success of neural summarization models stems from the meticulous encodings of source articles. To overcome the impediments of limited and sometimes noisy training data, one promising direction is to make better use of the available training data by applying filters during summarization. In this paper, we propose a novel Bi-directional Selective Encoding with Template (BiSET) model, which leverages template discovered from training data to softly select key information from each source article to guide its summarization process. Extensive experiments on a standard summarization dataset were conducted and the results show that the template-equipped BiSET model manages to improve the summarization performance significantly with a new state of the art.",The paper proposes a new model called Bi-directional Selective Encoding with Template (BiSET) for summarizing articles. The model uses templates discovered from training data to select key information from source articles and guide the summarization process. The experiments conducted on a standard summarization dataset show that the BiSET model significantly improves the summarization performance and achieves a new state of the art.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to shorten the source article or paragraph while preserving the main idea.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Unit Selection'],['Gigaword'],['ROUGE'],"['Informativeness', 'Conciseness', 'Readability']",https://github.com/InitialBug/BiSET,https://aclanthology.org/P19-1207/,"{'Sequence-to-sequence models tend to deteriorate with the accumulation of word generation, generating irrelevant and repeated words frequently due to the complexity and verbosity of natural language text and insufficient training data to distinguish important information from noise.': 'The authors propose a Bi-directional Selective Encoding with Template (BiSET) model for abstractive sentence summarization that involves a novel bi-directional selective layer with two gates to mutually select key information from an article and its template to assist with summary generation.', 'Creating hard templates manually for template-based summarization is unrealistic due to the considerable domain knowledge and labor-intensive work required.': 'The authors propose a multi-stage process for automatic retrieval of high-quality templates from the training corpus, referred to as soft templates, to exploit their potential in relieving the verbosity and insufficiency problems of natural language data.', 'Templates have not been exploited to full advantage in previous works, such as simply concatenating template encoding after the source article in summarization work.': 'The authors propose a novel bi-directional selective mechanism with two gates to mutually select important information from both article and template to assist with summary generation, and demonstrate the effectiveness of their approach in generating informative, concise, and readable summaries through extensive experiments and human evaluation.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:f3067b35450380ca17a466339b3ccd83a37cd772,Neural Query-Biased Abstractive Summarization Using Copying Mechanism,ECIR,2020,"['Tatsuya Ishigaki1(B', 'Hen-Hsen Huang', 'Hiroya Takamura', 'Hsin-Hsi Chen', 'Manabu Okumura']","This paper deals with the query-biased summarization task. Conventional non-neural network-based approaches have achieved better performance by primarily including the words overlapping between the source and the query in the summary. However, recurrent neural network (RNN)-based approaches do not explicitly model this phenomenon. Therefore, we model an RNN-based query-biased summarizer to primarily include the overlapping words in the summary, using a copying mechanism. Experimental results, in terms of both automatic evaluation with ROUGE and manual evaluation, show that the strategy to include the overlapping words also works well for neural query-biased summarizers.","System: The paper discusses the query-biased summarization task and how conventional approaches have achieved better performance by including overlapping words between the source and the query in the summary. However, RNN-based approaches do not explicitly model this phenomenon. The paper proposes an RNN-based query-biased summarizer that primarily includes overlapping words in the summary using a copying mechanism. Experimental results show that this strategy works well for neural query-biased summarizers.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to be used as snippets for search engine results.', 'Who is the target audience?': 'The summaries are intended to be used by search engines.', 'How will the summaries be used?': 'The summaries will be used as snippets for search engine results.'}",['method'],['Objective Function'],['Debatepedia'],['ROUGE'],"['Readability', 'Responsiveness']",,https://doi.org/10.1007/978-3-030-45442-5_22,"{'Conventional query-biased summarization approaches are mostly extractive and use overlapping words as cues to calculate the salience score of a sentence.': 'The authors propose incorporating the strategy of including overlapping words into RNN-based summarizers using copying mechanisms.', 'Copying mechanisms were originally designed for settings without query information, and it is not clear how to integrate them into a query-biased summarizer.': 'The authors propose three copying mechanisms designed for query-biased summarizers: copying from the source, copying the overlapping words, and copying the overlapping words and their surroundings.', 'RNN-based summarizers do not explicitly model the strategy of including overlapping words.': 'The authors propose using copying mechanisms to explicitly include overlapping words in the summary.', 'It is not clear which copying mechanism performs best for query-biased summarization.': 'The authors empirically show that the models copying the overlapping words perform better.', 'Lack of diversity in summaries generated by query-biased summarizers.': 'The authors focus on copying mechanisms to improve the inclusion of relevant information in the summary, rather than on diversity.'}",supervised,['Arguments'],[]
SP:8832c09f81b71bf69d0e56646cc7c90dcbb50468,The Summary Loop: Learning to Write Abstractive Summaries Without Examples,ACL,2020,"['Philippe Laban', 'Andrew Hsi']","This work presents a new approach to unsupervised abstractive summarization based on maximizing a combination of coverage and fluency for a given length constraint. It introduces a novel method that encourages the inclusion of key terms from the original document into the summary: key terms are masked out of the original document and must be filled in by a coverage model using the current generated summary. A novel unsupervised training procedure leverages this coverage model along with a fluency model to generate and score summaries. When tested on popular news summarization datasets, the method outperforms previous unsupervised methods by more than 2 R-1 points, and approaches results of competitive supervised methods. Our model attains higher levels of abstraction with copied passages roughly two times shorter than prior work, and learns to compress and merge sentences without supervision.",The paper presents a new approach to unsupervised abstractive summarization that maximizes coverage and fluency while adhering to a length constraint. The method includes key terms from the original document and uses a coverage model to fill them in the generated summary. The unsupervised training procedure uses both coverage and fluency models to generate and score summaries. The method outperforms previous unsupervised methods by more than 2 R-1 points and approaches results of competitive supervised methods. The model attains higher levels of abstraction with shorter copied passages and learns to compress and merge sentences without supervision.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the main points into a shorter document.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they are important for many text domains such as headlines for news and abstracts for research papers.'}",['method'],"['Unit Selection', 'Objective Function']","['CNN/DailyMail', 'Newsroom']",['ROUGE'],[''],https://github.com/CannyLab/summary_loop,https://aclanthology.org/2020.acl-main.460,"{'Inducing good coverage of important concepts from the original article.': 'The authors propose a coverage model that takes as input the original document with keywords masked out. It uses the current best automatically generated summary to try to uncover the missing keywords. The resulting coverage score is fed back into the training process of the summarization model with the objective of producing summaries with high coverage.', 'Unsupervised training procedure for summarization.': 'The authors propose the Summary Loop, which leverages the coverage model as well as a simple fluency model to generate and score summaries. During training, the procedure is conditioned on a desired summary length, forcing the Summarizer model to adapt to a length budget.', 'Guiding the model away from pathological behavior.': 'The authors employ a set of specialized techniques during training to guide the model away from pathological behavior. These guard rails include a method for reducing repetition, for encouraging the model to complete sentences, and to avoid frame filling patterns.'}",unsupervised,['News'],['controlled-and-tailored-summarization']
SP:1ad906029463b57f80887ca67fa7fa305617c894,Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization,ACL,2020,"['Sajad Sotudeh', 'Nazli Goharian', 'Ross W. Filice']","Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9% RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of improvement impacts patients’ welfare.","The paper discusses the limitations of the seq2seq network in identifying key regions of the source for text summarization. The authors propose a solution by augmenting salient ontological terms into the summarizer for clinical abstractive summarization. Their experiments on two clinical data sets show that their model significantly improves state-of-the-art results in terms of ROUGE metrics, which is important in the healthcare domain where any improvement can impact patients’ welfare.","{'What is the purpose of the summaries?': 'The authors are generating summaries of radiology reports to communicate critical findings to referring clinicians and save their read time.', 'Who is the target audience?': 'The summaries are for referring clinicians who have less time to review lengthy or intricate findings.', 'How will the summaries be used?': ""The summaries will be used to improve patients' well-being by automating the process of impression generation in radiology reporting, saving clinicians' read time, and decreasing fatigue. Clinicians would only need to proofread summaries or make minor edits.""}",['method'],"['External Knowledge', 'Unit Selection']",['MIMIC-CXR'],['ROUGE'],"['Readability', 'Accuracy', 'Completeness']",,https://aclanthology.org/2020.acl-main.172,"{""Generating IMPRESSION from FINDINGS can be subject to errors, which can have a negative impact on patients' well-being."": ""Automating the process of impression generation in radiology reporting would save clinicians' read time and decrease fatigue. The authors propose a novel seq2seq-based model to incorporate the salient clinical terms into the summarizer, which can improve the final IMPRESSION generation."", 'Clinicians mostly read the IMPRESSION as they have less time to review findings, particularly those that are lengthy or intricate.': 'The authors hypothesize that selecting the most significant clinical terms occurring in the FINDINGS and then incorporating them into the summarization would improve the final IMPRESSION generation. They further examine if refining FINDINGS word representations according to the identified clinical terms would result in improved IMPRESSION generation.', 'Previous studies have reported that augmenting the summarizer with entire ontology (i.e., clinical) terms within the FINDINGS can improve the content selection and summary generation to some noticeable extent.': 'The authors build on this previous work and propose to further improve the summarization process by selecting only the most significant clinical terms and incorporating them into the summarizer. They also use a sequence-tagger to learn the copying likelihood of a word as an indicator of its saliency in terms of forming IMPRESSION.', 'The effectiveness of the proposed model needs to be evaluated on different clinical datasets to assess its cross-organizational transferability.': 'The authors evaluate their model on two publicly available clinical datasets (MIMIC-CXR and OpenI) and show that it statistically significantly improves over competitive baselines.'}",supervised,['Medical Reports'],[]
SP:1d05457fc18ac94caab06a83d300b71b889715d3,Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward,ACL,2020,"['Luyang Huang', 'Lingfei Wu', 'Lu Wang', 'John M. Fabrizi', 'Joseph P. Ganim']","Sequence-to-sequence models for abstractive summarization have been studied extensively, yet the generated summaries commonly suffer from fabricated content, and are often found to be near-extractive. We argue that, to address these issues, the summarizer should acquire semantic interpretation over input, e.g., via structured representation, to allow the generation of more informative summaries. In this paper, we present ASGARD, a novel framework for Abstractive Summarization with GraphAugmentation and semantic-driven RewarD. We propose the use of dual encoders—a sequential document encoder and a graphstructured encoder—to maintain the global context and local characteristics of entities, complementing each other. We further design a reward based on a multiple choice cloze test to drive the model to better capture entity interactions. Results show that our models produce significantly higher ROUGE scores than a variant without knowledge graph as input on both New York Times and CNN/Daily Mail datasets. We also obtain better or comparable performance compared to systems that are finetuned from large pretrained language models. Human judges further rate our model outputs as more informative and containing fewer unfaithful errors.","The paper discusses the limitations of current sequence-to-sequence models for abstractive summarization and proposes a new framework called ASGARD, which uses dual encoders and a reward system based on a multiple choice cloze test to better capture entity interactions and generate more informative summaries. The authors show that their models produce significantly higher ROUGE scores and are rated as more informative and containing fewer errors by human judges compared to other systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to promote efficient information consumption and knowledge acquisition.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding the content of a document. They can also be used for information retrieval and knowledge management.'}",['method'],"['External Knowledge', 'Input Encoding']","['CNN/DailyMail', 'NYT']","['ROUGE', 'BERTScore']","['Informativeness', 'Fluency', 'Faithfulness']",https://github.com/luyang-huang96/GraphAugmentedSum,https://aclanthology.org/2020.acl-main.457,"{'Existing sequence-to-sequence-based neural models for single-document abstractive summarization frequently produce unfaithful content and near-extractive summaries due to the limitations of model structure and word prediction-based learning objectives.': 'The authors propose ASGARD, a framework for Abstractive Summarization with Graph-Augmentation and semantic-driven RewarD, which enhances the regular document encoder with a separate graph-structured encoder to maintain the global context and local characteristics of entities by using the outputs from an open information extraction (OpenIE) system.', 'Existing models lack semantic interpretation over the input, which is critical for summarization.': 'The authors argue that the generation of informative and succinct abstracts requires structured representation to facilitate the connection of relevant subjects, and the preservation of global context, e.g. entity interactions and topic flows. They propose using graph neural networks to explicitly encode entity-centered information for abstractive summary generation.', 'Automatic evaluation metrics only weakly correlate with unfaithful errors in summary generation, implying that new evaluation methods are needed to better gauge summary quality.': 'The authors carry out automatic and human evaluations on popular summarization datasets and find that models based on ASGARD yield significantly better ROUGE scores than a variant without access to the knowledge graph. They also find that ASGARD models attain performance better than or comparable to others that are fine-tuned from large pretrained language models. Human judges further confirm that ASGARD models generate more informative summaries with less unfaithful errors than their counterparts without the graph encoder.'}",reinforced,['News'],['robust-evaluation-methods']
SP:1395700ebfe0cac260af9c6ebac976e42ea4e442,Composing Elementary Discourse Units in Abstractive Summarization,ACL,2020,"['Zhenwen Li', 'Wenhao Wu', 'Sujian Li']","In this paper, we argue that elementary discourse unit (EDU) is a more appropriate textual unit of content selection than the sentence unit in abstractive summarization. To well handle the problem of composing EDUs into an informative and fluent summary, we propose a novel summarization method that first designs an EDU selection model to extract and group informative EDUs and then an EDU fusion model to fuse the EDUs in each group into one sentence. We also design the reinforcement learning mechanism to use EDU fusion results to reward the EDU selection action, boosting the final summarization performance. Experiments on CNN/Daily Mail have demonstrated the effectiveness of our model.",The paper proposes a new method for abstractive summarization using elementary discourse units (EDUs) instead of sentences. The method includes an EDU selection model to group informative EDUs and an EDU fusion model to combine them into sentences. The reinforcement learning mechanism is used to improve the summarization performance. The model was tested on CNN/Daily Mail and showed promising results.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to generate fluent and concise text from the original input document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a document, to save time, and to make it easier to find relevant information.'}",['method'],"['Unit Selection', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],"['Readability', 'Non-redundancy']",https://github.com/PKU-TANGENT/EDUSum,https://aclanthology.org/2020.acl-main.551,"{'A single document sentence usually cannot provide enough information that a summary sentence expresses, and composing a summary through only compressing sentences can cause performance degradation.': 'The authors propose using Elementary Discourse Unit (EDU) as the summarization unit, which is more information-intensive and elementary than a sentence. EDUs are defined as a clause and can be automatically obtained from the text using EDU segmentation technology.', 'Which EDUs should be selected to compose a good summary? How to well assemble the selected EDUs into a fluent summary?': 'The authors design an abstractive summarization method composed of two parts: EDU selection and EDU fusion. EDU selection aims to extract informative EDUs and group them, while EDU fusion takes the grouped EDUs as input to generate a sentence. The EDU fusion results are used as feedback to tune the EDU selection model, which in turn influences the EDU fusion process. The actor-critic reinforcement learning algorithm is employed to train the EDU-based summarization method.'}",reinforced,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:8e0de526d6955a4e9afcfa88e69be672f1be6447,Controlling the Amount of Verbatim Copying in Abstractive Summarization,AAAI,2020,"['Kaiqiang Song', 'Bingqing Wang', 'Zhe Feng', 'Liu Ren', 'Fei Liu']","An abstract must not change the meaning of the original text. A single most effective way to achieve that is to increase the amount of copying while still allowing for text abstraction. Human editors can usually exercise control over copying, resulting in summaries that are more extractive than abstractive, or vice versa. However, it remains poorly understood whether modern neural abstractive summarizers can provide the same flexibility, i.e., learning from single reference summaries to generate multiple summary hypotheses with varying degrees of copying. In this paper, we present a neural summarization model that, by learning from single human abstracts, can produce a broad spectrum of summaries ranging from purely extractive to highly generative ones. We frame the task of summarization as language modeling and exploit alternative mechanisms to generate summary hypotheses. Our method allows for control over copying during both training and decoding stages of a neural summarization model. Through extensive experiments we illustrate the significance of our proposed method on controlling the amount of verbatim copying and achieve competitive results over strong baselines. Our analysis further reveals interesting and unobvious facts.","The paper discusses the challenge of creating abstracts that accurately summarize the original text without changing its meaning. It explores the use of neural summarization models to generate summaries with varying degrees of copying, from purely extractive to highly generative. The authors present a method that allows for control over copying during both training and decoding stages, and demonstrate its effectiveness through extensive experiments. The paper also reveals interesting and unobvious findings about the process of summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide flexibility in generating summaries with varying proportions of reused text to cater to diverse usage scenarios.', 'Who is the target audience?': 'The summaries are for system abstracts that may not contain excessive copied content without proper permission and are required to preserve the meaning of the original text.', 'How will the summaries be used?': 'The summaries will be used to produce abstracts with varying degrees of copying and to exercise control over copying in abstractive summarization.'}",['method'],['Controlled Generation'],"['Gigaword', 'Newsroom']",['ROUGE'],"['Informativeness', 'Grammaticality', 'Truthfulness']",https://github.com/ucfnlp/control-over-copying,https://ojs.aaai.org/index.php/AAAI/article/view/6420,"{'Abstractive summarizers using encoder-decoder architectures can either copy words from the source text or generate new words unseen in the source, but it is poorly understood whether they can provide the needed flexibility to control over copying and generate diverse abstracts.': 'The authors propose a general framework that learns from single reference summaries to generate abstractive summaries with varying amounts of reused text. They define copy rate as the percentage of summary n-grams appearing in the source text and argue that abstractive summarizers should separate the prediction of summary words that are seen in the source text from those unseen. By employing a “mix-and-match” strategy, they enable an abstractive summarizer to generate summaries with more, or less, copying.', 'It can be time-consuming and costly to create human abstracts, and it is unlikely to be how humans learn to exercise control over copying.': 'The authors propose a method that allows for control over copying during both training and decoding stages of the neural model. They experiment with varying proportions of seen and unseen summary words in training to teach the summarizer to favor, or not to favor, copying. At decoding time, they compare different search strategies and reranking methods to encourage system abstracts to use wording similar to the original.', 'Only single reference summaries are available in benchmark evaluations, making it difficult to evaluate summary quality along multiple dimensions.': 'The authors evaluate summary quality along multiple dimensions, using automatic metrics based on lexical similarity and semantic similarity, and through human assessment of grammaticality, informativeness, and whether system abstracts remain true-to-original. Their method demonstrates strong performance, either outperforming or performing on par with the best published results.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:ff1e10c7d6a37beb4fd1e88e2e9a5ae6946cd273,Keywords-Guided Abstractive Sentence Summarization,AAAI,2020,"['Haoran Li', 'Junnan Zhu', 'Jiajun Zhang', 'Chengqing Zong', 'Xiaodong He']","We study the problem of generating a summary for a given sentence. Existing researches on abstractive sentence summarization ignore that keywords in the input sentence provide significant clues for valuable content, and humans tend to write summaries covering these keywords. In this paper, we propose an abstractive sentence summarization method by applying guidance signals of keywords to both the encoder and the decoder in the sequence-to-sequence model. A multi-task learning framework is adopted to jointly learn to extract keywords and generate a summary for the input sentence. We apply keywords-guided selective encoding strategies to filter source information by investigating the interactions between the input sentence and the keywords. We extend pointer-generator network by a dual-attention and a dual-copy mechanism, which can integrate the semantics of the input sentence and the keywords, and copy words from both the input sentence and the keywords. We demonstrate that multi-task learning and keywords-oriented guidance facilitate sentence summarization task, achieving better performance than the competitive models on the English Gigaword sentence summarization dataset. Introduction Sentence summarization is a task that creates a condensed version of a long sentence1. Different from extractive methods (Cheng and Lapata 2016; Jadhav and Rajan 2018; Dong et al. 2018; Zhang et al. 2018), which select a subset of text units in the original text to form the summary, abstractive methods (Rush, Chopra, and Weston 2015; Takase et al. 2016; Chen et al. 2016; See, Liu, and Manning 2017; Tan, Wan, and Xiao 2017; Zhou et al. 2017; Narayan, Cohen, and Lapata 2018; Lebanoff, Song, and Liu 2018; Zhu et al. 2019) can generate novel words not present in the input. Compared with extractive methods, abstractive summarization is much closer to the way human make a summary, while it is more challenging. Intuitively, some important words (a.k.a. keywords) in the original sentence proCopyright c © 2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. For sentence compression task (Clarke 2008), the word of the output must be in the input, while the vocabulary for sentence summarization is not constrained. Observation: Input sentence: France and Germany called on world leaders Monday to take rapid action to press for the closure of Ukraine 's Chernobyl nuclear plant , site of the world 's worst ever nuclear disaster . Reference summary: World leaders urged to back Chernobyl","This paper proposes an abstractive sentence summarization method that applies guidance signals of keywords to both the encoder and the decoder in the sequence-to-sequence model. A multi-task learning framework is adopted to jointly learn to extract keywords and generate a summary for the input sentence. The authors apply keywords-guided selective encoding strategies to filter source information by investigating the interactions between the input sentence and the keywords. They extend the pointer-generator network by a dual-attention and a dual-copy mechanism, which can integrate the semantics of the input sentence and the keywords, and copy words from both the input sentence and the keywords. The authors demonstrate that multi-task learning and keywords-oriented guidance facilitate sentence summarization task, achieving better performance than the competitive models on the English Gigaword sentence summarization dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to create a condensed version of a long sentence.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but the authors propose an abstractive sentence summarization method guided by keywords in the original sentence to improve the summarization process.'}",['method'],"['Unit Selection', 'Controlled Generation']",['Gigaword'],"['ROUGE', 'MoverScore', 'BERTScore']","['Readability', 'Informativeness']",,https://ojs.aaai.org/index.php/AAAI/article/view/6333,"{'Existing work has not explored the effectiveness of keywords for sentence summarization task.': 'The authors propose an abstractive sentence summarization method guided by the keywords in the original sentence.', 'The groundtruth keywords are not available for testing, and a keyword extractor is required.': 'The authors adopt a multi-task learning framework to model sentence summarization and keyword extraction jointly, which is expected to be beneficial for both tasks.', 'The encoder needs to recognize the crucial text fragments in the source sentence for both sentence summarization and keyword extraction.': 'The authors apply keywords-guided selective encoding strategies to filter source information and dynamically integrate the semantics of the input sentence and the keywords to build context representation via dual-attention. They also extend the copy mechanism to a dual-copy mode that can copy words from both the input sentence and the keywords.', 'The performance of the proposed method needs to be evaluated.': 'The authors achieve significantly better performance than the competitive methods on the English Gigaword dataset.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:195651d99f588778640822c33d6c4822b627bb18,A Cascade Approach to Neural Abstractive Summarization with Content Selection and Fusion,AACL,2020,"['Logan Lebanoff', 'Franck Dernoncourt', 'Doo Soon Kim', 'Walter Chang', 'Fei Liu']","We present an empirical study in favor of a cascade architecture to neural text summarization. Summarization practices vary widely but few other than news summarization can provide a sufficient amount of training data enough to meet the requirement of end-to-end neural abstractive systems which perform content selection and surface realization jointly to generate abstracts. Such systems also pose a challenge to summarization evaluation, as they force content selection to be evaluated along with text generation, yet evaluation of the latter remains an unsolved problem. In this paper, we present empirical results showing that the performance of a cascaded pipeline that separately identifies important content pieces and stitches them together into a coherent text is comparable to or outranks that of end-to-end systems, whereas a pipeline architecture allows for flexible content selection. We finally discuss how we can take advantage of a cascaded pipeline in neural text summarization and shed light on important directions for future research.","The paper presents an empirical study supporting the use of a cascade architecture for neural text summarization. The study shows that a pipeline architecture, which separately identifies important content pieces and stitches them together, performs comparably or better than end-to-end systems that perform content selection and surface realization jointly. The paper also discusses the challenges of evaluating summarization systems and suggests future research directions.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to explore the feasibility of a cascade approach to neural text summarization.', 'Who is the target audience?': 'The intended audience for the generated summaries is not specified in the paper.', 'How will the summaries be used?': 'The potential uses of the generated summaries are not specified in the paper.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],[''],https://github.com/ucfnlp/cascaded-summ,https://aclanthology.org/2020.aacl-main.52,"{'The lack of annotated resources suggests that end-to-end systems may not be a “one-size-fits-all” solution to neural text summarization.': 'Develop cascaded architectures to allow for customized content selectors to be combined with general-purpose neural text generators to realize the full potential of neural abstractive summarization.', 'Content selection concerns not only the selection of important segments from a document, but also the cohesiveness of selected segments and the amount of text to be selected in order for a neural text generator to produce a summary.': 'Advocate for explicit content selection as it allows for a rigorous evaluation and visualization of intermediate results of such a module, rather than associating it with text generation. Use highlighting sentence segments to perform fine-grained content selection that guides the neural text generator to stitch selected segments into a coherent sentence.', 'When a pair of sentences are selected, it is important to ensure that they are fusible—there exists cohesive devices that tie the two sentences together into a coherent text—to avoid generating nonsensical outputs.': 'Use a cascade approach to neural text summarization, where an abstract is created one sentence at a time through a cascaded pipeline. Choose one or two sentences from the source document, then highlight their summary-worthy segments and use those as a basis for composing a summary sentence.'}",supervised,['News'],['lack-of-suitable-training-data']
SP:1ad91120b863a424321f998daf67614a2dc84b25,SemSUM: Semantic Dependency Guided Neural Abstractive Summarization,AAAI,2020,"['Hanqi Jin', 'Tianming Wang', 'Xiaojun Wan']","In neural abstractive summarization, the generated summaries often face semantic irrelevance and content deviation from the input sentences. In this work, we incorporate semantic dependency graphs about predicate-argument structure of input sentences into neural abstractive summarization for the problem. We propose a novel semantics dependency guided summarization model (SemSUM), which can leverage the information of original input texts and the corresponding semantic dependency graphs in a complementary way to guide summarization process. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. Experiments show that the proposed model improves semantic relevance and reduces content deviation, and also brings significant improvements on automatic evaluation ROUGE metrics.","The paper proposes a new approach to neural abstractive summarization that incorporates semantic dependency graphs to improve semantic relevance and reduce content deviation in generated summaries. The proposed model, SemSUM, leverages the information of original input texts and corresponding semantic dependency graphs to guide the summarization process. The model was evaluated on three datasets and showed significant improvements in automatic evaluation ROUGE metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress the input text into a concise, fluent summary while retaining its main idea.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main idea of the original text without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding lengthy documents, and can be particularly useful for tasks such as information retrieval and document summarization.'}",['method'],['External Knowledge'],"['Gigaword', 'DUC 2004', 'MSR-ATC']",['ROUGE'],"['Faithfulness', 'Informativeness', 'Fluency']",https://github.com/zhongxia96/SemSUM,https://ojs.aaai.org/index.php/AAAI/article/view/6312,"{'Generated summaries often face the problem of semantic irrelevance and deviation from the input sentence, thus cannot reflect the main meaning of the original text accurately and faithfully.': 'The authors propose to guide the neural summarization system with the semantic dependency graph of the source sentence, which represents predicate-argument relations between content words in a sentence and can be leveraged as an additional input to guide summary generation.', 'Previous studies have explored various ways to address the problem of semantic irrelevance and deviation, such as extracting facts from the source sentence or incorporating entailment knowledge into abstractive summarization models.': 'The authors propose a novel semantic dependency guided summarization model based on the Transformer, which can incorporate the semantic dependency graph and the input text by stacking encoders to guide summary generation process.', 'The semantic dependency graph has various semantic representation schemes based on different annotation systems, and it is unclear which scheme to use.': 'The authors leverage the DM scheme, which has higher consistency and accuracy, as an additional input to guide summary generation.', 'It is unclear how to incorporate the semantic dependency graph and the input text to generate summary in a complementary way.': 'The authors propose stacked encoders consisting of a sentence encoder and a graph encoder, which can incorporate the semantic dependency graph and the input text to generate summary in a complementary way. The graph encoder captures semantic relationships and incorporates the semantic graph structure into the contextual-level representation, and a graph attention mechanism is adopted to aggregate information of relation triples into the corresponding sender and receiver nodes to construct a semantics-aware representation.', 'It is unclear whether the proposed model can outperform strong baselines on benchmark datasets.': 'Experiments on the Gigaword dataset show that the proposed approach significantly improves strong baselines, and the model also yields a large improvement on test-only DUC2004 and MSR abstractive sentence summarization datasets.'}",supervised,"['News', 'Web Documents']",[]
SP:a1f97d90d6a5b07e57843fa06bc8db6e49440575,Joint Parsing and Generation for Abstractive Summarization,AAAI,2020,"['Kaiqiang Song', 'Logan Lebanoff', 'Qipeng Guo', 'Xipeng Qiu', 'Xiangyang Xue', 'Chen Li', 'Dong Yu', 'Fei Liu']","Sentences produced by abstractive summarization systems can be ungrammatical and fail to preserve the original meanings, despite being locally fluent. In this paper we propose to remedy this problem by jointly generating a sentence and its syntactic dependency parse while performing abstraction. If generating a word can introduce an erroneous relation to the summary, the behavior must be discouraged. The proposed method thus holds promise for producing grammatical sentences and encouraging the summary to stay true-to-original. Our contributions of this work are twofold. First, we present a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder in a synchronized manner to generate a summary sentence and its syntactic parse. Secondly, we describe a novel human evaluation protocol to assess if, and to what extent, a summary remains true to its original meanings. We evaluate our method on a number of summarization datasets and demonstrate competitive results against strong baselines.",The paper proposes a solution to the problem of ungrammatical and inaccurate sentences produced by abstractive summarization systems. The proposed method involves generating a sentence and its syntactic dependency parse simultaneously to encourage grammatical sentences and maintain the original meaning. The paper presents a novel neural architecture for abstractive summarization that combines a sequential decoder with a tree-based decoder and a human evaluation protocol to assess the accuracy of the summary. The method is evaluated on various datasets and shows competitive results against strong baselines.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the source text and make it more effective for readers.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of the source text.', 'How will the summaries be used?': 'The summaries will be used to improve the applicability of summarization techniques in real-world scenarios and to help readers quickly understand the main points of the source text.'}",['method'],"['Controlled Generation', 'Objective Function']","['Gigaword', 'CNN/DailyMail', 'Newsroom', 'WebMerge']",['ROUGE'],"['Grammaticality', 'Meaning']",https://github.com/ucfnlp/joint-parse-n-summarize,https://ojs.aaai.org/index.php/AAAI/article/view/6419,"{'Summaries can be ineffective if they are not grammatical and fail to convey the intended meaning.': 'The authors propose a new architecture to jointly generate a summary sentence and its syntactic parse, while performing abstraction.', 'Summarization and parsing algorithms are two significant branches of NLP that need to be tightly coupled.': 'The authors propose a joint model for generating summary sentences and parse trees, which can be more appealing than a pipeline method and mimics human behavior.', 'Ill-formed summary sentences can lead to more parsing errors in a pipeline method.': 'The joint method proposed by the authors incrementally produces a summary sentence and its syntactic parse, allowing for instant corrections as the text is written.', 'Constructing effective representations that support both summarization and parsing tasks is a challenge, as they require different contextual representations.': 'The authors propose to couple a sequential decoder for predicting new summary words and a tree-based decoder for predicting dependency arcs, and ensure both decoders work in a synchronized fashion.', 'The training procedure for the proposed joint model may be computationally expensive.': 'The authors introduce an important addition making use of topological sorting of tree nodes to accelerate the training procedure, making the framework computationally feasible.', 'The literature largely under-investigates whether abstractive summaries introduce any new meanings that are nonexistent in the original text.': 'The authors describe a new human evaluation protocol to assess if an abstractive summary has preserved the original meanings and if it has introduced any new meanings that are nonexistent in the original text.'}",supervised,"['News', 'Web Documents']",['information-loss-and-incoherence-in-extractive-summarization']
SP:3f9499a29e354a396ca1034977e32d3dacafdd22,Self-Attention Guided Copy Mechanism for Abstractive Summarization,ACL,2020,"['Song Xu', 'Haoran Li', 'Peng Yuan', 'Youzheng Wu', 'Xiaodong He', 'Bowen Zhou']","Copy module has been widely equipped in the recent abstractive summarization models, which facilitates the decoder to extract words from the source into the summary. Generally, the encoder-decoder attention is served as the copy distribution, while how to guarantee that important words in the source are copied remains a challenge. In this work, we propose a Transformer-based model to enhance the copy mechanism. Specifically, we identify the importance of each source word based on the degree centrality with a directed graph built by the self-attention layer in the Transformer. We use the centrality of each source word to guide the copy process explicitly. Experimental results show that the self-attention graph provides useful guidance for the copy distribution. Our proposed models significantly outperform the baseline methods on the CNN/Daily Mail dataset and the Gigaword dataset.","The paper proposes a Transformer-based model to improve the copy mechanism in abstractive summarization. The model identifies the importance of each source word using degree centrality with a directed graph built by the self-attention layer. The centrality of each source word is used to guide the copy process explicitly, resulting in better performance than baseline methods on the CNN/Daily Mail and Gigaword datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to help people quickly grasp the key points from miscellaneous information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort when trying to understand the content of a document. They can also be used to provide a quick overview of a document before deciding whether to read it in full.'}",['method'],"['Controlled Generation', 'Objective Function']","['Gigaword', 'CNN/DailyMail']",['ROUGE'],"['Importance', 'Readability']",,https://aclanthology.org/2020.acl-main.125,"{'The copy mechanism in text summarization may miss important words in the source text.': 'The authors propose a Self-Attention Guided Copy mechanism (SAGCopy) that utilizes the self-attention graph to identify important source words and encourage the summarizer to copy them. They calculate the centrality of each source word based on the adjacency matrices using TextRank algorithm and use it as guidance for copy distribution. They also introduce an auxiliary loss to encourage the model to focus on important words.', 'Lack of guidance on important source words in text summarization.': 'The authors propose a centrality-aware attention and a guidance loss to encourage the model to pay attention to important source words. They use the centrality score obtained from the self-attention graph as guidance for copy distribution and introduce an auxiliary loss to encourage the model to focus on important words.', 'Need for improved text summarization performance.': 'The authors achieve state-of-the-art performance on a public text summarization dataset by proposing the SAGCopy mechanism and using centrality-aware attention and guidance loss to encourage the model to focus on important source words.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:7ea14a3a2f0b3f4ee7589ef6f9fb6f5f820afc4a,A Hierarchical Network for Abstractive Meeting Summarization with Cross-Domain Pretraining,EMNLP,2020,"['Chenguang Zhu', 'Ruochen Xu', 'Michael Zeng', 'Xuedong Huang']","With the abundance of automatic meeting transcripts, meeting summarization is of great interest to both participants and other parties. Traditional methods of summarizing meetings depend on complex multi-step pipelines that make joint optimization intractable. Meanwhile, there are a handful of deep neural models for text summarization and dialogue systems. However, the semantic structure and styles of meeting transcripts are quite different from articles and conversations. In this paper, we propose a novel abstractive summary network that adapts to the meeting scenario. We design a hierarchical structure to accommodate long meeting transcripts and a role vector to depict the difference among speakers. Furthermore, due to the inadequacy of meeting summary data, we pretrain the model on largescale news summary data. Empirical results show that our model outperforms previous approaches in both automatic metrics and human evaluation. For example, on ICSI dataset, the ROUGE-1 score increases from 34.66% to 46.28%.","The paper discusses the challenge of summarizing meeting transcripts and proposes a novel abstractive summary network that adapts to the meeting scenario. The network includes a hierarchical structure to accommodate long transcripts and a role vector to depict the difference among speakers. The model is pre-trained on largescale news summary data due to the inadequacy of meeting summary data. The empirical results show that the proposed model outperforms previous approaches in both automatic metrics and human evaluation, with an increase in ROUGE-1 score from 34.66% to 46.28% on the ICSI dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of meeting transcripts to provide a succinct summary of the content discussed during the meeting.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content discussed during the meeting, such as participants who were unable to attend or individuals who need to review the meeting content.', 'How will the summaries be used?': 'The summaries can be used to provide a quick overview of the meeting content, to identify key points discussed during the meeting, and to facilitate decision-making based on the meeting outcomes.'}",['method'],['Input Encoding'],"['AMI', 'ICSI']",['ROUGE'],"['Readability', 'Relevance']",,https://aclanthology.org/2020.findings-emnlp.19,"{'Meeting transcripts are usually much longer than those of a document, and the structure of a meeting transcript is very distinct from news articles. These challenges prevent existing news summarization models to be successfully applied to meetings.': 'The authors propose an end-to-end deep learning framework, Hierarchical Meeting summarization Network (HMNet), that leverages the encoder-decoder transformer architecture to produce abstractive summaries based on meeting transcripts. They also propose a hierarchical structure to reduce the burden of computing and ensure that each part of the summary stems from different portions of the transcript with varying granularities.', 'A meeting is carried out between multiple participants, and the different semantic styles, standpoints, and roles of each participant all contribute to the heterogeneous nature of the meeting transcript.': 'HMNet incorporates the role of each speaker to encode different semantic styles and standpoints among participants. The authors train a role vector for each meeting participant to represent the speaker’s information during encoding. This role vector is appended to the turn-level representation for later decoding.', 'Compared with news, there is very limited labelled training data for meeting summary. This is due to the privacy of meetings and the relatively high cost of writing summaries for long transcripts.': 'The authors leverage the idea of pretraining and collect summarization data from the news domain and convert them into the meeting format. They pretrain the HMNet model on the news task before finetuning it on meeting summarization. Empirical results show that this cross-domain pretraining can effectively enhance the model quality.'}",supervised,['Meeting Transcripts'],[]
SP:2c57bd2f1f55b5d75a614e7977914a5b2ab4ab59,Friendly Topic Assistant for Transformer Based Abstractive Summarization,EMNLP,2020,"['Zhengjue Wang', 'Zhibin Duan', 'Hao Zhang', 'Chaojie Wang', 'Long Tian', 'Bo Chen', 'Mingyuan Zhou']","Abstractive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformerbased models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.ive document summarization is a comprehensive task including document understanding and summary generation, in which area Transformer-based models have achieved the state-of-the-art performance. Compared with Transformers, topic models are better at learning explicit document semantics, and hence could be integrated into Transformers to further boost their performance. To this end, we rearrange and explore the semantics learned by a topic model, and then propose a topic assistant (TA) including three modules. TA is compatible with various Transformerbased models and user-friendly since i) TA is a plug-and-play model that does not break any structure of the original Transformer network, making users easily fine-tune Transformer+TA based on a well pre-trained model; ii) TA only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.","The paper discusses the use of topic models to improve the performance of Transformer-based models in abstractive document summarization. The proposed model, called topic assistant (TA), includes three modules and is compatible with various Transformer-based models. TA is user-friendly and only introduces a small number of extra parameters. Experimental results on three datasets demonstrate that TA is able to improve the performance of several Transformer-based models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to perform automatic summarization, which is a comprehensive task in natural language processing (NLP).', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be applied in various fields such as news articles, research papers, and legal documents.'}",['method'],"['External Knowledge', 'Auxiliary Tasks']","['CNN/DailyMail', 'NYT', 'XSum']",['ROUGE'],[''],,https://aclanthology.org/2020.emnlp-main.35,"{'Transformer-based models are better at exploring the relationships among local tokens than the document global semantics.': 'The authors propose to use topic models to explore the global semantics explicitly and develop a topic assistant (TA) for Transformer-based abstractive summarization models.', 'Most Transformer-based models have a maximum capacity of input tokens, which may lose some important semantics, especially for long documents.': 'The authors propose to use TA to rearrange and further explore the semantics of the topic model and introduce only a small number of parameters into the fine-tuning stage, making TA a flexible plug-and-play model.', 'The learned attentive patterns of many heads are not as reasonable as expected.': 'The authors propose to employ the semantic ""distribution over topics"" as a token representation to construct an explicit semantic-similarity matrix among tokens, which is further used as the attention weights of a newly added head. This is called Semantic-informed attention (SIA).', 'Topics with large proportions for a document cannot be considered as extra input tokens of the decoder without being affected by the summary-token features via attention.': 'The authors propose to use Topic embedding with masked attention (TEMA) to represent the corresponding topic embedding. This prevents the topic features from being affected by the summary-token features via attention.', 'The topic-proportion vector is a low-dimensional document representation that needs to be integrated into the network with a small number of extra parameters.': 'The authors propose to use Document-related modulation (DRM) to infer a document-related bias to modulate some hidden layers of the decoder. This is an efficient way to integrate conditions into the network with a small number of extra parameters.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'hallucinations-in-the-generated-summaries']"
SP:e4e0e0dc55426e9683bc2bb4338324e822110db7,Reducing Quantity Hallucinations in Abstractive Summarization,EMNLP,2020,"['Zheng Zhao', 'Shay B. Cohen', 'Bonnie Webber']","It is well-known that abstractive summaries are subject to hallucination—including material that is not supported by the original text. While summaries can be made hallucinationfree by limiting them to general phrases, such summaries would fail to be very informative. Alternatively, one can try to avoid hallucinations by verifying that any specific entities in the summary appear in the original text in a similar context. This is the approach taken by our system, HERMAN. The system learns to recognize and verify quantity entities (dates, numbers, sums of money, etc.) in a beamworth of abstractive summaries produced by state-of-the-art models, in order to up-rank those summaries whose quantity terms are supported by the original text. Experimental results demonstrate that the ROUGE scores of such up-ranked summaries have a higher Precision than summaries that have not been upranked, without a comparable loss in Recall, resulting in higher F1. Preliminary human evaluation of up-ranked vs. original summaries shows people’s preference for the former.","The paper discusses the issue of hallucination in abstractive summaries and proposes a solution using the HERMAN system. HERMAN verifies specific entities in summaries and up-ranks those whose quantity terms are supported by the original text. Experimental results show higher precision and F1 scores for up-ranked summaries without a loss in recall, and human evaluation shows a preference for up-ranked summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress lengthy texts into a more concise version that preserves the information of the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a lengthy text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading lengthy texts, and to quickly understand the main points of the text without having to read the entire document.'}",['method'],['Controlled Generation'],['XSum'],"['ROUGE', 'FactCC', 'QGQA']",['Faithfulness'],,https://aclanthology.org/2020.findings-emnlp.203,"{'Abstractive summarization systems produce summaries that contain hallucinated facts that are not supported by the source text.': 'The authors propose reducing the frequency of one type of hallucinated fact in abstractive summaries—hallucinated quantities. They present HERMAN1, a system that learns to recognize quantities in a summary and verify their factual consistency with the source text. After verifying consistency, they use a re-ranking approach that up-rank those summaries whose quantities are supported by the source text.', 'High levels of factual hallucination in abstractive summarization raise serious concern about the usefulness of abstractive summarization.': 'The authors focus on reducing the frequency of hallucinated quantities in abstractive summaries, which are important for factual consistency and are rarely noticed by readers unless they are wildly inaccurate.', 'Quantity entities are frequently hallucinated in abstractive summarization.': 'The authors categorize the quantities they address into seven types: dates, times, percentages, monetary values, measurements, ordinals, and cardinal numbers. They use a weakly supervised approach to automatically generate training data by selecting quantity entities from the summary and replacing them with randomly selected entities from the source text that are the same type.', 'The authors want to evaluate the effectiveness of their proposed system.': 'They perform experiments on the XSum dataset and use automatic evaluation using ROUGE to demonstrate that up-ranked summaries have higher ROUGE Precision than original summaries produced by three different summarization systems. They also conduct a preliminary human evaluation study that shows that subjects prefer the upranked summaries to the original summaries.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:067362ebe6aea6b0b2441a86c12743566f083501,Multi-Fact Correction in Abstractive Text Summarization,EMNLP,2020,"['Yue Dong', 'Shuohang Wang', 'Zhe Gan', 'Yu Cheng', 'Jackie Chi', 'Kit Cheung', 'Jingjing Liu']","Pre-trained neural abstractive summarization systems have dominated extractive strategies on news summarization performance, at least in terms of ROUGE. However, systemgenerated abstractive summaries often face the pitfall of factual inconsistency: generating incorrect facts with respect to the source text. To address this challenge, we propose SpanFact, a suite of two factual correction models that leverages knowledge learned from question answering models to make corrections in system-generated summaries via span selection. Our models employ single or multimasking strategies to either iteratively or autoregressively replace entities in order to ensure semantic consistency w.r.t. the source text, while retaining the syntactic structure of summaries generated by abstractive summarization models. Experiments show that our models significantly boost the factual consistency of system-generated summaries without sacrificing summary quality in terms of both automatic metrics and human evaluation.","The paper discusses the challenges faced by system-generated abstractive summaries, which often contain factual inconsistencies. To address this issue, the authors propose SpanFact, a suite of two factual correction models that use knowledge from question answering models to correct errors in system-generated summaries. The models use single or multimasking strategies to replace entities and ensure semantic consistency with the source text while retaining the syntactic structure of the summaries. Experiments show that SpanFact significantly improves the factual consistency of system-generated summaries without sacrificing summary quality.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to shorten a long piece of text while preserving its main message.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main message of a long piece of text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and can be particularly useful for researchers, students, and professionals who need to quickly understand the main message of a large number of documents.'}",['method'],"['Post Processing', 'External Knowledge']","['CNN/DailyMail', 'Gigaword', 'XSum']",['ROUGE'],['Factuality'],,https://aclanthology.org/2020.emnlp-main.749,"{'Abstractive summarization models often generate summaries that are factually inconsistent with the source text, despite high ROUGE scores.': 'The authors propose SpanFact, a suite of two neural-based factual correctors that improve summary factual correctness without sacrificing informativeness. They focus on factual edits on entities only, a major source of hallucinated errors in abstractive summarization systems in practice.', 'Existing evaluation metrics such as ROUGE or BERTScore correlate poorly with faithfulness.': 'The authors propose using question answering (QA) systems as an evaluation metric, as they show high correlations with human judgment on factuality.', 'Models that incorporate factual triples or textual entailment to boost factual consistency often sacrifice informativeness for the sake of correctness of the summary.': 'The authors propose a lightweight approach that adapts QA knowledge to enhance abstractive summarization, which can be readily applied to any system-generated summaries without retraining the model.', 'Multi-fact correction is a challenging problem in factual correction.': 'The authors propose two methods to solve multi-fact correction problem with single or multi-span selection in an iterative or auto-regressive manner, respectively.', 'Factual inconsistency is a well-known problem for conditional text generation, which requires models to generate readable text that is faithful to the input document.': 'The authors propose a factual correction framework that focuses on correcting erroneous facts in generated summaries, generalizable to any summarization system.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'pretraining-and-sample-efficiency']"
SP:d7c38fad22f0ae72e0c8e39f7624897370a6ab62,Factual Error Correction for Abstractive Summarization Models,EMNLP,2020,"['Meng Cao', 'Yue Dong', 'Jiapeng Wu', 'Jackie Chi', 'Kit Cheung']","Neural abstractive summarization systems have achieved promising progress, thanks to the availability of large-scale datasets and models pre-trained with self-supervised methods. However, ensuring the factual consistency of the generated summaries for abstractive summarization systems is a challenge. We propose a post-editing corrector module to address this issue by identifying and correcting factual errors in generated summaries. The neural corrector model is pre-trained on artificial examples that are created by applying a series of heuristic transformations on reference summaries. These transformations are inspired by an error analysis of state-of-the-art summarization model outputs. Experimental results show that our model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. We also find that transferring from artificial error correction to downstream settings is still very challenging1.","The paper discusses the challenge of ensuring factual consistency in abstractive summarization systems and proposes a post-editing corrector module to address this issue. The module is pre-trained on artificial examples created by applying heuristic transformations on reference summaries. Experimental results show that the model is able to correct factual errors in summaries generated by other neural summarization models and outperforms previous models on factual consistency evaluation on the CNN/DailyMail dataset. However, the paper also notes that transferring from artificial error correction to downstream settings is still challenging.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the factual consistency of system summaries with post-editing correction.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to provide a corrected final summary, conditioned on the source document, and to evaluate the factual consistency of abstractive summaries.'}",['method'],"['Post Processing', 'External Knowledge']","['CNN/DailyMail', 'K2019']",['ROUGE'],['Consistency'],https://github.com/mcao610/Factual-Error-Correction,https://aclanthology.org/2020.emnlp-main.506,"{'Ensuring factual consistency of generated summaries with respect to the source remains challenging.': 'The authors propose a model to improve the factual consistency of system summaries with post-editing correction. The model takes a draft summary that is generated by an abstractive summarization model and produces a corrected final summary, conditioned on the source document.', 'Most approaches to detect or ensure factual consistency either require a high-quality fact extraction model or only focus on factual consistency evaluation.': 'The authors propose to improve factuality correction by editing inconsistent parts in generated summaries, which is a direction that has not been explored much. They train their model with artificial data that has factual errors introduced using heuristics proposed by Kryściński et al. (2019).', 'The overall recall on correcting factual errors in real system summaries remains low, suggesting the errors introduced by heuristics have a different distribution than errors made by abstractive summarization systems.': 'The authors suggest that further research is needed to address this issue and improve the performance of their model on real system summaries.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:eda4e40681db57aa4041be1270f5a9efcc277bd6,Pre-training for Abstractive Document Summarization by Reinstating Source Text,EMNLP,2020,"['Yanyan Zou', 'Xingxing Zhang', 'Wei Lu', 'Furu Wei', 'Ming Zhou']","Abstractive document summarization is usually modeled as a sequence-to-sequence (SEQ2SEQ) learning problem. Unfortunately, training large SEQ2SEQ based summarization models on limited supervised summarization data is challenging. This paper presents three sequence-to-sequence pre-training (in shorthand, STEP) objectives which allow us to pre-train a SEQ2SEQ based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (≥160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness. Code and models are public available at https://github.com/ zoezou2015/abs_pretraining.ive document summarization is usually modeled as a sequence-to-sequence (SEQ2SEQ) learning problem. Unfortunately, training large SEQ2SEQ based summarization models on limited supervised summarization data is challenging. This paper presents three sequence-to-sequence pre-training (in shorthand, STEP) objectives which allow us to pre-train a SEQ2SEQ based abstractive summarization model on unlabeled text. The main idea is that, given an input text artificially constructed from a document, a model is pre-trained to reinstate the original document. These objectives include sentence reordering, next sentence generation and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets (i.e., CNN/DailyMail and New York Times) show that all three objectives can improve performance upon baselines. Compared to models pre-trained on large-scale data (≥160GB), our method, with only 19GB text for pre-training, achieves comparable results, which demonstrates its effectiveness. Code and models are public available at https://github.com/ zoezou2015/abs_pretraining.","The paper discusses the challenge of training large SEQ2SEQ based summarization models on limited supervised summarization data and presents three sequence-to-sequence pre-training objectives that allow for pre-training a SEQ2SEQ based abstractive summarization model on unlabeled text. These objectives include sentence reordering, next sentence generation, and masked document generation, which have close relations with the abstractive document summarization task. Experiments on two benchmark summarization datasets show that all three objectives can improve performance upon baselines. The method achieves comparable results to models pre-trained on large-scale data with only 19GB text for pre-training, demonstrating its effectiveness. Code and models are publicly available.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense them into shorter forms while preserving important content.', 'Who is the target audience?': 'It is not specified who the summaries are for in the paper.', 'How will the summaries be used?': 'It is not specified how the summaries will be used in the paper.'}",['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'Gigaword', 'NYT']",['ROUGE'],"['Informativeness', 'Fluency', 'Succinctness']",https://github.com/zoezou2015/abs_pretraining,https://aclanthology.org/2020.emnlp-main.297,"{'Abstractive summarization often involves content reordering, which is not well studied in prior work.': 'The authors propose a model that is capable of reordering content in abstractive summarization.', 'Pretrained SEQ2SEQ Transformer models have proven effective for natural language generation tasks, but there is a need for better pre-training objectives for abstractive summarization.': 'The authors propose three sequence-to-sequence pre-training objectives (Sentence Reordering, Next Sentence Generation, and Masked Document Generation) designed to reinstate the original source text.', 'Even heavily tuned large SEQ2SEQ Transformer models with strong pre-trained encoders may not perform well on summarization tasks.': 'The authors show that pre-training their proposed model on unlabeled documents and finetuning on supervised summarization datasets can significantly improve performance, even when pre-training on documents from the training split of a summarization dataset. By involving more data (19GB) for pre-training, the performance is further improved. Compared to models pre-trained with much more data (≥160GB), the proposed model can still achieve comparable or even higher ROUGE scores.'}",supervised,['News'],[]
SP:865a9ce2659818003e72786166f534a64c3e719a,Controllable Abstractive Sentence Summarization with Guiding Entities,COLING,2020,"['Changmeng Zheng', 'Yi Cai', 'Guanjie Zhang', 'Qing Li']","Entities are the major proportion and build up the topic of text summaries. Although existing text summarization models can produce promising results of automatic metrics, for example, ROUGE, it is difficult to guarantee that an entity is contained in generated summaries. In this paper, we propose a controllable abstractive sentence summarization model which generates summaries with guiding entities. Instead of generating summaries from left to right, we start with a selected entity, generate the left part first, then the right part of a complete summary. Compared to previous entity-based text summarization models, our method can ensure that entities appear in final output summaries rather than generating the complete sentence with implicit entity and article representations. Our model can also generate more novel entities with them incorporated into outputs directly. To evaluate the informativeness of the proposed model, we develop a fine-grained informativeness metrics in the relevance, extraness and omission perspectives. We conduct experiments in two widely-used sentence summarization datasets and experimental results show that our model outperforms the state-of-the-art methods in both automatic evaluation scores and informativeness metrics.","The paper proposes a controllable abstractive sentence summarization model that generates summaries with guiding entities. The model ensures that entities appear in final output summaries and can generate more novel entities. The proposed model is evaluated using fine-grained informativeness metrics in the relevance, extraness, and omission perspectives. Experimental results show that the model outperforms the state-of-the-art methods in both automatic evaluation scores and informativeness metrics.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to create a concise version of the text that represents the most important or relevant information within the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for information gathering, problem solving, or decision making. They can also be used by search engines or recommendation systems to provide users with relevant information.'}",['method'],['Controlled Generation'],"['Gigaword', 'DUC 2004']",['ROUGE'],"['Informativeness', 'Grammaticality', 'Coherence']",https://github.com/thecharm/Abs-LRModel,https://aclanthology.org/2020.coling-main.497,"{'Existing methods are difficult to identify salient entities and related events in the original articles, leading to unfaithful and incoherent summaries.': 'Incorporate entities in summaries as they are important for summary generation in three ways: (1) Summaries are mainly composed of entities extracted from the original texts. (2) Entities can reveal the main topics in an article, which can be utilized to generate highly topic coherent summaries. (3) Entities can provide basic answers to the Five Ws questions (Who, What, When, Where, Why) in information gathering or problem solving.', 'Existing methods are limited in control of the generation process and cannot guarantee to generate summaries with important named entities.': 'Develop a controllable framework which incorporates entity information and generates summaries with selected entities. Extract entities in the original texts using a pretrained named entity recognition model and identify the most important entities using an entity selector. Combine two LSTMs to generate the left part and the right part of the sequence around the entity. Each LSTM encodes information of the other part of the sequence and then generates a summary based on the encoded article and entity representations. This allows the two LSTM decoders to connect with the selected entities fluently, guaranteeing that important entities appear in output summaries.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:4ffbc2dd3369833b85663a1e1897a6cf64540287,Boosting Few-Shot Abstractive Summarization with Auxiliary Tasks,CIKM,2021,"['Qiwei Bi', 'Haoyuan Li', 'Hanfang Yang']","For summarization in niche domains, data is not enough to finetune the large pre-trained model. In order to alleviate the few-shot problem, we design several auxiliary tasks to assist the main task— abstractive summarization. In this paper, we employ BART as the base sequence-to-sequence model and incorporate the main and auxiliary tasks under the multi-task framework. We transform all the tasks in the format of machine reading comprehension [19]. Moreover, we utilize the task-specific adapter to effectively share knowledge across tasks and the adaptive weight mechanism to adjust the contribution of auxiliary tasks to the main task. Experiments show the effectiveness of our method for few-shot datasets. We also propose to firstly pre-train the model on unlabeled datasets, and the methods proposed in this paper can further improve the model performance.","The paper discusses the challenge of summarization in niche domains and proposes a solution to the few-shot problem by designing auxiliary tasks to assist abstractive summarization. The authors use BART as the base sequence-to-sequence model and incorporate the main and auxiliary tasks under a multi-task framework. They also use a task-specific adapter and adaptive weight mechanism to adjust the contribution of auxiliary tasks to the main task. The experiments show the effectiveness of their method for few-shot datasets, and they propose pre-training the model on unlabeled datasets to further improve performance.",{},['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'NYT', 'Newsroom']",['ROUGE'],"['Relevance', 'Grammaticality', 'Coherence']",,https://dl.acm.org/doi/10.1145/3459637.3482066,"{'Labeled data is expensive to produce and not always available across different domains, making it difficult to obtain reliable models with few data.': 'Recent works focus on unsupervised summarization which utilizes large unlabeled data. Goodwin et al. use labeled datasets from other domains to enable zero-shot conditional summarization. In this paper, the authors show that some useful information can still be extracted from only the low-resource summarization dataset.', 'Summarization can benefit from multidimensional and more fine-grained tasks, but without customized supervision in these aspects, it could be difficult to learn a summarization model directly.': 'The authors design three auxiliary tasks from the raw text, including recognizing salient entities and their relation, extracting salient sentences from the document, and ensuring factual consistency between the generated summaries and the document. These tasks are trained together with abstractive summarization using multi-task learning to boost the performance of the main task.', 'Balancing multiple tasks in multi-task learning can be challenging.': 'The authors propose task-specific adapters for effectively sharing knowledge from multiple tasks while overcoming problems in balancing multiple tasks. They also introduce adaptive weight to dynamically determine how much attention is paid to each auxiliary task.', 'Few-shot problems in summarization require a small set of samples to learn a reliable model.': 'The authors pre-train the model on unlabeled data and utilize auxiliary tasks to assist the model to be better fine-tuned on small samples. Experiments show that auxiliary tasks can enhance the few-shot capability in summarization.'}",supervised,['News'],['lack-of-suitable-training-data']
SP:bac3dcab5e06af29113ad82f901405e4f65cea9d,BASS: Boosting Abstractive Summarization with Unified Semantic Graph,ACL,2021,"['Wenhao Wu', 'Wei Li', 'Xinyan Xiao', 'Jiachen Liu', 'Ziqiang', 'Sujian Li', 'Hua Wu', 'Haifeng Wang']","Abstractive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present BASS, a novel framework for Boosting Abstractive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graphpropagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multidocument summarization tasks.ive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present BASS, a novel framework for Boosting Abstractive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graphpropagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multidocument summarization tasks.","The paper proposes a new framework called BASS for abstractive summarization of long or multi-document text, which is challenging for the Seq2Seq architecture due to its inability to analyze long-distance relations in text. BASS utilizes a unified Semantic graph to aggregate co-referent phrases and convey rich relations between them. A graph-based encoder-decoder model is also proposed to improve document representation and summary generation by leveraging the graph structure. Several graph augmentation methods are designed to encode both explicit and implicit relations in the text, while the graph propagation attention mechanism is developed in the decoder to select salient content for the summary. Empirical results show that BASS brings substantial improvements for both long-document and multi-document summarization tasks.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to facilitate content selection and organization, especially in complex summarization scenarios such as long-document or multi-document summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document or multiple documents, such as researchers, professionals, or the general public.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents or multiple documents, and to quickly identify relevant information for further analysis or decision-making.'}",['method'],"['Input Encoding', 'External Knowledge']","['BigPatent', 'WikiSum']",['ROUGE'],"['Informativeness', 'Fluency']",,https://aclanthology.org/2021.acl-long.472,"{'Seq2Seq models struggle with content selection and organization in complex summarization scenarios such as long-document or multi-document summarization.': 'The authors propose to apply a phrase-level unified semantic graph to facilitate content selection and organization. The graph aggregates co-referent phrases distributed in context and is suitable for information aggregation with the help of coreference resolution.', 'Sentence-relation graph is not flexible for fine-grained (such as entities) information aggregation and relation modeling.': 'The authors propose a phrase-level unified semantic graph that is based on fine-grained phrases extracted from dependency parsing. This graph is suitable for fine-grained information aggregation and relation modeling.', 'OpenIE-based graph only contains sparse relations between partially extracted phrases, which cannot reflect the global structure and rich relations of the overall sequence.': 'The authors propose a phrase-level unified semantic graph that captures the global structure and rich relations of the overall sequence by explicitly modeling the relations between phrases.', 'Seq2Seq models struggle with long-distance relations and global structure modeling in long-document summarization and MDS.': 'The authors propose a graph-based encoder-decoder model that effectively encodes long sequences by explicitly modeling the relations between phrases and capturing the global structure based on the semantic graph. The graph decoder incorporates the graph structure by graph propagate attention to guide the summary generation process.', 'Existing models have limited performance in long-document summarization and MDS.': 'The authors conduct extensive experiments on both the long-document summarization dataset BIGPATENT and MDS dataset WikiSUM to validate the effectiveness of their graph-based model. Experiment results demonstrate that their model significantly improves the performance of both long-document and multi-document summarization over several strong baselines.'}",supervised,"['Patents', 'Wikipedia']",['efficient-encoding-of-long-documents']
SP:2c6341a39597b1620035107b0370abca5f7b4c9e,Leveraging Lead Bias for Zero-shot Abstractive News Summarization,SIGIR,2021,"['Chenguang Zhu', 'Ziyi Yang', 'Robert Gmyr', 'Michael Zeng', 'Xuedong Huang']","A typical journalistic convention in news articles is to deliver the most salient information in the beginning, also known as the lead bias. While this phenomenon can be exploited in generating a summary, it has a detrimental effect on teaching a model to discriminate and extract important information in general. We propose that this lead bias can be leveraged in our favor in a simple and effective way to pre-train abstractive news summarization models on large-scale unlabeled news corpora: predicting the leading sentences using the rest of an article. We collect a massive news corpus and conduct data cleaning and filtering via statistical analysis. We then apply self-supervised pre-training on this dataset to existing generation models BART and T5 for domain adaptation. Via extensive experiments on six benchmark datasets, we show that this approach can dramatically improve the summarization quality and achieve stateof-the-art results for zero-shot news summarization without any fine-tuning. For example, in the DUC2003 dataset, the ROUGE-1 score of BART increases 13.7% after the lead-bias pre-training. We deploy the model in Microsoft News and provide public APIs as well as a demo website for multi-lingual news summarization.",The paper proposes leveraging the lead bias in news articles to pre-train abstractive news summarization models on large-scale unlabeled news corpora. The authors collect a massive news corpus and conduct data cleaning and filtering via statistical analysis. They apply self-supervised pre-training on this dataset to existing generation models BART and T5 for domain adaptation. The approach dramatically improves the summarization quality and achieves state-of-the-art results for zero-shot news summarization without any fine-tuning. The model is deployed in Microsoft News and provides public APIs as well as a demo website for multi-lingual news summarization.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to condense a piece of text into a shorter version that contains the salient information.', 'Who is the target audience?': 'The summaries are for readers who need to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to provide faster and easier understanding of news articles, and can be applied to various news summarization tasks. The authors have also deployed the pre-trained model in a Microsoft News coupled with translation and text-to-speech technologies, providing public APIs as well as a demo website to support news summarization in 30 different languages with both text and speech output.'}","['corpus', 'method']","['External Knowledge', 'Auxiliary Tasks']","['DUC 2003', 'DUC 2004', 'CNN/DailyMail', 'XSum', 'NYT', 'Gigaword']","['ROUGE', 'FactCC']","['Readability', 'Overall Quality']",,https://doi.org/10.1145/3404835.3462846,"{'The lead bias in news articles can cause undesirable consequences for summarization models, as the output from these models is inevitably affected by the positional information of sentences, making it hard to discriminate and extract important information for text that does not demonstrate this bias.': 'The authors propose a novel method to leverage the lead bias of news articles in their favor to conduct large-scale pre-training of summarization models. The idea is to predict the leading sentences of a news article given the rest of the content, which immediately renders the large quantity of unlabeled news corpora available for building summarization models.', 'Most current summarization models are fully supervised and require time-consuming and labor-intensive annotations to feed their insatiable appetite for labeled data.': 'The authors leverage the effectiveness of additional pre-training to adapt language models to downstream domains, starting from the pretrained language generation models BART and T5 and continuing to pre-train them on their lead prediction task. This pre-training can be considered as domain adaptation, and the resulting models BART-LB and T5-LB are leveraged in a zero-shot fashion, directly applied to target tasks without accessing any information for fine-tuning.', 'The lack of labeled data and the domain drift problem can affect the performance of summarization models.': 'The authors collect a massive corpus of online news articles over three years from the index of the Bing search engine and conduct thorough data cleaning and filtering to ensure the quality of leading sentences as the delegate summary. They compute the overlapping ratio of non-stopping words between the top 3 sentences and the rest of the article and only keep articles for which this ratio is higher than a threshold determined via statistical analysis. The retained data for pre-training contains 21.4M news articles and has a median overlapping ratio of 0.734.', 'The quality of summaries generated by summarization models needs improvement.': 'The authors conduct extensive evaluations on six news summarization datasets and show that their models significantly improve the summary quality over the original BART and T5, outperforming other zero-shot and unsupervised summarization baselines. They also provide insights from various aspects to analyze the results and conduct a human evaluation, showing that the lead-bias pretraining can improve both readability and relevance of generated summaries. They showcase examples of summaries and conduct error analysis to investigate the common types of error in the summaries generated by their model.', 'News summarization needs to be supported in multiple languages with both text and speech output.': 'The authors deploy the pre-trained model in a Microsoft News coupled with translation and text-to-speech technologies. They provide public APIs as well as a demo website to support news summarization in 30 different languages with both text and speech output.'}",supervised,['News'],[]
SP:ae364d89c271be3b416d9fd6bb7dda368a189973,Abstractive Text Summarization with Hierarchical Multi-scale Abstraction Modeling and Dynamic Memory,SIGIR,2021,"['Lihan Wang', 'Min Yang', 'Chengming Li', 'Ying Shen', 'Ruifeng Xu']","ive Text Summarization with Hierarchical Multi-scale Abstraction Modeling and Dynamic Memory Lihan Wang1,2, Min Yang1†, Chengming Li1†, Ying Shen3, Ruifeng Xu4 Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences University of Chinese Academy of Sciences Sun Yat-Sen University Harbin Institute of Technology (Shenzhen) {lh.wang1,min.yang,cm.li}@siat.ac.cn,sheny76@mail.sysu.edu.cn,xuruifeng@hit.edu.cn","

System: The paper proposes a new approach to text summarization using hierarchical multi-scale abstraction modeling and dynamic memory. The system is designed to extract important information from large amounts of text and generate a concise summary. The approach is evaluated on several datasets and shows promising results compared to other state-of-the-art methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create condensed and concise summaries that retain the salient information and overall meaning of the source articles.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used for a variety of purposes, including natural language processing (NLP) and information retrieval (IR), to quickly understand the main points of a long document without having to read the entire article.'}",['method'],"['Unit Relationship', 'Input Encoding', 'Objective Function']","['CNN/DailyMail', 'arXiv']","['ROUGE', 'BERTScore']","['Informativeness', 'Fluency']",,https://doi.org/10.1145/3404835.3462998,"{'An article, especially a long document, is usually composed of multiple facets discussed at hierarchical levels of abstraction. To comprehend the hierarchical multi-facets information within the article, it requires hierarchical multi-scale abstraction mining to encode the temporal dependencies with different timescales, which is not exploited in the previous methods.': 'The authors propose a hierarchical multi-scale abstraction modeling (HMAM) model to capture multiple hierarchical levels of abstraction of the source document. Specifically, they encode the temporal dependencies with different timescales, motivated by the fact that the high-level abstraction changes slowly while the low-level abstraction has quickly changing features.', 'Conventional attention mechanisms used in sequence-to-sequence models (seq2seq) are incapable of effectively keeping track of the attention history in learning the dynamic alignment between the neural representations of the source article and the corresponding summary. Lacking comprehensive information (attention history) might result in two issues for abstractive text summarization: (i) generating puzzling words where some subtopics are unnecessarily accessed for multiple times and (ii) generating faultiness summary in which some salient information is mistakenly unexplored.': 'The authors propose a dynamic key-value memory-augmented attention (DMA) to alleviate the problem of generating repetitive words and incomplete summary, which allows the model to track the comprehensive information typically for each salient facet within the source document. The DMA mechanism better keeps track of attention history and salient information coverage, facilitating the decoder to overcome the problems of generating repetitive and faultiness summary by automatically distinguishing which salient facets have been described and which salient facets are unexplored.'}",supervised,"['News', 'Scholarly Documents']",['efficient-encoding-of-long-documents']
SP:ff6888696b197d1006f7b70aa8a2c198d3e2cc7d,Improve Query Focused Abstractive Summarization by Incorporating Answer Relevance,ACL,2021,"['Dan Su', 'Tiezheng Yu', 'Pascale Fung']","Query focused summarization (QFS) models aim to generate summaries from source documents that can answer the given query. Most previous work on QFS only considers the query relevance criterion when producing the summary. However, studying the effect of answer relevance in the summary generating process is also important. In this paper, we propose QFS-BART, a model that incorporates the explicit answer relevance of the source documents given the query via a question answering model, to generate coherent and answerrelated summaries. Furthermore, our model can take advantage of large pre-trained models which improve the summarization performance significantly. Empirical results on the Debatepedia dataset show that the proposed model achieves the new state-of-the-art performance.1","The paper proposes a new model called QFS-BART for generating summaries that are both coherent and answer-related to a given query. Unlike previous QFS models, QFS-BART considers the explicit answer relevance of the source documents given the query via a question answering model. The model also takes advantage of large pre-trained models for improved summarization performance. Empirical results on the Debatepedia dataset show that QFS-BART achieves state-of-the-art performance.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract essential information and organize it into a summary that can answer a query.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document or set of documents in order to answer a specific query.', 'How will the summaries be used?': 'The summaries can be used for various applications, such as personalized search engines that provide users with an overview summary based on their query. They can also be used to improve the efficiency of information retrieval and decision-making processes.'}",['method'],['External Knowledge'],"['Debatepedia', 'DUC 2005', 'DUC 2007']",['ROUGE'],[''],https://github.com/HLTCHKUST/QFS,https://aclanthology.org/2021.findings-acl.275,"{'Early work on the QFS task mainly focused on generating extractive summaries, which may contain unreadable sentence ordering and lack cohesiveness.': 'The authors propose a BART-based framework for abstractive QFS that incorporates explicit answer relevance, which can produce more query-relevant summaries.', 'Other work on abstractive QFS incorporated the query relevance into existing neural summarization models, but did not take into consideration the answer relevance in the generation model.': 'The authors leverage a state-of-the-art QA model to predict the answer relevance of the given source documents to the query, then further incorporate the answer relevance into the BART-based generation model.', 'How to leverage recent neural summarization models and adapt them to the QFS task remains unexplored.': 'The authors propose QFS-BART, a BART-based framework for abstractive QFS that achieves state-of-the-art performance on a single-document QFS dataset (Debatepedia) and brings substantial improvements over several strong baselines on two multi-document QFS datasets (DUC 2006, 2007).'}",supervised,"['Arguments', 'News']",['information-loss-and-incoherence-in-extractive-summarization']
SP:ec322806a6d7e4e4d751c366efd0bf4b205d1365,Improving Factual Consistency of Abstractive Summarization via Question Answering,ACL,2021,"['Feng Nan', 'Cicero Nogueira dos Santos', 'Henghui Zhu', 'Patrick Ng', 'Kathleen McKeown', 'Ramesh Nallapati', 'Dejiao Zhang', 'Zhiguo Wang', 'Andrew O. Arnold', 'Bing Xiang']","A commonly observed problem with the stateof-the art abstractive summarization models is that the generated summaries can be factually inconsistent with the input documents. The fact that automatic summarization may produce plausible-sounding yet inaccurate summaries is a major concern that limits its wide application. In this paper we present an approach to address factual consistency in summarization. We first propose an efficient automatic evaluation metric to measure factual consistency; next, we propose a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, we confirm that our method is effective in improving factual consistency and even overall quality of the summaries, as judged by both automatic metrics and human evaluation.","The paper addresses the problem of factual inconsistency in abstractive summarization models. The authors propose an efficient automatic evaluation metric to measure factual consistency and a novel learning algorithm that maximizes the proposed metric during model training. Through extensive experiments, the authors confirm that their method is effective in improving factual consistency and overall quality of the summaries, as judged by both automatic metrics and human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the quality of abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the content of a document, without having to read the entire document.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'BERTScore', 'MoverScore']","['Informativeness', 'Factuality', 'Grammaticality']",,https://aclanthology.org/2021.acl-long.536,"{'Neural text summarization models tend to generate summaries that are not factually consistent with the input document.': 'The authors propose a new contrastive learning method that uses factualness as a training objective to improve the factual consistency of summarization models.', 'The lack of an effective (automatic) metric for factual consistency has been the major hurdle in improving abstractive summarization model training beyond MLE.': 'The authors propose an efficient automatic evaluation metric for factual consistency that is a simplification of the recently published QAGS protocol.', 'The widely used ROUGE score is inadequate to quantify factual consistency.': 'The authors propose a new evaluation metric for factual consistency that takes into account the relations among tokens in the context of an entire sequence.', 'Standard MLE training produces summaries with factual errors that, in addition to hallucinating facts, sometimes even contradict the input article.': 'The authors propose a new contrastive learning method that uses factualness as a training objective to improve the factual consistency of summarization models.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:b1ad6337b427609030f9598e1036d67aa66e1597,Reinforcement Learning for Abstractive Question Summarization with Question-aware Semantic Rewards,ACL,2021,"['Shweta Yadav', 'Deepak Gupta', 'Asma Ben Abacha', 'Dina Demner-Fushman']","The growth of online consumer health questions has led to the necessity for reliable and accurate question answering systems. A recent study showed that manual summarization of consumer health questions brings significant improvement in retrieving relevant answers. However, the automatic summarization of long questions is a challenging task due to the lack of training data and the complexity of the related subtasks, such as the question focus and type recognition. In this paper, we introduce a reinforcement learning-based framework for abstractive question summarization. We propose two novel rewards obtained from the downstream tasks of (i) question-type identification and (ii) question-focus recognition to regularize the question generation model. These rewards ensure the generation of semantically valid questions and encourage the inclusion of key medical entities/foci in the question summary. We evaluated our proposed method on two benchmark datasets and achieved higher performance over state-of-theart models. The manual evaluation of the summaries reveals that the generated questions are more diverse and have fewer factual inconsistencies than the baseline summaries. The source code is available here: https: //github.com/shwetanlp/CHQ-Summ.","The paper discusses the need for reliable and accurate question answering systems for online consumer health questions. It introduces a reinforcement learning-based framework for abstractive question summarization, which proposes two novel rewards obtained from downstream tasks to regularize the question generation model. The proposed method achieves higher performance over state-of-the-art models and generates more diverse and semantically valid questions with fewer factual inconsistencies. The source code is available on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of consumer health questions (CHQ) to improve the retrieval of relevant answers.', 'Who is the target audience?': 'The summaries are for consumers who use online web forums for their health information needs.', 'How will the summaries be used?': 'The summaries will be used to improve the quality of question summarization by enforcing the generation of semantically valid and factually correct question summaries. They will also be used to achieve higher abstraction levels and to be more semantically and factually similar to human-generated summaries.'}",['method'],['Objective Function'],"['MEQSUM', 'MATINF']","['ROUGE', 'Novel Bigrams']","['Semantics Preserved', 'Factual Consistency']",https://github.com/shwetanlp/CHQ-Summ,https://aclanthology.org/2021.acl-short.33,"{'The complexity of identifying the correct question type/intent.': 'The authors propose a new reinforcement learning based framework for abstractive question summarization that uses two novel question-aware semantic reward functions: Question-type Identification Reward (QTR) to measure correctly identified question-type(s) of the summarized question.', 'The difficulty of identifying salient medical entities and focus/topic of the question.': 'The authors propose a new reinforcement learning based framework for abstractive question summarization that uses two novel question-aware semantic reward functions: Question-focus Recognition Reward (QFR) to measure correctly recognized key medical concept(s) or focus/foci of the summary.', 'The lack of large-scale CHQ summarization datasets.': 'The authors propose a new reinforcement learning based framework for abstractive question summarization that achieves the new state-of-the-art performance on the MEQSUM and MATINF benchmark datasets.'}",reinforced,['Medical Reports'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:7d0ed56af5b7db5a163ec483a81146fbb2147c91,SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization,ACL,2021,"['Yixin Liu', 'Pengfei Liu']","In this paper, we present a conceptually simple while empirically powerful framework for abstractive summarization, SIMCLS, which can bridge the gap between the learning objective and evaluation metrics resulting from the currently dominated sequence-to-sequence learning framework by formulating text generation as a reference-free evaluation problem (i.e., quality estimation) assisted by contrastive learning. Experimental results show that, with minor modification over existing topscoring systems, SimCLS can improve the performance of existing top-performing models by a large margin. Particularly, 2.51 absolute improvement against BART (Lewis et al., 2020) and 2.50 over PEGASUS (Zhang et al., 2020a) w.r.t ROUGE-1 on the CNN/DailyMail dataset, driving the state-of-the-art performance to a new level. We have open-sourced our codes and results: https://github. com/yixinL7/SimCLS. Results of our proposed models have been deployed into EXPLAINABOARD (Liu et al., 2021a) platform, which allows researchers to understand our systems in a more fine-grained way.","The paper introduces a new framework called SIMCLS for abstractive summarization, which improves the performance of existing top-performing models by a large margin. The framework formulates text generation as a reference-free evaluation problem assisted by contrastive learning. The experimental results show that SIMCLS can achieve 2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on the CNN/DailyMail dataset, driving the state-of-the-art performance to a new level. The codes and results have been open-sourced, and the proposed models have been deployed into the EXPLAINABOARD platform for researchers to understand the systems in a more fine-grained way.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for language generation tasks, such as abstractive summarization and neural machine translation.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the document without reading the entire text.', 'How will the summaries be used?': ""The summaries can be used to save time and provide a quick overview of the document's content. They can also be used for information retrieval and knowledge management purposes.""}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum']",['ROUGE'],[''],https://github.com/yixinL7/SimCLS,https://aclanthology.org/2021.acl-short.135,"{'Seq2Seq models are usually trained under the framework of Maximum Likelihood Estimation (MLE) and in practice they are commonly trained with the teacher-forcing algorithm, which introduces a gap between the objective function and the evaluation metrics.': 'The authors propose to generalize the paradigm of contrastive learning to introduce an approach for abstractive summarization which achieves the goal of directly optimizing the model with the corresponding evaluation metrics, thereby mitigating the gaps between training and test stages in MLE training.', 'During the test stage, the model needs to generate outputs autoregressively, which means the errors made in the previous steps will accumulate. This gap between the training and test has been referred to as the exposure bias.': 'The authors propose a two-stage model for abstractive summarization, where a Seq2Seq model is first trained to generate candidate summaries with MLE loss, and then a parameterized evaluation model is trained to rank the generated candidates with contrastive learning. By optimizing the generation model and evaluation model at separate stages, they are able to train these two modules with supervised learning, bypassing the challenging and intricate optimization process of the RL-based methods.', 'RL-based training suffers from the noise gradient estimation problem, which often makes the training unstable and sensitive to hyper-parameters. Minimum risk training, as an alternative, has also been used in the language generation tasks. However, the accuracy of the estimated loss is restricted by the number of sampled outputs.': 'The authors propose to use contrastive learning to directly optimize the model with the corresponding evaluation metrics, thereby mitigating the limitations of MLE training and avoiding the challenges of deep RL and minimum risk training.', 'The relation between the evaluation metrics and the objective functions used in existing methods can be indirect and implicit.': 'The authors propose to disentangle the functions of contrastive loss and MLE loss by introducing them at different stages in their proposed framework, which allows for direct optimization of the model with the evaluation metrics.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:cf90500bcb8b8e0a7fef974e77461a3daa687072,Rewards with Negative Examples for Reinforced Topic-Focused Abstractive Summarization,EMNLP,2021,"['Khalil Mrini', 'Can Liu', 'Markus Dreyer']","We consider the problem of topic-focused abstractive summarization, where the goal is to generate an abstractive summary focused on a particular topic, a phrase of one or multiple words. We hypothesize that the task of generating topic-focused summaries can be improved by showing the model what it must not focus on. We introduce a deep reinforcement learning approach to topic-focused abstractive summarization, trained on rewards with a novel negative example baseline. We define the input in this problem as the source text preceded by the topic. We adapt the CNN-Daily Mail and New York Times summarization datasets for this task. We then show through experiments on existing rewards that the use of a negative example baseline can outperform the use of a self-critical baseline, in ROUGE, BERTSCORE, and human evaluation metrics.",System: This paper discusses the problem of generating abstractive summaries focused on a particular topic. The authors propose a deep reinforcement learning approach that uses a negative example baseline to improve the model's ability to identify what it should not focus on. They adapt existing datasets for this task and show that their approach outperforms a self-critical baseline in various evaluation metrics.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for topic-focused summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document related to a specific topic.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the main points of a document related to a specific topic, without having to read the entire document.'}",['method'],"['External Knowledge', 'Objective Function']","['CNN/DailyMail', 'NYT']","['ROUGE', 'Entity Specificity']","['Topic Relevance', 'Fluency']",,https://aclanthology.org/2021.newsum-1.4,"{'The authors identify the problem of topic-focused summarization, which involves generating a summary given a source text and a specific query or topic.': 'The authors propose a reinforcement learning-based approach to topic-focused summarization.', 'The authors note that existing approaches to topic-focused summarization include query relevance and importance, multi-modality manifold ranking, and query attention, but these approaches have limitations.': 'The authors propose a novel baseline that uses negative examples, which are sentences that contain information that the summarization model should not focus on.', 'The authors observe that many reinforced abstractive summarization methods use the self-critical baseline, which is obtained by greedily searching for a sequence that maximizes the likelihood probability of the current model.': 'The authors introduce a new baseline that uses negative examples instead of the self-critical baseline.', 'The authors note that existing datasets for topic-focused summarization, such as the DUC 2005 and 2006 datasets, are much smaller than benchmark datasets for generic summarization, resulting in fewer research work to train topic-focused summarization on state-of-the-art systems.': 'The authors adapt widely used generic summarization benchmarks to the task of topic-focused summarization, such that they aim to generate only one out of three summary sentences, given a corresponding topic.', 'The authors identify the need to optimize non-differentiable summarization metrics like ROUGE and BERTSCORE, or to encourage desirable summary aspects like semantic cohesion and entity coherence.': 'The authors propose using two existing rewards, the popular ROUGE-L reward and the Distributed Semantic Reward (DSR) of Li et al., inspired by BERTSCORE.', 'The authors aim to evaluate the effectiveness of their proposed negative example baseline compared to the self-critical baseline.': 'The authors run experiments on two existing generic summarization datasets adapted to their task, CNNDaily Mail and New York Times, and compare the performance of their proposed baseline to the self-critical baseline across both datasets and both rewards. They find that using their negative example baseline outperforms the self-critical baseline and results in more relevant summaries to the given topic.'}",reinforced,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:dd4fc57a9c7220a8521c3b49cdceb4ae66df6ca3,Sentence-level Planning for Especially Abstractive Summarization,EMNLP,2021,"['Andreas Marfurt', 'James Henderson']","Abstractive summarization models heavily rely on copy mechanisms, such as the pointer network or attention, to achieve good performance, measured by textual overlap with reference summaries. As a result, the generated summaries stay close to the formulations in the source document. We propose the sentence planner model to generate more abstractive summaries. It includes a hierarchical decoder that first generates a representation for the next summary sentence, and then conditions the word generator on this representation. Our generated summaries are more abstractive and at the same time achieve high ROUGE scores when compared to human reference summaries. We verify the effectiveness of our design decisions with extensive evaluations.ive summarization models heavily rely on copy mechanisms, such as the pointer network or attention, to achieve good performance, measured by textual overlap with reference summaries. As a result, the generated summaries stay close to the formulations in the source document. We propose the sentence planner model to generate more abstractive summaries. It includes a hierarchical decoder that first generates a representation for the next summary sentence, and then conditions the word generator on this representation. Our generated summaries are more abstractive and at the same time achieve high ROUGE scores when compared to human reference summaries. We verify the effectiveness of our design decisions with extensive evaluations.","

System: The paper proposes a new model called the sentence planner model to generate more abstractive summaries. The model includes a hierarchical decoder that generates a representation for the next summary sentence and conditions the word generator on this representation. The generated summaries are more abstractive and achieve high ROUGE scores when compared to human reference summaries. The effectiveness of the design decisions is verified through extensive evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the abstractiveness and coherence of the summaries while maintaining high ROUGE scores.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding large amounts of text, such as in research or news articles.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'Curation Corpus']","['ROUGE', 'BERTScore', 'SciBERTScore']","['Non-redundancy', 'Fluency', 'Coherence', 'Informativeness', 'Abstractiveness', 'Semantic Similarity']",https://github.com/idiap/sentence-planner,https://aclanthology.org/2021.newsum-1.1,"{'Abstractive summarization models rely heavily on copying long sequences from the input document, resulting in summaries that lack abstractiveness and coherence.': ""The authors propose a planning step at the sentence level before generating the summary word by word. This planning step involves outlining the next summary sentence at a higher level to give the model more capacity for abstraction. This reduces the model's reliance on copying the input and generates more abstractive summaries."", 'Current state-of-the-art models in abstractive summarization achieve high ROUGE scores but sacrifice abstractiveness and coherence.': 'The authors propose a hierarchical Transformer decoder that generates summaries from a latent sentence-level plan. This model, called the sentence planner, generates more abstractive summaries while improving the ROUGE scores of a state-of-the-art model without a hierarchical decoder.', ""Increasing the baseline's decoder parameters does not improve its performance to the level of the hierarchical decoder."": 'The authors verify the effectiveness of their model components with an ablation study, showing that the hierarchical decoder is necessary for generating more abstractive summaries while retaining high ROUGE scores.', 'There is a need for a more extensive evaluation of abstractive summarization models on different datasets.': 'The authors extensively evaluate their model on a recently published highly abstractive dataset and an established but more extractive corpus. They also perform a human evaluation study, where the sentence planner improves upon its strong baseline in each of six quality categories.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'robust-evaluation-methods']"
SP:58d7490b6ee6e39b2b74dd07a71fc0af5cffca76,Exploring Multitask Learning for Low-Resource Abstractive Summarization,EMNLP,2021,"['Ahmed Magooda', 'Mohamed Elaraby', 'Diane Litman']","This paper explores the effect of using multitask learning for abstractive summarization in the context of small training corpora. In particular, we incorporate four different tasks (extractive summarization, language modeling, concept detection, and paraphrase detection) both individually and in combination, with the goal of enhancing the target task of abstractive summarization via multitask learning. We show that for many task combinations, a model trained in a multitask setting outperforms a model trained only for abstractive summarization, with no additional summarization data introduced. Additionally, we do a comprehensive search and find that certain tasks (e.g. paraphrase detection) consistently benefit abstractive summarization, not only when combined with other tasks but also when using different architectures and training corpora.","The paper investigates the use of multitask learning for abstractive summarization with limited training data. Four different tasks, including extractive summarization, language modeling, concept detection, and paraphrase detection, are incorporated individually and in combination to improve abstractive summarization. The results show that multitask learning can enhance the performance of abstractive summarization, and certain tasks, such as paraphrase detection, consistently benefit the task.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization performance in low resource domains.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any particular audience.', 'How will the summaries be used?': 'The intended use of the summaries is not explicitly stated in the paper.'}",['method'],['Auxiliary Tasks'],"['CourseMirror', 'CNN/DailyMail', 'Amazon Product Reviews', 'Yelp Reviews']",['ROUGE'],[''],https://github.com/amagooda/MultiAbs,https://aclanthology.org/2021.findings-emnlp.142,"{'It is still unclear what range of tasks can best support summarization in multitask learning for text summarization.': 'The authors explore the utility of training on four different tasks (both alone and in combination) in addition to abstractive summarization.', 'It is unclear whether abstractive summarization performance can be boosted via multitask learning when training from a small dataset.': 'The authors use a pretrained BERT model within a multitask framework, and train all tasks using a small-sized corpus of student reflections (around 400 samples) to answer this question.', 'It is unclear whether the same findings will emerge if a very different learning model is used or if pretraining is performed.': 'The authors perform experiments using the T5 transformer model instead of fine-tuning with the BERT model to answer this question.', 'It is unclear whether the same findings will emerge if a very different small training corpus is used.': 'The authors replicate the student reflection experiments using two very different corpora (news and reviews) to answer this question.'}",supervised,"['Student Responses', 'News', 'Reviews']","['controlled-and-tailored-summarization', 'pretraining-and-sample-efficiency']"
SP:eec50ead17b03b8ffa6c1ea0af8d6546a79ae89d,Planning with Learned Entity Prompts for Abstractive Summarization,TACL,2021,"['Shashi Narayan', 'Yao Zhao', 'Joshua Maynez', 'Vitaly Nikolaev', 'Ryan McDonald']","We introduce a simple but flexible mechanism to learn an intermediate plan to ground the generation of abstractive summaries. Specifically, we prepend (or prompt) target summaries with entity chains—ordered sequences of entities mentioned in the summary. Transformer-based sequence-to-sequence models are then trained to generate the entity chain and then continue generating the summary conditioned on the entity chain and the input. We experimented with both pretraining and finetuning with this content planning objective. When evaluated on CNN/DailyMail, XSum, SAMSum, and BillSum, we demonstrate empirically that the grounded generation with the planning objective improves entity specificity and planning in summaries for all datasets, and achieves state-of-the-art performance on XSum and SAMSum in terms of ROUGE. Moreover, we demonstrate empirically that planning with entity chains provides a mechanism to control hallucinations in abstractive summaries. By prompting the decoder with a modified content plan that drops hallucinated entities, we outperform state-of-the-art approaches for faithfulness when evaluated automatically and by humans.","The paper introduces a mechanism to improve the generation of abstractive summaries by learning an intermediate plan that grounds the summary generation. This is achieved by prepending target summaries with entity chains, which are ordered sequences of entities mentioned in the summary. Transformer-based sequence-to-sequence models are then trained to generate the entity chain and continue generating the summary based on the entity chain and input. The approach was evaluated on multiple datasets and demonstrated improved entity specificity and planning in summaries, achieving state-of-the-art performance in terms of ROUGE on some datasets. The mechanism also provides a way to control hallucinations in abstractive summaries, outperforming state-of-the-art approaches for faithfulness when evaluated automatically and by humans.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to generate accurate and concise summaries from source document(s).', 'Who is the target audience?': 'The target audience for the generated summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the generated summaries will be used.'}",['method'],"['Input Encoding', 'Controlled Generation']","['BillSum', 'SAMSUM', 'CNN/DailyMail', 'XSum']",['ROUGE'],"['Faithfulness', 'Overall Quality']",https://github.com/google-research/google-research/tree/master/frost,https://aclanthology.org/2021.tacl-1.88,"{'Neural summarization models lack grounding in traditional methods, leading to undesired hallucinations in generated summaries.': 'The authors propose using Entity Chains as an intermediate summary representation to better plan and ground the generation of abstractive summaries. During training, they construct an augmented target summary by extracting and prepending its corresponding entity chain. At test time, the model generates both the entity chain followed by the summary. They use Transformer-based encoder-decoder models to generate an intermediate summary representation in the form of an entity chain and the summary conditioned on the entity chain and the input.', 'Lack of entity-level content planning in summarization models.': 'The authors introduce a novel training objective to neural summarization models for content planning with entity chains, referred to as FROST. As the entity chains are extracted from the reference summaries during training, their models learn to ground the generation of summaries to the entity chains found in them. FROST provides a very effective knob for entity-level content modification in abstractive summaries, enabling the drop-prompt mechanism where hallucinated entities are dropped out from the predicted content plan and the decoder is prompted with this modified plan to generate faithful summaries.', 'Limited diversity in generated summaries.': 'FROST enables generation of summaries with topical diversity by choosing different sets of entities from the source to plan what to discuss in the summary and with style diversity by reordering entities in the predicted plan to get an equivalent summary but with a different entity emphasis.'}",supervised,"['Legislative Bills', 'News', 'Dialog']","['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:ec1785ab7145e78ce82f0da23ca7208ac06ac3d5,Discourse Understanding and Factual Consistency in Abstractive Summarization,EACL,2021,"['Saadia Gabriel', 'Antoine Bosselut', 'Jeff Da', 'Ari Holtzman', 'Jan Buys', 'Kyle Lo', 'Asli Celikyilmaz', 'Yejin Choi']","We introduce a general framework for abstractive summarization with factual consistency and distinct modeling of the narrative flow in an output summary. Our work addresses current limitations of models for abstractive summarization that often hallucinate information or generate summaries with coherence issues. To generate abstractive summaries with factual consistency and narrative flow, we propose Cooperative Generator – Discriminator Networks (Co-opNet), a novel transformerbased framework where a generator works with a discriminator architecture to compose coherent long-form summaries. We explore four different discriminator objectives which each capture a different aspect of coherence, including whether salient spans of generated abstracts are hallucinated or appear in the input context, and the likelihood of sentence adjacency in generated abstracts. We measure the ability of Co-opNet to learn these objectives with arXiv scientific papers, using the abstracts as a proxy for gold longform scientific article summaries. Empirical results from automatic and human evaluations demonstrate that Co-opNet learns to summarize with considerably improved global coherence compared to competitive baselines.","The paper introduces a framework called Co-opNet for generating abstractive summaries with factual consistency and narrative flow. Co-opNet is a transformer-based framework where a generator works with a discriminator architecture to compose coherent long-form summaries. The paper explores four different discriminator objectives to capture different aspects of coherence. The ability of Co-opNet to learn these objectives is measured using arXiv scientific papers, with empirical results showing improved global coherence compared to competitive baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the challenge of generating summaries with coherent discourse structure and domain knowledge awareness.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a scientific paper.', 'How will the summaries be used?': 'The summaries will be used to provide a paragraph-length abstractive summary with proper discourse structure that contains factually correct claims.'}",['method'],['Objective Function'],"['arXiv', 'AAN']",['ROUGE'],"['Abstractiveness', 'Coherence', 'Factuality', 'Overall Quality']",https://github.com/skgabriel/coopnet,https://aclanthology.org/2021.eacl-main.34,"{'Current methods in summarization struggle to generate summaries with coherent discourse structure and domain knowledge awareness, and often produce factually incorrect content.': 'The authors propose a study on generating abstractive summaries with factuality and narrative flow, and introduce Cooperative Generator-Discriminator Networks (Co-opNet), a framework for abstractive summarization that considers subtle aspects of fact-checking and discourse necessary for coherent text generation.', 'Previous works on abstractive document-level summarization have difficulty in directly modeling or evaluating narrative flow and factuality in generated summaries, largely due to the limitations of existing datasets.': 'The authors test their summarization model on a set of arXiv scientific papers, which are ideal for modeling narrative flow and maintaining implicit abstractive alignments with respect to the introduction of the article.', 'Current models for abstractive summarization are often extractive rather than abstractive, due to the highly extractive nature of commonly used datasets.': 'The authors use scientific abstracts as a dataset, which are structured with highly coherent discourse flow and maintain implicit abstractive alignments, allowing for more abstractive summarization.', 'Current models for abstractive summarization often generate factually incorrect content.': 'The authors introduce a discriminator in their Co-opNet framework that scores the factuality or discourse quality of candidate summaries using one of four different objectives, leading to more factually consistent summaries.', 'There is a lack of comprehensive empirical results considering both automatic and human evaluations for abstractive summarization models.': 'The authors provide comprehensive empirical results considering both automatic and human evaluations, demonstrating that Co-opNet learns to summarize scientific articles with considerably improved global coherence compared to competitive baselines, and is effective at generating scientific abstracts that are more factually consistent.'}",supervised,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'hallucinations-in-the-generated-summaries']"
SP:f673ba2f731e0548ceafc93e3bbf77da8a72e9a8,EASE: Extractive-Abstractive Summarization End-to-End using the Information Bottleneck Principle,EMNLP,2021,"['Haoran Li', 'Arash Einolghozati', 'Srinivasan Iyer', 'Bhargavi Paranjape', 'Yashar Mehdad', 'Sonal Gupta', 'Marjan Ghazvininejad']","Current abstractive summarization systems outperform their extractive counterparts, but their widespread adoption is inhibited by the inherent lack of interpretability. Extractive summarization systems, though interpretable, suffer from redundancy and possible lack of coherence. To achieve the best of both worlds, we propose EASE, an extractive-abstractive framework that generates concise abstractive summaries that can be traced back to an extractive summary. Our framework can be applied to any evidence-based text generation problem and can accommodate various pretrained models in its simple architecture. We use the Information Bottleneck principle to jointly train the extraction and abstraction in an end-to-end fashion. Inspired by previous research that humans use a two-stage framework to summarize long documents (Jing and McKeown, 2000), our framework first extracts a pre-defined amount of evidence spans and then generates a summary using only the evidence. Using automatic and human evaluations, we show that the generated summaries are better than strong extractive and extractiveabstractive baselines.","The paper proposes a new framework called EASE that combines the strengths of extractive and abstractive summarization systems to generate concise and interpretable summaries. The framework uses the Information Bottleneck principle to jointly train extraction and abstraction in an end-to-end fashion. Inspired by human summarization methods, the framework first extracts a pre-defined amount of evidence spans and then generates a summary using only the evidence. The authors show through automatic and human evaluations that the generated summaries are better than strong extractive and extractive-abstractive baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce natural summaries that can be traced back to an interpretable extractive summary.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be applied to various evidence-based text generation tasks.'}",['method'],"['Unit Selection', 'Controlled Generation']","['CNN/DailyMail', 'XSum']",['ROUGE'],"['Consistency', 'Relevance']",,https://aclanthology.org/2021.newsum-1.10.pdf,"{'Pretrained sequence-to-sequence language models lack interpretability in abstractive generation, which hinders their broader adoption.': 'The authors propose EASE, a novel framework that combines extractive and abstractive systems to produce natural summaries that can be traced back to an interpretable extractive summary.', 'Existing extractive-abstractive systems fall short in providing usable evidence or are too granular to be useful for humans.': 'The authors seek a theoretically grounded model that can learn the evidence extraction end-to-end, based on the Information Bottleneck principle.', 'Zhao et al. (2020) proposed a complicated and specific framework for long-document summarization that achieved poor results on benchmarks such as CNN/DM.': 'The authors propose EASE, which extends the Information Bottleneck principle to generative tasks and leverages pretrained language models to extract necessary evidence from the source document and generate the final output using only the extracted evidence spans.', 'Extractive summarization systems are too restrictive by forcing the output to be spans from the document, reducing their naturalness, coherence, and conciseness.': 'The authors propose a new sparsity budget parameter that controls the trade-off between the length of the evidence spans (i.e., the extractive summary) and the final abstractive output’s quality.', 'The quality of the generated summary may be sacrificed when extracting evidence.': 'The authors show that EASE extracts evidence better than the baselines without significantly sacrificing the quality of the generated summary, compared with the state-of-the-art fully abstractive systems on the CNN/DailyMail dataset.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'controlled-and-tailored-summarization']"
SP:07114db881b94e3bdc3c7eff27dc08b10d0b88ff,Learn to Copy from the Copying History: Correlational Copy Network for Abstractive Summarization,EMNLP,2021,"['Haoran Li', 'Song Xu', 'Peng Yuan', 'Yujia Wang', 'Youzheng Wu', 'Xiaodong He', 'Bowen Zhou']","The copying mechanism has had considerable success in abstractive summarization, facilitating models to directly copy words from the input text to the output summary. Existing works mostly employ encoder-decoder attention, which applies copying at each time step independently of the former ones. However, this may sometimes lead to incomplete copying. In this paper, we propose a novel copying scheme named Correlational Copying Network (CoCoNet) that enhances the standard copying mechanism by keeping track of the copying history. It thereby takes advantage of prior copying distributions and, at each time step, explicitly encourages the model to copy the input word that is relevant to the previously copied one. In addition, we strengthen CoCoNet through pretraining with suitable corpora that simulate the copying behaviors. Experimental results show that CoCoNet can copy more accurately and achieves new state-of-the-art performances on summarization benchmarks, including CNN/DailyMail for news summarization and SAMSum for dialogue summarization. Our code is available at https:// github.com/hrlinlp/coconet.","The paper proposes a new copying scheme called Correlational Copying Network (CoCoNet) for abstractive summarization that enhances the standard copying mechanism by keeping track of the copying history. CoCoNet takes advantage of prior copying distributions and encourages the model to copy the input word that is relevant to the previously copied one. The model is strengthened through pretraining with suitable corpora that simulate the copying behaviors. Experimental results show that CoCoNet can copy more accurately and achieves new state-of-the-art performances on summarization benchmarks, including CNN/DailyMail for news summarization and SAMSum for dialogue summarization. The code is available at https://github.com/hrlinlp/coconet.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a condensed and cohesive version of the input text, enabling readers to grasp the main points without reading the full text.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly understand the main points of a document.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'SAMSUM']","['ROUGE', 'METEOR']","['Informativeness', 'Readability']",https://github.com/hrlinlp/coconet,https://aclanthology.org/2021.emnlp-main.336,"{'Seq2Seq framework suffers from handling out-of-vocabulary words (OOV).': 'The authors propose the copying mechanism, which copies words from the input sequence to form part of the summary. They build CoCoNet based on the Transformer-based Seq2Seq architecture, which copies from the input text at each time step by selecting what is relevant to the previously copied word. CoCoNet keeps track of the prior copying distribution and explicitly models the correlation between different source words by integrating semantic and positional correlations.', 'Existing models neglect the guidance of the copying history.': 'The authors propose a novel copying architecture named Correlational Copying Network (CoCoNet) that can learn to copy from the copying history. CoCoNet tracks the copying history and copies the next word from the input based on its relevance with the previously copied one. It explicitly models the correlation between different source words by integrating semantic and positional correlations.', 'The copying mechanism needs to be enhanced for better performance.': 'The authors enhance CoCoNet through pretraining with a self-supervised objective of text span generation with copying on the raw text corpora. They make sure their pretraining simulates the copying behaviors desired for the downstream summarization tasks. They divide each sequence in the corpora into two spans with some overlapping words, and the first span is used to generate the second in pre-training. They measure the overlap between the two spans based on ROUGE scores to ensure that there are enough words to be generated by copying.', 'The accuracy of copying needs to be improved.': 'CoCoNet achieves new state-of-the-art performances on news summarization and dialogue summarization tasks, and experimental results show that CoCoNet can copy more accurately.'}",supervised,"['News', 'Dialog']",['controlled-and-tailored-summarization']
SP:10698b344d9287d69ccfd05ab8d8a35f724fb378,Knowledge and Keywords Augmented Abstractive Sentence Summarization,EMNLP,2021,"['Shuo Guan', 'Ping Zhu', 'Zhihua Wei']","In this paper, we study the knowledge-based abstractive sentence summarization. There are two essential information features that can influence the quality of news summarization, which are topic keywords and the knowledge structure of the news text. Besides, the existing knowledge-augmented methods have poor performance on sentence summarization since the sparse knowledge structure problem. Considering these, we propose KAS, a novel Knowledge and",Abstractive Sentence summarization method that addresses the issue of sparse knowledge structure. The proposed method utilizes topic keywords and knowledge structure to generate high-quality summaries. The results show that KAS outperforms existing methods in terms of ROUGE scores and human evaluation.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of natural language text to cover all the essential information in sentence or short text summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document.', 'How will the summaries be used?': ""The summaries can be used to save time and provide a quick overview of the document's content. They can also be used to compare and contrast multiple documents on the same topic.""}",['method'],['External Knowledge'],['Gigaword'],['ROUGE'],"['Informativeness', 'Fluency', 'Diversity', 'Hallucination Error', 'Logical Error']",https://github.com/SeanG-325/KAS,https://aclanthology.org/2021.newsum-1.3,"{'Existing knowledge-based summarization methods are not applicable to sentence summarization.': 'The authors propose a new knowledge-augmented sentence summarization model that addresses the limitations of existing methods.', 'GNN has poor performance in sparse knowledge structure, which is common in sentence summarization.': 'The authors propose a special linearized knowledge sequence structure that is applicable to sentence summarization and enhances the performance of the model.', 'Most knowledge-based summarization models are only applicable to English.': 'The authors aim to make their model applicable to multiple languages and conduct experiments on English and Chinese corpus, achieving best performances on both.', 'The proposed model needs to consider both topic keyword context and knowledge structure context.': 'The authors propose a novel triencoder framework KAS that integrates three separate encoders, considering contexts of original text, topic keywords, and knowledge structure simultaneously based on their salience.'}",supervised,['News'],[]
SP:cbef24c7924ff88d06485ae2b2a2fecc4c4138f7,Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation,NAACL,2021,"['Alexander R. Fabbri', 'Simeng Han', 'Haoyuan Li', 'Haoran Li', 'Marjan Ghazvininejad', 'Shafiq Joty', 'Dragomir Radev', 'Yashar Mehdad']","Models pretrained with self-supervised objectives on large text corpora achieve state-of-theart performance on English text summarization tasks. However, these models are typically fine-tuned on hundreds of thousands of data points, an infeasible requirement when applying summarization to new, niche domains. In this work, we introduce a novel and generalizable method, called WikiTransfer, for fine-tuning pretrained models for summarization in an unsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained models on pseudo-summaries, produced from generic Wikipedia data, which contain characteristics of the target dataset, such as the length and level of abstraction of the desired summaries. WikiTransfer models achieve state-ofthe-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate the effectiveness of our approach on three additional diverse datasets. These models are more robust to noisy data and also achieve better or comparable few-shot performance using 10 and 100 training examples when compared to few-shot transfer from other summarization datasets. To further boost performance, we employ data augmentation via round-trip translation as well as introduce a regularization term for improved few-shot transfer. To understand the role of dataset aspects in transfer performance and the quality of the resulting output summaries, we further study the effect of the components of our unsupervised fine-tuning data and analyze few-shot performance using both automatic and human evaluation.","The paper discusses how models pretrained on large text corpora achieve state-of-the-art performance on English text summarization tasks, but fine-tuning them on new, niche domains is infeasible due to the requirement of hundreds of thousands of data points. The authors introduce a novel and generalizable method called WikiTransfer, which fine-tunes pretrained models for summarization in an unsupervised, dataset-specific manner using pseudo-summaries produced from generic Wikipedia data. WikiTransfer models achieve state-of-the-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate effectiveness on three additional diverse datasets. The authors also employ data augmentation and introduce a regularization term to improve few-shot transfer performance. The paper further studies the effect of dataset aspects on transfer performance and evaluates the quality of output summaries using both automatic and human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to distill the most salient content of a given text in a compact form.', 'Who is the target audience?': 'The summaries are for use in real-world applications where large pretrained models are being used.', 'How will the summaries be used?': 'The summaries will be used to improve zero-shot and few-shot summarization transfer by encoding characteristics of the target summarization dataset in unsupervised, intermediate fine-tuning data.'}",['method'],['External Knowledge'],"['CNN/DailyMail', 'XSum', 'Reddit-TIFU', 'BigPatent']","['ROUGE', 'Entity Precision']","['Consistency', 'Relevance']",,https://aclanthology.org/2021.naacl-main.57,"{'Creating data for every new domain is infeasible and highly costly, making it necessary to transfer large pretrained models to new domains with little or no in-domain data.': 'The authors propose to improve zero-shot and few-shot summarization by encoding characteristics of the target summarization dataset in unsupervised, intermediate fine-tuning data. They introduce a novel method called WikiTransfer, which creates pseudo-summaries with subaspects of the target dataset that can be used as unlabeled data for intermediate fine-tuning.', 'Little work has focused on domain adaptation in summarization.': 'The authors aim to build on recent work in pretrained models and improve zero-shot and few-shot summarization by encoding characteristics of the target summarization dataset in unsupervised, intermediate fine-tuning data.', 'Summarization can be seen as a function of subfunctions of the input, called subaspects, which determine the output form.': 'The authors aim to encode subaspects of a target dataset into unlabeled data to allow a model finetuned on this data to learn characteristics of the target dataset to improve zero-shot and few-shot transfer of the model. They focus on the subaspects of extractive diversity, compression ratio between the source document and summary, and lead bias.', 'Summarization models have difficulty generating text in the style of the target domain.': 'The authors propose to encode characteristics of the target summarization dataset in unsupervised, intermediate fine-tuning data to improve zero-shot and few-shot transfer of the model.', 'The authors aim to improve zero-shot and few-shot summarization.': 'The authors introduce a novel method called WikiTransfer, which creates pseudo-summaries with subaspects of the target dataset that can be used as unlabeled data for intermediate fine-tuning. They demonstrate the benefits of WikiTransfer in few-shot settings and show additional improvements when applying WikiTransfer with data augmentation and a regularization term for training with potentially noisy augmented data. They show robustness in these settings and analyze differences in performance in both automatic and human assessments.'}",supervised,"['News', 'Social Media', 'Patents', 'CQA']",[]
SP:5966dc71226118c08507af4af989412cb2c7daaa,Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization,NAACL,2021,"['Yichen Jiang', 'Asli Celikyilmaz', 'Paul Smolensky', 'Paul Soulos', 'Sudha Rao', 'Hamid Palangi', 'Roland Fernandez', 'Caitlin Smith', 'Mohit Bansal', 'Jianfeng Gao']","Abstractive summarization, the task of generating a concise summary of input documents, requires: (1) reasoning over the source document to determine the salient pieces of information scattered across the long document, and (2) composing a cohesive text by reconstructing these salient facts into a shorter summary that faithfully reflects the complex relations connecting these facts. In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture that enriches the original Transformer (Vaswani et al., 2017) with the explicitly compositional Tensor Product Representation (TPR), for the task of abstractive summarization. The key feature of our model is a structural bias that we introduce by encoding two separate representations for each token to represent the syntactic structure (with role vectors) and semantic content (with filler vectors) separately. The model then binds the role and filler vectors into the TPR as the layer output. We argue that the structured intermediate representations enable the model to take better control of the contents (salient facts) and structures (the syntax that connects the facts) when generating the summary. Empirically, we show that our TP-TRANSFORMER outperforms the Transformer and the original TPTRANSFORMER significantly on several abstractive summarization datasets based on both automatic and human evaluations. On several syntactic and semantic probing tasks, we demonstrate the emergent structural information in the role vectors and improved syntactic interpretability in the TPR layer outputs.1ive summarization, the task of generating a concise summary of input documents, requires: (1) reasoning over the source document to determine the salient pieces of information scattered across the long document, and (2) composing a cohesive text by reconstructing these salient facts into a shorter summary that faithfully reflects the complex relations connecting these facts. In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture that enriches the original Transformer (Vaswani et al., 2017) with the explicitly compositional Tensor Product Representation (TPR), for the task of abstractive summarization. The key feature of our model is a structural bias that we introduce by encoding two separate representations for each token to represent the syntactic structure (with role vectors) and semantic content (with filler vectors) separately. The model then binds the role and filler vectors into the TPR as the layer output. We argue that the structured intermediate representations enable the model to take better control of the contents (salient facts) and structures (the syntax that connects the facts) when generating the summary. Empirically, we show that our TP-TRANSFORMER outperforms the Transformer and the original TPTRANSFORMER significantly on several abstractive summarization datasets based on both automatic and human evaluations. On several syntactic and semantic probing tasks, we demonstrate the emergent structural information in the role vectors and improved syntactic interpretability in the TPR layer outputs.1","The paper discusses the task of abstractive summarization, which involves generating a concise summary of input documents. The authors adapt the TP-TRANSFORMER architecture, which enriches the original Transformer with the Tensor Product Representation (TPR), for this task. The model encodes two separate representations for each token to represent the syntactic structure and semantic content separately, and then binds them into the TPR as the layer output. The authors argue that this structured intermediate representation enables the model to better control the contents and structures when generating the summary. The TP-TRANSFORMER outperforms the Transformer and the original TP-TRANSFORMER significantly on several abstractive summarization datasets based on both automatic and human evaluations. The authors also demonstrate the emergent structural information in the role vectors and improved syntactic interpretability in the TPR layer outputs.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to create a shorter version of the source text while preserving the meaning of its salient contents.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the generated summaries will be used.'}",['method'],['Input Encoding'],"['XSum', 'WikiHow', 'arXiv', 'CNN/DailyMail']","['ROUGE', 'Relation Matching Rate', 'Textual Entailment']","['Grammaticality', 'Coherence', 'Faithfulness', 'Saliency', 'Repetition', 'Overall Quality']",https://github.com/jiangycTarheel/TPT-Summ,https://aclanthology.org/2021.naacl-main.381,"{'Models struggle with combining multiple salient aspects in the source text into a coherent and grammatical set of sentences that preserve the original information in the source document.': 'The authors investigate new types of computational primitives for transformers based on Tensor Product Representations (TPRs) which are explicitly-compositional vector embeddings of symbolic structures. They adapt the TP-TRANSFORMER for the task of abstractive summarization, which generates a pair of representations for every token at every layer: a filler vector returned by attention and a novel role vector. The model then binds the role and filler vectors to produce the output of every token as a TPR.', 'Current state-of-the-art transformer based approaches still struggle with systematic generalization of the composition of multiple salient pieces of information.': 'The authors test the ability of their TP-TRANSFORMER with discrete roles against the standard Transformer and the TP-TRANSFORMER with continuous roles on a number of summarization datasets spanning different degrees of abstractiveness, output summary lengths, and domains. Their TP-TRANSFORMER significantly outperforms the standard Transformer and the TP-TRANSFORMER with continuous roles on several abstractive summarization datasets.', 'The structural representation that naturally emerges during training and the advantage of having compositional TPR hidden states is not well understood.': 'The authors design a suite of decoder probing tasks to explore the information encoded in the role, filler, and TPR space. Their findings collectively show that the decoder’s role vectors encode a wealth of syntactic structures, aiding the decoder in deducing the syntactic features of the next token to be generated. The decoder’s filler vectors on the other hand encode more semantic information. They observe that having the compositional TPR results in a more interpretable final representation than the original Transformer has at every layer, regarding the syntactic features of the next word to be generated.'}",supervised,"['News', 'CQA']",[]
SP:1fa4074ee8155180f7ef258ea3ec622394800977,GSum: A General Framework for Guided Neural Abstractive Summarization,NAACL,2021,"['Zi-Yi Dou', 'Pengfei Liu', 'Hiroaki Hayashi', 'Zhengbao Jiang', 'Graham Neubig']","Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of guidance to control the output and increase faithfulness, it is not clear how these strategies compare and contrast to each other. In this paper, we propose a general and extensible guided summarization framework (GSum) that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.1","The paper discusses the challenges of neural abstractive summarization models, which can produce coherent summaries but may be unfaithful and difficult to control. The authors propose a guided summarization framework (GSum) that can effectively take different types of external guidance as input and demonstrate its effectiveness in achieving state-of-the-art performance on popular summarization datasets. The authors also show how different types of guidance can generate qualitatively different summaries, providing a degree of controllability to the learned models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a concise and informative representation of the original content.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the main points of the document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as information retrieval, document browsing, and content analysis.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'XSum', 'Reddit-TIFU', 'WikiHow', 'NYT', 'PubMed']",['ROUGE'],['Faithfulness'],https://github.com/neulab/guided_summarization,https://aclanthology.org/2021.naacl-main.384/,"{'Unfaithful summaries and hallucinated content can result from unconstrained abstractive summarization.': 'The authors propose guided neural abstractive summarization methods that constrain the summary to deviate less from the source document.', 'It can be difficult to control the content of summaries in abstractive summarization.': 'The authors propose guided neural abstractive summarization methods that allow for controllability through provision of user-specified inputs.', 'Previous methods for guiding neural abstractive summarization models focus on one particular type of guidance, and it is unclear which is better and whether they are complementary to each other.': 'The authors propose a general and extensible guided summarization framework that can take different kinds of external guidance as input, and investigate four types of guidance signals: highlighted sentences in the source document, keywords, salient relational triples, and retrieved summaries.', 'The model may not pay close attention to the guidance during training.': 'The authors propose to use an oracle to select informative guidance signals during training, which proved essential in effective learning of their guided summarization models.', 'It is unclear which guidance signal is the most effective.': 'The authors perform in-depth analyses of different guidance signals and demonstrate that they are complementary to each other, with potential to aggregate their outputs together and obtain further improvements.', 'Abstractive summarization models may generate unfaithful summaries and lack novelty.': 'The authors demonstrate that their guided models can generate more faithful summaries and more novel words.', 'It is difficult to control the output of abstractive summarization models.': 'The authors demonstrate that they can control the output by providing user-specified guidance signals, with different provided signals resulting in qualitatively different summaries.'}",supervised,"['News', 'Social Media', 'Scholarly Documents', 'CQA']",['hallucinations-in-the-generated-summaries']
SP:999833519c8daf593c2274fa1b41eb4b9ff72326,Entity-level Factual Consistency of Abstractive Text Summarization,EACL,2021,"['Feng Nan', 'Ramesh Nallapati', 'Zhiguo Wang', 'Cicero Nogueira dos Santos', 'Henghui Zhu', 'Dejiao Zhang', 'Kathleen McKeown', 'Bing Xiang']","A key challenge for abstractive summarization is ensuring factual consistency of the generated summary with respect to the original document. For example, state-ofthe-art models trained on existing datasets exhibit entity hallucination, generating names of entities that are not present in the source document. We propose a set of new metrics to quantify the entity-level factual consistency of generated summaries and we show that the entity hallucination problem can be alleviated by simply filtering the training data. In addition, we propose a summary-worthy entity classification task to the training process as well as a joint entity and summary generation approach, which yield further improvements in entity level metrics.","System: The paper discusses the challenge of ensuring factual consistency in abstractive summarization, particularly in relation to entity hallucination. The authors propose new metrics to measure entity-level factual consistency and suggest filtering training data as a solution to the problem. They also propose a summary-worthy entity classification task and a joint entity and summary generation approach to further improve entity level metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the quality of abstractive summarization using deep neural networks.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the content of a document, without having to read the entire document.'}",['metric'],"['Auxiliary Tasks', 'Objective Function']","['CNN/DailyMail', 'XSum', 'NYT']",['ROUGE'],[''],https://github.com/amazon-science/fact-check-summarization,https://aclanthology.org/2021.eacl-main.235,"{'Neural text summarization models tend to generate summaries that are not factually consistent with the input document.': 'The authors propose a set of simple metrics to quantify factual consistency at the entity level.', 'Factual inconsistency can occur at either the entity or the relation level.': 'The authors focus on the entity level and leave the relation level consistency to future work.', 'Model generated summaries may contain named entities that never appeared in the source document, which is called the entity hallucination problem.': 'The authors propose techniques including data filtering, multi-task learning, and joint sequence generation to improve performance on the entity hallucination problem.', 'Open Information Extraction (OpenIE) and dependency parsing tools are not yet accurate enough for practical use in identifying the underlying relations in a summary.': 'The authors rely on manually classifying generated summaries into faithful, fake, or unclear.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:bf2e7e85a32456e1a85ad0853791e8732815a88d,Enhancing Factual Consistency of Abstractive Summarization,NAACL,2021,"['Chenguang Zhu', 'William Hinthorn', 'Ruochen Xu', 'Qingkai Zeng', 'Michael Zeng', 'Xuedong Huang', 'Meng Jiang']","Automatic abstractive summaries are found to often distort or fabricate facts in the article. This inconsistency between summary and original text has seriously impacted its applicability. We propose a fact-aware summarization model FASUM to extract and integrate factual relations into the summary generation process via graph attention. We then design a factual corrector model FC to automatically correct factual errors from summaries generated by existing systems. Empirical results1 show that the fact-aware summarization can produce abstractive summaries with higher factual consistency compared with existing systems, and the correction model improves the factual consistency of given summaries via modifying only a few keywords.","The paper discusses the issue of inconsistency between automatic abstractive summaries and the original text, which can distort or fabricate facts. To address this problem, the authors propose a fact-aware summarization model called FASUM, which integrates factual relations into the summary generation process using graph attention. They also introduce a factual corrector model called FC to automatically correct factual errors in existing summaries. Empirical results show that FASUM produces more factually consistent summaries compared to existing systems, and FC can improve the factual consistency of given summaries by modifying only a few keywords.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long text to produce an abridged version while preserving salient information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long text, such as researchers, journalists, or general readers.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long texts, to quickly understand the main points of a text, or to get an overview of a topic before diving into the details.'}",['method'],"['External Knowledge', 'Post Processing']","['CNN/DailyMail', 'XSum']","['ROUGE', 'BERTScore', 'FEQA']","['Factuality', 'Informativeness']",https://github.com/zcgzcgzcg1/FASum/,https://aclanthology.org/2021.naacl-main.58,"{'Abstractive summarization models often contain factual inconsistencies, which can distort or fabricate the facts in the article.': 'The authors propose a Fact-Aware Summarization model (FASUM) that represents facts in the form of knowledge graphs extracted from the article itself. They use an information extraction tool to extract facts in the form of relational tuples and integrate them into the summary generation process. They also propose a Factual Corrector model (FC) to improve the factual consistency of any given summary by replacing wrong entities with the right ones.', 'Existing abstractive summarization models focus on token-level accuracy of summaries, neglecting semantic-level consistency between the summary and article.': 'The authors argue that a robust abstractive summarization system must be equipped with factual knowledge to accurately summarize the article. They propose using knowledge graphs to represent facts and integrate them into the summary generation process.', 'There is no easy-to-compute metric to evaluate factual consistency of summaries.': 'The authors propose a model-free metric, relation matching rate (RMR), that employs the extracted relations and does not require human-labelled summaries. They show that their models can help enhance the factual consistency of summaries under this metric.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:a9637bd1f8ebe8ef62220d14e791ae2e915e40e2,AdaptSum: Towards Low-Resource Domain Adaptation for Abstractive Summarization,NAACL,2021,"['Tiezheng Yu', 'Zihan Liu', 'Pascale Fung']","State-of-the-art abstractive summarization models generally rely on extensive labeled data, which lowers their generalization ability on domains where such data are not available. In this paper, we present a study of domain adaptation for the abstractive summarization task across six diverse target domains in a low-resource setting. Specifically, we investigate the second phase of pre-training on large-scale generative models under three different settings: 1) source domain pre-training; 2) domain-adaptive pre-training; and 3) taskadaptive pre-training. Experiments show that the effectiveness of pre-training is correlated with the similarity between the pre-training data and the target domain task. Moreover, we find that continuing pre-training could lead to the pre-trained model’s catastrophic forgetting, and a learning method with less forgetting can alleviate this issue. Furthermore, results illustrate that a huge gap still exists between the low-resource and high-resource settings, which highlights the need for more advanced domain adaptation methods for the abstractive summarization task.1","The paper discusses the challenges faced by state-of-the-art abstractive summarization models due to their reliance on extensive labeled data, which limits their generalization ability on domains where such data are not available. The authors present a study of domain adaptation for the abstractive summarization task in a low-resource setting, focusing on the second phase of pre-training on large-scale generative models under three different settings. The experiments show that the effectiveness of pre-training is correlated with the similarity between the pre-training data and the target domain task. The authors also find that continuing pre-training could lead to catastrophic forgetting, and a learning method with less forgetting can alleviate this issue. The results highlight the need for more advanced domain adaptation methods for the abstractive summarization task, as a huge gap still exists between the low-resource and high-resource settings.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to extract essential information and create short, concise, and readable text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly get an overview of the main points for decision-making or further research.'}",['method'],['Auxiliary Tasks'],"['SAMSUM', 'AESLC', 'IMDB Movie Review', 'Debate', 'Reddit-TIFU', 'CL-SciSumm']",['ROUGE'],[''],https://github.com/TysonYu/AdaptSum,https://aclanthology.org/2021.naacl-main.471/,"{'Abstractive summarization models require large numbers of human-annotated summaries to achieve state-of-the-art performance, making them not scalable to low-resource domains where only a few labeled data are available.': 'The authors present AdaptSum, the first benchmark to simulate the low-resource domain adaptation setting for abstractive summarization systems with a combination of existing datasets across six diverse domains, and for each domain, they reduce the number of training samples to a small quantity so as to create a low-resource scenario.', 'Very few studies have used domain adaptation methods on the low-resource scenario for the abstractive summarization task.': 'The authors systematically investigate adding a second phase of pre-training on large-scale generative models under three settings: source domain pre-training (SDPT), domain-adaptive pre-training (DAPT), and task-adaptive pre-training (TAPT).', 'The second phase of pre-training could cause catastrophic forgetting in the pre-trained model.': 'The authors propose to apply RecAdam into the pre-training process to alleviate this issue and further improve the adaptation performance.', 'The effectiveness of DAPT is correlated to the similarity between the pre-training data and the target domain task data.': 'The authors find that in the summarization task, DAPT could make the adaptation performance worse, even though the pre-training corpus is collected from domain-related sources.', 'There is a research gap in exploring the use of second-phase pre-training on large-scale generative models for generation tasks.': 'The authors systematically investigate the use of second-phase pre-training on large-scale generative models for the abstractive summarization task.', 'The authors hope to catalyze research in the low-resource abstractive summarization task.': 'The authors highlight the research questions and challenges in the low-resource abstractive summarization task.'}",supervised,"['Dialog', 'Emails', 'Reviews', 'Arguments', 'Social Media', 'Scholarly Documents']","['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:770cef6ed080f62bb1d243b16a77dc2bad10d658,A New Approach to Overgenerating and Scoring Abstractive Summaries,NAACL,2021,"['Kaiqiang Song', 'Bingqing Wang', 'Zhe Feng', 'Fei Liu']","We propose a new approach to generate multiple variants of the target summary with diverse content and varying lengths, then score and select admissible ones according to users’ needs. Abstractive summarizers trained on single reference summaries may struggle to produce outputs that achieve multiple desirable properties, i.e., capturing the most important information, being faithful to the original, grammatical and fluent. In this paper, we propose a two-staged strategy to generate a diverse set of candidate summaries from the source text in stage one, then score and select admissible ones in stage two. Importantly, our generator gives a precise control over the length of the summary, which is especially well-suited when space is limited. Our selectors are designed to predict the optimal summary length and put special emphasis on faithfulness to the original text. Both stages can be effectively trained, optimized and evaluated. Our experiments on benchmark summarization datasets suggest that this paradigm can achieve state-of-the-art performance.","The paper proposes a new approach to generate multiple summaries with diverse content and varying lengths, and then select the best ones based on user needs. The approach involves a two-staged strategy to generate a diverse set of candidate summaries from the source text and then score and select admissible ones. The generator gives precise control over the length of the summary, and the selectors are designed to predict the optimal summary length and emphasize faithfulness to the original text. The approach achieves state-of-the-art performance in benchmark summarization datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce system outputs that resemble reference summaries on a word-to-word basis and to promote outputs that possess multiple desirable properties.', 'Who is the target audience?': 'The summaries are for future summarizers to compare their outputs against multiple reference summaries, which is key to improve the reliability of evaluation results.', 'How will the summaries be used?': 'The summaries will be used to judge the effectiveness of summary selectors and to inform the design of summarizers of all forms.'}",['method'],['Controlled Generation'],"['Gigaword', 'Newsroom']","['ROUGE', 'QuestEval']","['Coverage', 'Truthfulness', 'Grammaticality', 'Overall Quality']",https://github.com/ucfnlp/varying-length-summ,https://aclanthology.org/2021.naacl-main.110,"{'The learning objective of a modern abstractive summarizer is to produce system outputs that resemble reference summaries on a word-to-word basis, but it does not promote outputs that possess multiple desirable properties, such as capturing the most important information, being faithful to the original text, grammatical and fluent, which can lead to changes in the meaning of the original document or failure to convey the main concepts.': 'The authors propose a new approach to overgenerate and select admissible summaries, which allows a summarizer to juggle multiple objectives and strike a good balance between them. Their approach consists of two stages: a generator that explores the space of all possible lengths to produce multiple variants of the target summary that contain diverse content, and selectors that validate the quality of alternative summaries to predict whether they are admissible.', 'Summaries of very short lengths may fail to capture the main concepts, and summaries of moderate lengths may still contain hallucinated content that is nonexistent in the source text.': 'The authors present two summary selectors to combat these issues. Their first selector aims to predict what summary length is most suitable for a source text, whereas a second selector puts special emphasis on the overall quality of the system summary, in particular its faithfulness to the original text.', 'The reliability of evaluation results for summarizers can be improved by comparing their outputs against multiple reference summaries.': 'The authors introduce a novel dataset where a source text is associated with multiple summaries, and admissible ones are manually labelled by human annotators. This dataset can be used to judge the effectiveness of summary selectors and provide a new testbed for future summarizers to compare their outputs against multiple reference summaries.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:ccbe0f89da9483d9e3189050d5b56af29557b937,Improving Faithfulness in Abstractive Summarization with Contrast Candidate Generation and Selection,NAACL,2021,"['Sihao Chen', 'Fan Zhang', 'Kazoo Sone', 'Dan Roth']","Despite significant progress in neural abstractive summarization, recent studies have shown that the current models are prone to generating summaries that are unfaithful to the original context. To address the issue, we study contrast candidate generation and selection as a model-agnostic post-processing technique to correct the extrinsic hallucinations (i.e. information not present in the source text) in unfaithful summaries. We learn a discriminative correction model by generating alternative candidate summaries where named entities and quantities in the generated summary are replaced with ones with compatible semantic types from the source document. This model is then used to select the best candidate as the final output summary. Our experiments and analysis across a number of neural summarization systems show that our proposed method is effective in identifying and correcting extrinsic hallucinations. We analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.","The paper discusses how current models for neural abstractive summarization often generate summaries that are not faithful to the original context. To address this issue, the authors propose a post-processing technique called contrast candidate generation and selection. They generate alternative candidate summaries where named entities and quantities are replaced with compatible semantic types from the source document, and then use a discriminative correction model to select the best candidate as the final output summary. The authors' experiments show that this method is effective in identifying and correcting extrinsic hallucinations. They also analyze the typical hallucination phenomenon by different types of neural summarization systems, in hope to provide insights for future work on the direction.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce concise and fluent summaries that are salient and faithful to the source document(s).', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and provide a quick overview of the content of a document. They can also be used for information retrieval and to help people make informed decisions based on the content of the document.'}",['method'],"['Controlled Generation', 'Post Processing']",['XSum'],"['ROUGE', 'FactCC', 'QuestEval']",['Faithfulness'],http://cogcomp.org/page/publication_view/938,https://aclanthology.org/2021.naacl-main.475,"{'Current state of the art models produce summaries that suffer from intrinsic and extrinsic hallucinations.': 'The authors focus on the problem of correcting such hallucinations as a post processing step. They study the method of contrast candidate generation and selection, where named entities in a potentially hallucinated summary are replaced with ones with compatible semantic types that are present in the source, and create variants of candidate summaries. In the selection step, they rank the generated candidates with a discriminative model trained to distinguish between faithful summaries and synthetic negative candidates generated given the source.', 'Less progress has been made on improving the faithfulness of the generated summaries.': 'The authors propose a method for correcting hallucinations in generated summaries, which improves the faithfulness of the summaries.', 'Large fraction of ground truth summarization data is hallucinated.': 'The authors study the method of contrast candidate generation and selection under the setting where a large fraction of ground truth summarization data suffers from hallucinations.', 'The article describes an event where the former UN-Secretary-General Ban KiMoon was re-elected for a second term. The model hallucinates ""2007"", which never appears in the source document, leading to inconsistency with the correct date of the event presented.': 'The authors propose a method for correcting such hallucinations as a post processing step, which replaces named entities in a potentially hallucinated summary with ones with compatible semantic types that are present in the source, and create variants of candidate summaries.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:abf79b472c9f91d526feed97ac1ea1cdbbcd9259,Attention Head Masking for Inference Time Content Selection in Abstractive Summarization,NAACL,2021,"['Shuyang Cao', 'Lu Wang']","How can we effectively inform content selection in Transformer-based abstractive summarization models? In this work, we present a simple-yet-effective attention head masking technique, which is applied on encoderdecoder attentions to pinpoint salient content at inference time. Using attention head masking, we are able to reveal the relation between encoder-decoder attentions and content selection behaviors of summarization models. We then demonstrate its effectiveness on three document summarization datasets based on both in-domain and cross-domain settings. Importantly, our models outperform prior state-ofthe-art models on CNN/Daily Mail and New York Times datasets. Moreover, our inferencetime masking technique is also data-efficient, requiring less than 20% of the training samples to outperform BART fine-tuned on the full CNN/DailyMail dataset.","The paper presents a technique called attention head masking to effectively inform content selection in Transformer-based abstractive summarization models. This technique is applied on encoder-decoder attentions to identify important content during inference. The authors demonstrate the effectiveness of this technique on three document summarization datasets, including in-domain and cross-domain settings. Their models outperform prior state-of-the-art models on CNN/Daily Mail and New York Times datasets. Additionally, the inferencetime masking technique is data-efficient, requiring less than 20% of the training samples to outperform BART fine-tuned on the full CNN/DailyMail dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the quality of abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document.', 'How will the summaries be used?': ""The summaries will be used to provide a quick overview of the document's content, without having to read the entire document.""}",['method'],['Unit Selection'],"['CNN/DailyMail', 'XSum', 'NYT']",['ROUGE'],"['Informativeness', 'Faithfulness']",https://shuyangcao.github.io/projects/inference_head_masking,https://aclanthology.org/2021.naacl-main.397,"{'It is still unclear how one can use large models more effectively for abstractive summarization.': 'The authors propose an inference-time attention head masking mechanism that works on encoder-decoder attentions to underscore salient content from the source and improve the quality of abstractive summaries.', 'With multi-heads attentions at all layers in Transformers, highlighting salient content becomes non-trivial.': 'The authors study whether multiple heads at the same layer collectively guide the summarization and find that partial masking is most effective, indicating a strong collaborative effect and the importance of head selection.', 'It is difficult to evaluate the effectiveness of attention head masking on summarization benchmarks.': 'The authors evaluate attention head masking on summarization benchmarks with salience labels provided by externally trained content selectors and show that their model consistently outperforms fine-tuned BART and several top performing Transformer-based abstractive summarization models.', 'It is unclear whether attention head masking is data-efficient.': 'The authors illustrate that attention head masking is data-efficient by showing that BART fine-tuned on less than 20% of the training data outperforms a version trained on the full set.', 'It is unclear whether attention head masking is effective under a cross-domain setting.': 'The authors show that their method is effective under a cross-domain setting by demonstrating that with a content selector trained on NYT, BART fine-tuned on CNN/DM gains more than three points of ROUGE scores when tested on NYT articles.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:96eaba13c18e0fe77d080dd46e0aae48f98b52de,Using Question Answering Rewards to Improve Abstractive Summarization,EMNLP,2021,"['Chulaka Gunasekara', 'Guy Feigenblat', 'Benjamin Sznajder', 'Ranit Aharonov', 'Sachindra Joshi']","Neural abstractive summarization models have drastically improved in the recent years. However, the summaries generated by these models generally suffer from issues such as: not capturing the critical facts in source documents, and containing facts that are inconsistent with the source documents. In this work, we present a general framework to train abstractive summarization models to alleviate such issues. We first train a sequence-to-sequence model to summarize documents, and then further train this model in a Reinforcement Learning setting with question-answering based rewards. We evaluate the summaries generated by the this framework using multiple automatic measures and human judgements. The experimental results show that the question-answering rewards can be used as a general framework to improve neural abstractive summarization. Particularly, the results from human evaluations show that the summaries generated by our approach are preferred over 30% of the time over the summaries generated by general abstractive summarization models.","The paper discusses the issues with current neural abstractive summarization models and presents a framework to train these models to improve their summaries. The framework involves training a sequence-to-sequence model and then further training it in a Reinforcement Learning setting with question-answering based rewards. The experimental results show that this approach can improve the quality of the summaries generated by these models, with human evaluations showing a preference for the approach over general abstractive summarization models 30% of the time.",{'Who is the target audience?': 'The target audience for the summaries is not specified in the paper.'},['method'],['External Knowledge'],"['XSum', 'SAMSUM']","['ROUGE', 'Entity Precision', 'FEQA']","['Factual Consistency', 'Overall Quality']",,https://aclanthology.org/2021.findings-emnlp.47,"{'Neural abstractive summarization models frequently fail to capture critical facts in source documents (low recall).': 'The authors propose a general framework to improve the recall of abstractive summarization by using question-answering(QA) based rewards. They generate questions and corresponding answers from the ground truth summaries and evaluate the answers obtained for the same questions from the generated summaries. If the generated summary does not contain some key information as captured in the ground truth summary, then this would lead to obtaining different answers from the ground truth summary for some of the generated questions. They use the similarity of answers to calculate a reward to improve the recall.', 'Neural abstractive summarization models generate content which are inconsistent with the source document (low precision).': 'The authors propose a general framework to improve the precision of abstractive summarization by using question-answering(QA) based rewards. They first generate questions and corresponding answers for each generated summary. Next, they evaluate the answers that they get for the same questions from the ground truth summaries. If a generated summary contains factually incorrect information, this would lead to having different answers from the ground truth summary for some of the generated questions. They use the similarity of answers to calculate a reward to improve the precision.', 'Factuality related issues make neural abstractive summarization models hardly usable in real-world applications.': 'The authors propose a general framework to alleviate factuality related issues and improve the quality of the abstractive summarization by using question-answering(QA) based rewards. They train a sequence-to-sequence(seq2seq) summary generation model to take a document as the input and generate a summary as the output. They use the calculated rewards in a Reinforcement Learning (RL) based framework to improve the summary generation model.'}",reinforced,"['News', 'Dialog']",['hallucinations-in-the-generated-summaries']
SP:724b22dfb4cd27c48f3fcea22d576515f5169b85,CLIFF: Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization,EMNLP,2021,"['Shuyang Cao', 'Lu Wang']","We study generating abstractive summaries that are faithful and factually consistent with the given articles. A novel contrastive learning formulation is presented, which leverages both reference summaries, as positive training data, and automatically generated erroneous summaries, as negative training data, to train summarization systems that are better at distinguishing between them. We further design four types of strategies for creating negative samples, to resemble errors made commonly by two state-of-the-art models, BART and PEGASUS, found in our new human annotations of summary errors. Experiments on XSum and CNN/Daily Mail show that our contrastive learning framework is robust across datasets and models. It consistently produces more factual summaries than strong comparisons with post error correction, entailmentbased reranking, and unlikelihood training, according to QA-based factuality evaluation. Human judges echo the observation and find that our model summaries correct more errors.","System: The paper discusses a new approach to generating abstractive summaries that are both faithful and factually consistent with the given articles. The approach uses a contrastive learning formulation that leverages both reference summaries and automatically generated erroneous summaries to train summarization systems that are better at distinguishing between them. The paper also describes four strategies for creating negative samples that resemble errors made commonly by two state-of-the-art models, BART and PEGASUS. Experiments on XSum and CNN/Daily Mail show that the contrastive learning framework consistently produces more factual summaries than other approaches, according to QA-based factuality evaluation. Human judges also find that the model summaries correct more errors.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the faithfulness and factuality of the generated summaries.', 'Who is the target audience?': 'The summaries are for abstractive summarization systems.', 'How will the summaries be used?': 'The summaries will be used to generate both faithful and informative summaries in an end-to-end fashion.'}",['method'],"['Data Augmentation', 'External Knowledge']","['CNN/DailyMail', 'XSum']","['ROUGE', 'FactCC']","['Informativeness', 'Factual Consistency']",https://shuyangcao.github.io/projects/cliff_summ,https://aclanthology.org/2021.emnlp-main.532,"{'Large pre-trained Transformers generate summaries with impeccable fluency but often contain factually inconsistent content.': ""The authors propose a new learning objective that includes factually inconsistent summaries (negative samples) for training, in addition to references (positive samples), to improve the model's ability to differentiate between the two types of summaries."", 'Using negative samples for training is challenging because it requires a suitable training objective and natural samples that mimic the diverse errors made by state-of-the-art systems.': 'The authors propose a new framework, CLIFF, that uses contrastive learning to improve faithfulness and factuality of the generated summaries. They design four types of strategies with different variants to construct negative samples by editing reference summaries via rewriting entity-/relation-anchored text and using system-generated summaries that may contain unfaithful errors.', 'Existing methods for improving summarization quality rely on heuristically created data for error handling or require learning a large number of new parameters, sacrificing summary informativeness.': ""The authors' proposed method, CLIFF, improves summarization quality without relying on heuristically created data or requiring a large number of new parameters. Their models trained with different types of negative samples uniformly outperform strong comparisons, including using a summarizer with post-error correction and reranking beams based on entailment scores to the source. Human evaluation further confirms that their models consistently reduce both extrinsic and intrinsic errors over baseline across datasets.""}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:cd6f42c4afc5f35b27ef52f8735d2875aa4c0264,Exploring Explainable Selection to Control Abstractive Summarization,AAAI,2021,"['Haonan Wang', 'Yang Gao', 'Yu Bai', 'Mirella Lapata', 'Heyan Huang']","Like humans, document summarization models can interpret a document’s contents in a number of ways. Unfortunately, the neural models of today are largely black boxes that provide little explanation of how or why they generated a summary in the way they did. Therefore, to begin prying open the black box and to inject a level of control into the substance of the final summary, we developed a novel select-and-generate framework that focuses on explainability. By revealing the latent centrality and interactions between sentences, along with scores for sentence novelty and relevance, users are given a window into the choices a model is making and an opportunity to guide those choices in a more desirable direction. A novel pair-wise matrix captures the sentence interactions, centrality and attribute scores, and a mask with tunable attribute thresholds allows the user to control which sentences are likely to be included in the extraction. A sentence-deployed attention mechanism in the abstractor ensures the final summary emphasizes the desired content. Additionally, the encoder is adaptable, supporting both Transformerand BERTbased configurations. In a series of experiments assessed with ROUGE metrics and two human evaluations, ESCA outperformed eight state-of-the-art models on the CNN/DailyMail and NYT50 benchmark datasets.","The paper discusses the limitations of current neural models for document summarization, which lack transparency and control. To address this issue, the authors propose a novel select-and-generate framework called ESCA that focuses on explainability. The framework reveals the latent centrality and interactions between sentences, along with scores for sentence novelty and relevance, to give users a window into the choices the model is making and an opportunity to guide those choices. A novel pair-wise matrix captures the sentence interactions, centrality, and attribute scores, and a mask with tunable attribute thresholds allows the user to control which sentences are likely to be included in the extraction. A sentence-deployed attention mechanism in the abstractor ensures the final summary emphasizes the desired content. ESCA outperformed eight state-of-the-art models on the CNN/DailyMail and NYT50 benchmark datasets in a series of experiments assessed with ROUGE metrics and two human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents because it is a valuable tool and neural networks have improved the quality of both extractive and abstractive summarization.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but it discusses the challenges and advancements in generating high-quality summaries using neural networks and proposes a novel approach for generating explainable and controllable abstractive summaries.'}",['method'],"['Unit Selection', 'Controlled Generation']","['CNN/DailyMail', 'NYT']","['ROUGE', 'FactCC', 'QAGS']","['Novelty', 'Relevance']",https://github.com/Wanghn95/Esca_Code,https://ojs.aaai.org/index.php/AAAI/article/view/17641,"{'Lack of explanation in current summarization models.': 'Develop a novel select-and-generate framework called ESCA that focuses on explainability. The framework includes an interaction matrix that highlights the decisions made about each sentence, which can be decoupled into three explicit components: the informativeness of a sentence, its relevance to the substance of the document, and its novelty with respect to the accumulated summary representation.', 'Difficulty in modeling long-range contexts in summarization.': 'Explore two broad strategies for tackling this problem: using pre-trained language models such as ELMo, OpenAI GPT, and BERT, and using a select and generate framework where an extractor selects salient sentences, then an abstractor generates a summary. The most recent frameworks based on this hybrid paradigm either follow a two-stage pipeline or an end-to-end learning approach.', 'Hallucination in abstractive summarization.': 'Alleviate this problem with pointer mechanisms to desired content or by interpolating nearest neighbors computed from the inputs. Develop a sentence-deployed attention mechanism in the abstractor, but populated with values from the extractor, to ensure the abstractive summary focuses on both correct and desired concepts.', 'Lack of understanding of inter-relations between sentences with respect to attributes such as redundancy, relevance, and informativeness.': 'Propose rigorous definitions of these concepts and develop methods for identifying sentence informativeness, identifying whether a sentence is relevant to a document and, if so, to what extent, and identifying the novelty of the contribution a sentence makes to a summary.', 'Scattered tracts of information in long documents leading to irrelevant and unnecessary content being picked up when generating summaries.': 'Control which content is selected for extraction by setting thresholds for novelty and relevance and applying a mask that adjusts the probability of extraction accordingly.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'hallucinations-in-the-generated-summaries']"
SP:737d1cd741810a4e00e78d7eca12b87acc51c30a,Improving the Faithfulness of Abstractive Summarization via Entity Coverage Control,NAACL,2022,"['Haopeng Zhang', 'Semih Yavuz', 'Wojciech Kryscinsk', 'Kazuma Hashimoto', 'Yingbo Zhou']","Abstractive summarization systems leveraging pre-training language models have achieved superior results on benchmark datasets. However, such models have been shown to be more prone to hallucinate facts that are unfaithful to the input context. In this paper, we propose a method to remedy entity-level extrinsic hallucinations with Entity Coverage Control (ECC). We first compute entity coverage precision and prepend the corresponding control code for each training example, which implicitly guides the model to recognize faithfulness contents in the training phase. We further extend our method via intermediate fine-tuning on large but noisy data extracted from Wikipedia to unlock zero-shot summarization. We show that the proposed method leads to more faithful and salient abstractive summarization in supervised fine-tuning and zero-shot settings according to our experimental results on three benchmark datasets XSum, Pubmed, and SAMSum of very different domains and styles.ive summarization systems leveraging pre-training language models have achieved superior results on benchmark datasets. However, such models have been shown to be more prone to hallucinate facts that are unfaithful to the input context. In this paper, we propose a method to remedy entity-level extrinsic hallucinations with Entity Coverage Control (ECC). We first compute entity coverage precision and prepend the corresponding control code for each training example, which implicitly guides the model to recognize faithfulness contents in the training phase. We further extend our method via intermediate fine-tuning on large but noisy data extracted from Wikipedia to unlock zero-shot summarization. We show that the proposed method leads to more faithful and salient abstractive summarization in supervised fine-tuning and zero-shot settings according to our experimental results on three benchmark datasets XSum, Pubmed, and SAMSum of very different domains and styles.","The paper discusses the limitations of abstractive summarization systems that use pre-training language models, which are prone to hallucinating facts that are not faithful to the input context. To address this issue, the authors propose a method called Entity Coverage Control (ECC) that computes entity coverage precision and adds a control code to each training example to guide the model to recognize faithful contents. They also extend their method through intermediate fine-tuning on noisy data extracted from Wikipedia to enable zero-shot summarization. The proposed method leads to more faithful and salient abstractive summarization in supervised fine-tuning and zero-shot settings, as demonstrated by experimental results on three benchmark datasets of different domains and styles.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create a compact and fluent summary that preserves the most salient content of the source document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the source document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding the source document, and can be used in various applications such as news articles, research papers, and business reports.'}",['method'],"['External Knowledge', 'Controlled Generation']","['XSum', 'PubMed', 'SAMSUM']",['ROUGE'],"['Faithfulness', 'Overall Quality']",,https://aclanthology.org/2022.findings-naacl.40,"{'Existing abstractive summarization systems lack faithfulness of generated outputs, which may contain hallucinated or fabricated statements.': 'The authors propose to guide the model learning process with entity control code (ECC) to reduce hallucinated entities effectively without decreasing the fluency and salience of generated summaries. They utilize the entity coverage precision between the training document and its reference summary as faithfulness guidance and prepend it to the corresponding document in the training phase. They also prepend faithful control code during inference.', 'Summary hallucination at the entity level is a common problem in abstractive summarization systems.': 'The authors propose to address entity hallucination by guiding the model learning process with entity control code (ECC) and utilizing the entity coverage precision between the training document and its reference summary as faithfulness guidance.', 'Existing methods to address entity hallucination, such as post-processing and filtering the training data, have limitations.': 'The authors propose a new method that utilizes entity control code (ECC) to reduce hallucinated entities effectively without decreasing the quality of the summary. They also extend control code to a Wikipedia-based intermediate fine-tuning model, which generates faithful and salient summaries across domains in the zero-shot setting. They validate their methods on three benchmark datasets across different domains, and experimental results demonstrate the effectiveness of their methods.'}",supervised,"['News', 'Dialog']",['hallucinations-in-the-generated-summaries']
SP:ef4d164af89cec52922d1449e2764a992706284d,FACTPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization,NAACL,2022,"['David Wan', 'Mohit Bansal']","We present FACTPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and finetuning: (1) We augment the sentence selection strategy of PEGASUS’s (Zhang et al., 2020) pre-training objective to create pseudosummaries that are both important and factual; (2) We introduce three complementary components for fine-tuning. The corrector removes hallucinations present in the reference summary, the contrastor uses contrastive learning to better differentiate nonfactual summaries from factual ones, and the connector bridges the gap between the pre-training and finetuning for better transfer of knowledge. Experiments on three downstream tasks demonstrate that FACTPEGASUS substantially improves factuality evaluated by multiple automatic metrics and humans. Our thorough analysis suggests that FACTPEGASUS is more factual than using the original pre-training objective in zero-shot and few-shot settings, retains factual behavior more robustly than strong baselines, and does not rely entirely on becoming more extractive to improve factuality.1","The paper presents FACTPEGASUS, an abstractive summarization model that focuses on factuality during pre-training and finetuning. The model uses a sentence selection strategy to create pseudosummaries that are both important and factual, and introduces three complementary components for fine-tuning: a corrector to remove hallucinations, a contrastor to differentiate factual from nonfactual summaries, and a connector to improve knowledge transfer. Experiments show that FACTPEGASUS substantially improves factuality and is more factual than using the original pre-training objective in zero-shot and few-shot settings, while also retaining factual behavior more robustly than strong baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to capture the essential information in a shorter format, known as abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, such as researchers, professionals, or the general public.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as decision-making, research, or information dissemination.'}",['method'],"['Objective Function', 'Controlled Generation']","['XSum', 'WikiHow', 'Gigaword']","['ROUGE', 'BERTScore', 'BLEURT']","['Informativeness', 'Factuality']",https://github.com/meetdavidwan/factpegasus,https://aclanthology.org/2022.naacl-main.74,"{'Current abstractive summarization models suffer from the problem of hallucinations, where a summary contains facts or entities not present in the original document, raising questions about their trustworthiness for real-world applications.': 'The authors propose FACTPEGASUS, a model that addresses the problem of hallucinations holistically by incorporating factuality into the whole training pipeline. They explore incorporating factuality into the pre-training objective of PEGASUS and propose three complementary modules that further address factuality problems during fine-tuning: Corrector, Contrastor, and Connector.', 'Current pre-training objectives focus on improving the quality of the generated output in the downstream tasks but often overlook the factuality aspect.': 'The authors explore incorporating factuality into the pre-training objective of PEGASUS by combining ROUGE and the factuality metric FactCC as the selection criteria, so that the model learns to generate sentences that cover the most important information of the input document as well as remain faithful to it.', 'Postprocessing models that correct hallucinations are often constrained by external resources to train additional correction or selection models.': 'The authors propose a Corrector module that removes hallucinations existing in reference summaries, allowing training on the full training set without learning unfaithful behaviors.', 'Models often struggle to differentiate factual summaries from nonfactual ones during fine-tuning.': 'The authors propose a Contrastor module that encourages the model to better differentiate factual summaries from nonfactual ones by paying attention to the document using contrastive learning.', 'Models often struggle to adapt their knowledge of generating factual summaries directly to the downstream tasks during fine-tuning.': 'The authors propose a Connector module, a special mask-token fine-tuning technique enabled by the GSG-style objective, that simulates the pre-training task during fine-tuning by inserting the mask token into the input document so that the pre-trained model can adapt its knowledge of generating factual summaries directly to the downstream tasks.', 'Models often struggle to maintain factuality during fine-tuning.': 'The authors conduct thorough factuality analysis and show that FACTPEGASUS generates more factual summaries with no or little supervision, slows down factuality degradation observed for current models, and improves factuality not by becoming more extractive. They also highlight the importance of ensuring factuality during fine-tuning.'}",supervised,"['News', 'CQA']",['hallucinations-in-the-generated-summaries']
SP:f99898ef8598438d958a6aacf1a122e7e9d5a695,Faithful Abstractive Summarization via Fact-aware Consistency-constrained Transformer,CIKM,2022,"['Yuanjie Lyu', 'Chen Zhu', 'Tong Xu', 'Zikai Yin', 'Enhong Chen']","Abstractive summarization is a classic task in Natural Language Generation (NLG), which aims to produce a concise summary of the original document. Recently, great efforts have been made on sequence-to-sequence neural networks to generate abstractive summaries with a high level of fluency. However, prior arts mainly focus on the optimization of token-level likelihood, while the rich semantic information in documents has been largely ignored. In this way, the summarization results could be vulnerable to hallucinations, i.e., the semantic-level inconsistency between a summary and corresponding original document. To deal with this challenge, in this paper, we propose a novel fact-aware abstractive summarization model, named Entity-Relation Pointer Generator Network (ERPGN). Specially, we attempt to formalize the facts in original document as a factual knowledge graph, and then generate the high-quality summary via directly modeling consistency between summary and the factual knowledge graph. To that end, we first leverage two pointer network structures to capture the fact in original documents. Then, to enhance the traditional token-level likelihood loss, we design two extra semantic-level losses to measure the disagreement between a summary and facts from its original document. Extensive experiments on public datasets demonstrate that our ERPGN framework could outperform both classic abstractive summarization models and the state-of-the-art fact-aware baseline methods, with significant improvement in terms of faithfulness.ive summarization is a classic task in Natural Language Generation (NLG), which aims to produce a concise summary of the original document. Recently, great efforts have been made on sequence-to-sequence neural networks to generate abstractive summaries with a high level of fluency. However, prior arts mainly focus on the optimization of token-level likelihood, while the rich semantic information in documents has been largely ignored. In this way, the summarization results could be vulnerable to hallucinations, i.e., the semantic-level inconsistency between a summary and corresponding original document. To deal with this challenge, in this paper, we propose a novel fact-aware abstractive summarization model, named Entity-Relation Pointer Generator Network (ERPGN). Specially, we attempt to formalize the facts in original document as a factual knowledge graph, and then generate the high-quality summary via directly modeling consistency between summary and the factual knowledge graph. To that end, we first leverage two pointer network structures to capture the fact in original documents. Then, to enhance the traditional token-level likelihood loss, we design two extra semantic-level losses to measure the disagreement between a summary and facts from its original document. Extensive experiments on public datasets demonstrate that our ERPGN framework could outperform both classic abstractive summarization models and the state-of-the-art fact-aware baseline methods, with significant improvement in terms of faithfulness.",The paper proposes a new model for abstractive summarization called Entity-Relation Pointer Generator Network (ERPGN) that formalizes the facts in the original document as a factual knowledge graph and generates a high-quality summary by directly modeling consistency between the summary and the knowledge graph. The model uses two pointer network structures to capture the facts in the original document and two semantic-level losses to measure the disagreement between the summary and the facts. The experiments show that ERPGN outperforms classic abstractive summarization models and state-of-the-art fact-aware baseline methods in terms of faithfulness.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce concise, informative, and faithful summaries for a given original document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of the original document.', 'How will the summaries be used?': 'The summaries can be used to save time and provide a quick overview of the original document, without having to read the entire document.'}",['method'],"['Input Encoding', 'Objective Function']","['CNN/DailyMail', 'XSum']","['ROUGE', 'BLEU']","['Informativeness', 'Faithfulness']",,https://doi.org/10.1145/3511808.3557319,"{'Abstractive summarization models are vulnerable to hallucinations, which can lead to inconsistencies between the summary and the original document.': 'The authors propose a fact-aware abstractive summarization model, named Entity-Relation Pointer Generator Network (ERPGN), which directly models the semantic consistency between a summary and a factual knowledge graph to improve faithfulness. They leverage two pointer network structures to capture the entities and relationships in the original document and design two extra semantic-level losses to measure the disagreement between the summary and facts from the original document.', 'Prior solutions to the hallucination problem have not directly modeled the semantic-level consistency between the summary and the original document, limiting their practical performance.': 'The authors propose a fact-aware approach that formalizes the faithfulness of abstractive summarization as the consistency between a summary and corresponding factual knowledge graph. They treat extrinsic hallucination as the inconsistency on entities and intrinsic hallucination as the semantic conflicts on relationships.', 'The rich semantic information in the original document, such as factual knowledge like entities and relations, has not been fully utilized to support the summarization task.': 'The authors extract the fact in original documents as a factual knowledge graph, which contains all the entities with their relationships mentioned in the documents. They use this graph to enhance the faithfulness of abstractive summarization via fact-aware consistency.', 'Most sequence-to-sequence solutions focus on the optimization of token-level likelihood, which may result in semantic-level inaccuracy.': 'The authors design two extra semantic-level losses to measure the disagreement between the summary and facts from the original document, in addition to the traditional token-level likelihood loss. This enhances the faithful abstractive summarization by integrating both token-level accuracy and semantic-level accuracy.', 'The authors aim to improve the faithfulness of abstractive summarization.': 'The authors propose a fact-aware abstractive summarization model, named ERPGN, which effectively integrates both token-level accuracy and semantic-level accuracy for enhancing the faithful abstractive summarization. Extensive experiments on two widely-used public datasets demonstrate that their ERPGN framework achieves significant improvements in terms of faithfulness by multiple factuality measurements.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:f015366bdd69a25b0d20ae666b5f0ad627832fc1,Attention Temperature Matters in Abstractive Summarization Distillation,ACL,2022,"['Shengqiang Zhang', 'Xingxing Zhang', 'Hangbo Bao', 'Furu Wei']","Recent progress of abstractive text summarization largely relies on large pre-trained sequence-to-sequence Transformer models, which are computationally expensive. This paper aims to distill these large models into smaller ones for faster inference and with minimal performance loss. Pseudo-labeling based methods are popular in sequence-tosequence model distillation. In this paper, we find simply manipulating attention temperatures in Transformers can make pseudo labels easier to learn for student models. Our experiments on three summarization datasets show our proposed method consistently improves vanilla pseudo-labeling based methods. Further empirical analysis shows that both pseudo labels and summaries produced by our students are shorter and more abstractive. Our code is available at https://github. com/Shengqiang-Zhang/plate.","The paper discusses how abstractive text summarization relies on large, computationally expensive pre-trained sequence-to-sequence Transformer models, and proposes a method to distill these models into smaller ones with minimal performance loss. The method involves manipulating attention temperatures in Transformers to make pseudo labels easier to learn for student models. Experiments on three summarization datasets show that this method consistently improves vanilla pseudo-labeling based methods, and both pseudo labels and summaries produced by the student models are shorter and more abstractive. The code for the proposed method is available on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to rewrite long documents into shorter forms while still retaining their most important content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main content of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and can be particularly useful in situations where quick decision-making is required.'}",['method'],"['Input Encoding', 'External Knowledge']","['CNN/DailyMail', 'XSum', 'NYT']",['ROUGE'],['Overall Quality'],https://github.com/Shengqiang-Zhang/plate,https://aclanthology.org/2022.acl-long.11,"{'The authors aim to distill large Transformer summarization models into smaller ones with minimal loss in performance, as the large models are slow for online inference and difficult to use in production environments.': 'The authors propose a class of methods called knowledge distillation, which leverages the output of a (large) teacher model to guide the training of a (small) student model. An effective distillation method for Seq2Seq models is called pseudo-labeling, where the teacher model generates pseudo summaries for all documents in the training set and the resulting document–pseudo-summary pairs are used to train the student model.', 'The attention distributions of a Seq2Seq teacher model might be too sharp, resulting in sub-optimal pseudo labels for student models.': 'The authors propose a method called PLATE (Pseudo-labeling with Larger Attention TEmperature) to smooth attention distributions of teacher models. Specifically, attention weights in all attention modules are re-scaled with a higher temperature, leading to softer attention distributions. This reduces the copy bias and leading bias in pseudo summaries, encouraging student models to be more abstractive and take advantage of longer context in documents.', 'Pseudo summaries generated from the teacher model tend to copy more continuous text spans from original documents and summarize the leading part of a document.': 'PLATE reduces the copy bias and leading bias in pseudo summaries, resulting in shorter and more abstractive summaries generated by both teacher and student models, which matches the goal of abstractive summarization.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:2eddfe909ff7af3110dbbd132f8eed354050bd05,Towards Abstractive Grounded Summarization of Podcast Transcripts,ACL,2022,"['Kaiqiang Song', 'Chen Li', 'Xiaoyang Wang', 'Dong Yu', 'Fei Liu']","Podcasts have shown a recent rise in popularity. Summarization of podcasts is of practical benefit to both content providers and consumers. It helps people quickly decide whether they will listen to a podcast and/or reduces the cognitive load of content providers to write summaries. Nevertheless, podcast summarization faces significant challenges including factual inconsistencies of summaries with respect to the inputs. The problem is exacerbated by speech disfluencies and recognition errors in transcripts of spoken language. In this paper, we explore a novel abstractive summarization method to alleviate these issues. Our approach learns to produce an abstractive summary while grounding summary segments in specific regions of the transcript to allow for full inspection of summary details. We conduct a series of analyses of the proposed approach on a large podcast dataset and show that the approach can achieve promising results. Grounded summaries bring clear benefits in locating the summary and transcript segments that contain inconsistent information, and hence improve summarization quality in terms of automatic and human evaluation.","The paper discusses the challenges of summarizing podcasts, including factual inconsistencies and speech disfluencies in transcripts. The authors propose a novel abstractive summarization method that grounds summary segments in specific regions of the transcript to improve summarization quality. They conducted a series of analyses on a large podcast dataset and found that their approach achieved promising results, improving both automatic and human evaluation of summarization quality.","{'What is the purpose of the summaries?': 'The authors are generating summaries of podcasts to help people decide if they want to listen to a podcast or subscribe to a channel. They are also helpful for users who want to find podcasts previously listened to and can be repurposed for social media posts or email marketing campaigns.', 'Who is the target audience?': 'The summaries are for anyone interested in podcasts, particularly those who want to quickly decide if they want to listen to a podcast or subscribe to a channel. They are also helpful for content creators who want to make their podcasts accessible to a larger audience.', 'How will the summaries be used?': 'The summaries will be used to provide a preview of notable podcast clips and reduce the barriers to deploy podcast summarization technology. They will also be used to frame, interpret, and place into context any system-generated summaries. Additionally, they can be repurposed for social media posts or email marketing campaigns.'}",['method'],"['Objective Function', 'Input Encoding']",['Spotify Podcast Dataset'],['ROUGE'],"['Coverage', 'Non-redundancy', 'Fluency', 'Informativeness', 'Overall Quality']",https://github.com/tencent-ailab/GrndPodcastSum,https://aclanthology.org/2022.acl-long.302,"{'There is an increased demand for textual summaries of podcasts to help people decide if they want to listen to a podcast or subscribe to a channel, but current summarization methods may contain misleading or inaccurate information due to transcription errors and hallucinations.': 'Generate grounded summaries from podcast transcripts, where summary text is closely tethered to the original audio, allowing users to verify the information consistency of summary parts against the original audio clips.', 'Aligning summary text and podcast transcripts in a post-processing step to generate grounded summaries is difficult due to hallucinations that are not found in the transcripts, and attention weights are not reliable indicators of the relative importance of inputs.': 'Explore an on-demand abstractive summarizer that mimics how a human might approach a lengthy transcript, identifying a portion of the transcript that is deemed most important and relevant to the existing summary, and using it as a ground to produce a new piece of the summary. This approach allows for a novel regularization technique that enables the summarizer to visit portions of the transcript in chronological order, while allowing zigzags in order to produce a coherent summary.', 'Earlier research on extract-then-abstract methods require selected transcript chunks to have high salience, but do not consider the importance of the salient content appearing at the beginning of the selected chunks, making it difficult for users to start listening to the corresponding audio clips.': 'Require selected transcript chunks to have high salience and for the salient content to appear at the beginning of the selected chunks, so that the corresponding audio clips can provide good jump-in points for users to start listening.'}",supervised,['Podcast Transcripts'],"['hallucinations-in-the-generated-summaries', 'identifying-important-contents-from-the-document']"
SP:d643dc12cdd7f80ff00e3d125e46d925778da94f,Extractive Elementary Discourse Units for Improving Abstractive Summarization,SIGIR,2022,"['Ye Xiong', 'Teeradaj Racharak', 'Minh Le Nguyen']","Abstractive summarization focuses on generating concise and fluent text from an original document while maintaining the original intent and containing the new words that do not appear in the original document. Recent studies point out that rewriting extractive summaries help improve the performance with a more concise and comprehensible output summary, which uses a sentence as a textual unit. However, a single document sentence normally cannot supply sufficient information. In this paper, we apply elementary discourse unit (EDU) as textual unit of content selection. In order to utilize EDU for generating a high quality summary, we propose a novel summarization model that first designs an EDU selector to choose salient content. Then, the generator model rewrites the selected EDUs as the final summary. To determine the relevancy of each EDU on the entire document, we choose to apply group tag embedding, which can establish the connection between summary sentences and relevant EDUs, so that our generator does not only focus on selected EDUs, but also ingest the entire original document. Extensive experiments on the CNN/Daily Mail dataset have demonstrated the effectiveness of our model.ive summarization focuses on generating concise and fluent text from an original document while maintaining the original intent and containing the new words that do not appear in the original document. Recent studies point out that rewriting extractive summaries help improve the performance with a more concise and comprehensible output summary, which uses a sentence as a textual unit. However, a single document sentence normally cannot supply sufficient information. In this paper, we apply elementary discourse unit (EDU) as textual unit of content selection. In order to utilize EDU for generating a high quality summary, we propose a novel summarization model that first designs an EDU selector to choose salient content. Then, the generator model rewrites the selected EDUs as the final summary. To determine the relevancy of each EDU on the entire document, we choose to apply group tag embedding, which can establish the connection between summary sentences and relevant EDUs, so that our generator does not only focus on selected EDUs, but also ingest the entire original document. Extensive experiments on the CNN/Daily Mail dataset have demonstrated the effectiveness of our model.","The paper discusses the use of elementary discourse units (EDUs) as the textual unit of content selection for abstractive summarization. The authors propose a novel summarization model that first designs an EDU selector to choose salient content, and then the generator model rewrites the selected EDUs as the final summary. To determine the relevancy of each EDU on the entire document, the authors apply group tag embedding. Extensive experiments on the CNN/Daily Mail dataset have demonstrated the effectiveness of their model.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the main points of the document into a shorter version.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of the document, to save time, and to make it easier to find relevant information.'}",['method'],['Unit Selection'],['CNN/DailyMail'],"['ROUGE', 'BERTScore']",[''],,https://doi.org/10.1145/3477495.3531916,"{'Extractive summarization approaches often contain irrelevant and redundant phrases, leading to a lack of conciseness and comprehensibility in the final summary.': 'The authors propose a two-step EDU-based extractor-rewriter summarization paradigm built upon BERT, which uses Elementary Discourse Units (EDUs) as the minimal selection unit for the extractor model. This reduces redundancy and concentrates on critical information in the document, resulting in a more informative and abstractive summary.', 'A single sentence in a document cannot accommodate enough information to express a summary sentence, and composing a summary through only compressing sentences can cause performance degradation.': 'The authors use EDUs instead of sentences as the minimal selection unit for the extractor model, and rewrite extracted EDUs using the entire input document as context. This approach allows for the inclusion of multiple sentences and additional information from the original document, resulting in a more faithful and informative summary.', 'Rewriting pre-selected content can lead to the loss of contextual information in the original document, resulting in a loss of information in the final summary.': 'The authors utilize group tag embedding as a connection between the extractor and the rewriter, grouping the summary sentence and its highly correlated EDUs into one group. This prompts the rewriter to focus on the critical parts being rewritten and ingest the entire original document to enhance informativeness and abstraction in the final summary.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:db3f6182226d780c9b665727501d13494d721873,Global-aware Beam Search for Neural Abstractive Summarization,NEURIPS,2022,"['Ye Ma', 'Zixun Lan Lu Zong', 'Kaizhu Huang']","This study develops a calibrated beam-based algorithm with awareness of the global attention distribution for neural abstractive summarization, aiming to improve the local optimality problem of the original beam search in a rigorous way. Specifically, a novel global protocol is proposed based on the attention distribution to stipulate how a global optimal hypothesis should attend to the source. A global scoring mechanism is then developed to regulate beam search to generate summaries in a near-global optimal fashion. This novel design enjoys a distinctive property, i.e., the global attention distribution could be predicted before inference, enabling step-wise improvements on the beam search through the global scoring mechanism. Extensive experiments on nine datasets show that the global (attention)-aware inference significantly improves state-of-the-art summarization models even using empirical hyper-parameters. The algorithm is also proven robust as it remains to generate meaningful texts with corrupted attention distributions. The codes and a comprehensive set of examples are available.2","The paper presents a new algorithm for neural abstractive summarization that improves upon the local optimality problem of the original beam search. The algorithm uses a novel global protocol based on the attention distribution to generate summaries in a near-global optimal fashion. The global attention distribution can be predicted before inference, allowing for step-wise improvements on the beam search through the global scoring mechanism. The algorithm is shown to significantly improve state-of-the-art summarization models on nine datasets and remains robust even with corrupted attention distributions. The codes and examples are available.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the algorithm for text decoding, specifically beam search, by proposing a global protocol to regulate beam search step-by-step.', 'Who is the target audience?': 'The summaries are for neural abstractive summarization, which is a task in natural language processing that involves generating a summary of a longer text.', 'How will the summaries be used?': 'The summaries will be used to evaluate the performance of the proposed global-aware inference algorithm, which is designed to enhance beam search for neural abstractive summarization. The algorithm is shown to stably and significantly boost two state-of-the-art summarization models to produce higher quality summaries on nine datasets.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum', 'BillSum', 'Multi-News', 'WikiHow', 'Reddit-TIFU', 'Newsroom', 'PubMed', 'arXiv']","['ROUGE', 'BERTScore', 'BARTScore']",[''],https://github.com/yema2018/global_aware,https://proceedings.neurips.cc/paper/2021/hash/89d4402dc03d3b7318bbac10203034ab-Abstract.html,"{'Beam search suffers from a major limitation due to its local property, which often leads it to get stuck in the local optimum from step τ onward in generating texts.': 'The authors propose a calibrated beam-based algorithm with global awareness at all searching steps. They predict the global attention distribution before beam search to calibrate it at each step, encouraging the generated hypotheses to attend to the source in a more near-global optimal way. During beam search, they develop a novel global scoring mechanism composed of attention scores and length rewards to guide beam search based on the predicted global attention distribution. This mechanism regulates the inference by discouraging local attention from exceeding their corresponding predicted global attention at all steps.', 'Previous works try to use attention distributions to improve beam search, but ignore that the global attention distribution is predictable.': 'The authors argue that the limitation of beam search roots from its defect in finding the global optimal hypothesis. They propose a global protocol to regulate beam search step-by-step by predicting and deploying the global attention distribution to calibrate the inference in a rigorous way, thus returning a hypothesis that attends to source tokens in a more near-global optimal manner.', 'The generation style of a dataset could not be transferred by the designated global attention distribution.': 'The authors find that the generation style of a dataset could be transferred by the designated global attention distribution. For instance, summaries of higher abstractness for CNN/DM could be generated by only replacing its global attention distribution with a highly abstractive distribution during inference.', 'The empirical hyper-parameters are not used to boost summarization models.': 'The proposed global-aware inference can stably and significantly boost two state-of-the-art summarization models BART and PEGASUS to produce higher quality summaries on nine datasets, even if only the empirical hyper-parameters are used.'}",supervised,"['News', 'Legislative Bills', 'CQA', 'Social Media', 'Scholarly Documents']",[]
SP:e38bc5e280ba0826da8bdd37f62739c2cef7f565,BRIO: Bringing Order to Abstractive Summarization,ACL,2022,"['Yixin Liu', 'Pengfei Liu', 'Dragomir Radev', 'Graham Neubig']","Abstractive summarization models are commonly trained using maximum likelihood estimation, which assumes a deterministic (onepoint) target distribution in which an ideal model will assign all the probability mass to the reference summary. This assumption may lead to performance degradation during inference, where the model needs to compare several system-generated (candidate) summaries that have deviated from the reference summary. To address this problem, we propose a novel training paradigm which assumes a non-deterministic distribution so that different candidate summaries are assigned probability mass according to their quality. Our method achieves a new state-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07 ROUGE-1) datasets. Further analysis also shows that our model can estimate probabilities of candidate summaries that are more correlated with their level of quality.1ive summarization models are commonly trained using maximum likelihood estimation, which assumes a deterministic (onepoint) target distribution in which an ideal model will assign all the probability mass to the reference summary. This assumption may lead to performance degradation during inference, where the model needs to compare several system-generated (candidate) summaries that have deviated from the reference summary. To address this problem, we propose a novel training paradigm which assumes a non-deterministic distribution so that different candidate summaries are assigned probability mass according to their quality. Our method achieves a new state-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07 ROUGE-1) datasets. Further analysis also shows that our model can estimate probabilities of candidate summaries that are more correlated with their level of quality.1","The paper proposes a new training paradigm for abstractive summarization models that assumes a non-deterministic distribution, which assigns probability mass to different candidate summaries based on their quality. This approach addresses the performance degradation issue during inference, where the model needs to compare system-generated summaries that deviate from the reference summary. The proposed method achieves a new state-of-the-art result on the CNN/DailyMail and XSum datasets, and can estimate probabilities of candidate summaries that are more correlated with their level of quality.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to formulate summarization as a sequence-to-sequence problem and learn to generate the summary in an autoregressive manner.', 'Who is the target audience?': ""The summaries are for anyone who needs a concise and accurate representation of the document's content."", 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of the document without having to read the entire text. They can also be used for information retrieval and text summarization tasks.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum', 'NYT']",['ROUGE'],[''],https://github.com/yixinL7/BRIO.,https://aclanthology.org/2022.acl-long.207,"{'Exposure bias can hurt model performance during inference, as the model must generate output based on possibly erroneous previous steps.': 'The model must accurately estimate the relative quality of different generated outputs, since effective inference requires comparison among these candidates.', 'Existing models cannot accurately perform relative comparisons between non-reference summaries.': 'Introduce a training paradigm that requires the abstractive model to be accurate with respect to predicting the tokens in the reference summaries and coordinated with respect to the candidate summaries. This involves giving the abstractive model a dual role: as a generation model and as an evaluation model that can score the quality of candidate summaries by estimating a probability distribution over candidate outputs.', 'MLE training only encourages the model to assign high probability to the reference summary and is agnostic about any relative comparison between non-reference summaries.': 'Introduce a contrastive loss defined over different candidate summaries generated by pre-trained abstractive models to train the evaluation model. This changes the target distribution of abstractive models from a one-point deterministic distribution assumed by MLE training to a non-deterministic distribution in which candidate summaries are also assigned probability mass according to their quality.'}",supervised,['News'],['robust-evaluation-methods']
SP:01e187adbad78a1b195c8a0a04096821ba2a8431,Source-summary Entity Aggregation in Abstractive Summarization,COLING,2022,"['José Ángel González', 'Annie Louis', 'Jackie C. K. Cheung']","In a text, entities mentioned earlier can be referred to in later discourse by a more general description. For example, Celine Dion and Justin Bieber can be referred to by Canadian singers or celebrities. In this work, we study this phenomenon in the context of summarization, where entities from a source text are generalized in the summary. We call such instances source-summary entity aggregations. We categorize these aggregations into two types and analyze them in the CNN/DAILYMAIL corpus, showing that they are reasonably frequent. We then examine how well three state-of-the-art summarization systems can generate such aggregations within summaries. We also develop techniques to encourage them to generate more aggregations. Our results show that there is significant room for improvement in producing semantically correct aggregations.","The paper discusses the phenomenon of referring to entities in later discourse by a more general description, and how this applies to summarization. The authors categorize these instances as source-summary entity aggregations and analyze them in the CNN/DAILYMAIL corpus. They examine how well three state-of-the-art summarization systems can generate such aggregations and develop techniques to encourage them to generate more. The results show that there is significant room for improvement in producing semantically correct aggregations.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to improve the quality of abstractive summarization systems.', 'Who is the target audience?': 'The summaries are for abstractive summarization systems.', 'How will the summaries be used?': 'The summaries will be used to better understand the specific linguistic and semantic operations which can lead to high-quality abstractive text.'}",['analysis'],['External Knowledge'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/2022.coling-1.526,"{'There is a lack of understanding about the specific linguistic and semantic operations that lead to high-quality abstractive text.': 'The authors focus on how entities can be referred to in summaries, especially with an expression more general than in the source, and explore the semantic aggregation of named entities in context.', 'There are few existing studies about the semantics of text generated by current abstractive systems.': 'The authors conduct a study on the prevalence and categorization of semantic aggregations in the CNN/DAILYMAIL corpus.', 'It is difficult for existing systems to generate copy and novel aggregations that match those found in reference summaries.': 'The authors evaluate three state-of-the-art Transformer-based abstractive summarization systems and explore how to fine-tune BART to generate more summary-worthy aggregations without compromising the overall summary quality.', 'The performance of all the summarization models is still far below the upper bounds posed by the oracles.': 'The authors suggest that there is room for improvement in abstractive summarization systems.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:38e80fcdfb18c0a2281fd2ca2771e2d61ff134b0,SummaReranker: A Multi-Task Mixture-of-Experts Re-ranking Framework for Abstractive Summarization,ACL,2022,"['Mathieu Ravaut', 'Shafiq Joty', 'Nancy F. Chen']","Sequence-to-sequence neural networks have recently achieved great success in abstractive summarization, especially through fine-tuning large pre-trained language models on the downstream dataset. These models are typically decoded with beam search to generate a unique summary. However, the search space is very large, and with the exposure bias, such decoding is not optimal. In this paper, we show that it is possible to directly train a secondstage model performing re-ranking on a set of summary candidates. Our mixture-of-experts SummaReranker learns to select a better candidate and consistently improves the performance of the base model. With a base PEGASUS, we push ROUGE scores by 5.44% on CNNDailyMail (47.16 ROUGE-1), 1.31% on XSum (48.12 ROUGE-1) and 9.34% on Reddit TIFU (29.83 ROUGE-1), reaching a new state-of-theart. Our code and checkpoints will be available at https://github.com/ntunlp/ SummaReranker.","The paper discusses the limitations of using beam search to generate summaries with sequence-to-sequence neural networks, due to the large search space and exposure bias. The authors propose a solution of directly training a second-stage model to perform re-ranking on a set of summary candidates, resulting in improved performance of the base model. Their SummaReranker model achieves state-of-the-art results on several datasets, with code and checkpoints available online.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of abstractive summarization models and to identify the best summary candidate.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document, such as news articles.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of a document without having to read the entire text. They can also be used in applications such as search engines and chatbots.'}",['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'XSum', 'Reddit-TIFU']","['ROUGE', 'Perplexity']",['Faithfulness'],https://github.com/ntunlp/SummaReranker,https://aclanthology.org/2022.acl-long.309,"{'Autoregressive decoding with beam search can be difficult to encode global constraints such as grammaticality, coherence, and factual consistency within this framework, properties that are believed to be useful in discriminating among candidate outputs.': 'Investigate whether it is possible to train a second-stage summarization model which learns to select the best summary among a set of candidates obtained from a base model and with a decoding process, which itself can potentially involve a set of decoding methods (e.g., beam search variants).', 'Decoding methods such as beam search maintain a list of top-k best candidates, and output a single best one. However, these (k − 1) other hypotheses often contain considerably better sequences in terms of different evaluation measures.': 'Design a robust re-ranker, named SummaReranker, which systematically explores the dimensions of summary re-ranking: base model, decoding process, and evaluation measure. It is considerably less computationally expensive to train than the single-stage summarization models that it is plugged on.', 'Summarization has been an underconstrained task and its evaluation is complex and remains an active research area.': 'Use a multi-task learning framework based on a mixture-of-experts architecture in order to optimize jointly over several measures.'}",supervised,"['News', 'Social Media']",['efficient-encoding-of-long-documents']
SP:1eccaa109721a4eb37ca93247b3176b2ac6855b6,Should We Trust This Summary? Bayesian Abstractive Summarization to The Rescue,ACL,2022,"['Alexios Gidiotis', 'Grigorios Tsoumakas']","We explore the notion of uncertainty in the context of modern abstractive summarization models, using the tools of Bayesian Deep Learning. Our approach approximates Bayesian inference by first extending stateof-the-art summarization models with Monte Carlo dropout and then using them to perform multiple stochastic forward passes. Based on Bayesian inference we are able to effectively quantify uncertainty at prediction time. Having a reliable uncertainty measure, we can improve the experience of the end user by filtering out generated summaries of high uncertainty. Furthermore, uncertainty estimation could be used as a criterion for selecting samples for annotation, and can be paired nicely with active learning and human-in-the-loop approaches. Finally, Bayesian inference enables us to find a Bayesian summary which performs better than a deterministic one and is more robust to uncertainty. In practice, we show that our Variational Bayesian equivalents of BART and PEGASUS can outperform their deterministic counterparts on multiple benchmark datasets.",The paper explores uncertainty in modern abstractive summarization models using Bayesian Deep Learning. They use Monte Carlo dropout to approximate Bayesian inference and perform multiple stochastic forward passes to quantify uncertainty at prediction time. This allows for filtering out generated summaries of high uncertainty and can be used for selecting samples for annotation. Bayesian inference also enables finding a summary that performs better than a deterministic one and is more robust to uncertainty. Their Variational Bayesian equivalents of BART and PEGASUS outperform their deterministic counterparts on multiple benchmark datasets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of automatic summarization models.', 'Who is the target audience?': 'The summaries are expected to be consumed by humans.', 'How will the summaries be used?': ""The summaries will be used to increase users' trust in automated summarization systems and to improve the overall performance of summarization models.""}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum', 'AESLC']","['ROUGE', 'BLEU', 'METEOR']",[''],,https://aclanthology.org/2022.findings-acl.325,"{'State-of-the-art text summarization models suffer from generating bad outputs when the inputs lie far from the training data distribution.': 'The authors propose to explore uncertainty estimation for state-of-the-art text summarization models from a Bayesian perspective. They extend the BART and PEGASUS summarization models with Monte Carlo dropout to create corresponding Variational Bayesian PEGASUS and BART models. Sampling multiple summaries from those models allows them to approximate Bayesian inference in a practical way, which in turn enables them to estimate summarization uncertainty.', 'It is important to know when the output of automatic summarization models is of good enough quality to be served to users.': ""The authors propose to use model uncertainty as a way of detecting when a model's output is likely to be poor on the grounds of predicting far away from its training distribution. They adapt the Monte Carlo BLEU variance metric to the summarization task and investigate its efficacy as a measure of summarization uncertainty. Their findings suggest that this uncertainty metric correlates well with the quality of the generated summaries and can be effective at identifying cases of questionable quality."", 'Obtaining labeled samples for training summarization models is hard and costly.': 'The authors propose that the development of uncertainty measures for summarization can pave the way for active learning approaches. Summarization is no different in this perspective, since creating good quality target summaries for training can be very costly. The value of active learning stems from the fact that it is relatively easy to obtain large amounts of unlabeled samples.', 'Summarization models are prone to generating particularly bad outputs and are usually fairly confident about them.': 'The authors propose to take the summarization uncertainty study one step further and select the summary with the lowest disagreement out of multiple summaries sampled from their Variational models. Experiments across multiple benchmark datasets show that this method consistently improves summarization performance, and by using it their VarPEGASUS and VarBART models achieve better ROUGE F-scores compared to their original deterministic counterparts.'}",unsupervised,"['News', 'Emails']",['lack-of-suitable-training-data']
SP:4fc5ac50be16954df7e92680757d09110b8f5e57,Length Control in Abstractive Summarization by Pretraining Information Selection,ACL,2022,"['Yizhu Liu', 'Qi Jia', 'Kenny Q. Zhu']","Previous length-controllable summarization models mostly control lengths at the decoding stage, whereas the encoding or the selection of information from the source document is not sensitive to the designed length. They also tend to generate summaries as long as those in the training data. In this paper, we propose a length-aware attention mechanism (LAAM) to adapt the encoding of the source based on the desired length. Our approach works by training LAAM on a summary length balanced dataset built from the original training data, and then fine-tuning as usual. Results show that this approach is effective in generating high-quality summaries with desired lengths and even those short lengths never seen in the original training set.","The paper proposes a new approach for length-controllable summarization models that adapts the encoding of the source based on the desired length. This is achieved through a length-aware attention mechanism (LAAM) that is trained on a summary length balanced dataset built from the original training data. The results show that this approach is effective in generating high-quality summaries with desired lengths, including those that were not seen in the original training set. Previous models tended to generate summaries as long as those in the training data, but LAAM can generate shorter summaries as well.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to reproduce the semantics and topics of the original text in a concise and fluent summary by paraphrasing.', 'Who is the target audience?': 'The summaries are for displaying on different mobile devices or websites with space limitations.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the original text and to save space on mobile devices or websites.'}",['method'],"['Data Augmentation', 'Controlled Generation']","['CNN/DailyMail', 'XSum']","['ROUGE', 'METEOR', 'Novel n-grams']","['Grammaticality', 'Informativeness', 'Overall Quality']",https://github.com/YizhuLiu/lengthcontrol,https://aclanthology.org/2022.acl-long.474,"{'Length-controllable summarization is a multi-objective optimization problem, including generating complete summaries within desired lengths and selecting proper information to summarize based on desired lengths.': 'The authors propose a length-aware attention mechanism (LAAM) which extends a transformer seq2seq model with the ability to select information in the context according to the length constraint. LAAM re-normalizes the attention between encoder and decoder to boost the tokens with higher attention scores based on the desired length, helping with selecting length-aware information from source document.', 'Early-stop during decoding methods focus on when to output eos (end of sequence), indicating the end of the summary. However, these methods simply add length requirements to the decoder and ignore the fact that encoding the content, or the information selection, from the source document must also adapt to different length requirements.': 'The authors propose LAAM as a hybrid approach between early-stop during decoding methods and methods based on information selection. LAAM can select length-aware information from the source document and stop the decoding process at the desired length.', 'Methods based on information selection are two-stage methods that suffer from noises introduced in the intermediate results and do not have first-hand length information, which weakens the length control.': 'The authors propose a heuristics to create a length-balanced dataset (LBD) by predefining the length ranges and constructing extractive summaries within different length ranges, which helps model to select different information from source document via desired lengths. They first train LAAM on LBD to enhance the ability of LAAM on information selection with length constraints and then fine-tune the pretrained LAAM on the original dataset to learn to paraphrase the selected information as abstractive summaries in different lengths. This approach can effectively solve the zero-shot length control problem.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:b271cd03d0f740d54359a75ef9cf360054792533,PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization,COLING,2022,"['Xiaochen Liu', 'Yang Gao', 'Yu Bai', 'Jiawei Li', 'Yinan Hu', 'Heyan Huang', 'Boxing Chen']","Few-shot abstractive summarization has become a challenging task in natural language generation. To support it, we developed a novel soft prompts architecture coupled with a prompt pre-training plus prompt fine-tuning paradigm, which is effective and tunes only extremely light parameters. To meet the structure of the generation models, the soft prompts comprise continuous input embeddings across an encoder and a decoder. Importantly, a new inner-prompt placed in the text is introduced to capture document-level information. The aim is to devote attention to understanding the document that better prompts the model to generate document-related content. In the training process, the prompt pre-training with self-supervised pseudo-data firstly teaches the model basic summarizing capability. Then, with few-shot examples, only the designed lightweight soft prompts are fine-tuned. Experimental results on the CNN/DailyMail and XSum datasets show that our method, with only 0.1% of the parameters, outperforms full-model tuning where all model parameters are tuned. It also surpasses Prompt Tuning by a large margin and delivers competitive results against PrefixTuning with 3% of the parameters.","The paper presents a new approach to few-shot abstractive summarization using a soft prompts architecture coupled with prompt pre-training and fine-tuning. The soft prompts consist of continuous input embeddings across an encoder and decoder, with a new inner-prompt introduced to capture document-level information. The approach uses prompt pre-training with self-supervised pseudo-data to teach the model basic summarizing capability, followed by fine-tuning with few-shot examples using lightweight soft prompts. Experimental results on the CNN/DailyMail and XSum datasets show that the method outperforms full-model tuning and Prompt Tuning, and delivers competitive results against PrefixTuning with significantly fewer parameters.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to perform few-shot abstractive summarization, which is highly challenging and demanding due to the high labor costs involved in obtaining quality abstractive summaries.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without having to read the entire document.', 'How will the summaries be used?': 'The summaries will be used to aid in understanding the content of a document quickly and efficiently, especially in situations where time is limited or when dealing with large volumes of documents.'}",['method'],"['Auxiliary Tasks', 'Input Encoding']","['CNN/DailyMail', 'XSum']",['ROUGE'],"['Informativeness', 'Relevance', 'Fluency']",,https://aclanthology.org/2022.coling-1.553,"{'Fine-tuning with few-shot examples usually leads to disappointing results, especially with generation tasks like abstractive summarization.': 'The authors propose a soft prompts tuning method that is specifically designed for summarization. Prompt tokens are added before the decoder input tokens to guide the generation process toward the target summary.', 'For every specific task, a large number of pre-trained parameters need to be updated and stored, which is not efficient to use.': 'The authors leverage prompt learning, which retrieves relevant knowledge from frozen language models, only tuning continuous prompts to quickly adapt to new tasks with very few examples.', 'Prompt Tuning for abstractive summarization yields simply abysmal performance.': 'The authors propose a novel soft prompt architecture for few-shot abstractive summarization, which outperforms full-model tuning under few-shot settings only with 0.1% of the parameters.', 'PrefixTuning shows increase in few-shot generation tasks over fine-tuning, but the training process is not stable and updates are required that add to the memory and training costs.': 'The authors propose a prompt pre-training strategy which benefits soft prompts model for few-shot summarization and shows excellent zero-shot capabilities.', 'The model needs to capture the structure in the source document and aid in understanding its semantics, so as to better prompt the model to generate document-related content.': 'The authors designed three inner prompts – interval, sequential, and fixed-length – one of which is placed among the source input tokens. Each kind of inner prompts focuses on different semantic units (e.g., phrases, sentences, and etc.), differentiating important units from non-informative ones.', 'The effect of different prompts needs to be investigated.': 'The authors conduct experiments that investigate the effect of different prompts by probing the attention weights. The results show that the designed prompt-pre-training phase and the inner prompts are effective for few-shot text summarization.'}",supervised,['News'],"['controlled-and-tailored-summarization', 'pretraining-and-sample-efficiency']"
SP:9a4d653430e6b87c7db9fa614617bf6a4d69a416,Neural Network-Based Abstract Generation for Opinions and Arguments,NAACL,2016,['Lu Wang'],"We study the problem of generating abstractive summaries for opinionated text. We propose an attention-based neural network model that is able to absorb information from multiple text units to construct informative, concise, and fluent summaries. An importance-based sampling method is designed to allow the encoder to integrate information from an important subset of input. Automatic evaluation indicates that our system outperforms state-ofthe-art abstractive and extractive summarization systems on two newly collected datasets of movie reviews and arguments. Our system summaries are also rated as more informative and grammatical in human evaluation.",System: The paper proposes a neural network model that generates informative and concise summaries for opinionated text. The model uses an attention-based mechanism to absorb information from multiple text units and an importance-based sampling method to integrate important input. The system outperforms state-of-the-art summarization systems on newly collected datasets of movie reviews and arguments and is rated higher in human evaluation for informativeness and grammaticality.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to efficiently absorb the massive amount of opinionated information and to help navigate through different aspects of life, ranging from making decisions on regular tasks to judging fundamental societal issues and forming personal ideology.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the opinion consensus of a set of text units containing opinions about the same topic, such as movie reviews or arguments for a controversial social issue.', 'How will the summaries be used?': 'The summaries will be used to provide informative, concise, and fluent opinion summaries that describe the opinion consensus of the input. They can be used to make decisions on regular tasks, judge fundamental societal issues, form personal ideology, and navigate through different aspects of life.'}",['method'],['Objective Function'],"['RottenTomatoes', 'IDebate']",['ROUGE'],"['Informativeness', 'Grammaticality', 'Compactness']",https://web.eecs.umich.edu/~wangluxy/datasets/opinion_abstracts.zip,https://aclanthology.org/N16-1007,"{'Extractive summarization methods include secondary or redundant information.': 'Use abstractive summarization methods that can generate text beyond the original input to produce more coherent and concise summaries.', 'Existing abstract generation systems for opinionated text mostly identify salient phrases and merge them into sentences, which may result in ungrammatical structure.': 'Use an attention-based abstract generation model that allows the encoder to automatically search for salient information within context and propose an importance-based sampling method to integrate information from an important subset of input text.', 'Some approaches require a large amount of human input to enforce summary quality.': 'Use a data-driven approach trained to generate informative, concise, and fluent opinion summaries based on the neural encoder-decoder models framework.'}",supervised,"['Opinions', 'Arguments']",['information-loss-and-incoherence-in-extractive-summarization']
SP:5a01b5698f7f2aefcaf127ed19cd249069edea40,Get To The Point: Summarization with Pointer-Generator Networks,ACL,2017,"['Abigail See', 'Peter J. Liu', 'Christopher D. Manning']","Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.","The paper discusses the limitations of neural sequence-to-sequence models for abstractive text summarization, which can inaccurately reproduce factual details and repeat themselves. The authors propose a new architecture that uses a hybrid pointer-generator network to accurately reproduce information while retaining the ability to generate novel words, and coverage to discourage repetition. The model is applied to the CNN/Daily Mail summarization task and outperforms the current abstractive state-of-the-art by at least 2 ROUGE points.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to condense a piece of text to a shorter version that contains the main information from the original.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding longer texts, and can be particularly useful for tasks such as research or decision-making.'}",['method'],"['Unit Selection', 'Objective Function']",['CNN/DailyMail'],"['ROUGE', 'Novel n-grams']",[''],http://www.github.com/abisee/pointer-generator,https://aclanthology.org/P17-1099,"{'Inaccurately reproducing factual details in abstractive summarization.': 'The authors propose a hybrid pointer-generator network that facilitates copying words from the source text via pointing, which improves accuracy.', 'Inability to deal with out-of-vocabulary (OOV) words in abstractive summarization.': 'The hybrid pointer-generator network also improves handling of OOV words.', 'Repeating themselves in abstractive summarization.': 'The authors propose a novel variant of the coverage vector from Neural Machine Translation, which is used to track and control coverage of the source document, and is remarkably effective for eliminating repetition.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:62ea5c5df44313bea7ff93ec73ea8b7bac262f39,From Neural Sentence Summarization to Headline Generation: A Coarse-to-Fine Approach,IJCAI,2017,"['Jiwei Tan', 'Jianguo Xiao']","Headline generation is a task of abstractive text summarization, and previously suffers from the immaturity of natural language generation techniques. Recent success of neural sentence summarization models shows the capacity of generating informative, fluent headlines conditioned on selected recapitulative sentences. In this paper, we investigate the extension of sentence summarization models to the document headline generation task. The challenge is that extending the sentence summarization model to consider more document information will mostly confuse the model and hurt the performance. In this paper, we propose a coarse-to-fine approach, which first identifies the important sentences of a document using document summarization techniques, and then exploits a multi-sentence summarization model with hierarchical attention to leverage the important sentences for headline generation. Experimental results on a large real dataset demonstrate the proposed approach significantly improves the performance of neural sentence summarization models on the headline generation task.","The paper discusses the challenge of extending sentence summarization models to the task of document headline generation. The proposed solution is a coarse-to-fine approach that first identifies important sentences using document summarization techniques and then uses a multi-sentence summarization model with hierarchical attention to generate headlines. The approach significantly improves the performance of neural sentence summarization models on the headline generation task, as demonstrated by experimental results on a large real dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce condensed versions of text while preserving its meaning.', 'Who is the target audience?': 'The summaries are useful for scenarios like compressing text for mobile device users, generating content tables, and more advanced artificial intelligence applications like machine writing.', 'How will the summaries be used?': 'The summaries will be used to generate informative, fluent headlines conditioned on recapitulative sentences. They will also be used to improve the sentence summarization model and leverage the content of the whole document.'}",['method'],"['Unit Selection', 'Input Encoding']",['NYT'],"['ROUGE', 'METEOR']",[''],,https://doi.org/10.24963/ijcai.2017/574,"{'Extractive methods for headline generation suffer from generating less informative headlines due to the highly condensed nature of headlines.': 'Abstractive methods are more appropriate for the task of headline generation, which treat phrases, concepts or events as candidates, and exploit sentence synthesis techniques to generate the headline.', 'Abstractive methods have difficulty ensuring the grammaticality of the generated headlines due to the immaturity of natural language generation techniques.': 'The recent success of neural sequence-to-sequence (seq2seq) models provides an effective way for text generation, which has achieved impressive progress on tasks like machine translation, image captioning, and sentence summarization.', 'Lead sentences are not always sufficient for headline generation, and the most important information is usually distributed across several sentences in an article.': 'The authors propose a coarse-to-fine approach, which first identifies the most important sentences of the document, and then generates the headline according to the important sentences. They propose a multi-sentence summarization model with hierarchical attention, and show that a recurrent layer built on the representations of multiple summaries has the ability to control the generation of a more appropriate headline.', 'Tackling the document-level input sequence remains a major challenge for seq2seq models, and introducing more information will probably confuse the sentence summarization model and result in degraded performance.': 'The authors propose a multi-sentence summarization model with hierarchical attention, which can distinguish the important information of the input and control the generation of a more appropriate headline.', 'Filtering the dataset by using the word overlap between the headlines and the lead sentences may not be realistic.': 'The authors conduct experiments on the New York Times news corpus without filtering the dataset by using the word overlap between the headlines and the lead sentences, which ensures the dataset to be more realistic.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:31f570b86354d8b31c734e1f9b17c4d7514a5c8b,"Don’t Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization",EMNLP,2018,"['Shashi Narayan', 'Shay B. Cohen', 'Mirella Lapata']","We introduce extreme summarization, a new single-document summarization task which does not favor extractive strategies and calls for an abstractive modeling approach. The idea is to create a short, one-sentence news summary answering the question “What is the article about?”. We collect a real-world, large scale dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC). We propose a novel abstractive model which is conditioned on the article’s topics and based entirely on convolutional neural networks. We demonstrate experimentally that this architecture captures longrange dependencies in a document and recognizes pertinent content, outperforming an oracle extractive system and state-of-the-art abstractive approaches when evaluated automatically and by humans.1","The paper introduces a new summarization task called extreme summarization, which requires an abstractive modeling approach to create a one-sentence news summary that answers the question ""What is the article about?"" A large dataset was collected from the BBC, and a novel abstractive model based on convolutional neural networks was proposed. The model was shown to outperform both extractive and abstractive approaches when evaluated by humans and automatically. The architecture captures long-range dependencies in a document and recognizes pertinent content.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to solve the central problem of automatic summarization in Natural Language Processing (NLP).', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': ""The summaries can be used to provide a brief overview of the document's content, to help with information retrieval, and to save time for readers who need to quickly understand the main points of a document.""}",['method'],"['External Knowledge', 'Input Encoding']",['XSum'],"['ROUGE', 'METEOR']",['Informativeness'],https://github.com/shashiongithub/XSum,https://aclanthology.org/D18-1206/,"{'Extractive summarization models are favored in large-scale document summarization datasets, but they do not provide a high degree of abstraction.': 'The authors propose a new single-document summarization task called extreme summarization, which requires an abstractive modeling approach. They build a dataset for this task by harvesting online articles from the British Broadcasting Corporation (BBC) that often include a first-sentence summary.', 'Most existing abstractive approaches rely on an encoder-decoder architecture modeled by recurrent neural networks (RNNs), which may not effectively capture long-range dependencies between words in the document.': 'The authors propose a novel topic-conditioned neural model based entirely on convolutional neural networks (CNNs). Their convolutional encoder associates each word with a topic vector capturing whether it is representative of the document’s content, while their convolutional decoder conditions each word prediction on a document topic vector.', 'It is unclear how well the proposed model performs compared to existing extractive and abstractive summarization models.': 'The authors evaluate their model using automatic metrics (ROUGE) and two human evaluations to assess the quality of the summaries produced. They find that their model outperforms existing models and is preferred by human subjects.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:3bb4f23caa19535110d2138fa80565ee290118e1,Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation,ACL,2018,"['Han Guo', 'Ramakanth Pasunuru', 'Mohit Bansal']","An accurate abstractive summary of a document should contain all its salient information and should be logically entailed by the input document. We improve these important aspects of abstractive summarization via multi-task learning with the auxiliary tasks of question generation and entailment generation, where the former teaches the summarization model how to look for salient questioning-worthy details, and the latter teaches the model how to rewrite a summary which is a directed-logical subset of the input document. We also propose novel multitask architectures with high-level (semantic) layer-specific sharing across multiple encoder and decoder layers of the three tasks, as well as soft-sharing mechanisms (and show performance ablations and analysis examples of each contribution). Overall, we achieve statistically significant improvements over the state-ofthe-art on both the CNN/DailyMail and Gigaword datasets, as well as on the DUC2002 transfer setup. We also present several quantitative and qualitative analysis studies of our model’s learned saliency and entailment skills.","The paper proposes a method to improve abstractive summarization by using multi-task learning with the auxiliary tasks of question generation and entailment generation. The former helps the summarization model identify salient questioning-worthy details, while the latter teaches the model how to rewrite a summary that is a directed-logical subset of the input document. The paper also proposes novel multitask architectures with high-level layer-specific sharing and soft-sharing mechanisms, which result in statistically significant improvements over the state-of-the-art on various datasets. The paper presents quantitative and qualitative analysis studies of the model's learned saliency and entailment skills.",{},['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'Gigaword', 'DUC 2002']",['ROUGE'],"['Relevance', 'Readability']",,https://aclanthology.org/P18-1064,"{'Abstractive summarization models need to improve their ability to detect salient information from the input document.': 'The authors propose a document-to-question generation task as an auxiliary task to teach the summarization model what are the right questions to ask, which is directly related to what the salient information in the input document is.', 'Abstractive summarization models need to improve their ability to rewrite a summary which is a directed-logical subset of the input document, and contains no contradictory or unrelated information.': 'The authors propose a premise-to-entailment generation task as an auxiliary task to teach the summarization model how to rewrite a summary which is a directed-logical subset of the input document, and contains no contradictory or unrelated information.', 'Multi-task learning architectures need to be optimized to improve the performance of abstractive summarization models.': 'The authors propose novel multi-task learning architectures based on multi-layered encoder and decoder models, where they empirically show that it is substantially better to share the higher-level semantic layers between the three aforementioned tasks, while keeping the lower-level (lexico-syntactic) layers unshared. They also explore different ways to optimize the shared parameters and show that ‘soft’ parameter sharing achieves higher performance than hard sharing.', 'Abstractive summarization models need to be improved in low-resource scenarios.': 'The authors demonstrate the importance of auxiliary knowledge in low-resource scenarios by showing that their soft, layer-specific sharing model with the question and entailment generation auxiliary tasks achieves statistically significant improvements over the state-of-the-art on both the CNN/DailyMail and Gigaword datasets, as well as on the DUC2002 transfer setup.', 'The performance of the proposed model needs to be evaluated and analyzed.': 'The authors present human evaluation studies as well as detailed quantitative and qualitative analysis studies of the improved saliency detection and logical inference skills learned by their multi-task model. They also report improvements on their auxiliary question and entailment generation tasks over their respective previous state-of-the-art.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:c8e00c11500c94551144740e739556e547229214,Improving Abstraction in Text Summarization,EMNLP,2018,"['Wojciech Kryściński', 'Romain Paulus', 'Caiming Xiong', 'Richard Socher']","Abstractive text summarization aims to shorten long text documents into a human readable form that contains the most important facts from the original document. However, the level of actual abstraction as measured by novel phrases that do not appear in the source document remains low in existing approaches. We propose two techniques to improve the level of abstraction of generated summaries. First, we decompose the decoder into a contextual network that retrieves relevant parts of the source document, and a pretrained language model that incorporates prior knowledge about language generation. Second, we propose a novelty metric that is optimized directly through policy learning to encourage the generation of novel phrases. Our model achieves results comparable to state-of-the-art models, as determined by ROUGE scores and human evaluations, while achieving a significantly higher level of abstraction as measured by n-gram overlap with the source document.ive text summarization aims to shorten long text documents into a human readable form that contains the most important facts from the original document. However, the level of actual abstraction as measured by novel phrases that do not appear in the source document remains low in existing approaches. We propose two techniques to improve the level of abstraction of generated summaries. First, we decompose the decoder into a contextual network that retrieves relevant parts of the source document, and a pretrained language model that incorporates prior knowledge about language generation. Second, we propose a novelty metric that is optimized directly through policy learning to encourage the generation of novel phrases. Our model achieves results comparable to state-of-the-art models, as determined by ROUGE scores and human evaluations, while achieving a significantly higher level of abstraction as measured by n-gram overlap with the source document.","The paper proposes two techniques to improve the level of abstraction in abstractive text summarization. The first technique involves decomposing the decoder into a contextual network and a pretrained language model. The second technique involves a novelty metric that encourages the generation of novel phrases. The proposed model achieves results comparable to state-of-the-art models, while achieving a significantly higher level of abstraction as measured by n-gram overlap with the source document.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress a long sequence of text into a more concise form.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the most important information in a document.', 'How will the summaries be used?': 'The summaries will be used to convey only the most important information in a document in a shorter and more concise form. They will be evaluated using word overlap metrics such as ROUGE scores.'}","['method', 'metric']","['External Knowledge', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],"['Relevance', 'Readability']",,https://aclanthology.org/D18-1207,"{'The state-of-the-art abstractive text summarization models tend to copy long passages of the source document directly into the summary, thereby producing summaries that are not abstractive.': 'The authors propose to decouple the extraction and generation responsibilities of the decoder by factoring it into a contextual network and a language model. The contextual network has the sole responsibility of extracting and compacting the source document whereas the language model is responsible for the generation of concise paraphrases.', 'Word overlap metrics do not capture the abstractive nature of high quality human-written summaries: the use of paraphrases with words that do not necessarily appear in the source document.': 'The authors propose a mixed objective that jointly optimizes the n-gram overlap with the ground-truth summary while encouraging abstraction. This is done by combining maximum likelihood estimation with policy gradient. They reward the policy with the ROUGE metric, which measures word overlap with the ground-truth summary, as well as a novel abstraction reward that encourages the generation of words not in the source document.'}",supervised,['News'],[]
SP:0155830d22c7923a28b4fdd22024c0b1608a6c9e,Multi-Reward Reinforced Summarization with Saliency and Entailment,NAACL,2018,"['Ramakanth Pasunuru', 'Mohit Bansal']","Abstractive text summarization is the task of compressing and rewriting a long document into a short summary while maintaining saliency, directed logical entailment, and non-redundancy. In this work, we address these three important aspects of a good summary via a reinforcement learning approach with two novel reward functions: ROUGESal and Entail, on top of a coverage-based baseline. The ROUGESal reward modifies the ROUGE metric by up-weighting the salient phrases/words detected via a keyphrase classifier. The Entail reward gives high (lengthnormalized) scores to logically-entailed summaries using an entailment classifier. Further, we show superior performance improvement when these rewards are combined with traditional metric (ROUGE) based rewards, via our novel and effective multi-reward approach of optimizing multiple rewards simultaneously in alternate mini-batches. Our method achieves the new state-of-the-art results on CNN/Daily Mail dataset as well as strong improvements in a test-only transfer setup on DUC-2002.ive text summarization is the task of compressing and rewriting a long document into a short summary while maintaining saliency, directed logical entailment, and non-redundancy. In this work, we address these three important aspects of a good summary via a reinforcement learning approach with two novel reward functions: ROUGESal and Entail, on top of a coverage-based baseline. The ROUGESal reward modifies the ROUGE metric by up-weighting the salient phrases/words detected via a keyphrase classifier. The Entail reward gives high (lengthnormalized) scores to logically-entailed summaries using an entailment classifier. Further, we show superior performance improvement when these rewards are combined with traditional metric (ROUGE) based rewards, via our novel and effective multi-reward approach of optimizing multiple rewards simultaneously in alternate mini-batches. Our method achieves the new state-of-the-art results on CNN/Daily Mail dataset as well as strong improvements in a test-only transfer setup on DUC-2002.","The paper discusses the task of abstractive text summarization, which involves compressing a long document into a short summary while maintaining important aspects such as saliency, logical entailment, and non-redundancy. The authors propose a reinforcement learning approach with two novel reward functions, ROUGESal and Entail, in addition to a coverage-based baseline. The ROUGESal reward up-weights salient phrases/words detected via a keyphrase classifier, while the Entail reward gives high scores to logically-entailed summaries using an entailment classifier. The authors show that combining these rewards with traditional metric-based rewards leads to superior performance improvement, achieving state-of-the-art results on the CNN/Daily Mail dataset and strong improvements on the DUC-2002 dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to perform abstractive summarization, which involves generating a natural short summary of a long document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and can also be used for tasks such as information retrieval and document classification.'}","['method', 'metric']",['Objective Function'],"['CNN/DailyMail', 'DUC 2002']",['ROUGE'],[''],,https://aclanthology.org/N18-2102,"{'Abstractive summarization requires choosing the most salient information from the input document, being logically entailed by it, and avoiding redundancy.': ""The authors introduce two novel rewards, 'ROUGESal' and 'Entail', to improve the task of abstractive summarization. The ROUGESal reward gives higher weight to the important, salient words in the summary, and the Entail reward gives higher weight to summaries whose sentences logically follow from the ground-truth summary."", 'Current state-of-the-art models need to be taught about saliency and logical entailment.': 'The authors use a reinforcement learning approach to teach models about saliency and logical entailment, with the introduction of the ROUGESal and Entail rewards.', 'The traditional ROUGE metric gives equal weight to all tokens in the summary.': ""The authors use a novel saliency scorer, trained on a reading comprehension dataset's answer spans, to give a saliency-based probability score to every token in the sentence."", 'Entailment scores can be misleadingly high for very short sentences.': 'The authors add a length normalization constraint to the Entail reward to avoid misleadingly high entailment scores for very short sentences.', 'Complex scaling and weighting issues can arise when combining multiple rewards.': 'The authors use a novel multi-reward optimization approach, where they optimize multiple rewards simultaneously in alternate mini-batches, inspired by how humans take multiple concurrent types of rewards to learn a task.', 'The performance of current state-of-the-art models can be improved.': 'The authors show that their new rewards with policy gradient approaches perform significantly better than a cross-entropy based state-of-the-art pointer-coverage baseline. They also show further performance improvements by combining these rewards via their novel multi-reward optimization approach.', ""The authors want to analyze their model's saliency, entailment, and abstractiveness skills."": ""The authors present several analyses of their model's saliency, entailment, and abstractiveness skills.""}",reinforced,['News'],[]
SP:08e62973fa8a02c8b794f4c82a305310b63e4be1,Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks,EMNLP,2018,"['Yau-Shian Wang', 'Hung-Yi Lee']","Auto-encoders compress input data into a latent-space representation and reconstruct the original data from the representation. This latent representation is not easily interpreted by humans. In this paper, we propose training an auto-encoder that encodes input text into human-readable sentences, and unpaired abstractive summarization is thereby achieved. The auto-encoder is composed of a generator and a reconstructor. The generator encodes the input text into a shorter word sequence, and the reconstructor recovers the generator input from the generator output. To make the generator output human-readable, a discriminator restricts the output of the generator to resemble human-written sentences. By taking the generator output as the summary of the input text, abstractive summarization is achieved without document-summary pairs as training data. Promising results are shown on both English and Chinese corpora.","The paper proposes a method for achieving unpaired abstractive summarization using an auto-encoder that encodes input text into human-readable sentences. The auto-encoder consists of a generator and a reconstructor, with a discriminator used to ensure the generator output resembles human-written sentences. The generator encodes the input text into a shorter word sequence, and the reconstructor recovers the generator input from the generator output. This approach achieves abstractive summarization without the need for document-summary pairs as training data, and promising results are shown on both English and Chinese corpora.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract the core idea of the documents.', 'Who is the target audience?': 'The summaries are for downstream tasks like document classification and sentiment classification.', 'How will the summaries be used?': 'The summaries will be used to generate summaries for documents that are not paired with summaries, such as movie reviews or lecture recordings.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'Gigaword']","['ROUGE', 'Perplexity']",[''],,https://aclanthology.org/D18-1451,"{'The latent representation learned by the seq2seq auto-encoder is usually not human-readable, which makes it difficult to use in downstream applications.': 'The authors propose using comprehensible natural language as a latent representation of the input source text in an auto-encoder architecture. This human-readable latent representation is shorter than the source text and reflects the core idea of the source text, allowing for unpaired abstractive summarization.', 'Previous work on using human comprehensible language as a latent representation has only been explored in a semi-supervised scenario, requiring labeled data to teach the compressor network to generate text summaries.': 'The authors propose a model composed of a generator, a discriminator, and a reconstructor, where the generator learns to generate short text segments that contain the main information in the original input without the need for labeled data.', ""The generator's output word sequence may not be readable by humans, making it difficult to use in downstream applications."": ""The authors introduce a third component, the discriminator, to regularize the generator's output word sequence. The discriminator discriminates between the generator output and human-written sentences, and the generator produces output as similar as possible to human-written sentences to confuse the discriminator, resulting in a human-like summary sentence as a latent representation."", 'Generating discrete distributions by GAN is challenging due to the non-differential property.': 'The authors propose a new method on language generation by GAN to tackle this problem.', 'Most documents are not paired with summaries, making it difficult to learn summarizer to generate summaries for these documents.': 'The authors evaluate the results on an abstractive text summarization task, where the output word sequence of the generator is regarded as the summaries of the input text. This technique makes it possible to learn summarizer to generate summaries for documents without summaries.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:89f1562b868a2d1ea69fba6a3b58caec508d47cd,A Hierarchical End-to-End Model for Jointly Improving Text Summarization and Sentiment Classification,IJCAI,2018,"['Shuming Ma', 'Xu Sun', 'Junyang Lin', 'Xuancheng Ren']","Text summarization and sentiment classification both aim to capture the main ideas of the text but at different levels. Text summarization is to describe the text within a few sentences, while sentiment classification can be regarded as a special type of summarization which “summarizes” the text into a even more abstract fashion, i.e., a sentiment class. Based on this idea, we propose a hierarchical endto-end model for joint learning of text summarization and sentiment classification, where the sentiment classification label is treated as the further “summarization” of the text summarization output. Hence, the sentiment classification layer is put upon the text summarization layer, and a hierarchical structure is derived. Experimental results on Amazon online reviews datasets show that our model achieves better performance than the strong baseline systems on both abstractive summarization and sentiment classification.1","The paper proposes a hierarchical end-to-end model for joint learning of text summarization and sentiment classification, where the sentiment classification label is treated as a further ""summarization"" of the text summarization output. The model achieves better performance than strong baseline systems on both abstractive summarization and sentiment classification, as shown by experimental results on Amazon online reviews datasets. Text summarization and sentiment classification aim to capture the main ideas of the text at different levels, with text summarization describing the text within a few sentences and sentiment classification summarizing the text into an even more abstract fashion, i.e., a sentiment class.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract the main points of the text and provide a shorter version of the original text.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the main ideas of the text without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as providing a quick overview of a document, helping with information retrieval, or assisting in decision-making processes.'}",['method'],['Auxiliary Tasks'],['Amazon Product Reviews'],['ROUGE'],[''],https://github.com/lancopku/HSSC,https://doi.org/10.24963/ijcai.2018/591,"{'Most existing models are built for either summarization or classification.': 'The authors propose a hierarchical end-to-end model that combines both tasks, consisting of a summarization layer and a sentiment classification layer.', 'Previous models that produce both summaries and sentiment labels train the two parts independently and require hand-crafted features.': 'The proposed model establishes a close bond between text summarization and sentiment classification, allowing the two tasks to improve each other. The sentiment classification provides a significant supervision signal for text summarization, and the summarization component captures the sentiment tendency of the original text.', 'Some previous work on sentiment summarization only focuses on summarization and does not improve sentiment classification.': 'The proposed model treats sentiment classification as a special type of summarization and performs both tasks using a unified model.', 'It can be difficult for sentiment classifiers to predict sentiment labels for long texts.': 'The summarization layer compresses the original text into shorter sentences, making it easier for the sentiment classifier to predict sentiment labels.', 'Redundant and misleading information in the original text can be harmful to predicting sentiment.': 'Text summarization can remove such information, improving the accuracy of sentiment classification.', 'Different representations of the text may be needed for summarization and sentiment classification.': 'The authors propose a multi-view attention mechanism to obtain different representations of the text for each task.', 'The performance of the proposed model is unknown.': 'The authors evaluate their model on Amazon online reviews datasets and show that it outperforms strong baseline systems on both summarization and sentiment classification.'}",supervised,['Reviews'],[]
SP:f383ecc1bad85bcfacdaff7e43a4aa2623a20c7a,Answers Unite! Unsupervised Metrics for Reinforced Summarization Models,EMNLP,2019,"['Thomas Scialom', 'Sylvain Lamprier', 'Benjamin Piwowarski', 'Jacopo Staiano']","Abstractive summarization approaches based on Reinforcement Learning (RL) have recently been proposed to overcome classical likelihood maximization. RL enables to consider complex, possibly non-differentiable, metrics that globally assess the quality and relevance of the generated outputs. ROUGE, the most used summarization metric, is known to suffer from bias towards lexical similarity as well as from suboptimal accounting for fluency and readability of the generated abstracts. We thus explore and propose alternative evaluation measures: the reported humanevaluation analysis shows that the proposed metrics, based on Question Answering, favorably compares to ROUGE – with the additional property of not requiring reference summaries. Training a RL-based model on these metrics leads to improvements (both in terms of human or automated metrics) over current approaches that use ROUGE as a reward.ive summarization approaches based on Reinforcement Learning (RL) have recently been proposed to overcome classical likelihood maximization. RL enables to consider complex, possibly non-differentiable, metrics that globally assess the quality and relevance of the generated outputs. ROUGE, the most used summarization metric, is known to suffer from bias towards lexical similarity as well as from suboptimal accounting for fluency and readability of the generated abstracts. We thus explore and propose alternative evaluation measures: the reported humanevaluation analysis shows that the proposed metrics, based on Question Answering, favorably compares to ROUGE – with the additional property of not requiring reference summaries. Training a RL-based model on these metrics leads to improvements (both in terms of human or automated metrics) over current approaches that use ROUGE as a reward.","The paper discusses how abstractive summarization approaches based on Reinforcement Learning (RL) can overcome classical likelihood maximization. The most commonly used summarization metric, ROUGE, has limitations such as bias towards lexical similarity and suboptimal accounting for fluency and readability. The paper proposes alternative evaluation measures based on Question Answering, which were found to be favorable compared to ROUGE and do not require reference summaries. Training a RL-based model on these metrics leads to improvements in both human and automated metrics.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide relevant and informative summaries given a variable-length text as input.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used to measure and drive the progress of summarization systems, and to train reinforcement learning-based models. They will also be evaluated through human assessment.'}","['method', 'metric']",['Objective Function'],"['CNN/DailyMail', 'Webis-TLDR-17']",['ROUGE'],"['Relevance', 'Readability']",https://www.github.com/recitalAI/summa-qa,https://aclanthology.org/D19-1320,"{'The current evaluation metric for summarization systems, ROUGE, has several problems, including poor accounting for fluency and readability of the generated abstracts, as well as bias towards lexical similarity.': 'The authors propose to overcome n-gram matching based metrics, such as ROUGE, by developing metrics which are better predictors of the quality of summaries. They introduce new metrics based on Question Answering that do not require human annotations.', 'Summarization models incur the risk of being unfairly penalized by ROUGE, as a high quality summary might still have very few tokens/n-grams in common with the reference it is evaluated against.': 'The authors propose to leverage the accuracy of the proposed metrics in several reinforcement learning schemes for summarization, including two unsupervised settings: in-domain (raw texts from the target documents) and out-of-domain (raw texts from another document collection). They also qualitatively evaluate the performances of the different approaches through human assessment.', 'The need for faithful evaluation metrics is crucial to measure and drive the progress of abstractive summarization systems.': 'The authors propose new metrics that are better predictors of the quality of summaries, which can be used to train reinforcement learning-based models and improve the state-of-the-art in terms of both ROUGE and human assessments.'}",reinforced,"['News', 'Social Media']",['robust-evaluation-methods']
SP:c0fcc6dad782750a42d380e2d95c7f086d79210c,Summary Cloze: A New Task for Content Selection in Topic-Focused Summarization,EMNLP,2019,['Daniel Deutsch'],"A key challenge in topic-focused summarization is determining what information should be included in the summary, a problem known as content selection. In this work, we propose a new method for studying content selection in topic-focused summarization called the summary cloze task. The goal of the summary cloze task is to generate the next sentence of a summary conditioned on the beginning of the summary, a topic, and a reference document(s). The main challenge is deciding what information in the references is relevant to the topic and partial summary and should be included in the summary. Although the cloze task does not address all aspects of the traditional summarization problem, the more narrow scope of the task allows us to collect a large-scale datset of nearly 500k summary cloze instances from Wikipedia. We report experimental results on this new dataset using various extractive models and a two-step abstractive model that first extractively selects a small number of sentences and then abstractively summarizes them. Our results show that the topic and partial summary help the models identify relevant content, but the task remains a significant challenge.","The paper proposes a new method for studying content selection in topic-focused summarization called the summary cloze task. The task involves generating the next sentence of a summary based on a topic, a partial summary, and a reference document. The challenge is deciding what information in the references is relevant to the topic and partial summary and should be included in the summary. The paper reports experimental results on a dataset of nearly 500k summary cloze instances from Wikipedia using various extractive and abstractive models. The results show that the task remains a significant challenge, but the topic and partial summary help the models identify relevant content.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for topic-focused multi-document summarization, which is a goal for natural language processing.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a set of reference documents with respect to a specific topic or information need.', 'How will the summaries be used?': 'The summaries will be used to help people quickly understand the main points of a set of reference documents with respect to a specific topic or information need. The authors propose a new task for content selection in topic-focused summarization, called the summary cloze task, and provide a large-scale dataset and baseline models for this task.'}","['corpus', 'method']","['Unit Selection', 'Auxiliary Tasks']","['WikiCite', 'DUC 2005', 'DUC 2006']",['ROUGE'],[''],https://cogcomp.seas.upenn.edu/page/publication_view/880,https://aclanthology.org/D19-1386,"{'The size of available datasets has made it difficult to train recent state-of-the-art summarization systems for topic-focused summarization.': 'The authors address the problem of content selection, which is a narrower aspect of the task, and formulate a new task for content selection in topic-focused summarization called the summary cloze task. They collect a new large-scale summary cloze dataset from Wikipedia, called the WIKICITE dataset, which contains nearly 500k summary cloze instances.', 'The primary challenge of the summary cloze task is to decide what information in the reference document(s) is relevant to the topic and partial summary.': 'The authors propose an extractive model and a two-step abstractive model, both of which are based on recent successful work on generic summarization. The extractive model combines representations of the topic and partial summary with representations of the document sentences through an attention mechanism to extract one reference sentence. The two-step model first reduces the length of the input data by extractively selecting a small number of sentences, then abstractively summarizes them using a decoder that has an initial hidden state which depends on the partial summary.', 'The task of content selection in topic-focused summarization remains a significant challenge.': ""The authors' experimental results show that the topic and context help the models identify relevant information, but the task remains a significant challenge.""}",supervised,['Wikipedia'],['lack-of-suitable-training-data']
SP:9582793e1a0bbd56e8aabf136908fc84f794d57b,Text Summarization with Pretrained Encoders,EMNLP,2019,"['Yang Liu', 'Mirella Lapata']","Bidirectional Encoder Representations from Transformers (BERT; Devlin et al. 2019) represents the latest incarnation of pretrained language models which have recently advanced a wide range of natural language processing tasks. In this paper, we showcase how BERT can be usefully applied in text summarization and propose a general framework for both extractive and abstractive models. We introduce a novel document-level encoder based on BERT which is able to express the semantics of a document and obtain representations for its sentences. Our extractive model is built on top of this encoder by stacking several intersentence Transformer layers. For abstractive summarization, we propose a new fine-tuning schedule which adopts different optimizers for the encoder and the decoder as a means of alleviating the mismatch between the two (the former is pretrained while the latter is not). We also demonstrate that a two-staged fine-tuning approach can further boost the quality of the generated summaries. Experiments on three datasets show that our model achieves stateof-the-art results across the board in both extractive and abstractive settings.1",The paper discusses the use of Bidirectional Encoder Representations from Transformers (BERT) in text summarization and proposes a framework for both extractive and abstractive models. They introduce a document-level encoder based on BERT that can express the semantics of a document and obtain representations for its sentences. They also propose a new fine-tuning schedule for abstractive summarization that adopts different optimizers for the encoder and decoder to alleviate the mismatch between the two. The experiments on three datasets show that their model achieves state-of-the-art results in both extractive and abstractive settings.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to condense a document into a shorter version while preserving most of its meaning.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['External Knowledge'],"['CNN/DailyMail', 'NYT', 'XSum']",['ROUGE'],['Overall Quality'],https://github.com/nlpyang/PreSumm,https://aclanthology.org/D19-1387,"{'Language model pretraining has not been extensively explored for text summarization.': 'The authors explore the potential of BERT for text summarization under a general framework encompassing both extractive and abstractive modeling paradigms.', 'Summarization requires wide-coverage natural language understanding going beyond the meaning of individual words and sentences.': 'The authors propose a novel document-level encoder based on BERT which is able to encode a document and obtain representations for its sentences.', 'Abstractive summarization requires language generation capabilities in order to create summaries containing novel words and phrases not featured in the source text.': 'The authors adopt an encoder-decoder architecture, combining the same pretrained BERT encoder with a randomly-initialized Transformer decoder.', 'The optimizers of the encoder and the decoder need to be separated in order to accommodate the fact that the former is pretrained while the latter must be trained from scratch.': 'The authors design a new training schedule which separates the optimizers of the encoder and the decoder.', 'Extractive summarization is often defined as a binary classification task with labels indicating whether a text span (typically a sentence) should be included in the summary.': 'The authors build an extractive model on top of the document-level encoder by stacking several intersentence Transformer layers to capture document-level features for extracting sentences.', 'The combination of extractive and abstractive objectives can help generate better summaries.': 'The authors present a two-stage approach where the encoder is fine-tuned twice, first with an extractive objective and subsequently on the abstractive summarization task.', 'The proposed models need to be evaluated on different datasets representative of different writing conventions and summary styles.': 'The authors evaluate the proposed approach on three single-document news summarization datasets representative of different writing conventions and summary styles and experimentally show that the proposed models achieve state-of-the-art results under both extractive and abstractive settings.', 'The importance of document encoding for the summarization task needs to be highlighted.': 'The authors highlight the importance of document encoding for the summarization task and achieve better results with a minimum-requirement model without using any of the recently proposed techniques to enhance summarization performance.', 'Effective ways to employ pretrained language models in summarization under both extractive and abstractive settings need to be showcased.': 'The authors showcase ways to effectively employ pretrained language models in summarization under both extractive and abstractive settings and expect any improvements in model pretraining to translate in better summarization in the future.', '10: The proposed models need to be used as a stepping stone to further improve summarization performance as well as baselines against which new proposals are tested.': '10: The authors propose that the proposed models can be used as a stepping stone to further improve summarization performance as well as baselines against which new proposals are tested.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:3c136603e31ec64d2ba78e78379084f2e6346cc5,Generating Formality-tuned Summaries Using Input-dependent Rewards,CONLL,2019,"['Kushal Chawla', 'Balaji Vasan Srinivasan', 'Niyati Chhaya']","Abstractive text summarization aims at generating human-like summaries by understanding and paraphrasing the given input content. Recent efforts based on sequence-to-sequence networks only allow the generation of a single summary. However, it is often desirable to accommodate the psycho-linguistic preferences of the intended audience while generating the summaries. In this work, we present a reinforcement learning based approach to generate formality-tailored summaries for an input article. Our novel input-dependent reward function aids in training the model with stylistic feedback on sampled and ground-truth summaries together. Once trained, the same model can generate formal and informal summary variants. Our automated and qualitative evaluations show the viability of the proposed framework.ive text summarization aims at generating human-like summaries by understanding and paraphrasing the given input content. Recent efforts based on sequence-to-sequence networks only allow the generation of a single summary. However, it is often desirable to accommodate the psycho-linguistic preferences of the intended audience while generating the summaries. In this work, we present a reinforcement learning based approach to generate formality-tailored summaries for an input article. Our novel input-dependent reward function aids in training the model with stylistic feedback on sampled and ground-truth summaries together. Once trained, the same model can generate formal and informal summary variants. Our automated and qualitative evaluations show the viability of the proposed framework.","The paper discusses a reinforcement learning based approach to generate formality-tailored summaries for an input article. The model can generate both formal and informal summary variants, accommodating the psycho-linguistic preferences of the intended audience. The proposed framework includes a novel input-dependent reward function that aids in training the model with stylistic feedback on sampled and ground-truth summaries. Automated and qualitative evaluations show the viability of the approach.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to aid in the quick and efficient consumption of content.', 'Who is the target audience?': 'The summaries are for the audience who may prefer a certain style or formality level in the content they consume.', 'How will the summaries be used?': ""The summaries will be used to provide a tailored version of the content that meets the audience's preferences for style and formality.""}","['method', 'metric']",['Objective Function'],"['CNN/DailyMail', 'Webis-TLDR-17']",['ROUGE'],"['Formality', 'Meaning Similarity', 'Semantic Correctness', 'Suitability']",,https://aclanthology.org/K19-1078,"{'Approaches to generate style-tailored summaries are limited.': 'The authors propose an approach to generate summaries while simultaneously tailoring towards formality preferences by incorporating formality in abstractive text summarization.', 'None of the existing approaches account for the length/succinctness of the created content, and hence do not address the stylized summarization task.': 'The authors define a novel input-dependent reward function which aids in training the model with stylistic feedback on sampled and ground-truth summaries together.', 'Extending existing approaches for formality tailored summarization would require a diverse summarization corpus that captures subtleties in various formal variants, which is difficult to curate.': 'The authors merge data from two domains: news and social media - the first one representing more formal language and the latter, informal, to build a formality-rich training dataset.', 'Reinforcement learning (RL) based loss functions have recently shown promise in tuning the output on rewards such as ROUGE, but if directly applied for controlling stylistic parameters like formality, such a method would need two separately trained models for generating formal and informal summaries and thus, may miss out on the common learnings.': 'The authors propose a method to incorporate formality in abstractive text summarization using a single model that can generate both formal and informal summary variants.'}",reinforced,"['News', 'Social Media']",['controlled-and-tailored-summarization']
SP:8ec238b180202d5886cf484ad363f144dafc719a,OPINIONDIGEST: A Simple Framework for Opinion Summarization,ACL,2020,"['Yoshihiko Suhara', 'Xiaolan Wang', 'Stefanos Angelidis', 'Wang-Chiew Tan']","We present OPINIONDIGEST, an abstractive opinion summarization framework, which does not rely on gold-standard summaries for training. The framework uses an Aspect-based Sentiment Analysis model to extract opinion phrases from reviews, and trains a Transformer model to reconstruct the original reviews from these extractions. At summarization time, we merge extractions from multiple reviews and select the most popular ones. The selected opinions are used as input to the trained Transformer model, which verbalizes them into an opinion summary. OPINIONDIGEST can also generate customized summaries, tailored to specific user needs, by filtering the selected opinions according to their aspect and/or sentiment. Automatic evaluation on YELP data shows that our framework outperforms competitive baselines. Human studies on two corpora verify that OPINIONDIGEST produces informative summaries and shows promising customization capabilities1.","The paper presents OPINIONDIGEST, an opinion summarization framework that uses an Aspect-based Sentiment Analysis model to extract opinion phrases from reviews and trains a Transformer model to reconstruct the original reviews. The framework selects the most popular opinions and uses them to generate an opinion summary. OPINIONDIGEST can also generate customized summaries by filtering opinions according to aspect and sentiment. The framework outperforms competitive baselines in automatic evaluation and produces informative summaries with promising customization capabilities, as verified by human studies.","{'What is the purpose of the summaries?': 'The authors are generating summaries of customer reviews to extract the most salient opinions expressed in the reviews.', 'Who is the target audience?': 'The summaries are for the Data Mining and Natural Language Processing communities.', 'How will the summaries be used?': ""The summaries can be used to understand the customers' satisfaction about an item across multiple aspects and to identify prevalent opinions in the input.""}",['method'],['Unit Selection'],['Yelp Reviews'],['ROUGE'],"['Informativeness', 'Coherence', 'Non-redundancy']",https://github.com/megagonlabs/opiniondigest,https://aclanthology.org/2020.acl-main.513/,"{'Summarizing opinions in customer reviews is challenging, and early efforts focused on producing structured summaries that numerically aggregate customer satisfaction across multiple aspects. Extractive approaches produce well-formed text, but selecting the sentences that approximate the most popular opinions in the input is difficult. Opinion summarization can rarely rely on gold-standard summaries for training, and recent work has utilized end-to-end unsupervised architectures based on auto-encoders. However, these approaches do not explicitly deal with opinion popularity or allow for controllable summarization.': 'The authors propose a pipeline framework called OPINIONDIGEST, which has three components: a pre-trained opinion extractor, a simple and controllable opinion selector, and a generator model. The opinion extractor identifies opinion phrases in reviews, and the opinion selector merges, ranks, and optionally filters the extracted opinions. The generator model is trained to reconstruct reviews from their extracted opinion phrases and can then generate opinion summaries based on the selected opinions. The authors believe that their approach is more interpretable and controllable than previous end-to-end architectures and explicitly deals with opinion popularity and sentiment and aspect control.'}",supervised,['Reviews'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:918b4795a7a94d5834b21818288f3e59c27422e4,Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach,EMNLP,2020,"['Bowen Tan', 'Lianhui Qin', 'Eric P. Xing', 'Zhiting Hu']","Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on arbitrary aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as ConceptNet and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects.1","The paper discusses aspect-based abstractive summarization, which generates a summary of a document based on a specific topic of interest. Previous studies have only focused on a small set of pre-defined topics, limiting the application of the task. The authors propose a new method that allows summarization on arbitrary topics relevant to the document, using external knowledge sources such as ConceptNet and Wikipedia. Experiments show that their approach improves performance on both real and synthetic documents.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to meet specific information needs in applications such as personalized intelligent assistants.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document, such as news articles or medical reports.', 'How will the summaries be used?': ""The summaries can be used to save time and provide a quick overview of the document's content, especially when specific aspects of the document are of interest.""}",['method'],"['Data Augmentation', 'Controlled Generation']",['CNN/DailyMail'],"['ROUGE', 'Textual Entailment']","['Accuracy', 'Informativeness', 'Fluency']",https://github.com/tanyuqian/aspect-based-summarization,https://aclanthology.org/2020.emnlp-main.510,"{'Lack of direct supervision data containing documents paired with multiple aspect-based summaries.': 'The authors develop a new approach that integrates rich external knowledge in both aspect modeling and weak supervision construction. Specifically, they derive weak supervisions from a generic summarization corpus, where the ConceptNet knowledge graph is used to substantially expand the aspect scope and enrich the supervisions.', 'Models trained on synthetic data tend to be restricted to the pre-defined set of aspects and fall short of summarizing on other diverse aspects.': 'The authors aim to go beyond pre-defined aspects and enable summarization on arbitrary aspects relevant to the document. They augment the model inputs with rich aspect-related information extracted from Wikipedia to assist the summarization model to better understand an aspect, especially a previously unseen one.', 'Limited data efficiency when adapting to the previous synthetic domain.': 'The BART model after fine-tuning with the proposed weak supervisions becomes substantially more data efficient and outperforms previous best-performing systems greatly using only 0.4% training examples.'}",supervised,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:eb21eb0f0c870716c053082135daa3528276d656,Multi-hop Inference for Question-driven Summarization,EMNLP,2020,"['Yang Deng', 'Wenxuan Zhang', 'Wai Lam']","Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for nonfactoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms stateof-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA.","The paper proposes a new method called Multi-hop Selective Generator (MSG) for question-driven abstractive summarization. This method incorporates multi-hop reasoning to provide justifications for the generated summaries. The proposed method outperforms state-of-the-art methods on two non-factoid QA datasets, namely WikiHow and PubMedQA. The method jointly models the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module and a gated selective pointer generator network with a multi-view coverage mechanism.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce concise but informative answers in non-factoid question answering scenarios.', 'Who is the target audience?': 'The summaries are for non-factoid question answering scenarios, such as community QA or explainable QA.', 'How will the summaries be used?': 'The summaries will be used to provide justification sentences as evidence for the answer in non-factoid question answering scenarios.'}",['method'],"['Unit Relationship', 'Input Encoding', 'Objective Function']","['WikiHow', 'PubMedQA']",['ROUGE'],"['Informativeness', 'Conciseness', 'Readability', 'Correctness']",https://github.com/dengyang17/msg,https://aclanthology.org/2020.emnlp-main.547,"{'Most related studies focus on query-based summarization approaches for summarizing the query-related content from the source document, which fall short of tackling question-driven summarization problem in QA scenario, since the query-based summarization process is typically based on semantic relevance measurement without a careful reasoning or inference process, which is essential to question-driven summarization.': 'The authors propose a novel question-driven abstractive summarization model for generating answers in non-factoid QA, which incorporates multi-hop reasoning to infer the important content for facilitating answer generation.', 'Currently, question-driven summarization is mainly explored by traditional information retrieval methods to select sentences from the source document to construct the final answer, which heavily rely on hand-crafted features or tedious multi-stage pipelines.': 'The authors propose a hierarchical text structure to be assessed with the importance degree in both word- and sentence-level for content selection. Then they develop a multi-hop inference module to enable human-like multi-hop reasoning in question-driven summarization, which considers the semantic relevance to the question as well as the information consistency among different sentences.', 'The generated summary is likely to lose important information, if we only focus on the semantically relevant content to the given question. Moreover, one-time inference sometimes is insufficient for collecting all the required information for producing a summary.': 'The authors propose a gated selective pointer generator network with multi-view coverage mechanism to generate a concise but informative summary as the answer to the given question, which addresses the repetition issue along with the multi-view pointer network and generates informative answers.', 'There is a need for justification sentences as the evidence for the answer.': 'The proposed method achieves state-of-the-art performance on WikiHow and PubMedQA datasets, and it is able to provide justification sentences as the evidence for the answer.'}",supervised,['CQA'],[]
SP:63d311033b85ec8efeb05ef14daa01de787a5235,Better Highlighting: Creating Sub-Sentence Summary Highlights,EMNLP,2020,"['Sangwoo Cho', 'Kaiqiang Song', 'Chen Li', 'Dong Yu', 'Hassan Foroosh', 'Fei Liu']","Amongst the best means to summarize is highlighting. In this paper, we aim to generate summary highlights to be overlaid on the original documents to make it easier for readers to sift through a large amount of text. The method allows summaries to be understood in context to prevent a summarizer from distorting the original meaning, of which abstractive summarizers usually fall short. In particular, we present a new method to produce self-contained highlights that are understandable on their own to avoid confusion. Our method combines determinantal point processes and deep contextualized representations to identify an optimal set of sub-sentence segments that are both important and non-redundant to form summary highlights. To demonstrate the flexibility and modeling power of our method, we conduct extensive experiments on summarization datasets. Our analysis provides evidence that highlighting is a promising avenue of research towards future summarization.",System: The paper proposes a method to generate summary highlights that can be overlaid on original documents to help readers sift through large amounts of text. The method aims to prevent distortion of the original meaning by providing summaries in context. The method combines determinantal point processes and deep contextualized representations to identify important and non-redundant sub-sentence segments to form self-contained highlights. The paper presents extensive experiments on summarization datasets to demonstrate the flexibility and modeling power of the method. The authors conclude that highlighting is a promising avenue for future summarization research.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide reliable and true-to-original information that avoids misdirecting readers to false conclusions.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly navigate through content, especially in areas involving legislation, political speeches, public policies, social media, and more.', 'How will the summaries be used?': 'The summaries will be overlaid on the original documents as highlight sub-sentence segments that are self-contained, informative, non-redundant, and easy to understand without the need for specific information from surrounding context.'}",['method'],"['Unit Selection', 'Objective Function']","['DUC 2004', 'TAC 2011']",['ROUGE'],['Self-containedness'],https://github.com/ucfnlp/better-highlighting,https://aclanthology.org/2020.emnlp-main.509,"{'Abstractive summarizers are less reliable because they can hallucinate facts and struggle to keep the original meanings intact.': 'Generate summary highlights to be overlaid on the original documents to allow summaries to be understood in context and avoid misdirecting readers to false conclusions.', 'There has not been any unified framework to account for all the characteristics of summary highlights.': 'Identify self-contained sub-sentence segments from the documents, then combine determinantal point processes and deep contextualized representations to produce highlights.', 'Whole sentences often contain excessive or unwanted details; keywords are succinct but less informative.': 'Study sub-sentence segments as they strike a balance between the quality and amount of highlights. Present a novel method to “overgenerate” a rich set of self-contained, partially-overlapping sub-sentence segments from any sentence based on contextualized representations, then leverage determinantal point processes to identify an essential subset based on saliency and non-redundancy criteria.', 'Highlighted text should be self-contained, i.e., understandable on its own, without the need for specific information from surrounding context.': 'Introduce a new algorithm based on deep contextual representations to obtain self-contained text segments. All candidate segments are fed to determinantal point processes to identify an optimal subset containing informative, non-redundant, and self-contained sub-sentence highlights.', 'There is a need to demonstrate the flexibility and modeling power of the proposed approach.': 'Perform experiments on benchmark summarization datasets to demonstrate the flexibility and modeling power of the approach.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'hallucinations-in-the-generated-summaries']"
SP:0b911222227c863502193b600041007d58b406b7,Improving Truthfulness of Headline Generation,ACL,2020,"['Kazuki Matsumaru', 'Sho Takase', 'Naoaki Okazaki']","Most studies on abstractive summarization report ROUGE scores between system and reference summaries. However, we have a concern about the truthfulness of generated summaries: whether all facts of a generated summary are mentioned in the source text. This paper explores improving the truthfulness in headline generation on two popular datasets. Analyzing headlines generated by the stateof-the-art encoder-decoder model, we show that the model sometimes generates untruthful headlines. We conjecture that one of the reasons lies in untruthful supervision data used for training the model. In order to quantify the truthfulness of article-headline pairs, we consider the textual entailment of whether an article entails its headline. After confirming quite a few untruthful instances in the datasets, this study hypothesizes that removing untruthful instances from the supervision data may remedy the problem of the untruthful behaviors of the model. Building a binary classifier that predicts an entailment relation between an article and its headline, we filter out untruthful instances from the supervision data. Experimental results demonstrate that the headline generation model trained on filtered supervision data shows no clear difference in ROUGE scores but remarkable improvements in automatic and manual evaluations of the generated headlines.","The paper discusses the concern about the truthfulness of generated summaries in abstractive summarization and explores improving the truthfulness in headline generation on two popular datasets. The study analyzes headlines generated by the state-of-the-art encoder-decoder model and shows that the model sometimes generates untruthful headlines due to untruthful supervision data used for training the model. To remedy this problem, the study hypothesizes that removing untruthful instances from the supervision data may help and builds a binary classifier that predicts an entailment relation between an article and its headline to filter out untruthful instances. Experimental results demonstrate that the headline generation model trained on filtered supervision data shows remarkable improvements in automatic and manual evaluations of the generated headlines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the text into a shorter version while maintaining the essential information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as news articles, research papers, and business reports, to save time and improve efficiency in information processing.'}",['analysis'],"['Data Augmentation', 'External Knowledge']",['Gigaword'],['ROUGE'],['Truthfulness'],https://github.com/nlp-titech/headline-entailment,https://aclanthology.org/2020.acl-main.123,{},supervised,['News'],"['lack-of-suitable-training-data', 'hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:4a3e63af0031b575f80211a76aec96cca7467bcb,Long-Span Summarization via Local Attention and Content Selection,ACL,2021,"['Potsawee Manakul', 'Mark J. F. Gales']","Transformer-based models have achieved state-of-the-art results in a wide range of natural language processing (NLP) tasks including document summarization. Typically these systems are trained by fine-tuning a large pretrained model to the target task. One issue with these transformer-based models is that they do not scale well in terms of memory and compute requirements as the input length grows. Thus, for long document summarization, it can be challenging to train or fine-tune these models. In this work, we exploit large pre-trained transformer-based models and address long-span dependencies in abstractive summarization using two methods: local self-attention; and explicit content selection. These approaches are compared on a range of network configurations. Experiments are carried out on standard long-span summarization tasks, including Spotify Podcast, arXiv, and PubMed datasets. We demonstrate that by combining these methods, we can achieve state-of-the-art results on all three tasks in the ROUGE scores. Moreover, without a large-scale GPU card, our approach can achieve comparable or better results than existing approaches.1","The paper discusses the use of transformer-based models in natural language processing tasks, specifically document summarization. While these models have achieved impressive results, they struggle with scaling as input length grows, making it difficult to train or fine-tune them for long document summarization. The paper proposes two methods, local self-attention and explicit content selection, to address long-span dependencies in abstractive summarization. The approaches are compared on various network configurations and tested on standard long-span summarization tasks, achieving state-of-the-art results on all three tasks in the ROUGE scores. The paper also notes that their approach can achieve comparable or better results than existing approaches without requiring a large-scale GPU card.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to tackle the challenge of long document summarization in natural language processing (NLP) tasks.', 'Who is the target audience?': 'The summaries are for practitioners who want to achieve good performance with less training time.', 'How will the summaries be used?': 'The summaries will be used to provide a condensed version of long documents, making it easier for practitioners to extract relevant information and insights.'}",['method'],"['Unit Selection', 'Objective Function', 'Input Encoding']","['Spotify Podcast Dataset', 'arXiv', 'PubMed']",['ROUGE'],[''],https://github.com/potsawee/longsum0,https://aclanthology.org/2021.acl-long.470,"{'Transformer-based models have limits on sequence length, which can be a problem for long document summarization.': 'The authors propose to exploit standard transformer models by constraining attention mechanism to be local, allowing longer input spans during training.', 'Training large transformer models on long sequences is expensive and may not be possible on a standard GPU card because of the self-attention mechanism that grows quadratically with sequence length.': 'Recent works have modified self-attention mechanism and proposed variants of the transformer such that the quadratic complexity is reduced. However, pre-trained weights of the modified models are not readily available. The authors propose to exploit pre-trained standard models such as BERT or BART for long-span summarization tasks.', 'Abstractive summarization systems perform content selection implicitly, which can lead to high memory and compute requirements.': 'The authors propose an alternative method to perform content selection explicitly before the abstractive stage. They study content selection during two phases: training time and test time. At training time, they investigate methods to select data for training fixed-span abstractive models. At test time, they propose a multitask content selection method that ranks sentences through extractive labelling based module and attention based module.'}",supervised,"['Podcast Transcripts', 'Scholarly Documents']","['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data']"
SP:ffce7e8b61846b5c9c9b0ea6cad948a983ec7f7a,RewardsOfSum: Exploring Reinforcement Learning Rewards for Summarisation,ACL,2021,"['Jacob Parnell', 'Inigo Jauregi Unanue', 'Massimo Piccardi']","To date, most abstractive summarisation models have relied on variants of the negative loglikelihood (NLL) as their training objective. In some cases, reinforcement learning has been added to train the models with an objective that is closer to their evaluation measures (e.g. ROUGE). However, the reward function to be used within the reinforcement learning approach can play a key role for performance and is still partially unexplored. For this reason, in this paper, we propose two reward functions for the task of abstractive summarisation: the first function, referred to as RwBHinge, dynamically selects the samples for the gradient update. The second function, nicknamed RISK, leverages a small pool of strong candidates to inform the reward. In the experiments, we probe the proposed approach by fine-tuning an NLL pre-trained model over nine summarisation datasets of diverse size and nature. The experimental results show a consistent improvement over the negative loglikelihood baselines.","The paper proposes two reward functions for abstractive summarization, RwBHinge and RISK, to improve upon the negative loglikelihood (NLL) baselines commonly used in training models. The experiments show that the proposed approach consistently improves performance over the NLL baselines when fine-tuning an NLL pre-trained model on nine diverse summarization datasets. The reward function used in reinforcement learning plays a key role in performance and is still partially unexplored.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the accuracy of language generation tasks, such as summarisation and machine translation.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used to provide a more practical and reasonable way to implement summarisation without compromising accuracy. They can also be used to inform decision-making or to quickly understand the content of a document.'}","['method', 'metric']",['Objective Function'],"['CNN/DailyMail', 'XSum', 'Gigaword', 'AESLC', 'Reddit-TIFU', 'Newsroom', 'PubMed', 'arXiv', 'BillSum']",['ROUGE'],[''],,https://aclanthology.org/2021.spnlp-1.1,"{'The standard negative loglikelihood (NLL) used as the training objective in neural text summarisation models fails to account for synonymous tokens and other potentially valid variations, and strongly biases the model towards the ground-truth reference.': 'The authors propose to adopt reinforcement learning (RL) in summarisation and other language generation tasks to optimize sequence-level metrics during training. They implement an objective function which includes multiple predicted sequences, allowing for a scenario in which several valid candidate summaries can be considered.', 'The success of RL techniques such as REINFORCE strongly depends on the use of an effective and appropriate reward.': 'The authors modify the reinforcement learning framework in such a way that enforces only a higher weighting to those predicted sequences which obtain a higher reward. They apply two techniques to summarisation; RwB-Hinge, which applies a hinge-loss modification to the classical REINFORCE with baseline to selectively apply the model gradients, and Expected Risk Minimization (RISK), which leverages a small pool of strong sampled candidates to smartly inform the reward function.', 'The inconsistency between token-level training and sequence-level evaluation.': 'The authors address this issue by adopting reinforcement learning to optimize sequence-level metrics during training. They modify the reinforcement learning framework to enforce a higher weighting to those predicted sequences which obtain a higher reward. They also propose to use multiple predicted sequences in the objective function to allow for a scenario in which several valid candidate summaries can be considered.'}",reinforced,"['News', 'Emails', 'Social Media', 'Scholarly Documents', 'Legislative Bills']",['robust-evaluation-methods']
SP:cacc22575dd5aa27e1281f628d3fee3935267013,Sparsity and Sentence Structure in Encoder-Decoder Attention of Summarization Systems,EMNLP,2021,"['Potsawee Manakul', 'Mark J. F. Gales']","Transformer models have achieved state-ofthe-art results in a wide range of NLP tasks including summarization. Training and inference using large transformer models can be computationally expensive. Previous work has focused on one important bottleneck, the quadratic self-attention mechanism in the encoder. Modified encoder architectures such as LED or LoBART use local attention patterns to address this problem for summarization. In contrast, this work focuses on the transformer’s encoder-decoder attention mechanism. The cost of this attention becomes more significant in inference or training approaches that require model-generated histories. First, we examine the complexity of the encoder-decoder attention. We demonstrate empirically that there is a sparse sentence structure in document summarization that can be exploited by constraining the attention mechanism to a subset of input sentences, whilst maintaining system performance. Second, we propose a modified architecture that selects the subset of sentences to constrain the encoder-decoder attention. Experiments are carried out on abstractive summarization tasks, including CNN/DailyMail, XSum, Spotify Podcast, and arXiv.1","The paper discusses the challenges of using transformer models for NLP tasks, particularly in summarization, due to the computational expense of the encoder-decoder attention mechanism. The authors propose a modified architecture that selects a subset of input sentences to constrain the attention mechanism, based on the empirical observation of a sparse sentence structure in document summarization. Experiments on various summarization tasks show that the proposed approach maintains system performance while reducing computational cost.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to reduce the computational cost of training and inference using large transformer models.', 'Who is the target audience?': 'The summaries are for a wide range of NLP tasks, from classification to seq2seq.', 'How will the summaries be used?': 'The summaries will be used to improve the efficiency of transformer architectures for NLP tasks.'}",['analysis'],"['Unit Selection', 'Objective Function', 'Input Encoding']","['CNN/DailyMail', 'XSum', 'Spotify Podcast Dataset', 'arXiv']","['ROUGE', 'Novel n-grams']",[''],https://github.com/potsawee/encdec_attn_sparse,https://aclanthology.org/2021.emnlp-main.739,"{'Training and inference using large transformer models can be computationally expensive because the self-attention’s time and memory grow quadratically with sequence length.': 'The authors propose efficient transformer architectures to tackle the quadratic complexity, and a comprehensive survey on efficient transformers has been compiled in Tay et al. (2020).', 'Most existing approaches for efficient transformers are developed for encoder-only architectures.': 'The authors propose efficient models such as BigBird (Zaheer et al., 2020) or LED (Beltagy et al., 2020) that consist of an efficient encoder with the vanilla decoder, which has been shown effective for long-document summarization.', 'The major bottleneck for long-document summarization is the encoder self-attention.': 'The authors focus on the encoder-decoder attention and propose a modified decoder architecture that can dynamically select salient input sentences to constrain the encoder-decoder attention without having to compute complete attention at inference time.', 'The computation cost of encoder-decoder attention can be high.': 'The authors study the sparsity of the encoder-decoder attention in a common transformer-based abstractive summarization model and propose an approximation method to exploit this sparsity. They also provide an empirical upper bound performance for their proposed method.'}",supervised,"['News', 'Podcast Transcripts', 'Scholarly Documents']",['efficient-encoding-of-long-documents']
SP:cfcf49e980d982eb3900b2d4fe7b8c1d107c4b36,Controllable Summarization with Constrained Markov Decision Process,TACL,2021,"['Hou Pong Chan', 'Lu Wang', 'Irwin King']","We study controllable text summarization, which allows users to gain control on a particular attribute (e.g., length limit) of the generated summaries. In this work, we propose a novel training framework based on Constrained Markov Decision Process (CMDP), which conveniently includes a reward function along with a set of constraints, to facilitate better summarization control. The reward function encourages the generation to resemble the human-written reference, while the constraints are used to explicitly prevent the generated summaries from violating user-imposed requirements. Our framework can be applied to control important attributes of summarization, including length, covered entities, and abstractiveness, as we devise specific constraints for each of these aspects. Extensive experiments on popular benchmarks show that our CMDP framework helps generate informative summaries while complying with a given attribute’s requirement.1","The paper discusses controllable text summarization, which allows users to control specific attributes of generated summaries. The authors propose a new training framework based on Constrained Markov Decision Process (CMDP) that includes a reward function and constraints to improve summarization control. The reward function encourages summaries to resemble human-written references, while the constraints prevent generated summaries from violating user-imposed requirements. The framework can be used to control important attributes of summarization, such as length, covered entities, and abstractiveness. Experiments show that the CMDP framework helps generate informative summaries while complying with specific attribute requirements.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to condense the information of an input document into a concise summary.', 'Who is the target audience?': 'The summaries can be used by various users, such as online advertisers, teachers, and information retrieval systems.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as fitting product descriptions within a word limit, demonstrating the technique of paraphrasing important information, and generating summaries covering the entities that users are interested in.'}","['method', 'metric']","['Controlled Generation', 'Objective Function']","['CNN/DailyMail', 'Newsroom']","['ROUGE', 'METEOR']","['Fluency', 'Faithfulness', 'Entity Relevance']",https://github.com/kenchan0226/control-sum-cmdp,https://doi.org/10.1162/tacl_a_00423,"{'Neural abstractive summarization models do not allow users to control different aspects of the generated summaries.': 'The authors propose a controllable text summarization model that allows users to control specific attributes of the generated summaries.', 'The maximum likelihood training objective of the token-based controllable summarization model (ControlSum) does not provide explicit supervision signals that prevent the model from violating the specified attribute requirement.': 'The authors propose a constrained Markov Decision Process (CMDP) framework that imposes constraints to disallow the summaries from violating a specified attribute requirement.', 'Selecting appropriate weights for different reward functions in reinforcement learning (RL) with Markov Decision Process (MDP) is a delicate task and requires intensive hyperparameter tuning.': 'The authors argue that applying constraints on the training objective is a more convenient way to control an attribute of a summary, since it avoids tuning reward function weights.', 'The authors want to control important summary attributes including length, covered entities, and abstractiveness.': 'The authors create specific constraints for each attribute. For length control, they divide summary length into disjoint length bins and restrict the summary length according to the desired length bin. For entity control, they design constraints that guide the generated summary to cover the salient information of user-specified entities. To control abstractiveness, they define bins corresponding to three abstractiveness levels, and design constraints that allow users to control the summary’s abstractiveness.', 'The authors want to evaluate the effectiveness of their CMDP training framework with different types of attribute requirements.': 'The authors conduct extensive experiments on popular benchmarks, using their CMDP framework to fine-tune controllable summarization models based on different architectures.', 'The authors want to confirm that their framework produces informative summaries that conform to the attribute requirement.': 'The authors conduct human evaluations to confirm that their framework produces informative summaries that conform to the attribute requirement.'}",reinforced,['News'],[]
SP:f04e07239f57a82f5ae5dba4d6b2efbfb648305c,StructSum: Summarization via Structured Representations,EACL,2021,"['Vidhisha Balachandran', 'Artidoro Pagnoni', 'Jay Yoon Lee', 'Dheeraj Rajagopal', 'Jaime Carbonell', 'Yulia Tsvetkov']","Abstractive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoderdecoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.1ive text summarization aims at compressing the information of a long source document into a rephrased, condensed summary. Despite advances in modeling techniques, abstractive summarization models still suffer from several key challenges: (i) layout bias: they overfit to the style of training corpora; (ii) limited abstractiveness: they are optimized to copying n-grams from the source rather than generating novel abstractive summaries; (iii) lack of transparency: they are not interpretable. In this work, we propose a framework based on document-level structure induction for summarization to address these challenges. To this end, we propose incorporating latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. Our framework complements standard encoderdecoder summarization models by augmenting them with rich structure-aware document representations based on implicitly learned (latent) structures and externally-derived linguistic (explicit) structures. We show that our summarization framework, trained on the CNN/DM dataset, improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines.1","The paper discusses the challenges faced by abstractive text summarization models, including layout bias, limited abstractiveness, and lack of transparency. The authors propose a framework based on document-level structure induction for summarization that incorporates latent and explicit dependencies across sentences in the source document into end-to-end single-document summarization models. The framework improves the coverage of content in the source documents, generates more abstractive summaries by generating more novel n-grams, and incorporates interpretable sentence-level structures, while performing on par with standard baselines. The framework was trained on the CNN/DM dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to identify important information in long source documents and express it in human-readable summaries.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document without reading the entire thing.', 'How will the summaries be used?': 'The summaries can be used to save time and improve efficiency in tasks such as research, news reporting, and decision-making.'}",['method'],"['Unit Relationship', 'Input Encoding']",['CNN/DailyMail'],['ROUGE'],[''],https://github.com/vidhishanair/structured_summarizer,https://aclanthology.org/2021.eacl-main.220/,"{'Standard training datasets for abstractive summarization are derived from news articles, causing model outputs to be strongly affected by the layout bias of the articles, with models relying on the leading sentences of source documents.': 'The authors introduce StructSum, a framework that incorporates structured document representations into summarization models. StructSum complements a standard encoder-decoder architecture with a latent-structure attention module that adapts structured representations for the summarization task.', 'Abstractive summarization systems often copy long sequences from the source, causing their outputs to resemble extractive summaries.': 'The authors incorporate an explicit-structure attention module that incorporates an external linguistic structure (e.g., coreference links) to mitigate the bias of copying large sequences from the source.', 'Current methods do not lend themselves easily to interpretation via intermediate structures, which could be useful for identifying major bottlenecks in summarization models.': 'The authors introduce a latent structure attention module that models the dependencies between sentences in a document using a variant of Kirchhoff’s matrix-tree theorem to produce interpretable sentence dependency structures.'}",supervised,['News'],[]
SP:5a60970e2043675c7f17b3de6781edd0fd883389,Informative and Controllable Opinion Summarization,EACL,2021,"['Reinald Kim Amplayo', 'Mirella Lapata', 'Samuel L. Jackson']","Opinion summarization is the task of automatically generating summaries for a set of reviews about a specific target (e.g., a movie or a product). Since the number of reviews for each target can be prohibitively large, neural network-based methods follow a two-stage approach where an extractive step first pre-selects a subset of salient opinions and an abstractive step creates the summary while conditioning on the extracted subset. However, the extractive model leads to loss of information which may be useful depending on user needs. In this paper we propose a summarization framework that eliminates the need to rely only on pre-selected content and waste possibly useful information, especially when customizing summaries. The framework enables the use of all input reviews by first condensing them into multiple dense vectors which serve as input to an abstractive model. We showcase an effective instantiation of our framework which produces more informative summaries and also allows to take user preferences into account using our zero-shot customization technique. Experimental results demonstrate that our model improves the state of the art on the Rotten Tomatoes dataset and generates customized summaries effectively.",The paper proposes a new approach to opinion summarization that eliminates the need for pre-selected content and allows for the use of all input reviews. The approach involves condensing the reviews into multiple dense vectors which are then used as input to an abstractive model. The framework also includes a zero-shot customization technique that takes user preferences into account. Experimental results show that the proposed model outperforms existing methods on the Rotten Tomatoes dataset and generates more informative and customized summaries.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to enable customers and companies to make informed decisions without having to absorb large amounts of opinionated text.', 'Who is the target audience?': 'The summaries are for customers and companies who want to make informed decisions about a specific target, such as a movie.', 'How will the summaries be used?': 'The summaries will be used to provide a condensed and informative overview of the opinions expressed in online reviews, blogs, and social media about a specific target. They can be used to make informed decisions about whether to purchase or engage with the target.'}",['method'],"['Input Encoding', 'Controlled Generation']",['RottenTomatoes'],"['ROUGE', 'BERTScore', 'Relation Triplet Overlap', 'QAGS', 'QuestEval']","['Informativeness', 'Correctness', 'Grammaticality']",https://github.com/rktamplayo/CondaSum,https://aclanthology.org/2021.eacl-main.229,"{'The proliferation of opinions expressed in online reviews, blogs, and social media has created a pressing need for automated systems which enable customers and companies to make informed decisions without having to absorb large amounts of opinionated text.': 'Opinion summarization is the task of automatically generating summaries for a set of opinions about a specific target. The authors propose a two-stage framework called CONDENSEABSTRACT (CA) which enables the use of all input reviews when generating the summary.', 'Previous work views opinion summarization as the final stage of a three-step process involving aspect extraction, sentiment prediction, and summary generation. Textual summaries are created following mostly extractive methods which select representative segments from the source text.': 'The authors propose an abstractive approach which attempts to generate summaries which are maximally informative and minimally redundant without simply rearranging passages from the original opinions.', 'The number of input reviews for each target entity tends to be very large, making it practically unfeasible to train a model in an end-to-end fashion.': 'The authors propose a two-stage framework called CONDENSEABSTRACT (CA) which uses a CONDENSE model to represent the input reviews as encodings and a ABSTRACT model to fuse these condensed representations into one aggregate encoding and generate an opinion summary from it.', 'Current approaches sacrifice end-to-end elegance in favor of a two-stage framework which selects a subset of opinions and generates the summary while conditioning on the extracted subset.': 'The authors propose a two-stage framework called CONDENSEABSTRACT (CA) which enables the use of all input reviews when generating the summary, avoiding the drawbacks of the extractive pass.', 'User preferences cannot be easily taken into account since more specialized information might have been removed during the extractive pass.': 'The authors introduce a zero-shot customization technique allowing users to control important aspects of the generated summary at test time, enabling controllable generation while leveraging the full spectrum of opinions available for a specific target.'}",supervised,['Opinions'],"['information-loss-and-incoherence-in-extractive-summarization', 'pretraining-and-sample-efficiency']"
SP:86e75a490e0a66d97d196633009f35a82bd09da7,Annotating and Modeling Fine-grained Factuality in Summarization,NAACL,2021,"['Tanya Goyal', 'Greg Durrett']","Recent pre-trained abstractive summarization systems have started to achieve credible performance, but a major barrier to their use in practice is their propensity to output summaries that are not faithful to the input and that contain factual errors. While a number of annotated datasets and statistical models for assessing factuality have been explored, there is no clear picture of what errors are most important to target or where current techniques are succeeding and failing. We explore both synthetic and human-labeled data sources for training models to identify factual errors in summarization, and study factuality at the word-, dependency-, and sentence-level. Our observations are threefold. First, exhibited factual errors differ significantly across datasets, and commonly-used training sets of simple synthetic errors do not reflect errors made on abstractive datasets like XSUM. Second, human-labeled data with fine-grained annotations provides a more effective training signal than sentence-level annotations or synthetic data. Finally, we show that our best factuality detection model enables training of more factual XSUM summarization models by allowing us to identify non-factual tokens in the training data.1",The paper discusses the issue of factual errors in abstractive summarization systems and explores different data sources for training models to identify these errors. The authors found that factual errors differ significantly across datasets and that human-labeled data with fine-grained annotations is more effective for training models than synthetic data or sentence-level annotations. They also show that their best factuality detection model enables training of more factual summarization models by identifying non-factual tokens in the training data.,"{'What is the purpose of the summaries?': 'The authors are investigating the factuality of current text generation and summarization models, specifically looking at errors in generated summaries.', 'Who is the target audience?': 'The generated summaries are for evaluation purposes, to determine the accuracy and factuality of the models.', 'How will the summaries be used?': 'The generated summaries will be used to compare different approaches for modeling and learning factuality, and to develop a modified training objective for summarizers that leverages information about error spans in gold summaries to improve factual accuracy.'}",['analysis'],"['External Knowledge', 'Data Augmentation']","['CNN/DailyMail', 'XSum']",['ROUGE'],['Factuality'],https://github.com/tagoyal/factuality-datasets,https://aclanthology.org/2021.naacl-main.114,"{'Synthetic data generation approaches for factuality evaluation do not align with actual errors made by generation models.': 'The authors propose that techniques using surface-level data corruption or paraphrasing target inherently different error distributions than those seen in actual model generations. They show that factuality models trained on these datasets perform poorly in practice. Furthermore, they suggest that different summarization domains exhibit substantially different error distributions in generated summaries, and the same dataset creation approach cannot be used across the board.', 'The best approach for modeling and learning factuality, particularly for highly abstractive summarization settings, is unclear.': 'The authors compare the utility of fine-grained human annotations with sentence-level factuality annotations. They use a prior factuality detection model capable of leveraging such fine-grained annotations and show that these allow us to more reliably detect errors as well as localize those errors within generated texts. They suggest that fine-grained human annotations are almost essential for any of their techniques to work well with high-performing summarizers in the challenging XSUM setting.', 'Noisy training data for summarization can lead to errors in generated summaries.': 'The authors propose a modified training objective that leverages information about error spans in gold summaries, derived from factuality models, to train the summarizer. They demonstrate that models trained using this approach are inherently more factual than standard training objectives when dealing with error-prone gold datasets. They suggest that this approach can be used to improve the factuality of generated summaries.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:9fe4846e35945fe698d993baea27fc728bc98a69,Sequence Level Contrastive Learning for Text Summarization,AAAI,2022,"['Shusheng Xu', 'Xingxing Zhang', 'Yi Wu', 'Furu Wei']","Contrastive learning models have achieved great success in unsupervised visual representation learning, which maximize the similarities between feature representations of different views of the same image, while minimize the similarities between feature representations of views of different images. In text summarization, the output summary is a shorter form of the input document and they have similar meanings. In this paper, we propose a contrastive learning model for supervised abstractive text summarization, where we view a document, its gold summary and its model generated summaries as different views of the same mean representation and maximize the similarities between them during training. We improve over a strong sequence-to-sequence text generation model (i.e., BART) on three different summarization datasets. Human evaluation also shows that our model achieves better faithfulness ratings compared to its counterpart without contrastive objectives. We release our code at https://github.com/xssstory/SeqCo.","The paper proposes a contrastive learning model for supervised abstractive text summarization, which maximizes the similarities between different views of the same mean representation during training. The model outperforms a strong sequence-to-sequence text generation model on three different summarization datasets and achieves better faithfulness ratings in human evaluation. The code is available at https://github.com/xssstory/SeqCo.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to rewrite a long document into a shorter form while still preserving its important content.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the important content of a long document.', 'How will the summaries be used?': 'The summaries will be used to provide a more efficient reading experience and to convey the same meaning as the original document.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'NYT', 'XSum']",['ROUGE'],['Faithfulness'],https://github.com/xssstory/SeqCo,https://ojs.aaai.org/index.php/AAAI/article/view/21409,"{'The training paradigm for abstractive models is still based on minimizing the negative log-likelihood (NLL) between the model predicted word distributions and the gold summary, which does not explicitly model the fact that a document and its summary should convey the same meaning.': 'The authors propose SeqCo (Sequence Level Contrastive Learning), which is based on contrastive learning. They view a document, its gold summary, and its model-generated summaries as different views of the same meaning representation and maximize the similarities between them. The contrastive objective in SeqCo tries to map representations of a document and its summary (or generated summary) to the same vector space, which helps the generation of summaries. During training, the contrastive objective encourages the model to encode important information from the document, which helps to generate better summaries.', 'Extractive summarization methods generate long and redundant summaries, which bring a bad reading experience.': 'The authors focus on abstractive summarization, which is usually modeled as a sequence-to-sequence (Seq2Seq) learning problem. Abstractive models have been more powerful due to the recent introduction of large pre-trained Transformers.', 'A document may contain distinct or unnecessary information from its summary, which can affect the quality of the generated summary.': 'The contrastive objective in SeqCo encourages the model to encode important and necessary information from the document, which helps to generate better summaries. In addition to the gold summaries, the authors also use dynamically generated summaries from their model during training to increase the diversity of inputs to SeqCo.', 'The authors want to evaluate the effectiveness of their proposed SeqCo model.': 'The authors conduct experiments and find that SeqCo consistently improves upon a strong abstractive summarization model based on BART across three different summarization datasets. Human evaluation also shows that SeqCo achieves better faithfulness ratings compared to its counterpart without contrastive objectives.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:b1fbee26d6497808a996683d9dadc8e4c97fc3ec,Jointly Learning Guidance Induction and Faithful Summary Generation via Conditional Variational Autoencoders,NAACL,2022,"['Wang Xu', 'Tiejun Zhao']","Abstractive summarization can generate high quality results with the development of the neural network. However, generating factual consistency summaries is a challenging task for abstractive summarization. Recent studies extract the additional information with off-the-shelf tools from the source document as a clue to guide the summary generation, which shows effectiveness to improve the faithfulness. Unlike these work, we present a novel framework based on conditional variational autoencoders, which induces the guidance information and generates the summary equipped with the guidance synchronously. Experiments on XSUM and CNNDM dataset show that our approach can generate relevant and fluent summaries which is more faithful than the existing state-of-theart approaches, according to multiple factual consistency metrics.ive summarization can generate high quality results with the development of the neural network. However, generating factual consistency summaries is a challenging task for abstractive summarization. Recent studies extract the additional information with off-the-shelf tools from the source document as a clue to guide the summary generation, which shows effectiveness to improve the faithfulness. Unlike these work, we present a novel framework based on conditional variational autoencoders, which induces the guidance information and generates the summary equipped with the guidance synchronously. Experiments on XSUM and CNNDM dataset show that our approach can generate relevant and fluent summaries which is more faithful than the existing state-of-theart approaches, according to multiple factual consistency metrics.","The paper discusses the challenges of generating factual consistency summaries through abstractive summarization and proposes a novel framework based on conditional variational autoencoders to induce guidance information and generate summaries equipped with guidance synchronously. The approach is shown to generate relevant and fluent summaries that are more faithful than existing state-of-the-art approaches according to multiple factual consistency metrics, as demonstrated through experiments on XSUM and CNNDM datasets.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to produce a shorter version of the document while preserving salient information, which helps people out of the information explosion.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and to help people make informed decisions based on the key information presented in the summary.'}",['method'],"['Input Encoding', 'Controlled Generation']","['CNN/DailyMail', 'XSum']",['ROUGE'],[''],,https://aclanthology.org/2022.findings-naacl.180,"{'Abstractive summarization often generates summaries that distort or fabricate the facts of the source document, which limits the usage of summarization systems.': 'Recent studies provide different guidance information as input to enhance the factual consistency of the summary. The authors propose a novel framework called Guidance Induction and Summary Generation (GISG) that trains guidance induction and summary generation jointly via conditional variational autoencoder.', 'Separate two-stage processing models that extract guidance information using external tools are limited by domain mismatch and inaccurate guidance extraction, leading to unfaithful summaries.': 'The GISG framework avoids domain mismatch by using phrases as the information granularity of guidance and inducing keyphrases of the source document that appear in the summary semantically. The authors extract all phrases from the source document by part-of-speech tagger as candidates and use latent variables to indicate the keyphrases. They then learn to induce the latent variables and generate the summary jointly, refining the guidance extraction during training.', 'Most models produce summaries with factual errors in the XSUM dataset.': 'The GISG framework generates relevant and fluent summaries that are more faithful to the source document than existing state-of-the-art approaches, according to multiple factual consistency metrics, as demonstrated in experiments on the XSUM and CNNDM datasets.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'pretraining-and-sample-efficiency']"
SP:e16d231c9eed75a9ed676400d11c3c93f9f4519a,Efficient Few-Shot Fine-Tuning for Opinion Summarization,NAACL,2022,"['Arthur Bražinskas', 'Ramesh Nallapati', 'Mohit Bansal', 'Markus Dreyer']","Abstractive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of customer reviews and, after fine-tuning, yield summaries with disfluencies and semantic mistakes. To address these problems, we utilize an efficient few-shot method based on adapters which, as we show, can easily store in-domain knowledge. Instead of fine-tuning the entire model, we add adapters and pretrain them in a task-specific way on a large corpus of unannotated customer reviews, using held-out reviews as pseudo summaries. Then, fine-tune the adapters on the small available human-annotated dataset. We show that this self-supervised adapter pre-training improves summary quality over standard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp datasets, respectively. Finally, for summary personalization, we condition on aspect keyword queries, automatically created from generic datasets. In the same vein, we pre-train the adapters in a query-based manner on customer reviews and then fine-tune them on annotated datasets. This results in better-organized summary content reflected in improved coherence and fewer redundancies.ive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of customer reviews and, after fine-tuning, yield summaries with disfluencies and semantic mistakes. To address these problems, we utilize an efficient few-shot method based on adapters which, as we show, can easily store in-domain knowledge. Instead of fine-tuning the entire model, we add adapters and pretrain them in a task-specific way on a large corpus of unannotated customer reviews, using held-out reviews as pseudo summaries. Then, fine-tune the adapters on the small available human-annotated dataset. We show that this self-supervised adapter pre-training improves summary quality over standard fine-tuning by 2.0 and 1.3 ROUGE-L points on the Amazon and Yelp datasets, respectively. Finally, for summary personalization, we condition on aspect keyword queries, automatically created from generic datasets. In the same vein, we pre-train the adapters in a query-based manner on customer reviews and then fine-tune them on annotated datasets. This results in better-organized summary content reflected in improved coherence and fewer redundancies.","The paper discusses the challenges of abstractive summarization in opinion summarization due to the lack of large annotated datasets of reviews paired with reference summaries. To address this, the authors propose a few-shot method based on adapters that can easily store in-domain knowledge. Instead of fine-tuning the entire model, adapters are added and pre-trained in a task-specific way on a large corpus of unannotated customer reviews, using held-out reviews as pseudo summaries. The adapters are then fine-tuned on the small available human-annotated dataset. The authors show that this self-supervised adapter pre-training improves summary quality over standard fine-tuning. Additionally, for summary personalization, the authors condition on aspect keyword queries, automatically created from generic datasets. This results in better-organized summary content reflected in improved coherence and fewer redundancies.","{'What is the purpose of the summaries?': 'The authors are generating summaries of customer reviews to inform potential buyers about customer experiences and whether a product or service is worth buying.', 'Who is the target audience?': 'The summaries are for potential buyers who want to make informed purchasing decisions based on customer experiences.', 'How will the summaries be used?': 'The summaries will be used to help potential buyers quickly understand what aspects of a product or service customers like and dislike, and ultimately decide whether to make a purchase.'}",['method'],"['Input Encoding', 'External Knowledge']","['Amazon Product Reviews', 'Yelp Reviews']","['ROUGE', 'METEOR']","['Coherence', 'Non-redundancy']",https://github.com/amazon-research/adasum,https://aclanthology.org/2022.findings-naacl.113,"{'The lack of sufficiently large annotated datasets makes it challenging to train supervised summarization models for review or opinion summarization.': 'The authors propose an unsupervised abstractive model called ADASUM that is based on adapters and pre-trained on customer reviews in a task-specific manner, and subsequently fine-tuned on gold summaries.', 'Language models pre-trained with generic objectives are less attuned to in-domain specifics, resulting in subtle semantic mistakes in generated summaries.': 'The authors propose a self-supervised pre-training method called leave-one-out prediction, where for any given product without a human-written summary, they predict one of the given reviews by conditioning on N other reviews with the highest lexical overlap. This method reduces semantic mistakes by learning in-domain specifics from customer reviews.', 'The lack of annotated data makes it challenging to learn a desired content structure for summaries.': 'The authors propose a query-based approach called ADAQSUM that capitalizes on text planning by providing an intermediate summary representation in the form of a query consisting of aspect keywords. This approach results in more coherent text patterns with fewer redundancies and can be useful for personalized summaries.'}",supervised,['Reviews'],['lack-of-suitable-training-data']
SP:3d32773c6061bfc929504854174e571f57ca0e5a,Towards Summarizing Healthcare Questions in Low-Resource Setting,COLING,2022,"['Shweta Yadav', 'Cornelia Caragea']","The current advancement in abstractive document summarization depends to a large extent on a considerable amount of human-annotated datasets. However, the creation of large-scale datasets is often not feasible in closed domains, such as medical and healthcare domains, where human annotation requires domain expertise. This paper presents a novel data selection strategy to generate diverse and semantic questions in a low-resource setting with the aim to summarize healthcare questions. Our method exploits the concept of guided semantic-overlap and diversity-based objective functions to optimally select the informative and diverse set of synthetic samples for data augmentation. Our extensive experiments on benchmark healthcare question summarization datasets demonstrate the effectiveness of our proposed data selection strategy by achieving new state-ofthe-art results. Our human evaluation shows that our method generates diverse, fluent, and informative summarized questions.","The paper discusses the challenges of creating large-scale datasets for abstractive document summarization in closed domains like healthcare, where human annotation requires domain expertise. The authors propose a data selection strategy that uses guided semantic-overlap and diversity-based objective functions to generate diverse and semantic questions in a low-resource setting. Their experiments on benchmark healthcare question summarization datasets show that their method achieves new state-of-the-art results and generates diverse, fluent, and informative summarized questions.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to assist consumers in their healthcare information search by summarizing their questions.', 'Who is the target audience?': 'The summaries are for consumers who seek health-related information on the internet.', 'How will the summaries be used?': 'The summaries will be used to improve the performance of the consumer health question summarization system and to provide informative and fluent summaries to consumers.'}",['method'],['Objective Function'],['MEQSUM'],['ROUGE'],"['Diversity', 'Informativeness', 'Factuality', 'Fluency']",https://github.com/abachaa/MedQuAD,https://aclanthology.org/2022.coling-1.255,"{""Consumers' health-related questions are often overly descriptive and include peripheral information, making it challenging to understand and summarize them automatically."": 'The authors propose a data selection strategy for abstractive consumer health question (CHQ) summarization task, using round-trip translation (RTT) as a data augmentation method. They devise multiple optimal data selection strategies, including Frechét Question Distance (FQD), Precision Recall Question Distance (PRQD), and Question Semantic Volume (QSV), to select diverse and informative questions. These strategies ensure that the selected additional data brings diversity to the whole training dataset and leads to significant performance improvement of the CHQ summarization system.', 'The majority of traditional data selection methods for summarization are based on word replacement, which falls short of generating a diversified sentence.': 'The authors propose a novel data selection strategy for abstractive summarization, particularly for CHQ summarization, using RTT as a data augmentation method. They enhance the capability of RTT by devising multiple optimal data selection strategies to select diverse and informative questions, which leads to significant performance improvement of the CHQ summarization system.', 'Some domains, such as biomedical and medical, require domain experts to create high-quality training datasets, which is tedious to create at a large-scale level.': 'The authors propose augmenting the large-scale synthetically generated samples with a human-annotated training set, which has shown effectiveness in other generation and translation tasks. They use RTT as a data augmentation method and devise multiple optimal data selection strategies to select diverse and informative questions, which leads to significant performance improvement of the CHQ summarization system.', 'The recent development in large-scale neural language models has led to significant performance on several abstractive summarization tasks, but their accuracy is partially due to the availability of large-scale human-annotated training data.': 'The authors propose a data selection strategy for abstractive summarization, particularly for CHQ summarization, using RTT as a data augmentation method. They enhance the capability of RTT by devising multiple optimal data selection strategies to select diverse and informative questions, which leads to significant performance improvement of the CHQ summarization system.'}",supervised,['CQA'],['lack-of-suitable-training-data']
SP:318a37a954f35014e1d13ad371be90f40c275be7,APRIL: Interactively Learning to Summarise by Combining Active Preference Learning and Reinforcement Learning,EMNLP,2018,"['Yang Gao', 'Christian M. Meyer', 'Iryna Gurevych']","We propose a method to perform automatic document summarisation without using reference summaries. Instead, our method interactively learns from users’ preferences. The merit of preference-based interactive summarisation is that preferences are easier for users to provide than reference summaries. Existing preference-based interactive learning methods suffer from high sample complexity, i.e. they need to interact with the oracle for many rounds in order to converge. In this work, we propose a new objective function, which enables us to leverage active learning, preference learning and reinforcement learning techniques in order to reduce the sample complexity. Both simulation and real-user experiments suggest that our method significantly advances the state of the art. Our source code is freely available at https://github.com/UKPLab/ emnlp2018-april.","The paper proposes a method for automatic document summarization that learns from users' preferences instead of using reference summaries. The method reduces sample complexity by leveraging active learning, preference learning, and reinforcement learning techniques through a new objective function. The authors conducted both simulation and real-user experiments, which showed that their method significantly advances the state of the art. The source code is available for free on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents due to the rapid growth of text-based information on the Internet, which attracts increasing research attention from the Natural Language Processing (NLP) community.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any specific group, but they are likely to be useful for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they could potentially be used for various purposes such as information retrieval, document clustering, or summarization evaluation.'}",['method'],['Objective Function'],"['DUC 2001', 'DUC 2002', 'DUC 2004']","['ROUGE', 'Perplexity', 'Copy Ratio', 'New Named Entities']",['Overall Quality'],https://github.com/UKPLab/emnlp2018-april,https://aclanthology.org/D18-1445/,"{'Existing document summarisation techniques require access to expensive reference summaries to train their systems.': 'The authors propose using the Structured Prediction from Partial Information (SPPI) framework, which can learn to make structured predictions without access to gold standard data.', 'SPPI has prohibitively high sample complexities in NLP tasks, even with simulated ""perfect"" users.': 'The authors propose a novel preference-based interactive learning framework called APRIL (Active Preference ReInforcement Learning), which divides the preference-based interactive learning problem into two phases (Active Preference Learning and Reinforcement Learning) to reduce sample complexity.', 'The gap between heuristics-based methods and the upper bound for document summarisation is still large.': 'The authors apply APRIL to Extractive Multi-Document Summarisation (EMDS) and compare its performance to a state-of-the-art SPPI implementation using both automatic metrics and human evaluation. Their results suggest that APRIL significantly outperforms SPPI.'}",reinforced,['News'],['pretraining-and-sample-efficiency']
SP:efbca8e4424c796b59a494fe8adff12665291971,Closed-Book Training to Improve Summarization Encoder Memory,EMNLP,2018,"['Yichen Jiang', 'Mohit Bansal']","A good neural sequence-to-sequence summarization model should have a strong encoder that can distill and memorize the important information from long input texts so that the decoder can generate salient summaries based on the encoder’s memory. In this paper, we aim to improve the memorization capabilities of the encoder of a pointer-generator model by adding an additional ‘closed-book’ decoder without attention and pointer mechanisms. Such a decoder forces the encoder to be more selective in the information encoded in its memory state because the decoder can’t rely on the extra information provided by the attention and possibly copy modules, and hence improves the entire model. On the CNN/Daily Mail dataset, our 2-decoder model outperforms the baseline significantly in terms of ROUGE and METEOR metrics, for both cross-entropy and reinforced setups (and on human evaluation). Moreover, our model also achieves higher scores in a test-only DUC-2002 generalizability setup. We further present a memory ability test, two saliency metrics, as well as several sanity-check ablations (based on fixed-encoder, gradient-flow cut, and model capacity) to prove that the encoder of our 2-decoder model does in fact learn stronger memory representations than the baseline encoder.","The paper discusses the importance of a strong encoder in neural sequence-to-sequence summarization models and proposes a method to improve the encoder's memorization capabilities by adding an additional 'closed-book' decoder without attention and pointer mechanisms. This forces the encoder to be more selective in the information it encodes in its memory state, leading to improved performance on the CNN/Daily Mail dataset in terms of ROUGE and METEOR metrics, as well as human evaluation. The paper also presents several tests and ablations to demonstrate the effectiveness of the proposed method.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense long passages into shorter versions that cover the most salient information from the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly get an overview of the main ideas and information contained in the text.'}",['method'],"['Input Encoding', 'Objective Function']","['CNN/DailyMail', 'DUC 2002']",['ROUGE'],['Overall Quality'],,https://aclanthology.org/D18-1440,"{'Summarization models struggle to find the most salient information in the source text when generating summaries.': 'The authors propose a novel 2-decoder architecture by adding another ‘closed book’ decoder without attention layer to a popular pointer-generator baseline, such that the ‘closed book’ decoder and pointer decoder share an encoder. This additional ‘closed book’ decoder encourages the encoder to be better at memorizing salient information from the source passage, and hence strengthen the entire model.', 'During the training of a seq-attention-seq model, most gradients are back-propagated from the decoder to the encoder’s hidden states through the attention layer. This encourages the encoder to correctly encode salient words at the corresponding encoding steps, but does make sure that this information is not forgotten (overwritten in the memory state) by the encoder afterward.': 'For a plain LSTM (closed-book) decoder without attention, its generated gradient flow is back-propagated to the encoder through the memory state, which is the only connection between itself and the encoder, and this, therefore, encourages the encoder to encode only the salient, important information in its memory state. Hence, to achieve this desired effect, the authors jointly train the two decoders, which share one encoder, by optimizing the weighted sum of their losses.', 'Summaries generated by existing models may not be salient enough.': ""The authors show that their 2-decoder model's enhanced ability to memorize and recover important information from the input document leads to summaries that are qualitatively better than baseline summaries. They achieve this by evaluating the representation power of the encoder’s final memory state after reading long passages via a cosine-similarity test and conducting three sets of ablation studies based on fixedencoder, gradient-flow cut, and model capacity.""}",reinforced,['News'],"['efficient-encoding-of-long-documents', 'identifying-important-contents-from-the-document']"
SP:55e6cb88967d3ef3debf05b1ac155486f9be054f,Generating topic-oriented summaries using neural attention,NAACL,2018,"['Kundan Krishna', 'Balaji Vasan Srinivasan']","Summarizing a document requires identifying the important parts of the document with an objective of providing a quick overview to a reader. However, a long article can span several topics and a single summary cannot do justice to all the topics. Further, the interests of readers can vary and the notion of importance can change across them. Existing summarization algorithms generate a single summary and are not capable of generating multiple summaries tuned to the interests of the readers. In this paper, we propose an attention based RNN framework to generate multiple summaries of a single document tuned to different topics of interest. Our method outperforms existing baselines and our results suggest that the attention of generative networks can be successfully biased to look at sentences relevant to a topic and effectively used to generate topic-tuned summaries.",System: The paper proposes an attention-based RNN framework to generate multiple summaries of a single document that are tuned to different topics of interest. Existing summarization algorithms generate a single summary and cannot generate multiple summaries that are tailored to the interests of different readers. The proposed method outperforms existing baselines and suggests that generative networks can be successfully biased to look at sentences relevant to a topic and generate topic-tuned summaries.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a concise representation of the content of a larger document or a collection of documents.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to enable better consumption of longer articles and to provide readers with topic-tuned summaries that align with their interests.'}",['method'],['Controlled Generation'],['CNN/DailyMail'],['ROUGE'],['Topic Relevance'],,https://aclanthology.org/N18-1153,"{'Extractive methods for summarization are limited by their inability to paraphrase the content of the article using new sentences, which results in summaries that are very different from those created by humans.': 'Recent works on summarization have come up with sequence-to-sequence models for generating summaries in a word-by-word fashion, thus ‘generating’ new sentences.', 'As articles get longer, a single summary is often insufficient to satisfy the interests of the reader.': 'To produce summaries that are aligned to the topical interests of the reader, the authors propose a neural encoder-decoder based framework which takes an article along with a topic of interest as input and generates a summary tuned to the target topic of interest.', 'For RNN-based frameworks, tuned summary generation is non-obvious due to the absence of explicit content based features.': 'The authors train a neural framework to pay higher attention to parts of the input articles relevant to given topic, thus extending the advantages of abstractive summarization and generating topic-tuned summaries.', 'Lack of dataset containing articles with multiple topic-oriented summaries.': 'The authors use a novel approach to artificially create a topic-centric training corpus from the CNN/Dailymail dataset for training their model.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:51f8eb55afef83db021662c2bfcc9ac23061a4b7,"Retrieve, Rerank and Rewrite: Soft Template Based Neural Summarization",ACL,2018,"['Ziqiang Cao', 'Wenjie Li', 'Furu Wei', 'Sujian Li']","Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably. Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model. To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates. Then, we extend the seq2seq framework to jointly conduct template Reranking and templateaware summary generation (Rewriting). Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness. In addition, the import of high-quality external summaries improves the stability and readability of generated summaries.",System: The paper proposes a new approach to seq2seq summarization that uses existing summaries as soft templates to guide the model. The authors retrieve proper summaries as candidate templates using an IR platform and extend the seq2seq framework to conduct template reranking and template-aware summary generation. Experiments show that this approach significantly outperforms state-of-the-art methods and even soft templates themselves demonstrate high competitiveness. Importing high-quality external summaries also improves the stability and readability of generated summaries.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the need for effective automatic summarization systems due to the exponentially growing online information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to design or refine appealing headlines, improve the readability and stability of generated summaries, and provide a reference point to guide the input sentence summarization process.'}",['method'],['External Knowledge'],['Gigaword'],"['ROUGE', 'Copy Ratio']",[''],,https://aclanthology.org/P18-1015,"{'Most previous seq2seq models purely depend on the source text to generate summaries, which leads to a deterioration in performance with the increase of the length of generation. Additionally, seq2seq models tend to ""lose control"" and focus on copying source words in order, without any actual summarization.': 'The authors propose to combine the seq2seq and template-based summarization approaches by introducing soft templates as additional input to improve the readability and stability of seq2seq summarization systems. They extend the seq2seq framework to conduct template reranking and template-aware summary generation simultaneously, utilizing a Recurrent Neural Network (RNN) encoder to convert the input sentence and each candidate template into hidden states. In Rerank, they measure the informativeness of a candidate template according to its hidden state relevance to the input sentence, and in Rewrite, the summary is generated according to the hidden states of both the sentence and template.', 'Template-based summarization is a traditional approach that requires manually defined rules and a lot of domain knowledge, making it extremely time-consuming and impossible to develop all templates for summaries in various domains.': 'The authors propose to use existing summaries of similar sentences as soft templates, which do not require any actual rules to build new summaries from them. They utilize a widely-used Information Retrieval (IR) platform to find out candidate soft templates from the training corpus, which can guide the input sentence summarization process.', 'The generated summaries lack informativeness and readability, reducing the quality of the summarization system.': 'The authors show that their proposed Re3Sum system significantly outperforms state-of-the-art seq2seq models in terms of informativeness, and even soft templates themselves demonstrate high competitiveness. They also demonstrate that the import of high-quality external summaries improves the stability and readability of generated summaries.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:a9920eab34302be1374ea7299d42f2246813fb1c,Attribute-aware Sequence Network for Review Summarization,EMNLP,2019,"['Junjie Li', 'Xuepeng Wang', 'Dawei Yin', 'Chengqing Zong']","Review summarization aims to generate a condensed summary for a review or multiple reviews. Existing review summarization systems mainly generate summary only based on review content and neglect the authors’ attributes (e.g., gender, age, and occupation). In fact, when summarizing a review, users with different attributes usually pay attention to specific aspects and have their own word-using habits or writing styles. Therefore, we propose an Attribute-aware Sequence Network (ASN) to take the aforementioned users’ characteristics into account, which includes three modules: an attribute encoder encodes the attribute preferences over the words; an attribute-aware review encoder adopts an attribute-based selective mechanism to select the important information of a review; and an attribute-aware summary decoder incorporates attribute embedding and attribute-specific word-using habits into word prediction. To validate our model, we collect a new dataset TripAtt, comprising 495,440 attribute-review-summary triplets with three kinds of attribute information: gender, age, and travel status. Extensive experiments show that ASN achieves state-of-the-art performance on review summarization in both auto-metric ROUGE and human evaluation.","The paper proposes an Attribute-aware Sequence Network (ASN) for review summarization that takes into account users' characteristics such as gender, age, and occupation. The ASN includes three modules: an attribute encoder, an attribute-aware review encoder, and an attribute-aware summary decoder. The authors validate their model using a new dataset called TripAtt, which includes 495,440 attribute-review-summary triplets. The experiments show that ASN achieves state-of-the-art performance on review summarization in both auto-metric ROUGE and human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of reviews to provide a condensed version of the review or multiple reviews.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the content of the reviews without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to make informed decisions about products or services based on the opinions of others. They can also be used for research purposes or to improve the quality of reviews.'}","['corpus', 'method']",['Input Encoding'],['TripAdvisor'],['ROUGE'],[''],https://github.com/Junjieli0704/ASN,https://aclanthology.org/D19-1297,"{'Previous studies on review summarization only focus on review content and neglect the attribute information of users who post these reviews.': 'The authors propose a model called Attribute-aware Sequence Network (ASN) to consider attribute information into review summarization.', 'People with different attributes may care about different aspects when writing reviews.': 'The authors design an attribute encoder to encode attribute preference for using words into attribute embedding.', 'People with different attributes have different word-using habits or writing styles to summarize a review.': 'The authors propose an attribute-aware summary decoder to consider different writing styles of users with different attributes. It incorporates attribute embedding and attribute-specific vocabulary memory into word prediction module to generate summaries.', 'It is hard to generate attribute-specific vocabulary when summarizing a review without considering the attribute information.': 'The authors incorporate attribute-specific vocabulary to further improve the summarization performance.', 'There is a lack of evaluation of review summarization with attribute information.': 'The authors collect a new dataset named TripAtt, which contains 495,440 attribute-review-summary triplets with three kinds of attribute information: gender, age, and travel status, to evaluate their approach.'}",supervised,['Reviews'],['controlled-and-tailored-summarization']
SP:6e57709c57b4af2b4f402d2ef81a7b60fd134900,Pretraining-Based Natural Language Generation for Text Summarization,CONLL,2019,"['Haoyu Zhang', 'Jingjing Cai', 'Jianjun Xu', 'Ji Wang']","In this paper, we propose a novel pretrainingbased encoder-decoder framework, which can generate the output sequence based on the input sequence in a two-stage manner. For the encoder of our model, we encode the input sequence into context representations using BERT. For the decoder, there are two stages in our model, in the first stage, we use a Transformer-based decoder to generate a draft output sequence. In the second stage, we mask each word of the draft sequence and feed it to BERT, then by combining the input sequence and the draft representation generated by BERT, we use a Transformer-based decoder to predict the refined word for each masked position. To the best of our knowledge, our approach is the first method which applies the BERT into text generation tasks. As the first step in this direction, we evaluate our proposed method on the text summarization task. Experimental results show that our model achieves new state-of-the-art on both CNN/Daily Mail and New York Times datasets.","System: The paper proposes a new pretraining-based encoder-decoder framework for generating output sequences from input sequences in two stages. The encoder uses BERT to encode the input sequence into context representations, while the decoder uses a Transformer-based decoder to generate a draft output sequence in the first stage. In the second stage, each word of the draft sequence is masked and fed to BERT, and the input sequence and draft representation generated by BERT are combined to predict the refined word for each masked position using a Transformer-based decoder. This approach is the first to apply BERT to text generation tasks, and the proposed method is evaluated on the text summarization task, achieving new state-of-the-art results on both CNN/Daily Mail and New York Times datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to keep salient information and to apply it to real-world applications.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used in various applications, such as news articles, research papers, and business reports, to provide a quick overview of the content.'}",['method'],['External Knowledge'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/K19-1074,"{'Previous abstractive methods use left-context-only decoder, thus do not have complete context when predicting each word.': 'The authors propose a two-stage decoding process to make good use of BERT’s context modeling ability. On the first stage, they generate the summary using a left-context-only-decoder. On the second stage, they mask each word of the summary and predict the refined word one-by-one using a refine decoder.', 'Previous abstractive methods do not utilize the pre-trained contextualized language models on the decoder side, so it is more difficult for the decoder to learn summary representations, context interactions and language modeling together.': 'The authors propose a natural language generation model based on pre-trained language models (they use BERT in this work). They make good use of the pre-trained language model in the encoder and decoder process, and the model can be trained end-to-end without handcrafted features.', 'Repetition and incoherent problem in abstractive methods.': 'The authors introduce intratemporal attention processes in the encoder and decoder to address the repetition and incoherent problem. They also cooperate reinforcement objective with the refine decoder to further improve the naturalness of the generated sequence.'}",supervised,['News'],[]
SP:67de367cd1f048567736d3fb54037dcf0114ea68,A Unified Dual-view Model for Review Summarization and Sentiment Classification with Inconsistency Loss,SIGIR,2020,"['Hou Pong Chan', 'Hong Kong', 'Wang Chen', 'Irwin King']","Acquiring accurate summarization and sentiment from user reviews is an essential component of modern e-commerce platforms. Review summarization aims at generating a concise summary that describes the key opinions and sentiment of a review, while sentiment classification aims to predict a sentiment label indicating the sentiment attitude of a review. To effectively leverage the shared sentiment information in both review summarization and sentiment classification tasks, we propose a novel dual-view model that jointly improves the performance of these two tasks. In our model, an encoder first learns a context representation for the review, then a summary decoder generates a review summary word by word. After that, a source-view sentiment classifier uses the encoded context representation to predict a sentiment label for the review, while a summary-view sentiment classifier uses the decoder hidden states to predict a sentiment label for the generated summary. During training, we introduce an inconsistency loss to penalize the disagreement between these two classifiers. It helps the decoder to generate a summary to have a consistent sentiment tendency with the review and also helps the two sentiment classifiers learn from each other. Experiment results on four real-world datasets from different domains demonstrate the effectiveness of our model.",The paper proposes a dual-view model that jointly improves review summarization and sentiment classification tasks. The model uses an encoder to learn a context representation for the review and a summary decoder to generate a review summary. Two sentiment classifiers are used to predict sentiment labels for the review and generated summary. An inconsistency loss is introduced during training to penalize disagreement between the two classifiers and help the decoder generate a summary with a consistent sentiment tendency. Experiment results on four real-world datasets demonstrate the effectiveness of the proposed model.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of user reviews to distill salient information and express key opinions and sentiment of the review.', 'Who is the target audience?': 'The summaries are for companies to improve the quality of their services or products by understanding the opinions of their customers.', 'How will the summaries be used?': 'The summaries will be used to guide a summarization model to capture the sentiment attitude of the review and assist a sentiment classification model to predict the sentiment label of a review.'}",['method'],"['Auxiliary Tasks', 'Objective Function']",['Amazon Product Reviews'],"['ROUGE', 'Novel Words']",[''],https://github.com/kenchan0226/dual_view_review_sum,https://doi.org/10.1145/3397271.3401039,"{'Existing methods can only solve either review summarization or sentiment classification problem.': 'The authors propose a dual-view model for joint review summarization and sentiment classification.', 'Existing methods rely on hand-crafted features for joint review summarization and sentiment classification.': 'The authors propose an end-to-end model that learns context representation for the review and utilizes attentional encoder-decoder framework for generating a summary.', 'Existing models do not fully utilize the sentiment information existing in the summary.': 'The authors propose a dual-view model that models sentiment information in the review and summary separately using source-view and summary-view sentiment classifiers.', 'Existing models do not provide enough supervision signals for both review summarization and sentiment classification.': 'The authors introduce an inconsistency loss function to penalize the disagreement between the source-view and summary-view sentiment classifiers, which provides more supervision signals for both tasks.', 'Existing models are affected by the exposure bias issue in the testing stage.': 'The authors use the sentiment label predicted by the source-view classifier as the final classification output during testing.', 'Existing models do not outperform strong baselines on both review summarization and sentiment classification.': 'The authors conduct extensive experiments and show that their dual-view model outperforms strong baselines on both tasks.'}",supervised,['Reviews'],[]
SP:058f5973f31d5a935768438031e2a0e610141988,Document Summarization with VHTM: Variational Hierarchical Topic-Aware Mechanism,AAAI,2020,"['Xiyan Fu', 'Jun Wang', 'Jinghan Zhang', 'Jinmao Wei', 'Zhenglu Yang']","Automatic text summarization focuses on distilling summary information from texts. This research field has been considerably explored over the past decades because of its significant role in many natural language processing tasks; however, two challenging issues block its further development: (1) how to yield a summarization model embedding topic inference rather than extending with a pre-trained one and (2) how to merge the latent topics into diverse granularity levels. In this study, we propose a variational hierarchical model to holistically address both issues, dubbed VHTM. Different from the previous work assisted by a pre-trained singlegrained topic model, VHTM is the first attempt to jointly accomplish summarization with topic inference via variational encoder-decoder and merge topics into multi-grained levels through topic embedding and attention. Comprehensive experiments validate the superior performance of VHTM compared with the baselines, accompanying with semantically","improved summaries. The paper introduces a new approach, VHTM, that combines summarization with topic inference and merges topics into multiple granularity levels. This is in contrast to previous work that relied on pre-trained single-grained topic models. The approach is validated through comprehensive experiments, which demonstrate its superior performance compared to baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to refine integrant information from long texts to a short summary for convenient understanding.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key points of a long document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used for various natural language processing tasks, such as text classification, information retrieval, and question answering. They can also be used to quickly understand the main ideas of a document without having to read the entire text.'}",['method'],"['Input Encoding', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],[''],,https://ojs.aaai.org/index.php/AAAI/article/view/6277,"{'Existing deep learning-based summarization works are assisted by an external topic model, which may not characterize the specified flavor of each article nor satisfy the individual requirement of each task.': 'The authors propose a co-optimization framework that incorporates summarization and topic inference in an end-to-end manner, without resorting to a pre-trained topic model.', 'Pre-trained topics are fetched in the document level, neglecting the non-trivial difference between paragraphs.': 'The authors introduce a hierarchical topic-aware technique that incorporates multi-scale topics, including paragraph-level and document-level ones, to capture local and global semantic and syntactic information of a document.', 'The fusion effect of a deep learning approach coupled with an arbitrary topic model is doubted.': 'The authors argue that their co-optimization framework is an applicable solution to dispense with the intricate selection of appropriate topic models.'}",supervised,['News'],[]
SP:af37c6d0d2a686a9fb4224a67722646dec8a3c01,Learning to summarize from human feedback,NEURIPS,2020,"['Nisan Stiennon', 'Long Ouyang', 'Jeff Wu', 'Daniel M. Ziegler', 'Ryan Lowe', 'Chelsea Voss', 'Alec Radford', 'Dario Amodei', 'Paul Christiano']","As language models become more powerful, training and evaluation are increasingly bottlenecked by the data and metrics used for a particular task. For example, summarization models are often trained to predict human reference summaries and evaluated using ROUGE, but both of these metrics are rough proxies for what we really care about—summary quality. In this work, we show that it is possible to significantly improve summary quality by training a model to optimize for human preferences. We collect a large, high-quality dataset of human comparisons between summaries, train a model to predict the human-preferred summary, and use that model as a reward function to fine-tune a summarization policy using reinforcement learning. We apply our method to a version of the TL;DR dataset of Reddit posts [63] and find that our models significantly outperform both human reference summaries and much larger models fine-tuned with supervised learning alone. Our models also transfer to CNN/DM news articles [22], producing summaries nearly as good as the human reference without any news-specific fine-tuning.2 We conduct extensive analyses to understand our human feedback dataset and fine-tuned models.3 We establish that our reward model generalizes to new datasets, and that optimizing our reward model results in better summaries than optimizing ROUGE according to humans. We hope the evidence from our paper motivates machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.","The paper discusses how language models are limited by the data and metrics used for a particular task, such as summarization models being trained to predict human reference summaries and evaluated using ROUGE. The authors propose training a model to optimize for human preferences, using a large dataset of human comparisons between summaries and reinforcement learning. They apply their method to a version of the TL;DR dataset of Reddit posts and find that their models significantly outperform both human reference summaries and larger models fine-tuned with supervised learning alone. The authors also conduct extensive analyses to understand their human feedback dataset and fine-tuned models and establish that their reward model generalizes to new datasets and results in better summaries than optimizing ROUGE according to humans. The paper aims to motivate machine learning researchers to pay closer attention to how their training loss affects the model behavior they actually want.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to advance methods for training language models on objectives that more closely capture the behavior humans care about.', 'Who is the target audience?': 'The summaries are for natural language processing (NLP) tasks.', 'How will the summaries be used?': 'The summaries will be used to improve the performance of language models on NLP tasks and to align AI systems with what humans want them to do.'}",['method'],"['External Knowledge', 'Objective Function']","['CNN/DailyMail', 'Webis-TLDR-17']",['ROUGE'],['Overall Quality'],https://github.com/openai/summarize-from-feedback,https://arxiv.org/abs/2009.01325,"{'There is a misalignment between the fine-tuning objective of language models and the goal of generating high-quality outputs as determined by humans. The maximum likelihood objective has no distinction between important and unimportant errors, and models are incentivized to place probability mass on all human demonstrations, including low-quality ones. Distributional shift during sampling can also degrade performance.': 'The authors propose optimizing for quality as a principled approach to overcoming these problems. They advance methods for training language models on objectives that more closely capture the behavior humans care about, focusing on abstractive English text summarization. They follow the works of [3, 73], who fine-tune language models from human feedback using reward learning [35].', 'Existing automatic metrics for evaluating summary quality, such as ROUGE, have poor correlation with human judgments.': 'The authors collect a dataset of human preferences between pairs of summaries, then train a reward model (RM) via supervised learning to predict the human-preferred summary. Finally, they train a policy via reinforcement learning (RL) to maximize the score given by the RM. They confirm that their reward model outperforms other metrics such as ROUGE at predicting human preferences, and that optimizing their reward model directly results in better summaries than optimizing ROUGE according to humans.', 'Supervised models do not generalize well to new domains.': 'The authors show that human feedback models generalize much better to new domains than supervised models. Their Reddit-trained human feedback models also generate high-quality summaries of news articles on the CNN/DailyMail (CNN/DM) dataset without any news-specific fine-tuning, almost matching the quality of the dataset’s reference summaries.', 'The misalignment of AI systems with what humans want them to do can become more subtle and safety-critical as AI systems become more powerful and are given increasingly important tasks.': 'The authors present methods for training language models on objectives that more closely capture the behavior humans care about, motivated in part by longer-term concerns about the misalignment of AI systems with what humans want them to do. They publicly release their human feedback dataset for further research.'}",reinforced,"['News', 'Social Media']",['robust-evaluation-methods']
SP:7a8cb8d69d3f9335df00e81a08a168fd96766cac,TLDR: Extreme Summarization of Scientific Documents,EMNLP,2020,"['Isabel Cachola', 'Kyle Lo', 'Arman Cohan', 'Daniel S. Weld']","We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. Data and code are publicly available at https://github.com/allenai/scitldr.","System: The paper introduces TLDR generation, a new extreme summarization technique for scientific papers that involves compressing the source material and requires expert knowledge of the domain-specific language. To facilitate research on this task, the authors introduce SCITLDR, a dataset of 5.4K TLDRs over 3.2K papers that includes both author-written and expert-derived summaries. The authors propose CATTS, a learning strategy that uses titles as an auxiliary training signal to generate TLDRs. CATTS outperforms strong baselines under both automated metrics and human evaluations. The data and code for this research are publicly available at https://github.com/allenai/scitldr.","{'What is the purpose of the summaries?': ""The authors are generating the summaries to provide an alternative to abstracts that focus on the key aspects of the paper, making it easier for readers to quickly discern a paper's key points and decide whether it's worth reading."", 'Who is the target audience?': ""The summaries are for readers who are struggling to keep up with the increasing pace of publication and need a quick way to understand a paper's main contributions without having to read the entire document."", 'How will the summaries be used?': ""The summaries will be used as a tool to help readers quickly identify the key points of a paper and decide whether it's worth reading in full.""}","['corpus', 'method']","['Auxiliary Tasks', 'Input Encoding']",['SCITLDR'],['ROUGE'],"['Informativeness', 'Content Accuracy']",https://github.com/allenai/scitldr,https://aclanthology.org/2020.findings-emnlp.428/,"{'The increasing pace of publication makes it difficult for readers to keep up with the literature.': 'TLDRs can enable readers to quickly discern a paper’s key points and decide whether it’s worth reading.', 'Existing work in summarization of scientific documents focuses on generating abstracts or providing complimentary summaries to abstracts.': 'TLDR generation provides an alternative to abstracts, focusing on the key aspects of the paper and producing an extreme (single sentence) summary given the entire paper.', 'TLDR generation is a challenging natural language generation task that requires expert background knowledge and understanding of complex domain-specific language.': 'CATTS (Controlled Abstraction for TLDRs with Title Scaffolding) is a simple yet effective learning strategy for TLDR generation that incorporates ideas from scaffold tasks for multitask learning and control codes in conditional language generation to address the problem of data scarcity in the highly-specialized scientific domain.', 'Variability in human-written gold summaries makes evaluation of TLDR generation difficult.': 'SCITLDR is a new multi-target dataset of 5,411 TLDRs over 3,229 scientific papers that contains both author-written and expert-derived TLDRs, providing multiple gold summaries per paper for evaluation. Extensive analysis and human evaluation of system-generated TLDRs is performed, focusing on informativeness and factual correctness.'}",supervised,['Scholarly Documents'],['lack-of-suitable-training-data']
SP:05c017d4c1b8c7e73a252aa907ca9d0a59b3afe4,Leveraging Pre-trained Checkpoints for Sequence Generation Tasks,TACL,2020,"['Sascha Rothe', 'Shashi Narayan']","Unsupervised pre-training of large neural modelshas recently revolutionized Natural Language Processing. By warm-starting from the publicly released checkpoints, NLP practitioners have pushed the state-of-the-art on multiple benchmarks while saving significant amounts of compute time. So far the focus has been mainly on the Natural Language Understanding tasks. In this paper, we demonstrate the efficacy of pre-trained checkpoints for Sequence Generation. We developed a Transformer-based sequence-to-sequence model that is compatible with publicly available pre-trained BERT, GPT-2, and RoBERTa checkpoints and conductedan extensiveempirical study on the utility of initializing our model, both encoder and decoder, with these checkpoints. Our models result in new state-of-the-art results on Machine Translation, Text Summarization, Sentence Splitting, and Sentence Fusion.","The paper discusses the effectiveness of using pre-trained checkpoints for Sequence Generation. The authors developed a Transformer-based sequence-to-sequence model that is compatible with pre-trained BERT, GPT-2, and RoBERTa checkpoints. They conducted an empirical study and found that initializing their model with these checkpoints resulted in new state-of-the-art results on Machine Translation, Text Summarization, Sentence Splitting, and Sentence Fusion. This demonstrates the potential of pre-training for Sequence Generation tasks.","{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to provide a brief overview of the paper's content."", 'Who is the target audience?': ""The summaries are for NLP researchers and practitioners who want to understand the paper's findings without reading the entire document."", 'How will the summaries be used?': 'The summaries will be used to provide actionable insights for researchers and practitioners when tackling various seq2seq tasks.'}",['method'],['External Knowledge'],"['CNN/DailyMail', 'Gigaword', 'XSum']","['ROUGE', 'BLEU', 'BERTScore']","['Informativeness', 'Fluency']",https://github.com/google-research/google-research/tree/master/bertseq2seq,https://aclanthology.org/2020.tacl-1.18,"{'There has been little attention paid to using pre-trained models to warm-start sequence-to-sequence (seq2seq) models.': 'The authors report on a Transformer-based seq2seq model that is compatible with publicly available pre-trained BERT, GPT-2, and RoBERTa checkpoints. They experiment with different settings to combine these pre-trained checkpoints to initialize their Transformer-based model.', 'It is unclear to what extent using large pre-trained models can be beneficial to warm-start seq2seq generation models.': 'The authors conduct experiments to provide an empirical answer to the research question of what is the best way to leverage publicly available pre-trained checkpoints for warm-starting sequence generation models.', 'The pre-training objective used by BERT is not well-suited for tasks that require decoding texts, such as conditional text generation in machine translation and summarization.': 'The authors demonstrate the benefit of leveraging unsupervised pre-trained models for conditional text generation tasks, including machine translation, text summarization, sentence splitting, and sentence fusion.', 'It is unclear whether a pre-trained encoder is an essential component for sequence generation tasks and whether these tasks benefit from sharing the weights between the encoder and the decoder.': ""The authors' results demonstrate that a pre-trained encoder is indeed an essential component for sequence generation tasks and that these tasks often benefit from sharing the weights between the encoder and the decoder.""}",unsupervised,['News'],['pretraining-and-sample-efficiency']
SP:976208c37a27ea9ecb4e59515a103876cc27bb91,Modeling Content Importance for Summarization with Pre-trained Language Models,EMNLP,2020,"['Liqiang Xiao', 'Lu Wang', 'Hao He', 'Yaohui Jin']","Modeling content importance is an essential yet challenging task for summarization. Previous work is mostly based on statistical methods that estimate word-level salience, which does not consider semantics and larger context when quantifying importance. It is thus hard for these methods to generalize to semantic units of longer text spans. In this work, we apply information theory on top of pretrained language models and define the concept of importance from the perspective of information amount. It considers both the semantics and context when evaluating the importance of each semantic unit. With the help of pre-trained language models, it can easily generalize to different kinds of semantic units (n-grams or sentences). Experiments on CNN/Daily Mail and New York Times datasets demonstrate that our method can better model the importance of content than prior work based on F1 and ROUGE scores.","The paper discusses the challenge of modeling content importance for summarization, which previous methods have struggled with due to their focus on word-level salience and lack of consideration for semantics and context. The authors propose a new approach that applies information theory to pretrained language models, allowing for a more comprehensive evaluation of importance that can be applied to different types of semantic units. Experiments on two datasets show that their method outperforms prior work in terms of F1 and ROUGE scores.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress long documents into a concise summary while maintaining the salient information.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],"['Input Encoding', 'External Knowledge']","['CNN/DailyMail', 'NYT']",['ROUGE'],[''],,https://aclanthology.org/2020.emnlp-main.293,"{'It is unclear how well large pre-trained language models can estimate ""content importance"" for a given document.': 'The authors propose a novel and general-purpose approach to model content importance for summarization by employing information theory on top of pre-trained language models, which are expected to better capture the information amount of semantic units by leveraging their meanings and context.', 'Previous studies for modeling importance are either empirical-based or theory-based, which often lacks support by empirical experiments.': 'The authors aim to formalize the concept of importance and develop general-purpose systems by modeling the background knowledge of readers based on information theory.', 'Bag-of-words approaches are difficult to generalize beyond unigrams due to the sparsity of n-grams when n is large.': 'The authors propose to employ information theory on top of pre-trained language models to better capture the information amount of semantic units by leveraging their meanings and context.', 'Most data-driven approaches conduct the information selection implicitly while generating the summaries, lacking theory support and being hard to be applied to low-resource domains.': 'The authors propose a novel and general-purpose approach to model content importance for summarization by employing information theory on top of pre-trained language models, which are expected to better capture the information amount of semantic units by leveraging their meanings and context.', 'Structure features, such as centrality, position, and title, are employed as proxies for importance, but the information captured by these features can vary in texts of different genres.': 'The authors propose to employ information theory on top of pre-trained language models to better capture the information amount of semantic units by leveraging their meanings and context, which is suitable for their study since they are trained from large-scaled datasets consisting of diverse documents and thus containing a wide range of knowledge.', 'Statistical method is only a rough evaluation for informativity, which largely ignores the effect of semantic and context.': ""The authors propose to employ information theory on top of pre-trained language models to better capture the information amount of semantic units by leveraging their meanings and context, which takes into account the semantic meaning, context, and reader's background knowledge."", 'The authors aim to demonstrate that their proposed method can outperform prior importance estimation models and can be adapted to model semantic units of different scales (n-grams and sentences).': 'The authors conduct experiments on popular summarization benchmarks of CNN/Daily Mail and New York Times corpora, where they show that their proposed method can outperform prior importance estimation models and can be adapted to model semantic units of different scales (n-grams and sentences).'}",supervised,['News'],[]
SP:b4762ad393860b87365ffc4c271df1f31ff1eb27,Towards Zero-Shot Conditional Summarization with Adaptive Multi-Task Fine-Tuning,EMNLP,2020,"['Travis R. Goodwin', 'Max E. Savery', 'Dina Demner-Fushman']","Automatic summarization research has traditionally focused on providing high quality general-purpose summaries of documents. However, there are many applications that require more specific summaries, such as supporting question answering or topic-based literature discovery. In this paper, we study the problem of conditional summarization in which content selection and surface realization are explicitly conditioned on an ad-hoc natural language question or topic description. Because of the difficulty in obtaining sufficient reference summaries to support arbitrary conditional summarization, we explore the use of multi-task fine-tuning (MTFT) on twentyone natural language tasks to enable zero-shot conditional summarization on five tasks. We present four new summarization datasets, two novel “online” or adaptive task-mixing strategies, and report zero-shot performance using T5 and BART, demonstrating that MTFT can improve zero-shot summarization quality.","The paper discusses the problem of conditional summarization, where content selection and surface realization are based on a natural language question or topic description. The authors explore the use of multi-task fine-tuning (MTFT) on twenty-one natural language tasks to enable zero-shot conditional summarization on five tasks. They present four new summarization datasets and report zero-shot performance using T5 and BART, demonstrating that MTFT can improve zero-shot summarization quality. The paper highlights the importance of specific summaries for applications such as question answering and literature discovery.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to enable zero-shot conditional summarization on previously unseen passages for previously unseen tasks.', 'Who is the target audience?': 'The summaries are for the community.', 'How will the summaries be used?': 'The summaries will be used for zero-shot domain specific and general domain conditional summarization tasks.'}",['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'arXiv']",['ROUGE'],[''],,https://aclanthology.org/2020.findings-emnlp.289/,"{'Transfer learning generalization failures are particularly problematic for a family of tasks referred to as conditional summarization.': 'The authors explore the use of multi-task fine-tuning to enable zero-shot conditional summarization on previously unseen passages for previously unseen tasks.', 'Obtaining sufficient human-authored reference summaries for conditional summarization can be even more time- or cost-prohibitive than for traditional summarization – particularly when dealing with specialized domains such as healthcare.': 'The authors propose using multi-task fine-tuning to enable zero-shot conditional summarization on previously unseen passages for previously unseen tasks, which can reduce the need for human-authored reference summaries.', 'The same passage may have very different ideal summaries, depending on the summarization context.': 'The authors propose using multi-task fine-tuning to enable zero-shot conditional summarization on previously unseen passages for previously unseen tasks, which can take into account the ad-hoc context and produce more accurate summaries.', 'There is a lack of understanding of the role of different tasks on zero-shot summary quality and the impact of different task mixing strategies for fine-tuning.': 'The authors provide an analysis of the role of 21 question answering, single- and multi-document summarization, causal reasoning, and argumentation tasks on zero-shot domain specific and general domain conditional summarization tasks, and propose two novel methods for “online” or adaptive task mixing.', 'There is a lack of summarization datasets that can be used by the community.': 'The authors provide four new summarization datasets that can be used by the community.'}",supervised,"['News', 'Scholarly Documents']",[]
SP:d58bcf6d2e716bdaf6b0722068440479592eb79e,Learning to Fuse Sentences with Transformers for Summarization,EMNLP,2020,"['Logan Lebanoff', 'Franck Dernoncourt', 'Doo Soon Kim', 'Lidan Wang', 'Walter Chang', 'Fei Liu']","The ability to fuse sentences is highly attractive for summarization systems because it is an essential step to produce succinct abstracts. However, to date, summarizers can fail on fusing sentences. They tend to produce few summary sentences by fusion or generate incorrect fusions that lead the summary to fail to retain the original meaning. In this paper, we explore the ability of Transformers to fuse sentences and propose novel algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. Through extensive experiments, we investigate the effects of different design choices on Transformer’s performance. Our findings highlight the importance of modeling points of correspondence between sentences for effective sentence fusion.","System: This paper explores the ability of Transformers to fuse sentences and proposes algorithms to enhance their ability to perform sentence fusion by leveraging the knowledge of points of correspondence between sentences. The authors conducted extensive experiments to investigate the effects of different design choices on Transformer's performance and found that modeling points of correspondence between sentences is crucial for effective sentence fusion. The ability to fuse sentences is important for summarization systems to produce succinct abstracts, but current summarizers can fail on fusing sentences, leading to few summary sentences or incorrect fusions that fail to retain the original meaning.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to develop neural abstractive summarizers that can fuse sentences properly.', 'Who is the target audience?': 'The summaries are for abstractive summarizers that are trained end-to-end and rewarded for generating summaries that contain the same words as human abstracts.', 'How will the summaries be used?': 'The summaries will be used to improve the performance of neural abstractive summarizers by emphasizing the importance of sentence fusion and developing new sentence fusion systems that model points of correspondence for fusion.'}",['analysis'],"['External Knowledge', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],['Truthfulness'],https://github.com/ucfnlp/sent-fusion-transformers,https://aclanthology.org/2020.emnlp-main.338,"{'Current neural abstractive summarization systems do not prioritize sentence fusion, resulting in summaries with few fused sentences and prone to errors.': 'Develop neural abstractive summarizers that properly fuse sentences, with a renewed emphasis on sentence fusion.', 'Previous studies on sentence fusion have focused on combining similar sentences, but humans also fuse disparate sentences that contain fundamentally different content.': 'Address the challenge of fusing disparate sentences by enhancing the Transformer architecture with points of correspondence between sentences, which tie two sentences together into a coherent text.', 'There is a lack of understanding of how sentences are combined in neural text summarization.': 'Make crucial use of points of correspondence between sentences for information fusion, and design new sentence fusion systems and experiment with a fusion dataset containing quality PoC annotations as the test bed for this investigation.'}",supervised,['News'],[]
SP:a01f74bed3f362a73b34a16022c5ffacba11c936,Focus Attention: Promoting Faithfulness and Diversity in Summarization,ACL,2021,"['Rahul Aralikatte', 'Shashi Narayan', 'Joshua Maynez', 'Sascha Rothe', 'Ryan McDonald']","Professional summaries are written with document-level information, such as the theme of the document, in mind. This is in contrast with most seq2seq decoders which simultaneously learn to focus on salient content, while deciding what to generate, at each decoding step. With the motivation to narrow this gap, we introduce Focus Attention Mechanism, a simple yet effective method to encourage decoders to proactively generate tokens that are similar or topical to the input document. Further, we propose a Focus Sampling method to enable generation of diverse summaries, an area currently understudied in summarization. When evaluated on the BBC extreme summarization task, two state-of-the-art models augmented with Focus Attention generate summaries that are closer to the target and more faithful to their input documents, outperforming their vanilla counterparts on ROUGE and multiple faithfulness measures. We also empirically demonstrate that Focus Sampling is more effective in generating diverse and faithful summaries than top-k or nucleus samplingbased decoding methods.","The paper introduces a new method called Focus Attention Mechanism to help seq2seq decoders generate summaries that are similar or topical to the input document. They also propose a Focus Sampling method to enable the generation of diverse summaries. The evaluation on the BBC extreme summarization task shows that models augmented with Focus Attention generate summaries that are closer to the target and more faithful to their input documents, outperforming their vanilla counterparts on ROUGE and multiple faithfulness measures. The paper also demonstrates that Focus Sampling is more effective in generating diverse and faithful summaries than other decoding methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce a shorter version while preserving salient information.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the given text.', 'How will the summaries be used?': 'The potential uses of the summaries are not specified in the given text.'}",['method'],['Objective Function'],['XSum'],['ROUGE'],[''],,https://aclanthology.org/2021.acl-long.474,"{'Generating summaries that are faithful to the input is an unsolved problem.': 'FAME promotes summaries faithful to the source by performing source-side planning to focus the summary on supported and topical content. FAME achieves this through a novel technique which augments standard contextual representations with a dynamic source-conditioned vocabulary biasing layer.', 'Neural generation models fail to account for generating diverse, yet faithful summaries.': 'FAME enables diverse summaries by supporting Focus Sampling – a technique that is more effective in sampling topically relevant tokens to generate diverse, yet topically consistent and faithful outputs, than other sampling methods. FAME provides a mechanism for trading-off high faithfulness with better diversity in summarization.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:aed8691eeea8327c1a2273a2feaa9ee32f6927c4,Transformer Reasoning Network for Personalized Review Summarization,SIGIR,2021,"['Hongyan Xu', 'Hongtao Liu', 'Pengfei Jiao', 'Wenjun Wang']","Review summarization aims to generate condensed text for online product reviews, and has attracted more and more attention in E-commerce platforms. In addition to the input review, the quality of generated summaries is highly related to the characteristics of users and products, e.g., their historical summaries, which could provide useful clues for the target summary generation. However, most previous works ignore the underlying interaction between the given input review and the corresponding historical summaries. Therefore, we aim to explore how to effectively incorporate the history information into the summary generation. In this paper, we propose a novel transformer-based reasoning framework for personalized review summarization. We design an elaborately adapted transformer network containing an encoder and a decoder, to fully infer the important and informative parts among the historical summaries in terms of the input review to generate more comprehensive summaries. In the encoder of our approach, we develop an interand intra-attention to involve the history information selectively to learn the personalized representation of the input review. In the decoder part, we propose to incorporate the constructed reasoning memory learning from historical summaries into the original transformer decoder, and design a memory-decoder attention module to retrieve more useful information for the final summary generation. Extensive experiments are conducted and the results show our approach could generate more reasonable summaries for recommendation, and outperform many competitive baseline methods. ∗Hongtao Liu contributes equally with Hongyan Xu and is the co-first author †Corresponding Author: Wenjun Wang Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’21, July 11–15, 2021, Virtual Event, Canada © 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8037-9/21/07. . . $15.00 https://doi.org/10.1145/3404835.3462854 CCS CONCEPTS • Information systems → Recommender systems.","The paper proposes a novel transformer-based reasoning framework for personalized review summarization in E-commerce platforms. The quality of generated summaries is highly related to the characteristics of users and products, including their historical summaries. However, most previous works ignore the interaction between the input review and corresponding historical summaries. The proposed approach involves inter- and intra-attention in the encoder to learn the personalized representation of the input review and a memory-decoder attention module in the decoder to retrieve more useful information for the final summary generation. The approach outperforms many competitive baseline methods in generating more reasonable summaries for recommendation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of online product reviews to help other users make reasonable purchase decisions quickly and alleviate the information overload problem.', 'Who is the target audience?': 'The summaries are for other users of E-commerce platforms, such as Amazon.', 'How will the summaries be used?': 'The summaries will be used to help other users make informed purchase decisions quickly by providing a brief summary of the online product review.'}",['method'],"['Input Encoding', 'Objective Function']",['Amazon Product Reviews'],['ROUGE'],[''],,https://doi.org/10.1145/3404835.3462854,"{'Existing approaches in review summarization simply adopt historical information as additional features along with the given input review to generate the target summary, neglecting the deep interaction between them.': 'The authors propose a novel Transformer Reasoning Network for personalized review Summarization (TRNS) that captures the deep interaction between the given review and the corresponding historical summaries. The model contains two reasoning units: one in the encoder that infers useful information from historical summaries to learn a more comprehensive representation for the given input review, and another in the decoder that generates target words not in the vocabulary by constructing a personalized dynamic vocabulary from historical summaries.', 'Different historical summaries are of different informativeness, and some are less relevant or irrelevant to the input review and summary generation.': 'The authors use inter-reasoning self-attention among historical summary documents of the current user and product in the encoder to reason and retrieve important information from historical summaries in terms of the given review. They also employ personalized intra-reasoning attention to select informative words in the input review, utilizing personalized features such as user/product IDs and ratings to obtain more personalized weights for all words in the input review.', 'Historical summaries are beneficial to alleviate the out-of-vocabulary problem in summarization tasks.': 'The authors construct a personalized dynamic vocabulary for each input review by filtering high-frequency words from historical reviews and summaries of the current user and product. They design a reasoning attention among the vocabulary in decoder layers to generate personalized words in terms of the given review, augmenting the original decoder in the transformer network.'}",supervised,['Reviews'],['controlled-and-tailored-summarization']
SP:781a542f2025949147380d20fbe85ea200e92145,RefSum: Refactoring Neural Summarization,NAACL,2021,"['Yixin Liu', 'Zi-Yi Dou', 'Pengfei Liu']","Although some recent works show potential complementarity among different state-of-theart systems, few works try to investigate this problem in text summarization. Researchers in other areas commonly refer to the techniques of reranking or stacking to approach this problem. In this work, we highlight several limitations of previous methods, which motivates us to present a new framework Refactor that provides a unified view of text summarization and summaries combination. Experimentally, we perform a comprehensive evaluation that involves twenty-two base systems, four datasets, and three different application scenarios. Besides new state-of-the-art results on CNN/DailyMail dataset (46.18 ROUGE1), we also elaborate on how our proposed method addresses the limitations of the traditional methods and the effectiveness of the Refactor model sheds light on insight for performance improvement. Our system can be directly used by other researchers as an offthe-shelf tool to achieve further performance improvements. We open-source all the code and provide a convenient interface to use it: https://github.com/yixinL7/ Refactoring-Summarization.","The paper presents a new framework called Refactor for text summarization and summaries combination. The authors highlight the limitations of previous methods and perform a comprehensive evaluation involving twenty-two base systems, four datasets, and three different application scenarios. The Refactor model achieves new state-of-the-art results on the CNN/DailyMail dataset and addresses the limitations of traditional methods. The authors open-source all the code and provide a convenient interface for other researchers to use as an off-the-shelf tool to achieve further performance improvements.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to address the issue of different selection biases in model architectures and decoding strategies, which lead to diverse system outputs.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of neural text summarization.', 'How will the summaries be used?': 'The summaries will be used to understand the limitations of existing two-stage learning methods and to propose a new framework, Refactor, that can alleviate the Base-Meta Learning Gap and Train-Test Distribution Gap. The proposed framework can be applied to different scenarios, such as multiple system combination or single system re-ranking, to improve the performance of summarization systems.'}",['analysis'],"['Auxiliary Tasks', 'Objective Function']","['CNN/DailyMail', 'XSum', 'PubMed', 'WikiHow']",['ROUGE'],[''],https://github.com/yixinL7/Refactoring-Summarization,https://aclanthology.org/2021.naacl-main.113/,"{'Existing methods for two-stage learning are designed for specific scenarios and lack a unified framework to utilize complementarity existing in different scenarios.': 'The authors propose a general framework named Refactor that can serve as a base system to construct a summary by selecting sentences from the source document and act as a meta system to select the best system output from multiple candidates. Refactor can be applied to different scenarios, and the unification of base and meta systems allows them to share a set of parameters.', 'Parameterized models between two learning stages are relatively independent, preventing the meta model from fully utilizing the knowledge encoded in the base systems.': 'The authors propose a new paradigm where the base and meta learners are parameterized with shared parameters, promoting communication between the two stages and alleviating the ""Base-Meta learning gap.""', 'There is a distribution gap between the training and test distributions in the meta-learning stage.': 'The authors propose a pretrain-then-finetune paradigm for Refactor that mitigates the ""Train-Test distribution gap.""'}",supervised,"['News', 'Scholarly Documents', 'CQA']",['pretraining-and-sample-efficiency']
SP:3d4e701d8829d1be8869b933b132f06815f202a5,Noisy Self-Knowledge Distillation for Text Summarization,NAACL,2021,"['Yang Liu', 'Sheng Shen', 'Mirella Lapata']","In this paper we apply self-knowledge distillation to text summarization which we argue can alleviate problems with maximumlikelihood training on single reference and noisy datasets. Instead of relying on one-hot annotation labels, our student summarization model is trained with guidance from a teacher which generates smoothed labels to help regularize training. Furthermore, to better model uncertainty during training, we introduce multiple noise signals for both teacher and student models. We demonstrate experimentally on three benchmarks that our framework boosts the performance of both pretrained and nonpretrained summarizers achieving state-of-theart results.1",System: The paper proposes a new method called self-knowledge distillation for text summarization that can improve the training process by using guidance from a teacher model and multiple noise signals to better model uncertainty. The proposed method achieves state-of-the-art results on three benchmarks for both pretrained and nonpretrained summarizers.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve automatic summarization using neural network models.', 'Who is the target audience?': 'The summaries are for improving the performance of automatic summarizers.', 'How will the summaries be used?': 'The summaries will be used to boost the performance of pretrained and non-pretrained abstractive summarizers, achieving new state-of-the-art results.'}",['method'],['External Knowledge'],"['CNN/DailyMail', 'XSum', 'WikiCatSum']",['ROUGE'],"['Succinctness', 'Informativeness', 'Fluency']",https://github.com/nlpyang/NoisySumm,https://aclanthology.org/2021.naacl-main.56,"{'The summarization task is subject to a great deal of human variation, making maximum-likelihood training on single reference datasets suboptimal.': 'The authors propose to use knowledge distillation to transfer knowledge from a larger ""teacher"" network to a smaller ""student"" model, providing a softened distribution over reference summaries and denoising the training data.', 'Most popular benchmarks are collated opportunistically, based on summaries which only loosely correspond to the source input.': 'The authors propose to use knowledge distillation to enrich the single reference setting and improve model generalization and performance.', 'The inherent noise in the data collection process hampers training, with models often being prone to hallucination and struggling to identify which content units are salient.': 'The authors introduce several noise injection techniques which, together with knowledge distillation, improve model generalization and performance.'}",supervised,"['News', 'Wikipedia']","['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization', 'pretraining-and-sample-efficiency']"
SP:9ec57685d9dcc904159c8411f84122ae3e102556,Efficient Attentions for Long Document Summarization,NAACL,2021,"['Luyang Huang', 'Shuyang Cao', 'Nikolaus Parulian', 'Heng Ji', 'Lu Wang']","The quadratic computational and memory complexities of large Transformers have limited their scalability for long document summarization. In this paper, we propose HEPOS, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source. We further conduct a systematic study of existing efficient self-attentions. Combined with HEPOS, we are able to process ten times more tokens than existing models that use full attentions. For evaluation, we present a new dataset, GOVREPORT, with significantly longer documents and summaries. Results show that our models produce significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on PubMed. Human evaluation also shows that our models generate more informative summaries with fewer unfaithful errors.","HEPOS is a new efficient encoder-decoder attention model that effectively identifies important information from a source document for summarization. The authors conducted a study of existing efficient self-attentions and combined them with HEPOS to process ten times more tokens than existing models that use full attentions. They also presented a new dataset, GOVREPORT, with longer documents and summaries, and showed that their models produced significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on PubMed. Human evaluation also showed that their models generated more informative summaries with fewer unfaithful errors.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to help readers quickly grasp the main topics of long documents, such as scientific papers and government reports, which are time-consuming to read and comprehend.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main topics of long documents, including researchers, policymakers, and the general public.', 'How will the summaries be used?': 'The summaries can be used to save time and improve comprehension of long documents, and can be particularly useful for decision-making and information dissemination purposes.'}","['corpus', 'method']",['Input Encoding'],['GovReport'],['ROUGE'],"['Informativeness', 'Faithfulness']",https://github.com/luyang-huang96/LongDocSum,https://aclanthology.org/2021.naacl-main.112,"{'Long documents are time-consuming to read and comprehend, and generating abstractive summaries for them is challenging.': 'The authors propose generating abstractive summaries for long documents using an efficient encoder-decoder attention with head-wise positional strides (HEPOS) that reduces computational and memory costs while maintaining the power of emphasizing important tokens and preserving the global context per head.', 'State-of-the-art systems for summarization are built upon Transformer, which has quadratic time and memory complexities and is too costly for long documents.': 'The authors propose solutions to reduce the calculation of encoder self-attentions by selectively attending to neighboring tokens or relevant words. They also propose using sparse encoder attentions and HEPOS attention to read more than 10K words and obtain significantly higher ROUGE scores on GOVREPORT and new state-of-the-art results on PubMed.', 'Truncation is commonly used to circumvent the issue of encoder-decoder attentions in summarization models, but it further aggravates ""hallucination"" in existing abstractive models.': 'The authors propose using HEPOS attention to efficiently handle both types of attentions required for summarizing long documents, without the need for truncation.', 'Existing datasets for summarization, such as PubMed and arXiv, have significantly shorter documents and summaries than those found in government reports.': 'The authors collect a new large-scale dataset, GOVREPORT, consisting of about 19.5k U.S. government reports with expert-written abstractive summaries, which contains significantly longer documents and summaries than existing datasets and is an important benchmark for producing long document summaries with multiple paragraphs.', 'Existing evaluation metrics for summarization do not adequately measure faithfulness.': 'The authors propose a new evaluation metric for faithfulness, APESsrc, which compares QA answers by reading the source and the system summary and is shown to be better correlated with human judgment than the original metric and an entailment-based scorer.'}",supervised,['Govt. Reports'],"['efficient-encoding-of-long-documents', 'exploiting-the-structure-of-long-documents', 'hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:110aa0c27acb9ebe8692ca4fe439325bad8c5cdf,Aspect-Controllable Opinion Summarization,EMNLP,2021,"['Reinald Kim Amplayo', 'Stefanos Angelidis', 'Mirella Lapata']","Recent work on opinion summarization produces general summaries based on a set of input reviews and the popularity of opinions expressed in them. In this paper, we propose an approach that allows the generation of customized summaries based on aspect queries (e.g., describing the location and room of a hotel). Using a review corpus, we create a synthetic training dataset of (review, summary) pairs enriched with aspect controllers which are induced by a multi-instance learning model that predicts the aspects of a document at different levels of granularity. We fine-tune a pretrained model using our synthetic dataset and generate aspect-specific summaries by modifying the aspect controllers. Experiments on two benchmarks show that our model outperforms the previous state of the art and generates personalized summaries by controlling the number of aspects discussed in them.","

System: This paper proposes a new approach for generating customized summaries based on aspect queries, such as describing the location and room of a hotel. The authors create a synthetic training dataset enriched with aspect controllers and fine-tune a pretrained model to generate aspect-specific summaries. Experiments show that their model outperforms previous state-of-the-art methods and can generate personalized summaries by controlling the number of aspects discussed.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to help consumers make decisions more efficiently when resorting to review websites.', 'Who is the target audience?': 'The summaries are for users who rely on review websites to inform their decision making, such as whether to buy a product or use a service.', 'How will the summaries be used?': 'The summaries will be used to create both general and aspect-specific summaries that are aspect-controllable, allowing users to generate summaries based on their preferences.'}",['method'],['Controlled Generation'],['SPACE'],['ROUGE'],"['Informativeness', 'Coherence', 'Conciseness', 'Fluency', 'Aspect Controllability']",https://github.com/rktamplayo/AceSum,https://aclanthology.org/2021.emnlp-main.528,"{'Models that create general opinion summaries may not satisfy the needs of all users, limiting their ability to make decisions.': 'The authors propose an extractive approach that produces both general and aspect-specific opinion summaries. They achieve this essentially by clustering opinions through a discrete latent variable model and extracting sentences based on popular aspects or a particular aspect.', 'Extractive models can be incoherent and verbose containing unnecessary redundancy.': 'The authors propose an abstractive opinion summarization model that generates aspect-controllable summaries.', 'It is not clear how to control the number of aspects in the output (e.g., to obtain summaries that mention multiple rather than a single aspect of an entity).': 'The authors induce aspect controllers automatically based on a multiple instance learning model and very little human involvement. By modifying the controllers, they can flexibly generate general and aspect-specific summaries, discussing one or more aspects.', 'The notion of salience in reviews largely depends on user interest.': 'The authors propose an approach that generates aspect-controllable summaries, allowing users to focus on the aspects that are most relevant to them.', 'Previous approaches to opinion summarization have limitations in terms of their ability to generate multi-aspect summaries based on user preferences.': 'The authors demonstrate that their model can effectively generate multi-aspect summaries based on user preferences.'}",supervised,['Opinions'],['information-loss-and-incoherence-in-extractive-summarization']
SP:0dc0f47c84e329fd4529b701f8f90c9e707e1c7a,Convex Aggregation for Opinion Summarization,EMNLP,2021,"['Hayate Iso', 'Xiaolan Wang', 'Yoshihiko Suhara', 'Stefanos Angelidis', 'Wang-Chiew Tan']","Recent advances in text autoencoders have significantly improved the quality of the latent space, which enables models to generate grammatical and consistent text from aggregated latent vectors. As a successful application of this property, unsupervised opinion summarization models generate a summary by decoding the aggregated latent vectors of inputs. More specifically, they perform the aggregation via simple average. However, little is known about how the vector aggregation step affects the generation quality. In this study, we revisit the commonly used simple average approach by examining the latent space and generated summaries. We found that text autoencoders tend to generate overly generic summaries from simply averaged latent vectors due to an unexpected L2-norm shrinkage in the aggregated latent vectors, which we refer to as summary vector degeneration. To overcome this issue, we develop a framework COOP, which searches input combinations for the latent vector aggregation using input-output word overlap. Experimental results show that COOP successfully alleviates the summary vector degeneration issue and establishes new state-of-theart performance on two opinion summarization benchmarks. Code is available at https: //github.com/megagonlabs/coop.","The paper discusses recent advances in text autoencoders and their ability to generate grammatically correct and consistent text from aggregated latent vectors. However, the commonly used simple average approach for vector aggregation can lead to overly generic summaries due to unexpected L2-norm shrinkage in the aggregated latent vectors, which the paper refers to as summary vector degeneration. To address this issue, the authors develop a framework called COOP, which searches input combinations for the latent vector aggregation using input-output word overlap. Experimental results show that COOP successfully alleviates the summary vector degeneration issue and establishes new state-of-the-art performance on two opinion summarization benchmarks. The code for COOP is available at https://github.com/megagonlabs/coop.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to represent salient opinions in the input reviews.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the opinions expressed in multiple reviews.', 'How will the summaries be used?': 'The summaries can be used to make informed decisions about products or services based on the opinions of others.'}",['method'],['Objective Function'],"['Amazon Product Reviews', 'Yelp Reviews']","['ROUGE', 'Cosine Similarity', 'BERTScore']","['Informativeness', 'Content Support']",https://github.com/megagonlabs/coop,https://aclanthology.org/2021.findings-emnlp.328,"{'Lack of gold-standard summaries for multi-document opinion summarization, making it challenging to collect at scale.': 'Employ text autoencoders for unsupervised opinion summarization, which can generate summaries by aggregating multiple latent vectors.', 'Uncertainty about whether the simple average is the best choice for summary generation, and little knowledge about the relationship between the latent vector and the generation quality.': 'Develop COOP, a latent vector aggregation framework that considers convex combinations of the latent vectors of input reviews for better summary generation. This optimization strategy helps the model generate summaries that are more consistent with input reviews, thus improving the quality of summarization for unsupervised opinion summarization models.', 'Summary vector degeneration caused by simply averaged latent vectors, resulting in overly generic summaries.': 'Formalize latent vector aggregation as an optimization problem, which considers the convex combination of input review latent vectors. Propose COOP to approximate the optimal latent vector with linear time complexity.', 'Limited comparative experiments against existing methods.': 'Conduct comparative experiments against existing methods (Chu and Liu, 2019; Bražinskas et al., 2020), which implement more sophisticated techniques. The experiments demonstrate that by coupling with COOP, two opinion summarization models (BIMEANVAE and Optimus) establish new state-of-the-art performance on both Yelp and Amazon datasets.'}",supervised,['Reviews'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data']"
SP:e49f073dd1d7e73376f2cd47fe0629f0ccca1410,Learning Opinion Summarizers by Selecting Informative Reviews,EMNLP,2021,"['Arthur Bražinskas', 'Mirella Lapata', 'Ivan Titov']","Opinion summarization has been traditionally approached with unsupervised, weaklysupervised and few-shot learning techniques. In this work, we collect a large dataset of summaries paired with user reviews for over 31,000 products, enabling supervised training. However, the number of reviews per product is large (320 on average), making summarization – and especially training a summarizer – impractical. Moreover, the content of many reviews is not reflected in the human-written summaries, and, thus, the summarizer trained on random review subsets hallucinates. In order to deal with both of these challenges, we formulate the task as jointly learning to select informative subsets of reviews and summarizing the opinions expressed in these subsets. The choice of the review subset is treated as a latent variable, predicted by a small and simple selector. The subset is then fed into a more powerful summarizer. For joint training, we use amortized variational inference and policy gradient methods. Our experiments demonstrate the importance of selecting informative reviews resulting in improved quality of summaries and reduced hallucinations.","The paper discusses the challenges of opinion summarization and proposes a new approach that involves jointly learning to select informative subsets of reviews and summarizing the opinions expressed in these subsets. The authors collected a large dataset of summaries paired with user reviews for over 31,000 products, but the large number of reviews per product made summarization impractical. The authors use amortized variational inference and policy gradient methods for joint training and demonstrate the importance of selecting informative reviews resulting in improved quality of summaries and reduced hallucinations.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of user opinions expressed in online resources to create digests, search, and report generation.', 'Who is the target audience?': 'The summaries are for various information access applications.', 'How will the summaries be used?': 'The summaries will be used for creating digests, search, and report generation.'}",['method'],['Unit Selection'],['AMASUM'],"['ROUGE', 'BLEU']",['Content Support'],https://github.com/abrazinskas/SelSum,https://aclanthology.org/2021.emnlp-main.743,"{'The lack of large high-quality resources for supervised learning in opinion summarization.': 'The authors introduce the largest multidocument opinion summarization dataset AMA-SUM consisting of verdicts, pros and cons for more than 31,000 summarized Amazon products.', 'It is virtually impossible to train a conventional encoder-decoder model using standard hardware due to the large number of reviews per product.': 'The authors propose SELSUM, an end-to-end model that jointly learns to select and summarize review subsets using amortized variational inference and policy gradient optimization.', 'Not all reviews cover the summary content, resulting in hallucinations when training to predict summaries based on random review subsets.': 'The authors utilize the summary to pre-compute lexical features and score review relevance with a tiny neural selector that has only 0.1% of the deep encoder’s parameters. Only selected reviews are then encoded by an ‘expensive’ encoder, in order to predict the summary.', 'Difficulty in selecting quality review subsets in test time when the summary is not available.': 'The authors approximate the summary relevance using another neural selector and show the importance of accurate review selection, affecting the summarizer in training and its output in testing.', 'The need to demonstrate the superiority of their proposed model to alternatives in terms of ROUGE scores and content fidelity.': 'The authors empirically demonstrate the superiority of their model to alternatives in terms of ROUGE scores and content fidelity.'}",supervised,['Reviews'],"['lack-of-suitable-training-data', 'hallucinations-in-the-generated-summaries']"
SP:e114377ddbfaa3c4a3a0b3e8008b0997a457e184,Make The Most of Prior Data: A Solution for Interactive Text Summarization with Preference Feedback,NAACL,2022,"['Duy-Hung Nguyen', 'Nguyen Viet Dung Nghiem', 'Bao-Sinh Nguyen', 'Dung Tien Le', 'Shahab Sabahi', 'Minh-Tien Nguyen', 'Hung Le', 'Hoang Cau', 'Dong Da']","For summarization, human preferences is critical to tame outputs of the summarizer in favor of human interests, as ground-truth summaries are scarce and ambiguous. Practical settings require dynamic exchanges between humans and AI agents wherein feedback is provided in an online manner, a few at a time. In this paper, we introduce a new framework to train summarization models with preference feedback interactively. By properly leveraging offline data and a novel reward model, we improve the performance regarding ROUGE scores and sample-efficiency. Our experiments on three various datasets confirm the benefit of the proposed framework in active, few-shot and online settings of preference learning.","The paper discusses the importance of incorporating human preferences in summarization models to align with human interests. It proposes a new framework for training summarization models with preference feedback in an interactive manner, leveraging offline data and a novel reward model to improve performance and sample efficiency. The experiments conducted on three datasets confirm the benefits of the proposed framework in active, few-shot, and online settings of preference learning.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of AI-powered machines in the field of Natural Language Processing (NLP).', 'Who is the target audience?': 'The summaries are for the purpose of training AI models in NLP.', 'How will the summaries be used?': 'The summaries will be used to fine-tune a pretrained extractive summarizer as the backbone with reinforcement learning by using a reward model that enforces the distance-based order of preferences. The goal is to improve the robustness of model predictions and achieve better performance in various settings such as active, online, and few-shot learning scenarios.'}",['method'],['External Knowledge'],"['BillSum', 'Reddit-TIFU']",['ROUGE'],[''],,https://aclanthology.org/2022.findings-naacl.147,"{'Document summarization is considered a subjective task, and it is hard to quantify what makes a ""good summary"" without human judgment input. Collecting human feedback and evaluating the crafted summaries from documents for building the training datasets is time-consuming and labor-expensive, particularly where domain knowledge is required.': 'The authors propose deploying an interactive HITL-based text summarization framework that continuously collects user feedback to improve model prediction robustness. The AI model will be trained with human-produced summaries and adapted as more human feedback is fed in.', 'Previous studies used human feedback to rank the label of objects, which ranked the entire solution space, including relevant and irrelevant pairs, wasting computing power. Other approaches employed Bayesian Optimization, which consumed a lot of computing power for a larger number of iterations and was vulnerable to the curse of dimensionality of input data. Researchers proposed learning a reward model simulating human preferences, but achieving sample-efficiency is still an open question.': 'The authors propose a novel interactive preference learning system for the summarization task. They fine-tune a pretrained extractive summarizer as the backbone with reinforcement learning using a reward model that enforces the distance-based order of preferences. The reward model is trained to differentiate two summaries regarding the topic, length, and quality (human preferences). To enable sample-efficiency, they propose utilizing offline data, which was previously used to pretrain the model. They introduce two mechanisms to selectively sample offline data in favor of human feedback learning, focusing on low-rewarded samples or documents similar to fine-tuning data.', 'The authors aim to demonstrate the effectiveness of their proposed method in various settings, such as active, few-shot, and online learning scenarios.': 'The authors conduct extensive empirical studies on three summarization datasets, showing that their proposed method consistently achieves significantly better results compared to competitive baselines in each setting.'}",reinforced,"['Legislative Bills', 'Social Media']",['robust-evaluation-methods']
SP:91d893447146f6cbbb6accf57271caf7479ab54e,Summarizing Patients’ Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models,COLING,2022,"['Yanjun Gao', 'Timothy Miller', 'Dongfang Xu', 'Matthew M. Churpek', 'Majid Afshar']","Automatically summarizing patients’ main problems from daily progress notes using natural language processing methods helps to battle against information and cognitive overload in hospital settings and potentially assists providers with computerized diagnostic decision support. Problem list summarization requires a model to understand, abstract, and generate clinical documentation. In this work, we propose a new NLP task that aims to generate a list of problems in a patient’s daily care plan using input from the provider’s progress notes during hospitalization. We investigate the performance of T5 and BART, two state-of-the-art seq2seq transformer architectures, in solving this problem. We provide a corpus built on top of progress notes from publicly available electronic health record progress notes in the Medical Information Mart for Intensive Care (MIMIC)-III. T5 and BART are trained on general domain text, and we experiment with a data augmentation method and a domain adaptation pre-training method to increase exposure to medical vocabulary and knowledge. Evaluation methods include ROUGE, BERTScore, cosine similarity on sentence embedding, and F-score on medical concepts. Results show that T5 with domain adaptive pre-training achieves significant performance gains compared to a rulebased system and general domain pre-trained language models, indicating a promising direction for tackling the problem summarization task.","The paper proposes a new NLP task of generating a list of problems in a patient's daily care plan using input from provider's progress notes during hospitalization. The study investigates the performance of T5 and BART, two state-of-the-art seq2seq transformer architectures, in solving this problem. The evaluation methods include ROUGE, BERTScore, cosine similarity on sentence embedding, and F-score on medical concepts. The results show that T5 with domain adaptive pre-training achieves significant performance gains compared to a rule-based system and general domain pre-trained language models, indicating a promising direction for tackling the problem summarization task. The study provides a corpus built on top of progress notes from publicly available electronic health record progress notes in the Medical Information Mart for Intensive Care (MIMIC)-III.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to assist healthcare providers in overcoming cognitive biases and heuristics and apply evidence-based medicine via information synthesis to accurately understand a patient’s condition.', 'Who is the target audience?': 'The summaries are for healthcare providers who write progress notes to document a patient’s daily progress and care plan.', 'How will the summaries be used?': 'The summaries will be used to reduce the effort in document review and augment care during a time-sensitive hospital event. Ultimately, the goal is to develop computerized diagnostic decision support systems that can assist healthcare providers and overcome the cognitive burden and information overload.'}",['method'],"['Data Augmentation', 'External Knowledge']",['MIMIC-III'],"['ROUGE', 'BERTScore']",[''],,https://aclanthology.org/2022.coling-1.264,"{""The complexity of progress notes increases as the patient's illness worsens, leading to cognitive overload and missed diagnoses."": ""Automatically generating a set of diagnoses/problems in a progress note may assist providers in overcoming cognitive biases and heuristics and apply evidence-based medicine via information synthesis to accurately understand a patient's condition."", ""Existing NLP literature lacks the ability to summarize a patient's problems and develop computerized diagnostic decision support systems."": 'The authors propose a new summarization task designed to meet the real-world need in the hospital setting as the first step to developing NLP models for clinical diagnostic reasoning.', 'The task of problem summarization requires complex cognitive processes to arrive at an accurate diagnosis.': 'The authors hypothesize that the ability of clinical diagnostic reasoning is the key for NLP systems and propose a new annotation subset of MIMIC-III to formulate the task as a problem list summarization.', 'There is a need to evaluate the progress of using state-of-the-art models over a rule-based medical concept extractor for problem summarization.': 'The authors evaluate two transformer models, T5 and BART, for this task in comparison to a rule-based medical concept extractor.', 'There is a need to establish benchmark performance for this task across multiple evaluation metrics.': 'The authors use domain adaptive pre-training to establish benchmark performance for this task and discuss key challenges and future directions.'}",supervised,['Medical Reports'],['controlled-and-tailored-summarization']
SP:bf74a0471ab5965307444c04edb58596a4057e9c,HIBRIDS: Attention with Hierarchical Biases for Structure-aware Long Document Summarization,ACL,2022,"['Shuyang Cao', 'Lu Wang']","Document structure is critical for efficient information consumption. However, it is challenging to encode it efficiently into the modern Transformer architecture. In this work, we present HIBRIDS, which injects Hierarchical Biases foR Incorporating Document Structure into the calculation of attention scores. We further present a new task, hierarchical questionsummary generation, for summarizing salient content in the source document into a hierarchy of questions and summaries, where each follow-up question inquires about the content of its parent question-summary pair. We also annotate a new dataset with 6, 153 questionsummary hierarchies labeled on long government reports. Experiment results show that our model produces better question-summary hierarchies than comparisons on both hierarchy quality and content coverage, a finding also echoed by human judges. Additionally, our model improves the generation of longform summaries from lengthy government reports and Wikipedia articles, as measured by ROUGE scores.","The paper discusses the importance of document structure for efficient information consumption, but notes that it is difficult to encode this structure into modern Transformer architecture. The authors present HIBRIDS, a model that incorporates hierarchical biases to better incorporate document structure into attention scores. They also introduce a new task, hierarchical questionsummary generation, which involves summarizing content into a hierarchy of questions and summaries. The authors annotate a new dataset with over 6,000 questionsummary hierarchies labeled on long government reports and show that their model produces better hierarchies than comparisons on both hierarchy quality and content coverage. The model also improves the generation of longform summaries from government reports and Wikipedia articles, as measured by ROUGE scores.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to facilitate information searching, reading comprehension, and knowledge acquisition by providing an informative overview of the content.', 'Who is the target audience?': 'The summaries are for readers who need to quickly identify aspects of interest to focus on, especially for long documents that cover numerous subjects with varying details.', 'How will the summaries be used?': 'The summaries will be used to support knowledge acquisition and information consumption, and to generate hierarchically organized question-summary pairs that lay out details for topics at different levels.'}","['corpus', 'method']","['Input Encoding', 'Objective Function']","['GovReport-QS', 'WikiBioSum']",['ROUGE'],"['Reorganized Edits', 'Answerable Questions']",https://github.com/ShuyangCao/hibrids_summ,https://aclanthology.org/2022.acl-long.58,"{'State-of-the-art abstractive summarization systems largely ignore document structures, which are important for information searching, reading comprehension, and knowledge acquisition.': ""The authors propose HIBRIDS (Hierarchical Biases foR Incorporating Document Structure), which uses learnable hierarchical biases as part of the Transformer attention calculation to adjust attention weights based on tokens' relative positions with regard to the document structure. This allows summarizers to capture long-range relatedness for better document understanding."", 'The structure of single document summaries remains largely ""flat"", such as a list of aspects, which limits the support for knowledge acquisition, especially for long documents that cover numerous subjects with varying details.': 'The authors present a new summarization task, hierarchical question-summary generation, which produces hierarchically organized question-summary pairs to facilitate information consumption. Each question asks about salient content of the document, and its child questions focus on content in the corresponding summary. This hierarchy not only exposes salient topics and their relations but also allows readers to quickly identify aspects of interest to focus on.', 'There is no available dataset with hierarchical question-summary annotations.': 'The authors label a new dataset, GOVREPORT-QS, consisting of 6,153 question-summary (QS) hierarchies for summary paragraphs based on 1,714 reports from the GOVREPORT dataset. Each summary paragraph contains 4.07 questions with an average QS hierarchy depth of 2.26 levels.', 'Existing structure-aware architectures for summarization require training large amounts of additional parameters, which leads to increased memory footprint and limits the allowed input length.': 'The authors propose HIBRIDS, which uses learnable hierarchical biases to adjust attention weights between tokens based on how conceptually close/distant their corresponding sections are. This approach is inspired by the relative position method that modifies attention calculation and leverages the natural structure of a document, i.e., section levels, to construct a document structure tree.'}",supervised,['Govt. Reports'],['efficient-encoding-of-long-documents']
SP:76ec35d032d04cfc55336da95bd7f7228ed81bee,Document Summarization with Latent Queries,TACL,2022,"['Yumo Xu', 'Mirella Lapata']","The availability of large-scale datasets has driven the development of neural models that create generic summaries for single or multiple documents. For query-focused summarization (QFS), labeled training data in the form of queries, documents, and summaries is not readily available. We provide a unified modeling framework for any kind of summarization, under the assumption that all summaries are a response to a query, which is observed in the case of QFS and latent in the case of generic summarization. We model queries as discrete latent variables over document tokens, and learn representations compatible with observed and unobserved query verbalizations. Our framework formulates summarization as a generative process, and jointly optimizes a latent query model and a conditional language model. Despite learning from generic summarization data only, our approach outperforms strong comparison systems across benchmarks, query types, document settings, and target domains.1","The paper discusses the development of neural models for creating generic summaries for single or multiple documents, driven by the availability of large-scale datasets. However, for query-focused summarization (QFS), labeled training data is not easily accessible. The authors propose a unified modeling framework for any type of summarization, assuming that all summaries are a response to a query, which is observed in QFS and latent in generic summarization. They model queries as discrete latent variables over document tokens and learn representations compatible with observed and unobserved query verbalizations. The framework formulates summarization as a generative process and optimizes a latent query model and a conditional language model. Despite learning from generic summarization data only, their approach outperforms strong comparison systems across benchmarks, query types, document settings, and target domains.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for the task of query-focused summarization (QFS), which aims to create a summary from one or multiple document(s) that answers a specific query.', 'Who is the target audience?': 'The summaries are for users who want to quickly understand the content of a document in response to a specific query.', 'How will the summaries be used?': 'The summaries will be used to provide users with relevant information from a document in response to their query, without having to read the entire document.'}",['method'],"['Input Encoding', 'Objective Function']",['CNN/DailyMail'],['ROUGE'],"['Relevance', 'Succinctness', 'Coherence']",https://github.com/yumoxu/lqsum,https://aclanthology.org/2022.tacl-1.36,"{'Lack of labeled data for query-focused summarization (QFS) task.': 'The authors resort to distant supervision provided by pretrained models, paraphrase identification, and question-answering datasets to make up for the absence of labeled QFS data. They also induce proxy queries from generic summarization datasets without additional question-answering resources.', 'Difficulty in building and scaling QFS systems due to the many different ways natural language queries express users’ information needs.': 'The authors provide a unified modeling framework for generic summarization and QFS, under the assumption that only data for the former is available. They treat generic summarization as a special case of QFS where the query is latent. They model queries as discrete latent variables over document tokens, and learn representations compatible with observed and unobserved query verbalizations.', 'QFS systems are not expected to work well on out-of-distribution queries.': 'The authors propose a non-parametric calibration of the latent query distribution to further handle user queries at test time, which allows them to perform zero-shot QFS without model re-training.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:8594ef9b2ce13f688cc1a0f64430160c44552d90,Long-Span Language Models for Query-Focused Unsupervised Extractive Text Summarization,ECIR,2018,"['Mittul Singh', 'Arunav Mishra', 'Youssef Oualil', 'Klaus Berberich', 'Dietrich Klakow']","Effective unsupervised query-focused extractive summarization systems use query-specific features along with short-range language models (LMs) in sentence ranking and selection summarization subtasks. We hypothesize that applying long-span n-gram-based and neural LMs that better capture larger context can help improve these subtasks. Hence, we outline the first attempt to apply long-span models to a query-focused summarization task in an unsupervised setting. We also propose the Across Sentence Boundary LSTM-based LMs, ASBLSTM and biASBLSTM, that is geared towards the query-focused summarization subtasks. Intrinsic and extrinsic experiments on a real word corpus with 100 Wikipedia event descriptions as queries show that using the long-span models applied in an integer linear programming (ILP) formulation of MMR criterion are the most effective against several state-of-the-art baseline methods from the literature.",The paper discusses the use of long-span language models (LMs) in unsupervised query-focused extractive summarization systems. The authors propose the use of Across Sentence Boundary LSTM-based LMs (ASBLSTM and biASBLSTM) that are specifically designed for this task. They conducted experiments on a real-world corpus with 100 Wikipedia event descriptions as queries and found that using the long-span models in an integer linear programming (ILP) formulation of MMR criterion was the most effective approach compared to several state-of-the-art baseline methods from the literature.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address information overloading and facilitate efficient consumption of information that spans across multiple documents.', 'Who is the target audience?': 'The summaries are for anyone who needs to consume large amounts of information from multiple documents.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points and relevant information from multiple documents without having to read through all of them.'}",['method'],['Unit Selection'],['Gigaword'],['ROUGE'],[''],https://resources.mpi-inf.mpg.de/d5/asblstmSumm/,https://doi.org/10.1007/978-3-319-76941-7_59,"{'In the supervised setting, deep neural network-based models require a large number of training examples and have poor interpretability, limiting their usage as black boxes.': 'With enough examples, neural network-based models with end-to-end training have shown impressive results.', 'Unsupervised approaches that rely on document and corpus statistics have been outperformed by unsupervised long-span neural LMs on similar sentence ranking tasks.': 'Utilize long-span-based neural sentence LMs for an unsupervised query-focused extractive multi-document summarization task.', 'Traditional unsupervised extractive multi-document summarization systems address a global inference problem that aims to generate a length-budgeted summary with the candidate sentences that maximize the overall relevance while avoiding informational redundancy. However, these ILP-based approaches work for summarizing a small number of pre-selected documents and do not scale to larger number input documents (e.g., entire corpus).': 'Extend the ILP-based approach to incorporate the proposed LM and perform a preliminary sentence ranking step to generate a smaller set of (top-k ranked) candidate sentences.', 'In the unsupervised query-focused extractive multi-document summarization task, long-span LMs need to be robust to variable sentence lengths and effective for computing relevance to query and inter-sentence redundancies for global inference.': 'Develop long-span LMs that are robust to variable sentence lengths and effective for computing relevance to query and inter-sentence redundancies for global inference.', 'There is a lack of incorporation of across sentence-based and LSTM-based long-span LMs for an unsupervised query-focused extractive summarization task.': 'Incorporate across sentence-based and LSTM-based long-span LMs for an unsupervised query-focused extractive summarization task and present two Across Sentence Boundary LSTM-based LMs: ASBLSTM and biASBLSTM.', 'There is a need to evaluate the effectiveness of the LMs for an unsupervised query-focused extractive summarization task.': 'Perform intrinsic and extrinsic experiments to evaluate the effectiveness of the LMs with a test query set containing 100 Wikipedia event descriptions released by [3] on the English Gigaword corpus [14].'}",unsupervised,['News'],"['identifying-important-contents-from-the-document', 'pretraining-and-sample-efficiency']"
SP:7d6d144b72b8125e36797a012f0a9cc273e9c2ef,Self-Supervised Learning for Contextualized Extractive Summarization,ACL,2019,"['Hong Wang', 'Xin Wang', 'Wenhan Xiong', 'Mo Yu', 'Xiaoxiao Guo', 'Shiyu Chang', 'William Yang Wang']","Existing models for extractive summarization are usually trained from scratch with a crossentropy loss, which does not explicitly capture the global context at the document level. In this paper, we aim to improve this task by introducing three auxiliary pre-training tasks that learn to capture the document-level context in a self-supervised fashion. Experiments on the widely-used CNN/DM dataset validate the effectiveness of the proposed auxiliary tasks. Furthermore, we show that after pretraining, a clean model with simple building blocks is able to outperform previous state-ofthe-art that are carefully designed. 1","The paper proposes a new approach to improve extractive summarization by introducing three pre-training tasks that capture document-level context in a self-supervised manner. The proposed method is validated through experiments on the CNN/DM dataset, and the results show that a simple model with pre-training outperforms previous state-of-the-art models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to shorten the original article while retaining the key information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire article.', 'How will the summaries be used?': 'The summaries can be used to save time and improve efficiency in tasks such as research, decision-making, and information gathering.'}",['method'],"['External Knowledge', 'Auxiliary Tasks']",['CNN/DailyMail'],['ROUGE'],[''],https://github.com/hongwang600/Summarization,https://aclanthology.org/P19-1214,"{'Previous works on extractive summarization have not explicitly modeled the document context, making it difficult for end-to-end systems to learn to leverage the document context from scratch.': 'The authors propose new pre-training methods that take the whole document into consideration to learn the contextualized sentence representation with self-supervision.', 'Most works on learning word or sentence representations only use a sentence or a few sentences when learning the representation, and the document context can hardly be included in the representation.': 'The authors introduce new pre-training methods that take the whole document into consideration to learn the contextualized sentence representation with self-supervision.', 'It is difficult for end-to-end systems to learn to leverage the document context from scratch due to the challenges of this task.': 'The authors propose using a well pre-trained embedding model that incorporates document context to help with the task.', 'The authors want to verify the effectiveness of their proposed methods.': 'The authors conduct experiments on the CNN/DM dataset based on a hierarchical model and demonstrate that all of the three pre-training tasks perform better and converge faster than the basic model, one of which even outperforms the state-of-the-art extractive method NEUSUM.', 'The authors want to contribute to the field of extractive summarization.': 'The authors are the first to consider using the whole document to learn contextualized sentence representations with self-supervision and without any human annotations. They also introduce and experiment with various self-supervised approaches for extractive summarization, one of which achieves the new state-of-the-art results with a basic hierarchical model. Additionally, the summarization model is more sample efficient and converges much faster than those trained from scratch thanks to the self-supervised pretraining.'}",supervised,['News'],[]
SP:12a95b57383350ee0aa0c0dd980a6388626a3356,Identifying Implicit Quotes for Unsupervised Extractive Summarization of Conversations,AACL,2020,"['Ryuji Kano', 'Yasuhide Miura', 'Tomoki Taniguchi', 'Tomoko Ohkuma']","We propose Implicit Quote Extractor, an endto-end unsupervised extractive neural summarization model for conversational texts. When we reply to posts, quotes are used to highlight important part of texts. We aim to extract quoted sentences as summaries. Most replies do not explicitly include quotes, so it is difficult to use quotes as supervision. However, even if it is not explicitly shown, replies always refer to certain parts of texts; we call them implicit quotes. Implicit Quote Extractor aims to extract implicit quotes as summaries. The training task of the model is to predict whether a reply candidate is a true reply to a post. For prediction, the model has to choose a few sentences from the post. To predict accurately, the model learns to extract sentences that replies frequently refer to. We evaluate our model on two email datasets and one social media dataset, and confirm that our model is useful for extractive summarization. We further discuss two topics; one is whether quote extraction is an important factor for summarization, and the other is whether our model can capture salient sentences that conventional methods cannot.","The paper proposes an unsupervised extractive neural summarization model called Implicit Quote Extractor for conversational texts. The model aims to extract quoted sentences as summaries, even if they are not explicitly shown in replies. The training task of the model is to predict whether a reply candidate is a true reply to a post, and to do so, the model learns to extract sentences that replies frequently refer to. The model is evaluated on two email datasets and one social media dataset, and the results confirm that it is useful for extractive summarization. The paper also discusses whether quote extraction is an important factor for summarization and whether the model can capture salient sentences that conventional methods cannot.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents because there is a growing demand for automated summarization of conversations as the amount of information exchanged via online conversations is increasing rapidly.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a conversation or document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and improve efficiency in various fields such as business, research, and education. They can also be used to provide a quick overview of a conversation or document for decision-making purposes.'}",['method'],['Unit Selection'],"['Avocado Collection', 'Enron Summarization Dataset', 'Reddit-TIFU']",['ROUGE'],[''],,https://aclanthology.org/2020.aacl-main.32,"{'The authors note that while neural network-based models have achieved great performance on supervised summarization, their application to unsupervised summarization is not sufficiently explored. This is because supervised summarization requires tens of thousands of human-annotated summaries, which is not realistic to prepare for every domain.': 'The authors propose unsupervised methods for summarization, which do not require human-annotated summaries. They explore diverse methods of unsupervised summarization, including graph-centrality, centroid of vectors, Kullback-Leibler divergence, reconstruction loss, and path scores of word graphs.', 'The authors note that relying solely on the frequency of important topics in a document is not sufficient for accurate summarization, as important topics may appear only a few times.': 'The authors propose an alternative aspect for summarization, which is ""the probability of being quoted"". They argue that when one replies to an email or a post, a quote is used to highlight the important parts of the text. If they can predict quoted parts, they can extract important sentences irrespective of how frequently the same topic appears in the text.', 'The authors note that most replies do not include quotes, so it is difficult to use quotes as the training labels of neural models.': 'The authors propose a model that can be trained without explicit labels of quotes. The model is called Implicit Quote Extractor (IQE), which extracts implicit quotes for extractive summarization. The model uses pairs of a post and reply candidate to train, and predicts if a reply candidate is an actual reply to the post. IQE extracts a few sentences of the post as a feature for prediction.', 'The authors note that summaries should not depend on replies, so IQE does not use reply features to extract sentences.': 'The authors propose that the model requires replies only during the training and not during the evaluation.', 'The authors note that it is important to verify that ""the possibility of being quoted"" is useful for summarization, and that it reflects an important aspect of saliency that conventional methods do not.': 'The authors evaluate their model with two datasets of Enron mail and a Reddit TIFU dataset, and demonstrate that their model outperforms baseline models. They also verify that quote extraction leads to a high performance of summarization, and that their model can capture salient sentences that conventional frequency-based methods cannot.'}",unsupervised,['Online Conversations'],"['lack-of-suitable-training-data', 'identifying-important-contents-from-the-document']"
SP:36419061b16039a005f7cce320f86035808a56b3,Unsupervised Extractive Summarization by Pre-training Hierarchical Transformers,EMNLP,2020,"['Shusheng Xu', 'Xingxing Zhang', 'Yi Wu', 'Furu Wei', 'Ming Zhou']","Unsupervised extractive document summarization aims to select important sentences from a document without using labeled summaries during training. Existing methods are mostly graph-based with sentences as nodes and edge weights measured by sentence similarities. In this work, we find that transformer attentions can be used to rank sentences for unsupervised extractive summarization. Specifically, we first pre-train a hierarchical transformer model using unlabeled documents only. Then we propose a method to rank sentences using sentence-level self-attentions and pre-training objectives. Experiments on CNN/DailyMail and New York Times datasets show our model achieves state-of-the-art performance on unsupervised summarization. We also find in experiments that our model is less dependent on sentence positions. When using a linear combination of our model and a recent unsupervised model explicitly modeling sentence positions, we obtain even better results.","

The paper discusses a new method for unsupervised extractive document summarization, which involves selecting important sentences from a document without using labeled summaries during training. The authors propose using transformer attentions to rank sentences, and pre-train a hierarchical transformer model using unlabeled documents only. They then use sentence-level self-attentions and pre-training objectives to rank sentences. Experiments on CNN/DailyMail and New York Times datasets show that their model achieves state-of-the-art performance on unsupervised summarization, and is less dependent on sentence positions. When combined with a recent unsupervised model explicitly modeling sentence positions, the results are even better.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to transform long documents into shorter versions while still retaining important content.', 'Who is the target audience?': 'The intended audience for the document summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the document summaries will be used.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT']",['ROUGE'],[''],https://github.com/xssstory/STAS,https://aclanthology.org/2020.findings-emnlp.161,"{'Most summarization models require labeled data, which is expensive to obtain and results in a scarcity of high-quality labeled summarization datasets.': 'The authors focus on unsupervised summarization, where only unlabeled documents are needed during training.', 'The core problem in unsupervised summarization is identifying salient sentences in a document.': 'The authors propose using sentence-level self-attentions obtained through pre-training tasks for hierarchical transformers to rank sentences for unsupervised extractive summarization.', 'Previous work on unsupervised summarization mostly leverages graph-based or rule-based methods and sentence similarities computed with off-the-shelf sentence embeddings.': 'The authors propose using (sentence-level) transformer attentions in a hierarchical transformer to rank sentences for unsupervised extractive summarization.', 'Unsupervised abstractive summarization models based on sequence to sequence learning and sequential denoising auto-encoding have no guarantee of producing grammatical and factually consistent summaries.': 'The authors propose using the pre-trained hierarchical transformer model for document modeling to estimate the importance of sentences for unsupervised extractive summarization.', 'Sentence position dependency is a challenge in unsupervised summarization.': 'The authors find that their model is less dependent on sentence positions and achieve even better results when using a linear combination of their model and a recent unsupervised model explicitly modeling sentence positions.'}",unsupervised,['News'],"['lack-of-suitable-training-data', 'identifying-important-contents-from-the-document']"
SP:c90e8094a886083dc6411ca95456eb1d6c1c15db,Unsupervised Extractive Text Summarization with Distance-Augmented Sentence Graphs,SIGIR,2021,"['Jingzhou Liu', 'Dominic J. D. Hughes', 'Yiming Yang']","Supervised summarization has made significant improvements in recent years by leveraging cutting-edge deep learning technologies. However, the true success of supervised methods relies on the availability of large quantity of human-generated summaries of documents, which is highly costly and difficult to obtain in general. This paper proposes an unsupervised approach to extractive text summarization, which uses an automatically constructed sentence graph from each document to select salient sentences for summarization based on both the similarities and relative distances in the neighborhood of each sentences. We further generalize our approach from single-document summarization to a multi-document setting, by aggregating document-level graphs via proximity-based cross-document edges. In our experiments on benchmark datasets, the proposed approach achieved competitive or better results than previous state-of-the-art unsupervised extractive summarization methods in both single-document and multi-document settings, and the performance is competitive to strong supervised baselines.","The paper discusses the limitations of supervised summarization due to the high cost and difficulty of obtaining large quantities of human-generated summaries. It proposes an unsupervised approach to extractive text summarization using an automatically constructed sentence graph to select salient sentences based on similarities and relative distances. The approach is generalized from single-document to multi-document settings by aggregating document-level graphs via proximity-based cross-document edges. In experiments on benchmark datasets, the proposed approach achieved competitive or better results than previous state-of-the-art unsupervised extractive summarization methods in both single-document and multi-document settings, and the performance is competitive to strong supervised baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense a given document or set of documents into a shorter piece of textual summary that preserves the main contents of the input.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main contents of a document or set of documents without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for personal or classroom use, and can also be used for commercial purposes as long as copies are not made or distributed for profit or commercial advantage and that copies bear the full citation on the first page. They can also be used for research purposes to improve the state of the art in unsupervised extractive text summarization.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'NYT', 'Multi-News']",['ROUGE'],[''],,https://doi.org/10.1145/3404835.3463111,"{'The success of supervised methods in text summarization heavily depends on the availability of large training corpora with human-generated high-quality summaries, which are costly to produce and difficult to obtain.': 'The authors propose to focus on improving the state of the art in unsupervised extractive text summarization, which avoids the expensive cost of data annotation.', 'The graph formulation in PACSUM may not be sufficient for fully leveraging the positional information of sentences within a document, as it only encodes the pairwise ordering but not the distance information.': 'The authors propose to introduce their Distance-Augmented Sentence Graphs (DASG) formalism, which encodes the relative distances of sentence pairs for edge weighting in graph construction for single-document extractive summarization.', 'Multi-document models are much less explored, especially with respect to unsupervised neural graph-based methods.': 'The authors propose to generalize the DASG formalism from the single-document setting to a multi-document setting, by generating DASGs for individual documents and merging them into a multi-document DASG via proximity-based cross-document edges.'}",unsupervised,['News'],['lack-of-suitable-training-data']
SP:f913e1125f34b37041d094ca57c07f28cb2569a6,Improving Unsupervised Extractive Summarization with Facet-Aware Modeling,ACL,2021,"['Xinnian Liang', 'Shuangzhi Wu', 'Mu Li', 'Zhoujun Li']","Unsupervised extractive summarization aims to extract salient sentences from documents without labeled corpus. Existing methods are mostly graph-based by computing sentence centrality. These methods usually tend to select sentences within the same facet, however, which often leads to the facet bias problem especially when the document has multiple facets (i.e. long-document and multidocuments). To address this problem, we proposed a novel facet-aware centrality-based ranking model. We let the model pay more attention to different facets by introducing a sentence-document weight. The weight is added to the sentence centrality score. We evaluate our method on a wide range of summarization tasks that include 8 representative benchmark datasets. Experimental results show that our method consistently outperforms strong baselines especially in longand multi-document scenarios and even performs comparably to some supervised models. Extensive analyses confirm that the performance gains come from alleviating the facet bias problem.","The paper discusses the problem of facet bias in unsupervised extractive summarization, where existing graph-based methods tend to select sentences within the same facet. To address this, the authors propose a facet-aware centrality-based ranking model that introduces a sentence-document weight to pay more attention to different facets. The method is evaluated on 8 benchmark datasets and consistently outperforms strong baselines, especially in long and multi-document scenarios. The performance gains are attributed to alleviating the facet bias problem.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to transform long documents into shorter versions while retaining the most important content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the most important information.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT', 'Multi-News', 'PubMed', 'arXiv', 'WikiSum', 'WikiHow', 'Billsum']",['ROUGE'],"['Facet Bias', 'Non-redundancy']",,https://aclanthology.org/2021.findings-acl.147,"{'Existing extractive or abstractive methods for document summarization are mostly in supervised fashion which rely on large amounts of labeled corpora, which are not available for different summarization styles, domains, and languages.': 'Recent work has shown successful practices on unsupervised extractive summarization, which removes the dependency on large-scale annotated document-summary pairs and is more general for various scenarios.', 'Centrality-based models for extractive summarization tend to select sentences from one facet, which is supported by more similar sentences, leading to the facet bias problem.': 'The authors proposed a facet-aware centrality-based model, called Facet-Aware Rank (FAR), which introduces a modified graph-based ranking method to filter irrelevant sentences and encodes the whole document into vector space to capture all facets. They also calculate a similarity score between the summary sentences and the document to measure the relevance between summary and document, and combine it with sentence centrality in the ranking phase to guarantee the selected sentences are important and cover all facets.', 'Redundancy in summary.': 'The authors found that their method can tackle redundancy in summary to some extent.'}",unsupervised,"['News', 'Scholarly Documents', 'Wikipedia', 'CQA', 'Legal Proceedings']",['lack-of-suitable-training-data']
SP:da604881429db84ff56030fef053c7e8f3ce702f,Unsupervised Extractive Summarization using Pointwise Mutual Information,EACL,2021,['Vishakh Padmakumar'],"Unsupervised approaches to extractive summarization usually rely on a notion of sentence importance defined by the semantic similarity between a sentence and the document. We propose new metrics of relevance and redundancy using pointwise mutual information (PMI) between sentences, which can be easily computed by a pre-trained language model. Intuitively, a relevant sentence allows readers to infer the document content (high PMI with the document), and a redundant sentence can be inferred from the summary (high PMI with the summary). We then develop a greedy sentence selection algorithm to maximize relevance and minimize redundancy of extracted sentences. We show that our method outperforms similarity-based methods on datasets in a range of domains including news, medical journal articles, and personal anecdotes.","System: The paper proposes a new approach to unsupervised extractive summarization using pointwise mutual information (PMI) between sentences to measure relevance and redundancy. The method involves a greedy sentence selection algorithm to maximize relevance and minimize redundancy of extracted sentences. The authors show that their method outperforms similarity-based methods on datasets in various domains, including news, medical journal articles, and personal anecdotes.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to tackle the problem of unsupervised extractive summarization, which aims to select important sentences from the document.', 'Who is the target audience?': 'The target audience for the generated summaries is not explicitly mentioned in the paper.', 'How will the summaries be used?': 'The generated summaries can be used to provide a brief overview of the document content, which can be useful in various applications such as information retrieval and document browsing.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'XSum', 'Reddit-O', 'Reddit-TIFU', 'PubMed']",['ROUGE'],[''],https://github.com/vishakhpk/mi-unsup-summ,https://aclanthology.org/2021.eacl-main.213,"{'Modern neural network-based approaches to summarization require a large amount of document-summary pairs that are usually unavailable outside of the news domain.': 'The authors propose an unsupervised extractive summarization algorithm that does not require a large amount of document-summary pairs.', 'Most approaches to extractive summarization rely on the assumption that important sentences are similar to other sentences in the document, but it is unclear if similarity-based features lead to meaningful content selection.': 'The authors propose metrics for relevance and redundancy based on pointwise mutual information (PMI) to measure the importance of sentences in a document.', 'It is difficult to measure the relevance and redundancy of a summary.': 'The authors measure the relevance of a summary by its PMI with the document and measure redundancy by PMI of sentence pairs within the summary.', 'It is difficult to extract important sentences from a document.': 'The authors design a simple sentence extraction algorithm that estimates the PMI of sentence pairs by a pre-trained language model fine-tuned on in-domain documents and uses a simple sequential sentence selection algorithm for extractive summarization.', 'Existing extractive summarization algorithms do not perform well across multiple domains.': ""The authors' algorithm outperforms similarity-based methods across multiple domains, including news, personal stories, and medical articles.""}",unsupervised,"['News', 'Social Media', 'Scholarly Documents']",['lack-of-suitable-training-data']
SP:9c1ecca7fffddfdce54441c2ff5140f842d78fab,Unsupervised Extractive Opinion Summarization Using Sparse Coding,ACL,2022,"['Somnath Basu', 'Roy Chowdhury', 'Chao Zhao', 'Snigdha Chaturvedi']","Opinion summarization is the task of automatically generating summaries that encapsulate information from multiple user reviews. We present Semantic Autoencoder (SemAE) to perform extractive opinion summarization in an unsupervised manner. SemAE uses dictionary learning to implicitly capture semantic information from the review and learns a latent representation of each sentence over semantic units. A semantic unit is supposed to capture an abstract semantic concept. Our extractive summarization algorithm leverages the representations to identify representative opinions among hundreds of reviews. SemAE is also able to perform controllable summarization to generate aspect-specific summaries. We report strong performance on SPACE and AMAZON datasets, and perform experiments to investigate the functioning of our model. Our code is publicly available at https://github.com/brcsomnath/SemAE.",The paper presents a new method called Semantic Autoencoder (SemAE) for extractive opinion summarization in an unsupervised manner. SemAE uses dictionary learning to capture semantic information from reviews and learns a latent representation of each sentence over semantic units. The extractive summarization algorithm leverages these representations to identify representative opinions among hundreds of reviews. SemAE can also perform controllable summarization to generate aspect-specific summaries. The authors report strong performance on SPACE and AMAZON datasets and provide their code publicly.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of user opinions in online forums for entities such as products, hotels, and services to enable faster comparison, search, and better consumer feedback understanding.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the opinions of others about a particular entity, such as potential consumers or researchers.', 'How will the summaries be used?': 'The summaries can be used for comparison, search, and better understanding of consumer feedback for a particular entity. They can also be used for research purposes, such as analyzing trends in consumer opinions over time.'}",['method'],['Input Encoding'],"['SPACE', 'Amazon Product Reviews']",['ROUGE'],"['Informativeness', 'Coherence', 'Non-redundancy', 'Aspect Specificity']",https://github.com/brcsomnath/SemAE,https://aclanthology.org/2022.acl-long.86,"{'Existing approaches for opinion summarization rely on human-annotated reference summaries, which are scarce for opinion summarization.': 'The authors propose to leverage unsupervised or weakly supervised techniques for opinion summarization, such as their proposed Semantic Autoencoder (SemAE) model.', 'Abstractive models for opinion summarization suffer from problems common in text generation like hallucination, text degeneration, and topic drift.': 'The authors propose an extractive approach for opinion summarization, which creates summaries by selecting review sentences to reflect the popular opinions corresponding to an entity. They also introduce the SemAE model, which learns a representation of text over latent semantic units using dictionary learning.', 'The Quantized Transformer (QT) approach for extractive summarization is restrictive because a text phrase can encapsulate multiple semantic senses.': 'The authors build on the framework introduced by QT and propose the SemAE model, which models text as a combination of semantics and forms a distribution over latent units (dictionary). This allows sentence representations to capture fine-grained and diverse semantics.', 'Existing approaches for extractive summarization rely on identification of aspect-specific head representations, which limits controllable summarization.': 'The authors achieve controllable summarization by utilizing information-theoretic measures (such as relevance, redundancy, etc) on sentence representations. Their sentence selection algorithm is more flexible and allows a broader spectrum of controllable summarization.', 'Existing approaches for opinion summarization have been evaluated on small scales (10 reviews per entity or fewer), which does not reveal their utility in the real world where there are hundreds of reviews per entity.': 'The authors experimentally show strong performance on two opinion summarization datasets, demonstrating the utility of their proposed SemAE model and sentence selection algorithm. They also perform analysis to understand how the learnt representations align with human semantics.'}",unsupervised,['Reviews'],"['lack-of-suitable-training-data', 'hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:bb58bc1567c414b3fa0ab8bda527377037ebd1f9,Summarizing Opinions: Aspect Extraction Meets Sentiment Prediction and They Are Both Weakly Supervised,EMNLP,2018,"['Stefanos Angelidis', 'Mirella Lapata']","We present a neural framework for opinion summarization from online product reviews which is knowledge-lean and only requires light supervision (e.g., in the form of product domain labels and user-provided ratings). Our method combines two weakly supervised components to identify salient opinions and form extractive summaries from multiple reviews: an aspect extractor trained under a multi-task objective, and a sentiment predictor based on multiple instance learning. We introduce an opinion summarization dataset that includes a training set of product reviews from six diverse domains and human-annotated development and test sets with gold standard aspect annotations, salience labels, and opinion summaries. Automatic evaluation shows significant improvements over baselines, and a largescale study indicates that our opinion summaries are preferred by human judges according to multiple criteria.1","

The paper presents a neural framework for summarizing opinions from online product reviews. The framework is knowledge-lean and only requires light supervision in the form of product domain labels and user-provided ratings. The method combines two weakly supervised components to identify salient opinions and form extractive summaries from multiple reviews. The authors introduce an opinion summarization dataset that includes a training set of product reviews from six diverse domains and human-annotated development and test sets with gold standard aspect annotations, salience labels, and opinion summaries. Automatic evaluation shows significant improvements over baselines, and a largescale study indicates that the opinion summaries generated by the framework are preferred by human judges according to multiple criteria.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to help consumers efficiently absorb large amounts of opinionated text and to help manufacturers keep track of what customers think about their products.', 'Who is the target audience?': 'The summaries are for consumers who need to make informed decisions about products and for manufacturers who want to understand what customers think about their products.', 'How will the summaries be used?': 'The summaries will be used as a tool for information access applications, such as product reviews, blogs, internet forums, or social media. They will help consumers and manufacturers to quickly and easily understand the opinions expressed in large amounts of text.'}",['method'],"['Unit Selection', 'Objective Function']",['OPOSUM'],['ROUGE'],"['Informativeness', 'Coherence', 'Non-redundancy', 'Polarity']",https://github.com/stangelid/oposum,https://aclanthology.org/D18-1403,"{'Opinion summarization is a challenging task that requires the aggregation of user opinions expressed in online reviews, blogs, internet forums, or social media. This task is important for various information access applications, such as helping consumers make informed decisions and allowing manufacturers to keep track of what customers think about their products.': 'The authors propose a neural framework for opinion extraction from product reviews that combines aspect and sentiment information and does not require unrealistic amounts of supervision. Their system accurately identifies aspect-specific opinions by using different sources of information freely available with product reviews (product domain labels, user ratings) and minimal domain knowledge (essentially a few aspect-denoting keywords). They incorporate these ideas into a recently proposed aspect discovery model and a weakly supervised sentiment predictor to identify highly salient opinions. Their approach takes advantage of weak supervision signals only, requires minimal human intervention and no gold-standard salience labels or summaries for training.', 'The majority of work on opinion summarization is entity-centric, aiming to create summaries from text collections that are relevant to a particular entity of interest, e.g., product, person, company, and so on. A popular decomposition of the problem involves three subtasks: aspect extraction, sentiment prediction, and summary generation.': 'The authors follow the standard architecture for aspect-based summarization, which involves the three subtasks of aspect extraction, sentiment prediction, and summary generation. However, they take advantage of the success of neural network models in learning continuous features without recourse to preprocessing tools or linguistic annotations.', 'Various techniques have been proposed for aspect discovery and sentiment prediction, including part of speech tagging, syntactic parsing, clustering, data mining, information extraction, lexicon and rule-based methods, and learning approaches. Textual summaries are created following mostly extractive methods, and various formats ranging from lists of words to sentences.': 'The authors incorporate different sources of information freely available with product reviews and minimal domain knowledge to accurately identify aspect-specific opinions. They use a weakly supervised sentiment predictor to identify highly salient opinions. Their system outputs extractive summaries using a greedy algorithm to minimize redundancy. Their approach takes advantage of weak supervision signals only, requires minimal human intervention and no gold-standard salience labels or summaries for training. They also introduce an opinion summarization dataset which consists of Amazon reviews from six product domains, and includes development and test sets with gold standard aspect annotations, salience labels, and multi-document extractive summaries. They conduct a large-scale user study on the quality of the final summaries paired with automatic evaluations for each stage in the summarization pipeline (aspects, extraction accuracy, final summaries). Experimental results demonstrate that their approach outperforms strong baselines in terms of opinion extraction accuracy and similarity to gold standard summaries. Human evaluation further shows that their summaries are preferred over comparison systems across multiple criteria.'}",supervised,['Opinions'],['lack-of-suitable-training-data']
SP:990ca56bbc2f321c073bf05a61989baf09e87f84,Discourse-Aware Unsupervised Summarization of Long Scientific Documents,EACL,2021,"['Yue Dong', 'Andrei Mircea', 'Jackie C. K. Cheung']","We propose an unsupervised graph-based ranking model for extractive summarization of long scientific documents. Our method assumes a two-level hierarchical graph representation of the source document, and exploits asymmetrical positional cues to determine sentence importance. Results on the PubMed and arXiv datasets show that our approach1 outperforms strong unsupervised baselines by wide margins in automatic metrics and human evaluation. In addition, it achieves performance comparable to many state-of-the-art supervised approaches which are trained on hundreds of thousands of examples. These results suggest that patterns in the discourse structure are a strong signal for determining importance in scientific articles.",The paper proposes an unsupervised graph-based ranking model for summarizing long scientific documents. The method uses a two-level hierarchical graph representation of the document and asymmetrical positional cues to determine sentence importance. The approach outperforms strong unsupervised baselines in automatic metrics and human evaluation on the PubMed and arXiv datasets. It also achieves performance comparable to many state-of-the-art supervised approaches. The results suggest that patterns in the discourse structure are a strong signal for determining importance in scientific articles.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to shorten the text and preserve the most important ideas of the source document.', 'Who is the target audience?': 'The summaries are for cases where faithfully preserving the original text is a priority, such as legal arguments that can hinge on the exact wording of a contract, or in the health or scientific domains where ensuring the factual correctness of a summary can be critical.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main ideas of a long scientific article, and can be generated using unsupervised approaches that rely on the discourse structure of the document.'}",['method'],"['Input Encoding', 'Objective Function']","['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/mirandrom/HipoRank,https://arxiv.org/abs/2005.00513,"{'Supervised neural-based models for extractive summarization are not easily adaptable to out-of-domain data with greater length and fewer training examples, such as scientific article summarization.': 'The authors explore unsupervised approaches to address these challenges on long document summarization, using a simple unsupervised graph-based ranking model combined with proper sophisticated modelling of discourse information as an inductive bias.', 'The typical setup of using a token-level encoder-decoder with an attention mechanism does not scale well to longer documents, as the number of attention computations is quadratic with respect to the number of tokens in the input document.': 'The authors use an unsupervised graph-based ranking model, where sentences are nodes and weighted edges represent the degree of similarity between sentences. Summary generation is formulated as a node selection problem, in which nodes that are semantically similar to other nodes are chosen to be included in the final summary.', 'Important information in long scientific documents typically occurs at the start and end of sections, and most sentences across section boundaries are unlikely to interact significantly with each other.': 'The authors augment the document graph with directionality and hierarchy to reflect the rich discourse structure of long scientific documents. They implement this using an asymmetric edge weighting function in a directed graph which considers the distance of a sentence to a boundary, and by injecting hierarchies into their model, introducing section-level representations as graph nodes in addition to sentence nodes.', 'Previous unsupervised models for long document summarization have limitations in terms of performance.': 'The authors propose a new approach called Hierarchical and Positional Ranking model (HIPORANK), which significantly improves performance over previous unsupervised models in both automatic and human evaluation. Their simple unsupervised approach achieves performance comparable to many expensive state-of-the-art supervised neural models that are trained on hundreds of thousands of examples of long document pairs.'}",unsupervised,['Scholarly Documents'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'hallucinations-in-the-generated-summaries']"
SP:03141d5417cb6c161d5d02583c5b209eb6b9bfea,SummVD : An efficient approach for unsupervised topic-based text summarization,AACL,2022,"['Gabriel Shenouda', 'Christophe Rodrigues', 'Aurélien Bossard']","This paper introduces a new method, SummVD, for automatic unsupervised extractive summarization. This method is based on singular value decomposition, a linear method in the number of words, in order to reduce the dimensionality of word embeddings and propose a representation of words on a small number of dimensions, each representing a hidden topic. It also uses word clustering to reduce the vocabulary size. This representation, specific to one document, reduces the noise brought by several dimensions of the embeddings that are useless in a restricted context. It is followed by a linear sentence extraction heuristic. This makes SummVD an efficient method for text summarization. We evaluate SummVD using several corpora of different nature (news, scientific articles, social network). Our method outperforms in effectiveness recent extractive approaches. Moreover, SummVD requires low resources, in terms of data and computing power. So it can be run on long single documents such as scientific papers as much as large multi-document corpora and is fast enough to be used in live summarization systems.","The paper introduces a new method called SummVD for automatic unsupervised extractive summarization. It uses singular value decomposition and word clustering to reduce the dimensionality of word embeddings and propose a representation of words on a small number of dimensions, each representing a hidden topic. This makes SummVD an efficient method for text summarization, outperforming recent extractive approaches. It requires low resources in terms of data and computing power, making it suitable for use in live summarization systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to tackle the problem of unsupervised extractive summarization, which aims to select sentences from one or multiple documents and put them together in order to build a summary.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be applied to any kind of document, including scientific articles.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'XSum', 'PubMed', 'Reddit-O', 'Multi-News', 'DUC 2004']",['ROUGE'],[''],https://github.com/SummVD/SummVD,https://aclanthology.org/2022.aacl-main.38,"{'Supervised summarization approaches require substantial learning corpora composed of a large amount of documents and summary pairs, and are limited to specific domains.': 'The authors propose to focus on unsupervised summarization methods, specifically unsupervised extractive summarization, which aims to select sentences from one or multiple documents and put them together in order to build a summary based on centrality and diversity notions.', 'It is difficult to derive word centrality scores from a text represented as a word embeddings matrix.': 'The authors assume that hidden topics specific to a text can emerge from word embeddings computed from a general corpus. Each topic stands for a particular aspect of the text semantics. These hidden topics allow to remove unnecessary information from word representations and can be viewed as a new representation of the text. Words can be matched against a hidden topic, and this way, we can derive word centrality scores from a text.', 'There is a need for a new efficient method for unsupervised extractive summarization.': 'The authors propose a new efficient method for unsupervised extractive summarization, called SummVD, whose code is available online. They present recent unsupervised methods in Section 2 and describe their method in Section 3.1. They also present experiments led on a large variety of summarization corpora combining single and multi-document benchmarks in Section 4 to test its generalization. The results shown in Section 5 outperform recent unsupervised methods on most of the evaluation corpora, and get sometimes close to supervised methods. They then discuss in Section 6 complexity and scalability of their method.'}",unsupervised,"['News', 'Scholarly Documents', 'Social Media']",['lack-of-suitable-training-data']
SP:d0b85f8f91f29825be11d53e2a21dcb576618124,GUSUM: Graph-Based Unsupervised Summarization using Sentence Features Scoring and Sentence-BERT,COLING,2022,"['Tuba Gokhan', 'Phillip Smith', 'Mark Lee']","Unsupervised extractive document summarization aims to extract salient sentences from a document without requiring a labelled corpus. In existing graph-based methods, vertex and edge weights are usually created by calculating sentence similarities. In this paper, we develop a Graph-Based Unsupervised Summarization(GUSUM) method for extractive text summarization based on the principle of including the most important sentences while excluding sentences with similar meanings in the summary. We modify traditional graph ranking algorithms with recent sentence embedding models and sentence features and modify how sentence centrality is computed. We first define the sentence feature scores represented at the vertices, indicating the importance of each sentence in the document. After this stage, we use Sentence-BERT for obtaining sentence embeddings to better capture the sentence meaning. In this way, we define the edges of a graph where semantic similarities are represented. Next we create an undirected graph that includes sentence significance and similarities between sentences. In the last stage, we determine the most important sentences in the document with the ranking method we suggested on the graph created. Experiments on CNN/Daily Mail, New York Times, arXiv, and PubMed datasets show our approach achieves high performance on unsupervised graph-based summarization when evaluated both automatically and by humans.",The paper presents a new method for unsupervised extractive document summarization called Graph-Based Unsupervised Summarization (GUSUM). The method uses sentence embeddings and features to modify traditional graph ranking algorithms and compute sentence centrality. The approach aims to include the most important sentences while excluding those with similar meanings in the summary. The method is evaluated on several datasets and achieves high performance when evaluated both automatically and by humans.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress long texts into shorter versions while preserving key information and significance of the content.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but it does mention that the authors focus on unsupervised summarization, which only requires unlabeled documents.'}",['method'],"['Input Encoding', 'Unit Selection']","['CNN/DailyMail', 'NYT', 'PubMed', 'arXiv']",['ROUGE'],['QA'],https://github.com/tubagokhan/GUSUM/,https://aclanthology.org/2022.textgraphs-1.5.pdf,"{'The authors note that the success of supervised text summarization methods is strongly reliant on the availability of large training corpora with human-generated high-quality summaries, which are expensive to produce and difficult to obtain.': 'The authors propose an unsupervised summarization approach that only requires unlabeled documents.', 'The fundamental issue with unsupervised summarizing is determining which sentences in a document are important.': 'The authors suggest enhancing the centrality measure in two significant ways: defining an initial score that specifies the importance of the sentence that each vertex represents, and using SentenceBERT to better capture sentence meaning and calculate sentence similarity.', 'Pre-trained embeddings are generally used only for measuring sentence similarities in graph-based summarization systems, causing the importance of the sentences in the document to be ignored.': 'The authors propose a ranking method that combines sentence similarities and sentence features to calculate sentence centrality, resulting in better results by creating weighted graphs in which the main features of the sentence are represented in the ordering stage based on sentence centrality.', 'The authors propose a novel approach, GUSUM, to improve graph-based unsupervised extractive text summarization.': 'The authors evaluate GUSUM on various datasets and show that it is a simple and powerful approach to improving graph-based unsupervised extractive text summarization.'}",unsupervised,"['News', 'Scholarly Documents']","['lack-of-suitable-training-data', 'identifying-important-contents-from-the-document']"
SP:d537b3d26d07d4fa613c14d4a3fbda3e0474a925,Sentence Centrality Revisited for Unsupervised Summarization,ACL,2019,"['Hao Zheng', 'Mirella Lapata']","Single document summarization has enjoyed renewed interest in recent years thanks to the popularity of neural network models and the availability of large-scale datasets. In this paper we develop an unsupervised approach arguing that it is unrealistic to expect large-scale and high-quality training data to be available or created for different types of summaries, domains, or languages. We revisit a popular graph-based ranking algorithm and modify how node (aka sentence) centrality is computed in two ways: (a) we employ BERT, a state-of-the-art neural representation learning model to better capture sentential meaning and (b) we build graphs with directed edges arguing that the contribution of any two nodes to their respective centrality is influenced by their relative position in a document. Experimental results on three news summarization datasets representative of different languages and writing styles show that our approach outperforms strong baselines by a wide margin.1","The paper discusses the development of an unsupervised approach for single document summarization, which utilizes a modified graph-based ranking algorithm. The algorithm incorporates BERT, a neural representation learning model, to capture sentential meaning, and builds graphs with directed edges to consider the relative position of nodes in a document. The approach was tested on three news summarization datasets and outperformed strong baselines by a significant margin. The authors argue that this approach is more realistic than relying on large-scale and high-quality training data for different types of summaries, domains, or languages.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to create a shorter version of the document while retaining its most important content.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but the authors propose a new approach for measuring directed centrality for single-document summarization.'}",['method'],"['Input Encoding', 'Unit Selection']","['CNN/DailyMail', 'NYT']",['ROUGE'],['QA'],https://github.com/mswellhao/PacSum,https://aclanthology.org/P19-1628,"{'Large-scale and high-quality training data is not available or created for different summarization styles, domains, and languages.': 'Use unsupervised approaches, which have been the subject of much previous research, such as TextRank, a very popular algorithm for extractive single-document summarization.', 'The centrality measure used in TextRank cannot distinguish between semantically related sentences that have different contributions to the summary.': 'Improve the centrality measure by employing BERT, a neural representation learning model that better captures sentential meaning and computes sentence similarity. Also, advocate for directed edges instead of undirected ones, since the contribution induced by two nodes’ connection to their respective centrality can be in many cases unequal.', 'The proposed approach for measuring directed centrality needs to take into account the relative position of the sentences.': 'Transform undirected edges between sentences into directed ones by differentially weighting them according to their orientation. Given a pair of sentences in the same document, one is looking forward (to the sentences following it), and the other is looking backward (to the sentences preceding it).', 'The proposed approach needs to be evaluated on different datasets representative of different languages, writing conventions, and summary styles.': 'Evaluate the proposed approach on three single-document news summarization datasets representative of different languages, writing conventions, and summary styles.', 'The proposed approach needs to be compared to strong baselines and supervised systems trained on hundreds of thousands of examples.': 'Experimentally show that position-augmented centrality significantly outperforms strong baselines (including TextRank) across the board. Also, show that the best system achieves performance comparable to supervised systems trained on hundreds of thousands of examples.', 'The significance of directed centrality for unsupervised summarization has gone largely unnoticed in the research community.': 'Highlight the effectiveness of pretrained embeddings for the summarization task and their promise for the development of unsupervised methods in the future.', 'There are no previous neural-based approaches to unsupervised single-document summarization.': 'Propose a neural-based approach to unsupervised single-document summarization, which is an alternative to more data-hungry models and should be used as a standard comparison when assessing the merits of more sophisticated supervised approaches over and above the baseline of extracting the leading sentences.'}",unsupervised,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:f16ef01a51c34075fe9a6fa612d8c669c5390c9f,Discrete Optimization for Unsupervised Sentence Summarization with Word-Level Extraction,ACL,2020,"['Raphael Schumann', 'Lili Mou', 'Yao Lu', 'Olga Vechtomova', 'Katja Markert']","Automatic sentence summarization produces a shorter version of a sentence, while preserving its most important information. A good summary is characterized by language fluency and high information overlap with the source sentence. We model these two aspects in an unsupervised objective function, consisting of language modeling and semantic similarity metrics. We search for a high-scoring summary by discrete optimization. Our proposed method achieves a new state-of-the art for unsupervised sentence summarization according to ROUGE scores. Additionally, we demonstrate that the commonly reported ROUGE F1 metric is sensitive to summary length. Since this is unwillingly exploited in recent work, we emphasize that future evaluation should explicitly group summarization systems by output length brackets.1","The paper discusses the process of automatic sentence summarization, which involves creating a shorter version of a sentence while retaining its most important information. The authors propose an unsupervised objective function that considers language fluency and semantic similarity metrics to find a high-scoring summary through discrete optimization. Their method achieves a new state-of-the-art for unsupervised sentence summarization according to ROUGE scores. The authors also highlight the sensitivity of the commonly reported ROUGE F1 metric to summary length and suggest that future evaluation should group summarization systems by output length brackets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to transform long source sentences into short summaries while preserving key information.', 'Who is the target audience?': 'The summaries are for wide applications, such as news headline generation and text simplification.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as providing a quick overview of a document or generating headlines for news articles.'}",['method'],['Objective Function'],"['Gigaword', 'DUC 2004']",['Pyramid'],"['Fidelity', 'Fluency']",https://github.com/raphael-sch/HC_Sentence_Summarization,https://aclanthology.org/2020.acl-main.452,"{'State-of-the-art sentence summarization systems require massive parallel data for training, making unsupervised sentence summarization an attractive alternative.': 'The authors propose an unsupervised sentence summarization method based on hill climbing with word-level extraction, which does not require massive parallel data for training.', 'Cycle-consistency approaches treat the summary as a discrete latent variable and use it to reconstruct the source sentence, which fails to explicitly model the resemblance between the source sentence and the target summary.': 'The authors propose a scoring function that evaluates the quality of a candidate summary by language fluency, semantic similarity to the source, and a hard constraint on output length, which explicitly models the resemblance between the source sentence and the target summary.', 'Beam search approaches are biased towards the first few words of the source sentence.': 'The authors propose a hill-climbing approach to unsupervised sentence summarization, which is not biased towards the first few words of the source sentence.', 'The summary length is weakly controlled by length embeddings or a soft length penalty, resulting in summaries of varying lengths.': 'The authors propose a hard constraint on output length, which explicitly controls the length of the summary.', 'ROUGE F1 is sensitive to summary output length, in general favoring models that produce longer summaries.': 'The authors emphasize the importance of explicitly controlling summary length for a fair comparison among different summarization systems.'}",unsupervised,['News'],['robust-evaluation-methods']
SP:5f65a6580c81b7ab4a3c5956e33ec951919da90d,Extractive Summarisation Based on Keyword Profile and Language Model,NAACL,2015,"['Han Xu', 'Eric Martin', 'Ashesh Mahidadia']","We present a statistical framework to extract information-rich citation sentences that summarise the main contributions of a scientific paper. In a first stage, we automatically discover salient keywords from a paper’s citation summary, keywords that characterise its main contributions. In a second stage, exploiting the results of the first stage, we identify citation sentences that best capture the paper’s main contributions. Experimental results show that our approach using methods rooted in quantitative statistics and information theory outperforms the current state-of-the-art systems in scientific paper summarisation.","System: The paper presents a statistical framework for summarizing scientific papers by extracting information-rich citation sentences that capture the main contributions of the paper. The framework involves two stages, where salient keywords are automatically discovered in the first stage and citation sentences that best capture the paper's main contributions are identified in the second stage. The approach outperforms current state-of-the-art systems in scientific paper summarization using methods rooted in quantitative statistics and information theory.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to facilitate understanding the key contributions of papers in those parts of the network being explored.', 'Who is the target audience?': 'The summaries are for researchers who find themselves constantly in need to explore the network further from the core of their research.', 'How will the summaries be used?': 'The summaries will be used as a tool to automatically extract information-rich sentences describing the main contributions of a given paper.'}",['method'],['Unit Selection'],"['Qazvnian et al', 'single paper summarisation corpus', '25 ACL papers']",['ROUGE'],[''],,https://aclanthology.org/N15-1013,"{'Researchers constantly need to explore the network further from the core of their research.': 'The authors propose an application that automatically extracts information-rich sentences describing the main contributions of a given paper from the set of citing sentences to the paper (from other papers).', 'The contributions as perceived by the authors can significantly deviate from those judged extrospectively by the community over time.': 'Instead of using the abstract of the paper, the authors take as corpus the set of citing sentences to the paper, which can be deemed as a form of crowd-sourced review of the paper’s main contributions.', 'Abstracts may not be as focused as citation summaries in describing papers’ main contributions.': 'The authors use citation summaries, which have been found to contain extra information that does not appear in paper abstracts and have higher self-cohesion in describing papers’ main contributions.', 'Summarizing scientific papers using the most informative and diversified part of their citation summaries.': 'The authors present a statistical framework built upon quantitative statistics and information theory to summarize scientific papers using the most informative and diversified part of their citation summaries. They also evaluate and compare the performance of their method with state-of-the-art systems.'}",unsupervised,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'robust-evaluation-methods']"
SP:f9a935dbaae2ef1e25a1a1098684af109b643b74,"Integrating Importance, Non-Redundancy and Coherence in Graph-Based Extractive Summarization",IJCAI,2015,"['Daraksha Parveen', 'Michael Strube']","We propose a graph-based method for extractive single-document summarization which considers importance, non-redundancy and local coherence simultaneously. We represent input documents by means of a bipartite graph consisting of sentence and entity nodes. We rank sentences on the basis of importance by applying a graph-based ranking algorithm to this graph and ensure non-redundancy and local coherence of the summary by means of an optimization step. Our graph based method is applied to scientific articles from the journal PLOS Medicine. We use human judgements to evaluate the coherence of our summaries. We compare ROUGE scores and human judgements for coherence of different systems on scientific articles. Our method performs considerably better than other systems on this data. Also, our graph-based summarization technique achieves state-of-the-art results on DUC 2002 data. Incorporating our local coherence measure always achieves the best results.","The paper proposes a graph-based method for extractive single-document summarization that considers importance, non-redundancy, and local coherence simultaneously. The method uses a bipartite graph consisting of sentence and entity nodes to rank sentences based on importance and ensure non-redundancy and local coherence of the summary. The method is applied to scientific articles from the journal PLOS Medicine and achieves better results than other systems on this data. The method also achieves state-of-the-art results on DUC 2002 data, and incorporating the local coherence measure always achieves the best results. Human judgments are used to evaluate the coherence of the summaries.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to extract the most important information from them.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of the documents, such as researchers, students, or professionals.', 'How will the summaries be used?': ""The summaries will be used to evaluate the performance of the authors' graph-based extractive summarization technique on scientific articles from the journal PLOS Medicine and the DUC 2002 data. They will also be judged by human subjects to evaluate their coherence.""}",['method'],"['Input Encoding', 'Unit Selection']","['PLOS Medicine', 'DUC 2002']",['ROUGE'],[''],,http://ijcai.org/Abstract/15/187,"{'Summaries should contain the most important information from input documents.': 'The authors propose a graph-based extractive summarization technique that computes importance, non-redundancy, and coherence simultaneously.', 'Summaries should not contain redundant information.': 'The authors use a method based on maximum marginal relevance to ensure that the extracted information is non-redundant.', 'Summaries should be readable, hence they should be grammatical and coherent.': 'The authors extend their graph-based technique with discourse processing techniques to improve the coherence of the summaries. They also evaluate the coherence by having their summaries judged by human subjects.', 'There has been little research on including discourse processing techniques into extractive summarization.': 'The authors propose to use the entity graph to extend their graph-based technique with discourse processing techniques.', 'The entity grid has not been used directly in extractive summarization to ensure summary coherence.': 'The authors propose to use their local coherence model, the entity grid, to ensure summary coherence.'}",unsupervised,"['News', 'Scholarly Documents']",['lack-of-suitable-training-data']
SP:8f278285c95eb5f3572a8d2fb670799becbf3751,Topical Coherence for Graph-based Extractive Summarization,EMNLP,2015,"['Daraksha Parveen', 'Hans-Martin Ramsl', 'Michael Strube']","We present an approach for extractive single-document summarization. Our approach is based on a weighted graphical representation of documents obtained by topic modeling. We optimize importance, coherence and non-redundancy simultaneously using ILP. We compare ROUGE scores of our system with state-of-the-art results on scientific articles from PLOS Medicine and on DUC 2002 data. Human judges evaluate the coherence of summaries generated by our system in comparision to two baselines. Our approach obtains competitive performance.","

System: The paper presents an approach for extractive single-document summarization using a weighted graphical representation of documents obtained by topic modeling. The approach optimizes importance, coherence, and non-redundancy simultaneously using ILP. The system's performance is compared with state-of-the-art results on scientific articles from PLOS Medicine and on DUC 2002 data using ROUGE scores. Human judges evaluate the coherence of summaries generated by the system in comparison to two baselines, and the approach obtains competitive performance.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide a concise version of the original document that contains salient information and is coherent and readable.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a long document without having to read the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort for readers who need to quickly understand the main points of a long document. They can also be used to compare different summarization techniques and evaluate their effectiveness.'}",['method'],['Objective Function'],"['PLOS Medicine', 'DUC 2002']",['ROUGE'],[''],,https://aclanthology.org/D15-1226,"{'Summarization systems need to generate concise documents that contain salient information from the original document.': 'The authors propose an unsupervised graph-based summarization technique using latent drichlet allocation (LDA) to measure the semantic relatedness between words and ensure topical coherence in extractive single-document summaries.', 'Summaries should not include redundant information.': 'The authors use their topical coherence measure to ensure that their summaries do not include redundant information.', 'Summaries should be coherent and of high readability.': 'The authors use their topical coherence measure to ensure that their summaries are coherent and of high readability.', 'The entity graph used by previous summarization systems is unweighted and sparse.': 'The authors introduce a topical graph that is weighted and dense, which improves the performance of their summarization technique.', 'The authors need to evaluate the performance of their summarization technique.': ""The authors use the PLOS Medicine dataset and the DUC 2002 dataset to evaluate the performance of their summarization technique and compare it to state-of-the-art techniques. They also use the editor's summary and author's abstract as gold summaries for evaluation.""}",unsupervised,['Scholarly Documents'],[]
SP:a03568a4ca13a1c2bf9c85615ef32e99ce102b12,"Gibberish, Assistant, or Master? Using Tweets Linking to News for Extractive Single-Document Summarization",SIGIR,2015,"['Zhongyu Wei', 'Wei Gao']","Single-document summarization is a challenging task. In this paper, we explore effective ways using the tweets linking to news for generating extractive summary of each document. We reveal the very basic value of tweets that can be utilized by regarding every tweet as a vote for candidate sentences. Base on such finding, we resort to unsupervised summarization models by leveraging the linking tweets to master the ranking of candidate extracts via random walk on a heterogeneous graph. The advantage is that we can use the linking tweets to opportunistically “supervise” the summarization with no need of reference summaries. Furthermore, we analyze the influence of the volume and latency of tweets on the quality of output summaries since tweets come after news release. Compared to truly supervised summarizer unaware of tweets, our method achieves significantly better results with reasonably small tradeoff on latency; compared to the same using tweets as auxiliary features, our method is comparable while needing less tweets and much shorter time to achieve significant outperformance.","The paper explores using tweets linking to news for generating extractive summaries of documents. By regarding every tweet as a vote for candidate sentences, they use unsupervised summarization models to rank candidate extracts via random walk on a heterogeneous graph. They can use the linking tweets to opportunistically ""supervise"" the summarization with no need for reference summaries. The influence of the volume and latency of tweets on the quality of output summaries is analyzed. Compared to truly supervised summarizers unaware of tweets, their method achieves significantly better results with a reasonably small tradeoff on latency. Compared to the same using tweets as auxiliary features, their method is comparable while needing fewer tweets and much shorter time to achieve significant outperformance.","{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to reduce the reader's information load and help them quickly capture the gist of the document."", 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of the document.', 'How will the summaries be used?': 'The summaries can be used to reduce the time and effort required to read the entire document, and to help readers decide whether they want to read the full document or not.'}",['method'],"['External Knowledge', 'Data Augmentation']",['CNN/USAToday; news-tweets-highlights triples'],['ROUGE'],['Coherence'],,https://doi.org/10.1145/2766462.2767835,"{'Generating abstractive summaries is technically challenging due to the need for language understanding capability.': 'Most summarizers are based on extractive approach, which aims at selecting a subset of textual units of the documents such as sentences, clauses and phrases that can optimize an objective for sentence scoring and satisfy a length constraint. Sentence scoring can be done by learning from various statistical and linguistic features, or by graph-based centrality method for capturing the relative importance of textual units.', 'Tweets content is notoriously informal and noisy, and Twitter users’ elusive posting behavior can hardly be related to summarization in the first place.': 'The authors intend to address three major concerns about using relevant tweets for single-document summarization: (i) Are the linking tweets largely gibberish or useful for producing summaries? (ii) If being useful, do they play assistant or master roles? (iii) Is the latency of tweets a major setback or a reasonable tradeoff regarding the quality of summaries?', 'The latency of tweets linking to a news come after the news exposure, which might drag the summarization performance.': 'The authors come with unsupervised models that leverage the linking tweets to opportunistically “supervise” the sentence scoring. Furthermore, by comparing with state-of-the-art baselines, they examine how the volume and latency of tweets influence the summaries to provide deeper insight into the practicality and usefulness of using tweets linking to news for single-document summarization.'}",unsupervised,['News'],[]
SP:6070041dce99a8b46cdf869454e76420244edca5,Learning Summary Prior Representation for Extractive Summarization,ACL,2015,"['Ziqiang Cao', 'Furu Wei', 'Sujian Li', 'Wenjie Li', 'Ming Zhou', 'Houfeng Wang']","In this paper, we propose the concept of summary prior to define how much a sentence is appropriate to be selected into summary without consideration of its context. Different from previous work using manually compiled documentindependent features, we develop a novel summary system called PriorSum, which applies the enhanced convolutional neural networks to capture the summary prior features derived from length-variable phrases. Under a regression framework, the learned prior features are concatenated with document-dependent features for sentence ranking. Experiments on the DUC generic summarization benchmarks show that PriorSum can discover different aspects supporting the summary prior and outperform state-of-the-art baselines.","The paper introduces the concept of summary prior, which determines how much of a sentence should be included in a summary without considering its context. The authors propose a new summary system called PriorSum, which uses convolutional neural networks to capture summary prior features from length-variable phrases. The learned prior features are combined with document-dependent features for sentence ranking. Experiments on the DUC generic summarization benchmarks show that PriorSum outperforms existing methods and can identify different aspects supporting the summary prior.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for extractive summarization.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Unit Selection'],"['DUC 2001', 'DUC 2004']",['ROUGE'],[''],,https://aclanthology.org/P15-2136,"{'The performance of extractive summarization largely depends on feature engineering, which can be divided into document-dependent and document-independent features.': 'The authors propose to learn document-independent features that reflect the summary prior nature, which is the fact that a sentence can often be judged by itself whether it is appropriate to be included in a summary no matter which document it lies in.', 'Document-independent features are usually hand-crafted and difficult to exhaust each aspect of the summary prior nature.': 'The authors propose to use Convolutional Neural Networks (CNNs) with multiple filters to capture a comprehensive set of document-independent features derived from length-variable phrases.', 'Items representing the same feature may contribute differently to a summary.': 'The authors propose to adopt a two-stage max-over-time pooling operation to associate these filters since phrases with different lengths may express the same aspect of summary prior.', 'Certainty, a context-free measure critical to ranking sentences in summarization, does not always represent low quality of being a summary sentence.': 'The authors propose to view certainty as a specific aspect of the summary prior nature.', 'Document-independent features beyond word level (e.g., phrases) are seldom involved in current research.': 'The authors propose to use CNNs with multiple filters to capture document-independent features derived from length-variable phrases.'}",supervised,['News'],[]
SP:1efc0551978363aa698737997f067124ab4e31f4,A Redundancy-Aware Sentence Regression Framework for Extractive Summarization,COLING,2016,"['Pengjie Ren', 'Furu Wei', 'Zhumin Chen', 'Jun Ma', 'Ming Zhou']","Existing sentence regression methods for extractive summarization usually model sentence importance and redundancy in two separate processes. They first evaluate the importance f(s) of each sentence s and then select sentences to generate a summary based on both the importance scores and redundancy among sentences. In this paper, we propose to model importance and redundancy simultaneously by directly evaluating the relative importance f(s|S) of a sentence s given a set of selected sentences S. Specifically, we present a new framework to conduct regression with respect to the relative gain of s given S calculated by the ROUGE metric. Besides the single sentence features, additional features derived from the sentence relations are incorporated. Experiments on the DUC 2001, 2002 and 2004 multi-document summarization datasets show that the proposed method outperforms state-of-the-art extractive summarization approaches.",The paper proposes a new approach to extractive summarization that models sentence importance and redundancy simultaneously by evaluating the relative importance of a sentence given a set of selected sentences. The proposed method uses a new framework to conduct regression with respect to the relative gain of a sentence calculated by the ROUGE metric and incorporates additional features derived from sentence relations. Experiments on multi-document summarization datasets show that the proposed method outperforms state-of-the-art extractive summarization approaches.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents as a branch of extractive summarization methods to achieve state-of-the-art performances.', 'Who is the target audience?': 'The summaries are for practical systems.', 'How will the summaries be used?': 'The summaries will be used to improve the performance of extractive summarization approaches on benchmark datasets from DUC 2001, 2002, and 2004 multi-document summarization tasks.'}",['method'],['Unit Selection'],"['DUC 2001', 'DUC 2002', 'DUC 2004']",['ROUGE'],[''],,https://aclanthology.org/C16-1004,"{'Existing sentence regression methods model sentence importance and sentence redundancy in two separate processes, namely sentence ranking and sentence selection.': 'The authors propose a novel regression framework to directly model the relative importance f(s|S) of a sentence s given the sentences S. They evaluate the relative importance f(s|S) with a regression model where additional features involving the sentence relations are incorporated.', 'Existing methods discard redundant sentences that are similar to the already selected sentences.': ""The authors' method is redundancy-aware by considering importance and redundancy simultaneously instead of two separate processes."", 'Manually tuning parameters is inconvenient in practice.': ""The authors' method has no manually tuned parameters, which is more convenient in practice."", 'Existing methods do not treat the scores computed using the official evaluation tool as the ground truth.': ""The authors' method treats the scores computed using the official evaluation tool as the ground truth and finds that their method has a higher upper bound."", 'Existing methods do not achieve state-of-the-art performance in terms of ROUGE-2 recall metric on all three benchmark datasets from DUC 2001, 2002, and 2004 multi-document summarization tasks.': ""The authors' method achieves the best performance in terms of ROUGE-2 recall metric and outperforms state-of-the-art extractive summarization approaches on all three datasets.""}",supervised,['News'],[]
SP:8ecb0fe8bd0303116dc8139bad67ba509cfb1868,Combining Graph Degeneracy and Submodularity for Unsupervised Extractive Summarization,EMNLP,2017,"['Antoine J.-P. Tixier', 'Polykarpos Meladianos', 'Michalis Vazirgiannis']","We present a fully unsupervised, extractive text summarization system that leverages a submodularity framework introduced by past research. The framework allows summaries to be generated in a greedy way while preserving near-optimal performance guarantees. Our main contribution is the novel coverage reward term of the objective function optimized by the greedy algorithm. This component builds on the graph-of-words representation of text and the k-core decomposition algorithm to assign meaningful scores to words. We evaluate our approach on the AMI and ICSI meeting speech corpora, and on the DUC2001 news corpus. We reach state-of-the-art performance on all datasets. Results indicate that our method is particularly well-suited to the meeting domain.","The paper presents an unsupervised text summarization system that uses a submodularity framework to generate summaries in a greedy way while maintaining high performance. The system includes a novel coverage reward term that assigns scores to words based on the graph-of-words representation of text and the k-core decomposition algorithm. The system was evaluated on three datasets and achieved state-of-the-art performance, particularly in the meeting domain.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract important information from spontaneous multiparty meeting speech text and news articles.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the documents without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and resources by quickly identifying important information in meeting speech transcriptions and news articles.'}",['method'],['Objective Function'],"['AMI', 'ISCI', 'DUC 2001']",['ROUGE'],[''],,https://aclanthology.org/W17-4507,"{'Summarizing spontaneous multiparty meeting speech text is a difficult task fraught with many unique challenges.': 'The authors present an extractive text summarization system to tackle this problem.', 'The input data consist of utterances, or fragments of speech transcripts, rather than well-formed grammatical sentences found in traditional documents.': 'The authors use an extractive approach to summarize the input data, which involves selecting and combining important sentences or phrases from the input text.', 'Information is diluted across utterances due to speakers frequently hesitating and interrupting each other, and noise abounds in the form of disfluencies and unrelated chit-chat.': 'The authors use various techniques, such as sentence clustering and sentence ranking, to identify and extract the most important information from the input text.', 'Recognition errors in Automatic Speech Recognition (ASR) output introduce much additional noise, making the task of summarization even more difficult.': 'The authors use ASR output as their sole input and develop techniques to handle recognition errors, such as using confidence scores to filter out unreliable sentences.'}",unsupervised,"['Meeting Transcripts', 'News']",[]
SP:46c87de3edcd55c9282a708ea1fbeb1f8283faa6,Extractive Summarization Using Multi-Task Learning with Document Classification,EMNLP,2017,"['Masaru Isonuma', 'Toru Fujino', 'Junichiro Mori', 'Yutaka Matsuo', 'Ichiro Sakata']","The need for automatic document summarization that can be used for practical applications is increasing rapidly. In this paper, we propose a general framework for summarization that extracts sentences from a document using externally related information. Our work is aimed at single document summarization using small amounts of reference summaries. In particular, we address document summarization in the framework of multitask learning using curriculum learning for sentence extraction and document classification. The proposed framework enables us to obtain better feature representations to extract sentences from documents. We evaluate our proposed summarization method on two datasets: financial report and news corpus. Experimental results demonstrate that our summarizers achieve performance that is comparable to stateof-the-art systems.","The paper proposes a framework for automatic document summarization that extracts sentences using externally related information. The focus is on single document summarization using small amounts of reference summaries, and the framework uses multitask learning with curriculum learning for sentence extraction and document classification. The proposed method is evaluated on financial report and news corpus datasets, and the results show comparable performance to state-of-the-art systems.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to address the need for automatic document summarization that can be implemented in practical scenarios due to the rapid increase in the volume of textual data available both online and offline.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key subjects mentioned in a document without reading the entire document.', 'How will the summaries be used?': ""The summaries will be used to provide a quick overview of the document's content and to help readers understand the main topics and key points discussed in the document. They can be used in various practical applications where large volumes of textual data need to be processed efficiently.""}",['method'],"['External Knowledge', 'Auxiliary Tasks']","['NIKKEI', 'NYT']",['ROUGE'],['Informativeness'],,https://aclanthology.org/D17-1223,"{'Neural network-based approaches for extractive summarization rely heavily on large amounts of reference summaries for training neural models, which can be costly and infeasible for domain-specific or expert knowledge.': 'The authors propose regarding the subjects of a document as pseudo-rough reference summaries and estimate them with small amounts of documents and external information. This allows for the identification of salient sentences from a document to be supported by sentence features learned from document subject estimation, reducing the need for actual reference summaries.', 'A fundamental requirement in extractive summarization is the identification of salient sentences from a document that represent key subjects mentioned in the document.': 'The authors propose a general framework for summarization that formalizes the estimation of document subjects as a document classification task and solves document summarization in the framework of multitask learning for sentence extraction and document classification. This allows for the selection of sentences relevant to the subjects of an input document.', 'Extractive summarization approaches based on neural network-based approaches require a large number of parameters to be tuned, which can be computationally expensive.': 'The authors propose a multi-task learning method with curriculum learning that supports sentence extraction from a document while solving document classification. This allows for the learning of common feature representations of salient sentences for summarization, reducing the number of parameters that need to be tuned.'}",supervised,"['Financial Reports', 'News']","['identifying-important-contents-from-the-document', 'pretraining-and-sample-efficiency']"
SP:fd36d56a82e64a2183412972877a78e87ea07db3,A Supervised Approach to Extractive Summarisation of Scientific Papers,CONLL,2017,"['Ed Collins', 'Isabelle Augenstein', 'Sebastian Riedel']","Automatic summarisation is a popular approach to reduce a document to its main arguments. Recent research in the area has focused on neural approaches to summarisation, which can be very data-hungry. However, few large datasets exist and none for the traditionally popular domain of scientific publications, which opens up challenging research avenues centered on encoding large, complex documents. In this paper, we introduce a new dataset for summarisation of computer science publications by exploiting a large resource of author provided summaries and show straightforward ways of extending it further. We develop models on the dataset making use of both neural sentence encoding and traditionally used summarisation features and show that models which encode sentences as well as their local and global context perform best, significantly outperforming well-established baseline methods.","The paper discusses the challenges of summarizing large, complex scientific publications using neural approaches, which require large datasets. The authors introduce a new dataset for summarization of computer science publications and develop models using both neural sentence encoding and traditional summarization features. They find that models that encode sentences and their local and global context perform best, outperforming established baseline methods.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to reduce them to their main points.', 'Who is the target audience?': 'The summaries are for scientific publications.', 'How will the summaries be used?': 'The summaries will be used for extractive summarisation of scientific publications, which involves copying parts of a document to form a summary. They can also be used for abstractive summarisation, which involves generating a summary from a document that can contain phrases not appearing in the document. The summaries can be used for research challenges such as encoding very large technical documents and for tasks such as keyphrase extraction, semantic relation extraction, and topic classification of scientific articles.'}","['corpus', 'method']",['Input Encoding'],['CSPubSum'],['ROUGE'],[''],https://github.com/EdCo95/scientific-paper-summarisation,https://aclanthology.org/K17-1021,"{'Existing datasets for summarisation of scientific publications are very small, consisting of tens of documents, which are not sufficient to learn supervised summarisation models relying on neural methods for sentence and document encoding.': 'The authors introduce a new dataset for summarisation of scientific publications consisting of over 10k documents, created by exploiting an existing resource, ScienceDirect, where many journals require authors to submit highlight statements along with their manuscripts.', 'The authors want to improve summarisation performance and extend the dataset automatically.': 'The authors introduce a method, HighlightROUGE, which can be used to automatically extend the dataset and show empirically that this improves summarisation performance.', 'The authors want to extract summaries by exploiting the abstract of a paper.': 'The authors take inspiration from previous work in summarising scientific literature and introduce a metric they use as a feature, AbstractROUGE, which can be used to extract summaries by exploiting the abstract of a paper.', 'The authors want to benchmark several neural as well traditional summarisation methods on the dataset and use simple features to model the global context of a summary statement, which contribute most to the overall score.': 'The authors benchmark several neural as well traditional summarisation methods on the dataset and use simple features to model the global context of a summary statement, which contribute most to the overall score.', 'The authors want to compare their best performing system to several well-established baseline methods and show that their best performing model outperforms them on this extractive summarisation task by a considerable margin.': 'The authors compare their best performing system to several well-established baseline methods, some of which use more elaborate methods to model the global context than they do, and show that their best performing model outperforms them on this extractive summarisation task by a considerable margin.', 'The authors want to analyze to what degree different sections in scientific papers contribute to a summary.': 'The authors analyze to what degree different sections in scientific papers contribute to a summary.'}",supervised,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'lack-of-suitable-training-data']"
SP:5e948ea4699bc8a750b68dcd2c1919b7718ef86a,Enumeration of Extractive Oracle Summaries,EACL,2017,"['Tsutomu Hirao', 'Masaaki Nishino', 'Jun Suzuki', 'Masaaki Nagata']","To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGEn. We also propose an algorithm that enumerates all of the oracle summaries for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following: (1) room still exists to improve the performance of extractive summarization; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.",The paper proposes an Integer Linear Programming formulation to obtain extractive oracle summaries in terms of ROUGEn and an algorithm that enumerates all of the oracle summaries for a set of reference summaries to evaluate system summaries. The experimental results show that there is room for improvement in extractive summarization and that F-measures derived from the enumerated oracle summaries have stronger correlations with human judgment than those derived from single oracle summaries.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the usefulness of extractive summarization as a research topic and compare it with compressive and abstractive summarization methods.', 'Who is the target audience?': 'The summaries are for the research community working on text summarization.', 'How will the summaries be used?': 'The summaries will be used to determine the upper bound of extractive summarization and compare it with the performance of state-of-the-art summarization methods. They will also be used to evaluate the effectiveness of classification-based extractive summarization using F-measures and to scrutinize the failure analysis of systems.'}",['method'],['Objective Function'],['DUC 2004'],['ROUGE'],[''],,https://aclanthology.org/E17-1037,"{'The authors want to determine if extractive summarization is still a useful research topic compared to compressive or abstractive summarization.': 'The authors propose to determine the upper bound of extractive summarization by comparing its performance with state-of-the-art summarization methods using an oracle summary, which is defined as a set of sentences with a maximum ROUGEn score.', 'The authors want to utilize another evaluation measure for extractive summarization.': 'The authors propose to use F-measures, which are useful for evaluating classification-based extractive summarization, by comparing system summaries with oracle summaries to identify important sentence extraction and scrutinize the failure analysis of systems.', 'More than one oracle summary might exist for a set of reference summaries.': 'The authors propose to enumerate the oracle summaries for a set of reference summaries and compute the F-measures based on them.', 'It is difficult to enumerate oracle summaries for a set of reference summaries using ILP solvers.': 'The authors propose an algorithm that efficiently enumerates all oracle summaries by exploiting the branch and bound technique.', 'The authors want to show the effectiveness of their proposed approach.': 'The authors present experimental results on the Document Understanding Conference (DUC) corpora, which show that there is still room for improvement in extractive summarization and that F-measures derived from multiple oracle summaries obtain significantly stronger correlations with human judgment than those derived from single oracle summaries.'}",unsupervised,['News'],['robust-evaluation-methods']
SP:a3e9c525aadf6394f82179dca893fc58cab83c3a,Toward Extractive Summarization of Online Forum Discussions via Hierarchical Attention Networks,AAAI,2017,"['Sansiri Tarnpradab', 'Fei Liu', 'Kien A. Hua']","Forum threads are lengthy and rich in content. Concise thread summaries will benefit both newcomers seeking information and those who participate in the discussion. Few studies, however, have examined the task of forum thread summarization. In this work we make the first attempt to adapt the hierarchical attention networks for thread summarization. The model draws on the recent development of neural attention mechanisms to build sentence and thread representations and use them for summarization. Our results indicate that the proposed approach can outperform a range of competitive baselines. Further, a redundancy removal step is crucial for achieving outstanding results.","

System: This paper discusses the task of forum thread summarization, which has not been extensively studied. The authors propose a model that uses hierarchical attention networks and neural attention mechanisms to build sentence and thread representations for summarization. The results show that their approach outperforms other methods and that removing redundancies is important for achieving the best results.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to benefit both newcomers seeking information and those who participate in the discussion.', 'Who is the target audience?': 'The summaries are for anyone interested in the forum thread discussions, including those who are new to the topic and those who are already participating in the discussion.', 'How will the summaries be used?': 'The summaries will provide a concise overview of the forum thread discussions and can be used to quickly understand the main points and opinions expressed in the thread.'}",['method'],['Input Encoding'],"['TripAdvisor', 'UbuntuForums']",['ROUGE'],[''],,http://arxiv.org/abs/1805.10390,"{'Lack of studies on forum thread summarization.': 'The authors introduce a novel supervised thread summarization approach that is adapted from the hierarchical attention networks (HAN) proposed in (Yang et al. 2016).', 'Traditional approaches to forum thread summarization are largely based on multi-document summarization frameworks.': 'The authors propose a new approach that draws on the recent development of neural attention mechanisms and hierarchical network structures.', 'Lack of annotated datasets for supervised summarization approaches.': 'The authors created a dataset by manually annotating 600 threads with human summaries, allowing the development of a supervised system trained in an end-to-end fashion.', 'Difficulty in predicting summary sentences.': 'The HAN models are effective in predicting summary sentences, and a redundancy removal step is crucial for achieving outstanding results.'}",supervised,['Forum Discussions'],"['information-loss-and-incoherence-in-extractive-summarization', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization', 'identifying-important-contents-from-the-document']"
SP:342563a8013464686edd1c7c38ea932345d00be0,SummaRuNNer: A Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents,AAAI,2017,"['Ramesh Nallapati', 'Feifei Zhai', 'Bowen Zhou']","We present SummaRuNNer, a Recurrent Neural Network (RNN) based sequence model for extractive summarization of documents and show that it achieves performance better than or comparable to state-of-the-art. Our model has the additional advantage of being very interpretable, since it allows visualization of its predictions broken up by abstract features such as information content, salience and novelty. Another novel contribution of our work is abstractive training of our extractive model that can train on human generated reference summaries alone, eliminating the need for sentence-level ex-","The paper presents SummaRuNNer, a Recurrent Neural Network (RNN) based model for extractive summarization of documents. The model achieves performance better than or comparable to state-of-the-art and is very interpretable, allowing visualization of its predictions broken up by abstract features such as information content, salience, and novelty. The paper also introduces abstractive training of the extractive model, which can train on human-generated reference summaries alone, eliminating the need for sentence-level extraction.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to solve the important problem of document summarization, which has many applications in information retrieval and natural language understanding.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used in various applications such as search engines, news aggregation, and content recommendation systems.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'DUC 2002']",['ROUGE'],[''],https://github.com/deepmind/rc-data,http://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14636,"{'Document summarization is an important problem with many applications, and there are two main techniques: extractive and abstractive summarization.': 'The authors provide an overview of the two techniques and their differences.', 'Extractive summarization is the most common approach, and traditional methods can be classified into greedy, graph-based, and constraint optimization approaches.': 'The authors provide an overview of these traditional methods.', 'Neural network-based approaches have become popular for extractive summarization, and there are several recent examples of their use.': 'The authors provide examples of recent neural network-based approaches, including recursive autoencoders, convolutional neural networks, and attention-based models.', 'Abstractive summarization techniques are also becoming increasingly popular, and there are several recent examples of their use.': 'The authors provide examples of recent abstractive summarization techniques, including attentional feed-forward networks and recurrent neural network-based encoder-decoder models.', 'Despite the emergence of abstractive techniques, extractive techniques are still attractive due to their simplicity and effectiveness.': 'The authors explain why extractive techniques are still popular and effective.', 'The authors propose a new approach called SummaRuNNer for extractive summarization using a recurrent neural network-based sequence classifier.': 'The authors describe their new approach and show that it outperforms or matches state-of-the-art models for extractive summarization.', 'The authors also present a novel training mechanism that allows their extractive model to be trained end-to-end using abstractive summaries.': 'The authors describe their training mechanism and show that it improves the performance of their model.'}",supervised,['News'],[]
SP:437e04a16f8952301717ff1c322212347f2ff8b6,Hybrid MemNet for Extractive Summarization,CIKM,2017,"['Abhishek Kumar Singh', 'Manish Gupta', 'Vasudeva Varma']","Extractive text summarization has been an extensive research problem in the eld of natural language understanding. While the conventional approaches rely mostly on manually compiled features to generate the summary, few aempts have been made in developing data-driven systems for extractive summarization. To this end, we present a fully data-driven end-to-end deep network which we call as Hybrid MemNet for single document summarization task. e network learns the continuous unied representation of a document before generating its summary. It jointly captures local and global sentential information along with the notion of summary worthy sentences. Experimental results on two dierent corpora conrm that our model shows signicant performance gains compared with the state-of-the-art baselines.","The paper discusses the problem of extractive text summarization and the limitations of conventional approaches that rely on manually compiled features. The authors propose a data-driven system called Hybrid MemNet, which uses an end-to-end deep network to learn a continuous unified representation of a document and generate its summary. The system captures both local and global sentential information and identifies summary-worthy sentences. Experimental results on two corpora show significant performance gains compared to state-of-the-art baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to make a concise representation of large text while retaining the core meaning of the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to retrieve, analyze and understand a large amount of information, which can be time-consuming.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a document without having to read the entire text. They can be used for various purposes such as research, news, and information gathering.'}",['method'],['Input Encoding'],"['DailyMail', 'DUC 2002']",['ROUGE'],[''],,http://arxiv.org/abs/1912.11701,"{'The tremendous growth of data over the web has increased the need to retrieve, analyze, and understand a large amount of information, which can often be time-consuming. The motivation to make a concise representation of large text while retaining the core meaning of the original text has led to the development of various summarization systems.': 'The authors propose a data-driven, end-to-end enhanced encoder-decoder based deep network that summarizes a news article by extracting salient sentences.', 'Summarization methods can be broadly classified into two categories: extractive and abstractive. Extractive methods aim to select salient phrases, sentences, or elements from the text while abstractive techniques focus on generating summaries from scratch without the constraint of reusing phrases from the original text.': 'The authors focus on extractive summarization and propose the use of memory networks and convolutional bidirectional long short term memory networks for capturing better document representation.', 'Traditional approaches to extractive summarization identify sentences based on human-crafted features such as sentence position and length, the words in the title, the presence of proper nouns, content features like term frequency, and event features like action nouns.': 'The authors propose a purely data-driven approach that uses neural networks to compute sentential features. They apply Convolution Neural Networks (CNN) with multiple filters to automatically capture latent semantic features and a Long Short Term memory (LSTM) network to obtain a comprehensive set of features known as thought vector.', 'Most successful summarization systems use extractive methods, and sentence extraction is a crucial step in such systems.': 'The authors propose a novel architecture to learn better unified document representation combining the features from the memory network as well as the features from convolutional LSTM/BLSTM network. They experiment with Conv-LSTM encoder as well as Convolutional Bidirectional LSTM (Conv-BLSTM) encoder and show that the proposed method outperforms the basic systems and several competitive baselines.'}",supervised,['News'],[]
SP:76698aa73fe1cd2cefee5040ea34a78c4aa045bb,Extractive Summarization with SWAP-NET: Sentences and Words from Alternating Pointer Networks,ACL,2018,"['Aishwarya Jadhav', 'Vaibhav Rajan']","We present a new neural sequence-tosequence model for extractive summarization called SWAP-NET (Sentences and Words from Alternating Pointer Networks). Extractive summaries comprising a salient subset of input sentences, often also contain important key words. Guided by this principle, we design SWAP-NET that models the interaction of key words and salient sentences using a new twolevel pointer network based architecture. SWAP-NET identifies both salient sentences and key words in an input document, and then combines them to form the extractive summary. Experiments on large scale benchmark corpora demonstrate the efficacy of SWAP-NET that outperforms state-of-the-art extractive summarizers.","SWAP-NET is a new neural sequence-to-sequence model for extractive summarization that identifies both salient sentences and key words in an input document, and then combines them to form the extractive summary. The model uses a new two-level pointer network based architecture that models the interaction of key words and salient sentences. Experiments on large scale benchmark corpora demonstrate that SWAP-NET outperforms state-of-the-art extractive summarizers.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to shorten a text document while maintaining the salient information of the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a text document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding large amounts of textual information in various domains.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],[''],https://github.com/aishj10/swap-net,https://aclanthology.org/P18-1014/,"{'Extractive summarization methods may have problems like incorrect or unclear referring expressions or lack of coherence.': 'The authors propose using an attention-based mechanism to select important sentences and words from the input document to generate a more accurate and coherent summary.', 'Classical approaches to extractive summarization rely on human-engineered features from the text, which can be time-consuming and may not capture all relevant information.': 'The authors propose using end-to-end deep learning models that do not require human-crafted features, which have shown to improve performance in several NLP tasks.', 'Extractive summarization methods do not address factual and grammatical errors that may be introduced in the summary.': 'The authors propose using a switch mechanism to select between words and sentences during decoding, which allows for the selection of more accurate and grammatically correct information.', 'Previous models have not explicitly modeled the interaction between key words and salient sentences in the selection process.': 'The authors propose a two-level encoder and decoder architecture that models the interaction between key words and salient sentences, which improves the accuracy and coherence of the generated summary.', 'Labeled data is required for deep learning models, which can be difficult to obtain for summarization tasks.': 'The authors use a labeled dataset of news stories from CNN and Daily Mail consisting of around 280,000 documents and human-generated summaries to train their model.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:ff4b6317ad50b640f8e01e63c64957819afbacfb,Reinforced Extractive Summarization with Question-Focused Rewards,ACL,2018,"['Kristjan Arumae', 'Fei Liu']","We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because human abstracts and source documents cannot be easily aligned at the word level. In this paper we convert human abstracts to a set of Cloze-style comprehension questions. System summaries are encouraged to preserve salient source content useful for answering questions and share common words with the abstracts. We use reinforcement learning to explore the space of possible extractive summaries and introduce a question-focused reward function to promote concise, fluent, and informative summaries. Our experiments show that the proposed method is effective. It surpasses state-of-the-art systems on the standard summarization dataset.","The paper proposes a new training method for extractive summarization using Cloze-style comprehension questions instead of human abstracts, which are often inaccurate due to difficulty aligning them with source documents. The method encourages system summaries to preserve important source content and share common words with the abstracts, and uses reinforcement learning with a question-focused reward function to promote concise, fluent, and informative summaries. Experiments show that the proposed method is effective and outperforms state-of-the-art systems on standard summarization datasets.",{},['method'],['Objective Function'],['CNN'],['ROUGE'],[''],,https://aclanthology.org/P18-3015,"{'Existing supervised approaches to extractive summarization frequently use human abstracts to create annotations for extraction units, but a vast majority of the source words are tagged 0s, only a small portion are 1s.': 'The authors propose to use neural extractive summarization instead of human abstracts to alleviate this issue.', 'Failing to reproduce factual details has been revealed as one of the main obstacles for neural abstractive summarization.': 'The authors choose to focus on neural extractive summarization instead of neural abstractive summarization.', 'Source words that are labelled 0 may be paraphrases, generalizations, or otherwise related to words in the abstracts. These source words are often mislabelled.': 'The authors propose to convert human abstracts to a set of Cloze-style comprehension questions to provide supervision for extractive summarization.', 'The goal of the study is to produce fluent, generic document summaries that are semantically close to human abstracts in addition to sharing common words.': 'The authors investigate an alternative training scheme for extractive summarization and compare two methods to convert human abstracts to Cloze-style questions to achieve this goal.'}",reinforced,['News'],"['hallucinations-in-the-generated-summaries', 'identifying-important-contents-from-the-document']"
SP:df7791d07a10ffd3aa8ada3ab37093d4b67ffb8b,Attentive Encoder-based Extractive Text Summarization,CIKM,2018,"['Chong Feng', 'Fei Cai', 'Honghui Chen', 'Maarten de Rijke']","In previous work on text summarization, encoder-decoder architectures and attention mechanisms have both been widely used. Attention-based encoder-decoder approaches typically focus on taking the sentences preceding a given sentence in a document into account for document representation, failing to capture the relationships between a sentence and sentences that follow it in a document in the encoder. We propose an attentive encoder-based summarization (AES) model to generate article summaries. AES can generate a rich document representation by considering both the global information of a document and the relationships of sentences in the document. A unidirectional recurrent neural network (RNN) and a bidirectional RNN are considered to construct the encoders, giving rise to unidirectional attentive encoder-based summarization (Uni-AES) and bidirectional attentive encoder-based summarization (Bi-AES), respectively. Our experimental results show that Bi-AES outperforms Uni-AES. We obtain substantial improvements over a relevant start-of-the-art baseline.","The paper proposes an attentive encoder-based summarization (AES) model for generating article summaries that considers both the global information of a document and the relationships of sentences in the document. The model uses both unidirectional and bidirectional recurrent neural networks (RNNs) to construct encoders, resulting in unidirectional attentive encoder-based summarization (Uni-AES) and bidirectional attentive encoder-based summarization (Bi-AES). The experimental results show that Bi-AES outperforms Uni-AES and achieves substantial improvements over a relevant baseline.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to quickly locate the key sentences of an article.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to save time when reading long documents, to get a quick overview of a topic, or to help with information retrieval.'}",['method'],['Unit Relationship'],['CNN'],['ROUGE'],[''],,https://doi.org/10.1145/3269206.3269251,"{'Most encoder-decoder-based methods implement an attention mechanism in the decoder rather than in the encoder, where they mainly focus on selecting the sentences that are relevant to the source document but may neglect the relationships between sentences.': 'The authors propose an attentive encoder-based summarization (AES) model for text summarization, which consists of an attention-based document encoder and an attention-based sentence extractor.', 'Relationships of sentences may indicate whether sentences express the same meaning, which may help to make the decision of selecting them into the summary.': 'The proposed AES model takes into account the relationships between sentences to select the correct sentences into an article summary.', 'It is unclear whether a unidirectional or bidirectional RNN is more effective in the document encoder for text summarization.': 'The authors compare the effectiveness of a unidirectional RNN and a bidirectional RNN in their model and find that document encoder composed of a bidirectional RNN produces a better performance for text summarization.', 'It is unclear how the proposed AES model performs on various document lengths and summary lengths.': 'The authors investigate the performance of their models on various documents lengths and for various summary lengths, and find that Bi-AES can generate better summaries for short documents and is more effective when generating longer summaries.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:faebb548eada2bfe036ff968accc0a7e451a6079,Ranking Sentences for Extractive Summarization with Reinforcement Learning,NAACL,2018,"['Shashi Narayan', 'Shay B. Cohen', 'Mirella Lapata']",Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans.,"

System: This paper proposes a new algorithm for single document summarization, which is the task of creating a shorter version of a document while retaining its main information. The algorithm is based on a sentence ranking task and uses a reinforcement learning objective to optimize the ROUGE evaluation metric. The authors trained a neural summarization model using this algorithm on the CNN and DailyMail datasets and found that it outperformed existing extractive and abstractive systems in both automatic and human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to aid users in navigating and digesting web content, question answering, and personalized recommendation engines.', 'Who is the target audience?': 'The summaries are for users who need to access information quickly and efficiently.', 'How will the summaries be used?': 'The summaries will be used to provide a shorter version of a document while preserving its information content, making it easier for users to access and understand the information.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],['QA'],https://github.com/shashiongithub/Refresh,https://aclanthology.org/N18-1158,"{'Cross-entropy training is not optimal for extractive summarization.': 'The authors propose to globally optimize the ROUGE evaluation metric and learn to rank sentences for summary generation through a reinforcement learning objective.', 'Extractive models trained using cross-entropy loss do not necessarily learn to rank sentences based on their importance due to the absence of a ranking-based objective.': 'The authors propose to combine the maximum-likelihood cross-entropy loss with rewards from policy gradient reinforcement learning to directly optimize the evaluation metric relevant for the summarization task.', 'Existing extractive models are prone to generating verbose summaries with unnecessarily long sentences and redundant information.': 'The authors propose a global optimization framework that renders extractive models better at discriminating among sentences for the final summary; a sentence is ranked high for selection if it often occurs in high scoring summaries.'}",reinforced,['News'],"['controlled-and-tailored-summarization', 'identifying-important-contents-from-the-document', 'robust-evaluation-methods']"
SP:67538cf513620914016328d2b8c817bffa877d19,BANDITSUM: Extractive Summarization as a Contextual Bandit,EMNLP,2018,"['Yue Dong', 'Yikang Shen', 'Eric Crawford', 'Herke van Hoof', 'Jackie C.K. Cheung']","In this work, we propose a novel method for training neural networks to perform singledocument extractive summarization without heuristically-generated extractive labels. We call our approach BANDITSUM as it treats extractive summarization as a contextual bandit (CB) problem, where the model receives a document to summarize (the context), and chooses a sequence of sentences to include in the summary (the action). A policy gradient reinforcement learning algorithm is used to train the model to select sequences of sentences that maximize ROUGE score. We perform a series of experiments demonstrating that BANDITSUM is able to achieve ROUGE scores that are better than or comparable to the state-of-the-art for extractive summarization, and converges using significantly fewer update steps than competing approaches. In addition, we show empirically that BANDITSUM performs significantly better than competing approaches when good summary sentences appear late in the source document.","The paper proposes a new method called BANDITSUM for training neural networks to perform single-document extractive summarization without heuristically-generated extractive labels. The approach treats extractive summarization as a contextual bandit problem, where the model chooses a sequence of sentences to include in the summary based on the document context. A policy gradient reinforcement learning algorithm is used to train the model to select sequences of sentences that maximize ROUGE score. The experiments show that BANDITSUM achieves better or comparable ROUGE scores than state-of-the-art approaches and converges using fewer update steps. Additionally, BANDITSUM performs significantly better than competing approaches when good summary sentences appear late in the source document.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide concise and informative representations of the content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and comprehending lengthy documents, as well as to facilitate information retrieval and knowledge discovery.'}",['method'],['Objective Function'],['CNN/DailyMail'],['Relevance Ranking'],"['Overall Quality', 'Coverage', 'Non-redundancy']",https://github.com/yuedongP/summarization_RL,https://aclanthology.org/D18-1409/,"{'Extractive summarization methods suffer from exposure bias and the quality of extractive labels is limited by the quality of the heuristic used to generate them.': 'The authors propose using reinforcement learning to directly optimize a measure of summary quality, such as the ROUGE score, to avoid exposure bias. They also introduce BANDITSUM, a method that formulates extractive summarization as a contextual bandit, which removes the need for supervised pre-training and improves the quality of extractive labels.', 'The search space for extractive summarization is large, making the exploration problem faced by the reinforcement learning algorithm during training very difficult. Additionally, the sequential nature of selection biases the model in favor of selecting earlier sentences over later ones.': 'BANDITSUM does away with the sequential binary labeling setting and instead formulates extractive summarization as a contextual bandit, which greatly reduces the size of the space that must be explored and prevents systematically privileging earlier sentences over later ones. BANDITSUM outputs an affinity for each sentence in the document, which is used in a process of repeated sampling-without-replacement that does not privilege earlier sentences over later ones.', 'The performance of extractive summarization models is limited when good sentences occur late in the source article.': 'The authors show that the contextual bandit setting greatly improves model performance when good sentences occur late without sacrificing performance when good sentences occur early. They also provide evidence that the improved performance of BANDITSUM over competitors stems in part from better handling of summary-worthy sentences that come near the end of the document.'}",reinforced,['News'],[]
SP:0f05267fcc096dd32b28377ef68c40e541c89d3c,Harnessing Popularity in Social Media for Extractive Summarization of Online Conversations,EMNLP,2018,"['Ryuji Kano', 'Yasuhide Miura', 'Motoki Taniguchi', 'Yan-Ying Chen', 'Francine Chen', 'Tomoko Ohkuma']","We leverage a popularity measure in social media as a distant label for extractive summarization of online conversations. In social media, users can vote, share, or bookmark a post they prefer. The number of these actions is regarded as a measure of popularity. However, popularity is not determined solely by content of a post, e.g., a text or an image it contains, but is highly based on its contexts, e.g., timing, and authority. We propose Disjunctive model that computes the contribution of content and context separately. For evaluation, we build a dataset where the informativeness of comments is annotated. We evaluate the results with ranking metrics, and show that our model outperforms the baseline models which directly use popularity as a measure of informativeness.",The paper discusses using popularity measures in social media as a way to summarize online conversations. They propose a Disjunctive model that separates the contribution of content and context in determining popularity. They evaluate their model using a dataset where the informativeness of comments is annotated and show that their model outperforms baseline models that use popularity as a measure of informativeness.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of online conversations to organize overwhelming information from these conversations.', 'Who is the target audience?': 'The summaries are for researchers who are working on summarizing online conversations.', 'How will the summaries be used?': 'The summaries will be used to develop state-of-the-art models in both abstractive and extractive summarization tasks based on neural networks, which require large amounts of training data.'}",['method'],"['External Knowledge', 'Data Augmentation']",['Reddit Threads'],['ROUGE'],[''],,https://aclanthology.org/D18-1144,"{'The overwhelming amount of information in online conversations makes it difficult to summarize them.': 'The authors propose summarizing online conversations using distant labels as a way to reduce the need for manual labeling. They leverage a measure of popularity as a distant label for extractive summarization.', 'Popularity is not solely determined by content but is highly affected by contexts, such as timing and authority.': 'The authors propose a Disjunctive model that computes two scalar values, one from a content feature and the other from a context feature, to exclude the effect of context. These two values are then multiplied to predict the popularity, and the scalar values can be interpreted as the contribution of content and context to the prediction.', 'The appropriateness of the number of extracts is unknown.': 'The authors employ ranking metrics in the evaluation to extract informative posts. They build a test dataset where comments are annotated for informativeness, and they select Reddit as a data source, where the karma score, a measure of popularity in Reddit, is known to be affected by contexts.', 'Baseline models that directly adopt karma scores as an indicator of informativeness do not perform well.': 'The authors demonstrate that their model outperforms baseline models that directly adopt karma scores as an indicator of informativeness. Furthermore, their model focuses on a local feature of a single post, whereas conventional centrality-based models use a global context of posts. The complementary hybrid of both models outperforms both the centrality-based models and their models.'}",supervised,['Forum Discussions'],['lack-of-suitable-training-data']
SP:8e745fe0df57cbcd4e5ec131125b66399eccba02,Neural Latent Extractive Document Summarization,EMNLP,2018,"['Xingxing Zhang', 'Mirella Lapata', 'Furu Wei', 'Ming Zhou']","Extractive summarization models require sentence-level labels, which are usually created heuristically (e.g., with rule-based methods) given that most summarization datasets only have document-summary pairs. Since these labels might be suboptimal, we propose a latent variable extractive model where sentences are viewed as latent variables and sentences with activated variables are used to infer gold summaries. During training the loss comes directly from gold summaries. Experiments on the CNN/Dailymail dataset show that our model improves over a strong extractive baseline trained on heuristically approximated labels and also performs competitively to several recent models.","System: The paper proposes a new approach to extractive summarization that uses a latent variable model where sentences are viewed as latent variables. This approach avoids the need for heuristically created sentence-level labels, which may be suboptimal. Instead, sentences with activated variables are used to infer gold summaries, and the loss during training comes directly from these summaries. The model was tested on the CNN/Dailymail dataset and was found to outperform a strong extractive baseline trained on heuristically approximated labels and perform competitively with several recent models.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically rewrite them into shorter versions while retaining their most important content.', 'Who is the target audience?': 'The intended audience for the document summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the document summaries will be used.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/D18-1088,"{'Extractive summarization requires sentence-level labels, which are not included in most summarization datasets.': 'The authors propose a latent variable extractive model and view labels of sentences in a document as binary latent variables (i.e., zeros and ones). Instead of maximizing the likelihood of “gold” standard labels, the latent model directly maximizes the likelihood of human summaries given selected sentences.', 'Sentence labels obtained by rule-based methods or by maximizing the ROUGE score between a subset of sentences and the human written summaries might be suboptimal.': 'The authors propose a latent variable extractive model that directly maximizes the likelihood of human summaries given selected sentences, which fully exploits the human summaries.', 'Abstractive models underperform or are on par with the baseline of simply selecting the leading sentences in the document as summaries.': 'The authors propose a latent variable extractive model that improves upon a strong extractive baseline trained on rule-based labels and also performs competitively to several recent models.'}",supervised,['News'],['robust-evaluation-methods']
SP:e207151e8aeed9ae0f59d3e145e73dc2dad22d06,DeepChannel: Salience Estimation by Contrastive Learning for Extractive Document Summarization,AAAI,2019,"['Jiaxin Shi', 'Chen Liang', 'Lei Hou', 'Juanzi Li', 'Zhiyuan Liu', 'Hanwang Zhang']","We propose DeepChannel, a robust, data-efficient, and interpretable neural model for extractive document summarization. Given any document-summary pair, we estimate a salience score, which is modeled using an attention-based deep neural network, to represent the salience degree of the summary for yielding the document. We devise a contrastive training strategy to learn the salience estimation network, and then use the learned salience score as a guide and iteratively extract the most salient sentences from the document as our generated summary. In experiments, our model not only achieves state-of-the-art ROUGE scores on CNN/Daily Mail dataset, but also shows strong robustness in the out-of-domain test on DUC2007 test set. Moreover, our model reaches a ROUGE-1 F-1 score of 39.41 on CNN/Daily Mail test set with merely 1/100 training set, demonstrating a tremendous data efficiency.","DeepChannel is a neural model for extractive document summarization that uses a salience score to represent the importance of sentences in a document. The salience score is estimated using an attention-based deep neural network, and the model uses a contrastive training strategy to learn the salience estimation network. The most salient sentences are iteratively extracted from the document to generate a summary. The model achieves state-of-the-art ROUGE scores on the CNN/Daily Mail dataset and shows strong robustness in out-of-domain tests. It also demonstrates tremendous data efficiency, achieving a high ROUGE-1 F-1 score with only 1/100 of the training set.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to compress a textual document to a shorter highlight that contains the most representative information of the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be particularly useful for tasks such as information retrieval and decision-making.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'DUC 2007']",['ROUGE'],[''],https://github.com/lliangchenc/DeepChannel,https://doi.org/10.1609/aaai.v33i01.33016999,"{'Existing neural summarizers mostly aim to build an end-to-end mapping from the input document to its summary, which requires a huge amount of training corpus, easily suffers from the overfitting problem, and usually lacks interpretability.': 'The authors propose a neural extractive summarizer named DeepChannel, which estimates salience for guiding the extraction procedure instead of learning an end-to-end mapping. They design a neural channel model to draw support from the great representation power of deep learning. Given any document-summary pair (D,S), they learn a channel probability (i.e., salience score) P (D|S), representing that they start with a short summary S and add “noise” to it, yielding a longer document, how likely D is produced. They design an attention-based neural network to model the channel probability, and train it with a contrastive training strategy. With a well-learned P (D|S), they produce the optimal summary S∗ = argmaxSP (D|S) by greedily extracting the most salient sentences which have a maximum probability to expand to the whole document.', 'Statistical approaches for summarization depend on manual rules, lack generality, suffer from data sparsity, and fail to capture semantics, which is the key for document understanding.': 'The authors propose a neural channel model to draw support from the great representation power of deep learning. Compared with the statistical noisy-channel, their neural model can make use of semantics involved in distributed representations, alleviate the training sparseness, and avoid the high-cost expert-designed rules.', 'Most state-of-the-art approaches usually learn a direct mapping from a document to its annotated summary, which is not robust to domain variations and suffers from the overfitting problem.': 'The authors propose a salience estimation that learns a mapping from any document-summary pair to a salience score. It brings two significant benefits: 1) Their model is more robust to domain variations. DeepChannel performs much better than other end-to-end baselines when testing on DUC 2007 while training on CNN/Daily Mail. 2) Their model is much more data-efficient and alleviates the overfitting problem to a great degree. DeepChannel performs well even when they reduce the size of the CNN/Daily Mail training set to 1/100.', 'Existing summarization systems lack interpretability.': 'The authors demonstrate that their model shows high interpretability due to the well-designed attention mechanism. They conduct quantitative and qualitative experiments on the standard CNN/Daily Mail benchmark, demonstrating that their model not only performs on par with state-of-the-art summarization systems but also shows high interpretability.'}",supervised,['News'],[]
SP:8bfedb07730514218d6cc52de9c3a478e92bd572,Reward Learning for Efficient Reinforcement Learning in Extractive Document Summarisation,IJCAI,2019,"['Yang Gao', 'Christian Meyer', 'Mohsen Mesgar', 'Iryna Gurevych']","Document summarisation can be formulated as a sequential decision-making problem, which can be solved by Reinforcement Learning (RL) algorithms. The predominant RL paradigm for summarisation learns a cross-input policy, which requires considerable time, data and parameter tuning due to the huge search spaces and the delayed rewards. Learning input-specific RL policies is a more efficient alternative but so far depends on handcrafted rewards, which are difficult to design and yield poor performance. We propose RELIS, a novel RL paradigm that learns a reward function with Learning-to-Rank (L2R) algorithms at training time and uses this reward function to train an input-specific RL policy at test time. We prove that RELIS guarantees to generate near-optimal summaries with appropriate L2R and RL algorithms. Empirically, we evaluate our approach on extractive multi-document summarisation. We show that RELIS reduces the training time by two orders of magnitude compared to the state-of-the-art models while performing on par with them.","The paper proposes a new approach to document summarization using Reinforcement Learning (RL) algorithms. The approach, called RELIS, learns a reward function with Learning-to-Rank (L2R) algorithms at training time and uses this reward function to train an input-specific RL policy at test time. This approach reduces training time by two orders of magnitude compared to state-of-the-art models while performing on par with them. The authors prove that RELIS guarantees to generate near-optimal summaries with appropriate L2R and RL algorithms. The approach is evaluated on extractive multi-document summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents as a form of extractive document summarization, which is a popular summarization paradigm that selects important phrases or sentences from input documents.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of the input documents without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and resources by providing a condensed version of the input documents, and can be applied to various natural language generation tasks such as translation and sentence simplification.'}",['method'],['Objective Function'],"['DUC 2001', 'DUC 2002', 'DUC 2004']",['ROUGE'],[''],https://github.com/UKPLab/ijcai2019-relis,https://doi.org/10.24963/ijcai.2019/326,"{'Learning cross-input policies in RL-based summarisation systems is very expensive due to the huge search space.': 'The authors propose a novel paradigm called REward Learning for Input-Specific reinforcement learning (RELIS) that learns a cross-input reward oracle at training time and uses the learnt reward to train an input-specific policy for each input at test time.', 'Delayed rewards in RL-based summarisers cause them to take longer time to converge.': 'The authors propose using Learning-to-Rank (L2R) algorithms to approximate the ground-truth reward oracle from ""weak supervisions"" such as numeric scores that indicate the quality of the summary or preferences over summary pairs.', 'Designing a reward function for input-specific RL is highly challenging as it should fit all inputs.': 'The authors propose using RELIS, which learns a cross-input reward oracle at training time and uses the learnt reward to train an input-specific policy for each input at test time, thus reducing the size of the search space and diminishing the training time and computational resources.'}",reinforced,['News'],[]
SP:bb418a05a024a2590c3aa5f204006e32c7138548,Neural Extractive Text Summarization with Syntactic Compression,EMNLP,2019,['Jiacheng Xu'],"Recent neural network approaches to summarization are largely either selection-based extraction or generation-based abstraction. In this work, we present a neural model for single-document summarization based on joint extraction and syntactic compression. Our model chooses sentences from the document, identifies possible compressions based on constituency parses, and scores those compressions with a neural model to produce the final summary. For learning, we construct oracle extractive-compressive summaries, then learn both of our components jointly with this supervision. Experimental results on the CNN/Daily Mail and New York Times datasets show that our model achieves strong performance (comparable to state-of-the-art systems) as evaluated by ROUGE. Moreover, our approach outperforms an off-theshelf compression module, and human and manual evaluation shows that our model’s output generally remains grammatical.","The paper discusses recent neural network approaches to summarization, which are either selection-based extraction or generation-based abstraction. The authors present a neural model for single-document summarization that combines extraction and syntactic compression. The model selects sentences from the document, identifies possible compressions based on constituency parses, and scores those compressions with a neural model to produce the final summary. The authors construct oracle extractive-compressive summaries for learning and achieve strong performance on the CNN/Daily Mail and New York Times datasets, outperforming an off-the-shelf compression module. Human and manual evaluation shows that the model's output generally remains grammatical.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for single document news summarization datasets.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of a document without having to read the entire document. They can also be used for information retrieval and other natural language processing tasks.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT']",['ROUGE'],['Grammaticality'],https://github.com/jiacheng-xu/neu-compression-sum,https://aclanthology.org/D19-1324,"{'Extractive and abstractive summarization systems have their own strengths and weaknesses.': 'The authors propose a model that combines the high performance of neural extractive systems, additional flexibility from compression, and interpretability given by having discrete compression options.', 'There has been little work studying neural network models that combine extractive and compressive systems.': 'The authors propose a model that sequentially selects a set of sentences to further compress, with each sentence having a set of compression options available that are selected to preserve meaning and grammaticality.', 'Constructing the oracle summary for supervision in an extractive and compressive model is a principal challenge.': ""The authors identify a set of high-quality sentences from the document with beam search and derive oracle compression labels in each sentence through an additional refinement process. Their model's training objective combines these extractive and compressive components and learns them jointly."", 'The fluency and grammaticality of compressed sentences generated by the model need to be investigated.': 'The authors conduct a human evaluation that shows that their system yields generally grammatical output, with many remaining errors being attributed to the parser.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:2cf33c67ca55114f338aa10f6cd5a9f4674b23e5,Exploiting Discourse-Level Segmentation for Extractive Summarization,EMNLP,2019,"['Zhengyuan Liu', 'Nancy F. Chen']","Extractive summarization selects and concatenates the most essential text spans in a document. Most, if not all, neural approaches use sentences as the elementary unit to select content for summarization. However, semantic segments containing supplementary information or descriptive details are often nonessential in the generated summaries. In this work, we propose to exploit discourse-level segmentation as a finer-grained means to more precisely pinpoint the core content in a document. We investigate how the sub-sentential segmentation improves extractive summarization performance when content selection is modeled through two basic neural network architectures and a deep bi-directional transformer. Experiment results on the CNN/Daily Mail dataset show that discourse-level segmentation is effective in both cases. In particular, we achieve state-of-the-art performance when discourse-level segmentation is combined with our adapted contextual representation model.","The paper proposes using discourse-level segmentation to improve extractive summarization, as it can more precisely identify the core content in a document compared to using sentences as the elementary unit. The authors investigate the effectiveness of this approach using two basic neural network architectures and a deep bi-directional transformer, and achieve state-of-the-art performance when combining discourse-level segmentation with their adapted contextual representation model on the CNN/Daily Mail dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to automatically generate a shorter version of one or multiple documents while retaining the most important information.', 'Who is the target audience?': 'The intended audience for the document summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the document summaries will be used.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],"['ROUGE', 'METEOR']",[''],,https://aclanthology.org/D19-5415,"{'The selected content in current neural approaches for document summarization is often not succinct enough, diluting the density of key information in the summary.': 'The authors propose to benefit from finer-grained text segmentation by splitting documents into sub-sentential segments following their discourse structure, which can help pinpoint key information more precisely. They use the rhetorical structure theory (RST) to guide this segmentation.', 'Sentence-level extraction in document summarization often includes nonessential phrases or clauses, diluting the density of key information in the summary.': 'The authors propose to use discourse-level segmentation to create more concise summaries by removing nonessential phrases or clauses.', 'Traditional approaches to document summarization rely heavily on human-engineered features, which is time-consuming and difficult to expand to massive data.': 'The authors propose to use neural networks trained in an end-to-end manner with fewer linguistic annotations, achieving favorable improvements on large-scale benchmarks.', 'The authors need to compare different selector architectures for document summarization.': 'The authors empirically compare a multi-layer recurrent neural network (RNN) and a Transformer network, as they each have their own model assumptions and knowledge representations. They also finetune a contextualized language model based on the deep bi-directional Transformer.', 'The authors need to demonstrate the effectiveness of their proposed approach.': 'The authors conduct experiments on the CNN/Daily Mail dataset and show that discourse-level segmentation combined with an adapted large-scale pre-trained model of contextualized language representation achieves state-of-the-art performance.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:61d7e9ce87aaee068c42546277385f2efd1e5e98,Extractive Summarization of Long Documents by Combining Global and Local Context,EMNLP,2019,"['Wen Xiao', 'Giuseppe Carenini']","In this paper, we propose a novel neural singledocument extractive summarization model for long documents, incorporating both the global context of the whole document and the local context within the current topic. We evaluate the model on two datasets of scientific papers , Pubmed and arXiv, where it outperforms previous work, both extractive and abstractive models, on ROUGE-1, ROUGE-2 and METEOR scores. We also show that, consistently with our goal, the benefits of our method become stronger as we apply it to longer documents. Rather surprisingly, an ablation study indicates that the benefits of our model seem to come exclusively from modeling the local context, even for the longest documents.","The paper proposes a new neural summarization model for long documents that considers both global and local context. The model outperforms previous work on two scientific paper datasets and shows that its benefits increase with longer documents. Surprisingly, the study finds that the benefits of the model come mainly from modeling the local context, even for the longest documents.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract informative sentences, especially for long documents like scientific articles.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the most important information in a given document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly get an overview of the main topics and findings discussed in the document.'}",['method'],['Input Encoding'],"['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/Wendy-Xiao/Extsumm_local_global_context,https://aclanthology.org/D19-1298,"{'Single-document summarization is a challenging task that requires an in-depth understanding of the source document, and current automatic solutions are still far from human performance.': 'The authors propose to focus on extracting informative sentences from a given document (without dealing with redundancy), especially when the document is relatively long (e.g., scientific articles).', 'Extractive methods for single-document summarization may contain much redundancy and lack in coherence across sentences, while abstractive methods may include misleading or even utterly false statements.': 'The authors propose to use an extractive method that picks sentences directly from the original document based on their importance, and form the summary as an aggregate of these sentences.', 'Most recent works on neural extractive summarization struggle with longer sequences in long documents.': 'The authors propose to capture a distributed representation of both the global (the whole document) and the local context (e.g., the section/topic) when deciding if a sentence should be included in the summary, using LSTM-minus to learn embeddings of text spans.', 'Only one previous work in extractive summarization has explicitly leveraged section information to guide the generation of summaries, but it only uses categorical feature values.': 'The authors propose to capture a distributed representation of both the global and local context to exploit section information when deciding if a sentence should be included in the summary.', 'It is unclear whether the proposed method effectively summarizes long documents.': 'The authors test their method on the Pubmed and arXiv datasets and find that it outperforms the baseline and previous approaches, especially for longer documents.', 'It is unclear whether the benefits of the proposed method come from modeling the global or local context.': 'The authors conduct an ablation study and find that the benefits of their method come exclusively from modeling the local context, even for the longest documents.', 'There is a lack of annotated datasets for extractive summarization.': 'The authors create oracle labels for both Pubmed and arXiv using a greedy oracle labeling algorithm and make the datasets annotated with extractive labels public.'}",supervised,['Scholarly Documents'],['exploiting-the-structure-of-long-documents']
SP:4c919783fcf15ef7b7e96561e297a499cd702d23,Reading Like HER: Human Reading Inspired Extractive Summarization,EMNLP,2019,"['Ling Luo', 'Xiang Ao', 'Yan Song', 'Feiyang Pan', 'Min Yang', 'Qing He']","In this work, we re-examine the problem of extractive text summarization for long documents. We observe that the process of extracting summarization of human can be divided into two stages: 1) a rough reading stage to look for sketched information, and 2) a subsequent careful reading stage to select key sentences to form the summary. By simulating such a two-stage process, we propose a novel approach for extractive summarization. We formulate the problem as a contextualbandit problem and solve it with policy gradient. We adopt a convolutional neural network to encode gist of paragraphs for rough reading, and a decision making policy with an adapted termination mechanism for careful reading. Experiments on the CNN and DailyMail datasets show that our proposed method can provide high-quality summaries with varied length, and significantly outperform the state-of-the-art extractive methods in terms of ROUGE metrics.",The paper proposes a new approach to extractive text summarization for long documents by simulating the two-stage process of human summarization. The approach uses a convolutional neural network to encode the gist of paragraphs for rough reading and a decision-making policy with an adapted termination mechanism for careful reading. The problem is formulated as a contextual bandit problem and solved with policy gradient. Experiments on the CNN and DailyMail datasets show that the proposed method provides high-quality summaries with varied length and outperforms state-of-the-art extractive methods in terms of ROUGE metrics.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents for NLP applications such as producing digests, headlines, and reports.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main idea of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding large amounts of text, and can be applied in various fields such as news, research, and business.'}",['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],"['Coverage', 'Non-redundancy', 'Overall Quality']",,https://doi.org/10.18653/v1/D19-1300,"{'Existing extractive summarization methods neglect how human beings read and form summaries, leading to suboptimal results.': 'The authors propose a new approach called HER (Human-bEing-Reading inspired extractive summarization) that simulates human reading cognitive process. They simplify the three-stage reading process to two stages called rough reading and careful reading, and use a hierarchical neural network for rough reading and a neural network to score each sentence for careful reading. They formulate the whole process as a contextual bandit problem and train a reinforcement learning agent to solve it using the policy gradient method.', 'Existing extractive summarization methods tend to extract earlier sentences over later ones due to the sequential nature of selection.': 'The authors use a multi-armed bandit policy with an adapted termination mechanism to select various but proper numbers of sentences during careful reading, which helps to avoid bias towards earlier sentences.', 'Existing extractive summarization methods are usually explored as either abstractive or extractive summarizations, with extractive methods being more practical and applicable.': 'The authors focus on extractive summarization and propose a new approach that improves upon existing extractive methods by simulating human reading cognitive process. They show that their proposed model can outperform state-of-the-art methods and provide high-quality summaries.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:c1a8d7d6472dc6d0e993813d962cb0952c92134e,Guiding Extractive Summarization with Question-Answering Rewards,NAACL,2019,"['Kristjan Arumae', 'Fei Liu']","Highlighting while reading is a natural behavior for people to track salient content of a document. It would be desirable to teach an extractive summarizer to do the same. However, a major obstacle to the development of a supervised summarizer is the lack of ground-truth. Manual annotation of extraction units is costprohibitive, whereas acquiring labels by automatically aligning human abstracts and source documents can yield inferior results. In this paper we describe a novel framework to guide a supervised, extractive summarization system with question-answering rewards. We argue that quality summaries should serve as a document surrogate to answer important questions, and such question-answer pairs can be conveniently obtained from human abstracts. The system learns to promote summaries that are informative, fluent, and perform competitively on question-answering. Our results compare favorably with those reported by strong summarization baselines as evaluated by automatic metrics and human assessors.",The paper discusses the challenge of developing a supervised summarization system due to the lack of ground-truth data. The authors propose a novel framework that uses question-answering rewards to guide the system in producing informative and fluent summaries that perform well on question-answering tasks. The system learns from human abstracts and aims to produce summaries that can answer important questions. The results show that the proposed framework outperforms strong summarization baselines as evaluated by automatic metrics and human assessors.,{},['method'],['Objective Function'],['CNN/DailyMail'],['ROUGE'],"['QA', 'Informativeness']",https://github.com/ucfnlp/summ_qa_rewards,https://aclanthology.org/N19-1264,"{'Neural abstractive summarization can alter or falsify objective details and introduce new meanings not present in the original text, leading to misinterpretation of the source materials.': 'The authors focus on extractive summarization, which guarantees to remain faithful to the original content by identifying salient and consecutive sequences of words from the source document and highlighting them in the text to assist users in browsing and comprehending lengthy documents.', 'Extractive summarizers lack annotated data, and using human abstracts to derive labels for extraction units can be suboptimal since summary saliency cannot be easily captured with a rule-based categorization.': 'The authors investigate a new strategy that seeks to better utilize human abstracts to guide the extraction of summary text units by identifying answer tokens from each sentence of the human abstract and replacing each answer token with a blank to create a Cloze-style question-answer pair. The system summary must contain content that is semantically close to and collectively resembles the human abstract to answer all questions.', 'There is a need for a novel framework generating extractive summaries by selecting consecutive sequences of words from source documents that explores various encoding mechanisms and new sampling techniques to capture phrase level data.': 'The authors describe a novel framework generating extractive summaries by selecting consecutive sequences of words from source documents that utilizes a novel reinforcement learning framework to explore the space of possible extractive summaries and assess each summary using a novel reward function judging the summary’s adequacy, fluency, length, and its competency to answer important questions.', 'Automatic summarization evaluation methods may not fully capture the information saliency of the summaries.': 'The authors conduct a methodical empirical evaluation from the point of view of information saliency by assessing the summary quality with reading comprehension tasks. Their summaries compare favorably with the automatic metrics against state of the art and show promising results against baselines when evaluated by humans for question answering.'}",reinforced,['News'],['hallucinations-in-the-generated-summaries']
SP:5408611ca425b7fb0363348d784489bfe44aa50d,STRASS: A Light and Effective Method for Extractive Summarization Based on Sentence Embeddings,ACL,2019,"['Léo Bouscarrat', 'Antoine Bonnefoy', 'Thomas Peel', 'Cécile Pereira', 'EURA NOVA']","This paper introduces STRASS: Summarization by TRAnsformation Selection and Scoring. It is an extractive text summarization method which leverages the semantic information in existing sentence embedding spaces. Our method creates an extractive summary by selecting the sentences with the closest embeddings to the document embedding. The model learns a transformation of the document embedding to minimize the similarity between the extractive summary and the ground truth summary. As the transformation is only composed of a dense layer, the training can be done on CPU, therefore, inexpensive. Moreover, inference time is short and linear according to the number of sentences. As a second contribution, we introduce the French CASS dataset, composed of judgments from the French Court of cassation and their corresponding summaries. On this dataset, our results show that our method performs similarly to the state of the art extractive methods with effective training and inferring time.","The paper introduces STRASS, an extractive text summarization method that selects sentences with the closest embeddings to the document embedding. The model learns a transformation of the document embedding to minimize the similarity between the extractive summary and the ground truth summary. The training is inexpensive and can be done on CPU, and the inference time is short and linear. The paper also introduces the French CASS dataset and shows that the method performs similarly to state-of-the-art extractive methods with effective training and inferring time.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents because numerous industries are faced with a growing amount of textual data that they need to process. Creating summary by hand is a costly and time-demanding task, thus automatic methods to generate them are necessary.', 'Who is the target audience?': 'The summaries are for industries that need to process a large amount of textual data.', 'How will the summaries be used?': 'The summaries will be used to process a large amount of textual data in an efficient and cost-effective manner.'}",['method'],['Input Encoding'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/P19-2034/,"{'Creating summaries by hand is a costly and time-consuming task.': 'Automatic methods to generate summaries are necessary.', 'Redundancy can be a problem when generating longer summaries using abstractive summarization.': 'See et al. (2017) introduced a pointer-generator model (PGN) that generates summaries by copying words from the text or generating new words. Moreover, they added a coverage loss to avoid repetitions on long summaries.', 'The PGN model is slow to learn and generate.': 'Paulus et al. (2017) added a layer of reinforcement learning on an encoder-decoder architecture to improve the PGN model.', 'It is hard to find datasets for extractive summarization tasks.': 'Nallapati et al. (2016a) introduced a way to train an extractive summarization model without labels by applying a Recurrent Neural Network (RNN) and using a greedy matching approach based on ROUGE. Recently, Narayan et al. (2018b) combined reinforcement learning and an encoder-decoder architecture to extract and select sentences.', 'Some models using only abstractors can be slow.': 'Some models combine extractive and abstractive summarization, using an extractor to select sentences and then an abstractor to rewrite them. These models are generally faster than models using only abstractors while maintaining or even improving the quality of the summaries.', 'There is a need for an inexpensive, scalable, CPU-trainable and efficient method of extractive text summarization.': 'The authors propose a method of extractive text summarization based on the use of sentence embeddings. They suggest that similar embeddings are semantically similar, and so by looking at the proximity of the embeddings it is possible to rank the sentences.', 'There is a lack of datasets for extractive summarization in French.': 'The authors introduce the French CASS dataset, composed of 129,445 judgments with their corresponding summaries.'}",supervised,"['News', 'Legal Proceedings']",['information-loss-and-incoherence-in-extractive-summarization']
SP:d9cd16f7cbf45015b59650bcb925c6601bdc84ff,Extractive Summarization as Text Matching,ACL,2020,"['Ming Zhong', 'Pengfei Liu', 'Yiran Chen', 'Danqing Wang', 'Xipeng Qiu', 'Xuanjing Huang']","This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a semantic space. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the framework with a simple form of a matching model, we have driven the state-of-the-art extractive result on CNN/DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five datasets also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in https://github. com/maszhongming/MatchSum.","The paper proposes a new approach to building neural extractive summarization systems by formulating the task as a semantic text matching problem. This paradigm shift is based on a comprehensive analysis of the gap between sentence-level and summary-level extractors. The authors demonstrate the effectiveness of the matching framework by achieving state-of-the-art results on the CNN/DailyMail dataset and five other datasets. They also release their codes, processed dataset, and generated summaries to encourage further research in this area.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress the textual document to a shorter highlight while keeping salient information on the original text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as information retrieval, question answering, and natural language inference. They can also be used to save time and improve efficiency in reading and understanding large amounts of text.'}",['method'],"['Input Encoding', 'Unit Selection']","['CNN/DailyMail', 'XSum', 'Multi-News', 'Reddit-TIFU', 'WikiHow', 'PubMed']",['ROUGE'],[''],https://github.com/maszhongming/MatchSum,https://aclanthology.org/2020.acl-main.552,"{'Most of the neural extractive summarization systems score and extract sentences one by one from the original text, resulting in high redundancy and ignoring the coupling of multiple sentences.': 'Introduce an auto-regressive decoder or Trigram Blocking to allow the scoring operations of different sentences to influence each other and remove duplication.', 'Sentence-level extractors do not consider the semantics of the entire summary, leading to the selection of highly generalized sentences.': 'Propose a summary-level framework (MATCHSUM) that conceptualizes extractive summarization as a semantic text matching problem, where a good summary should be more semantically similar to the source document than unqualified summaries.', 'Limited to the architecture of sentence-level summarizers, reinforcement learning (RL) has been utilized to achieve summary-level scoring.': 'Propose a Siamese-BERT architecture to compute the similarity between the source document and the candidate summary, leveraging pre-trained BERT in a Siamese network structure to derive semantically meaningful text embeddings that can be compared using cosine-similarity.'}",supervised,"['News', 'Social Media', 'Scholarly Documents']",['information-loss-and-incoherence-in-extractive-summarization']
SP:4fc2a5d851bd46d954344b9ee5c4d865f53dde7a,Bridging Hierarchical and Sequential Context Modeling for Question-driven Extractive Answer Summarization,SIGIR,2020,"['Yang Deng', 'Wenxuan Zhang', 'Yaliang Li', 'Min Yang', 'Wai Lam', 'Ying Shen', 'Hong Kong', '2Alibaba']","Non-factoid question answering (QA) is one of the most extensive yet challenging application and research areas of retrieval-based question answering. In particular, answers to non-factoid questions can often be too lengthy and redundant to comprehend, which leads to the great demand on answer sumamrization in non-factoid QA. However, the multi-level interactions between QA pairs and the interrelation among different answer sentences are usually modeled separately on current answer summarization studies. In this paper, we propose a unified model to bridge hierarchical and sequential context modeling for question-driven extractive answer summarization. Specifically, we design a hierarchical compare-aggregate method to integrate the interaction between QA pairs in both wordlevel and sentence-level into the final question and answer representations. After that, we conduct the question-aware sequential extractor to produce a summary for the lengthy answer. Experimental results show that answer summarization benefits from both hierarchical and sequential context modeling and our method achieves superior performance on WikiHowQA and PubMedQA. ACM Reference Format: Yang Deng1, Wenxuan Zhang1, Yaliang Li2, Min Yang3, Wai Lam1, Ying Shen4,∗. 2020. Bridging Hierarchical and Sequential Context Modeling for Question-driven Extractive Answer Summarization. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ’20), July 25–30, 2020, Virtual Event, China.ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3397271.3401208",The paper discusses the challenges of answer summarization in non-factoid question answering and proposes a unified model that integrates hierarchical and sequential context modeling for question-driven extractive answer summarization. The model uses a hierarchical compare-aggregate method to integrate the interaction between QA pairs in both word-level and sentence-level into the final question and answer representations. The question-aware sequential extractor is then used to produce a summary for the lengthy answer. The experimental results show that the proposed method achieves superior performance on WikiHowQA and PubMedQA.,{},['method'],"['Unit Relationship', 'Objective Function']","['WikiHowQA', 'PubMedQA']",['ROUGE'],[''],https://github.com/dengyang17/hscm,https://doi.org/10.1145/3397271.3401208,"{'Original answers in non-factoid QA often contain irrelevant and redundant information, leading to reading difficulties and misunderstandings for other users.': 'Text summarization can be an effective approach to tackle the issue of answer redundancy. The authors focus on extractive answer summarization, which is computationally efficient and can generate more grammatical and coherent summaries.', 'The imbalance of information in the question and answer causes difficulties in differentiating the semantic relevancy among answer sentences with the question.': 'The authors propose a special design to carefully model the interaction between the question and the original answer to tackle the issue of information imbalance.', 'Existing extractive answer summarization studies often underutilize the interaction information between the question and answer during the extraction process or rely heavily on feature engineering for relevance measurement.': 'The authors propose to hierarchically model the relevant information between QA pairs in both word-level and sentence-level to obtain suitable sentence representations for the concerned answer summarization task. They also use a sequential modeling approach to capture the correlation among different sentences in the original answer.', 'Current query-based summarization and answer sentence selection methods both fall short in capturing the correlation among different sentences in the original answer, which is supposed to be of great importance in extractive summarization settings.': 'The authors bridge the Hierarchical and Sequential Context Modeling (HSCM) for question-driven extractive answer summarization. They propose a hierarchical compare-aggregate method to integrate the hierarchical interaction information between question-answer pairs in both word-level and sentence-level into a sequential extractive summarization model.'}",supervised,['CQA'],[]
SP:19db69b0b3f59b476018be035fd3923f1b37ccc2,Heterogeneous Graph Neural Networks for Extractive Document Summarization,ACL,2020,"['Danqing Wang', 'Pengfei Liu', 'Yining Zheng', 'Xipeng Qiu', 'Xuanjing Huang']","As a crucial step in extractive document summarization, learning cross-sentence relations has been explored by a plethora of approaches. An intuitive way is to put them in the graphbased neural network, which has a more complex structure for capturing inter-sentence relationships. In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HETERSUMGRAPH), which contains semantic nodes of different granularity levels apart from sentences. These additional nodes act as the intermediary between sentences and enrich the cross-sentence relations. Besides, our graph structure is flexible in natural extension from a singledocument setting to multi-document via introducing document nodes. To our knowledge, we are the first one to introduce different types of nodes into graph-based neural networks for extractive document summarization and perform a comprehensive qualitative analysis to investigate their benefits. The code will be released on Github1.","System: The paper presents a new approach called HETERSUMGRAPH for extractive document summarization. It uses a graph-based neural network that includes semantic nodes of different granularity levels, which act as intermediaries between sentences and enrich cross-sentence relations. The graph structure is flexible and can be extended from a single-document setting to multi-document by introducing document nodes. The authors claim to be the first to introduce different types of nodes into graph-based neural networks for extractive document summarization and have performed a comprehensive qualitative analysis to investigate their benefits. The code for HETERSUMGRAPH will be released on Github.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract relevant sentences and reorganize them as a summary.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, as well as for information retrieval and knowledge management purposes.'}",['method'],['Unit Relationship'],"['CNN/DailyMail', 'NYT', 'Multi-News']",['ROUGE'],[''],https://github.com/brxx122/HeterSUMGraph,https://aclanthology.org/2020.acl-main.553,"{'Current models for extractive document summarization struggle to capture sentence-level long-distance dependency, especially in the case of long documents or multidocuments.': 'The authors propose a heterogeneous graph network that models the relations between sentences and other semantic units, such as words. This approach enriches the relationships between sentences and allows for different granularities of information to be fully used through multiple message passing processes.', 'It is challenging to find an effective graph structure for summarization.': 'The authors introduce more semantic units as additional nodes in the graph to act as intermediaries that connect sentences. This approach allows for different sentences to interact with each other in consideration of the explicit overlapping word information, and for word nodes to aggregate information from sentences and get updated.', 'Existing models for extractive document summarization rely on external tools and need to take account of the error propagation problem.': ""The authors' proposed framework is very flexible in extension and can be easily adapted from single-document to multi-document summarization tasks. Their model outperforms all existing competitors on three benchmark datasets without the need for pre-trained language models. Ablation studies and qualitative analysis show the effectiveness of their models.""}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:9b2124f7d839e36795a810fb6a0feee952a7c809,Discourse-Aware Neural Extractive Text Summarization,ACL,2020,"['Jiacheng Xu', 'Zhe Gan', 'Yu Cheng', 'Jingjing Liu']","Recently BERT has been adopted for document encoding in state-of-the-art text summarization models. However, sentence-based extractive models often result in redundant or uninformative phrases in the extracted summaries. Also, long-range dependencies throughout a document are not well captured by BERT, which is pre-trained on sentence pairs instead of documents. To address these issues, we present a discourse-aware neural summarization model DISCOBERT1. DISCOBERT extracts sub-sentential discourse units (instead of sentences) as candidates for extractive selection on a finer granularity. To capture the long-range dependencies among discourse units, structural discourse graphs are constructed based on RST trees and coreference mentions, encoded with Graph Convolutional Networks. Experiments show that the proposed model outperforms state-of-the-art methods by a significant margin on popular summarization benchmarks compared to other BERT-base models.","The paper introduces a new neural summarization model called DISCOBERT1, which addresses issues with sentence-based extractive models and the limitations of BERT in capturing long-range dependencies in documents. DISCOBERT extracts sub-sentential discourse units and constructs structural discourse graphs to capture long-range dependencies, which are encoded with Graph Convolutional Networks. The proposed model outperforms state-of-the-art methods on popular summarization benchmarks compared to other BERT-base models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide a concise and informative representation of the main ideas and events in the text.', 'Who is the target audience?': 'The summaries are intended for readers who want to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as to provide an overview of a document, to aid in decision-making, or to facilitate information retrieval.'}",['method'],['Unit Relationship'],"['CNN/DailyMail', 'NYT']",['ROUGE'],"['Coherence', 'Grammaticality', 'Overall Quality']",https://github.com/jiacheng-xu/DiscoBERT,https://aclanthology.org/2020.acl-main.451,"{'Hybrid methods suffer from disconnection between the two stages in the pipeline.': 'The authors propose DISCOBERT, a discourse-aware neural extractive summarization model built upon BERT, which performs compression with extraction simultaneously and reduces redundancy across sentences by taking Elementary Discourse Unit (EDU) as the minimal selection unit for extractive summarization.', 'Modeling long-range context for document summarization remains a challenge.': 'The authors propose to finetune the representations of discourse units with the injection of prior knowledge to leverage intra-sentence discourse relations. They also propose two discourse-oriented graphs, RST Graph GR and Coreference Graph GC, and impose Graph Convolutional Network (GCN) to capture long-range interactions among EDUs.', 'Standard encoders such as LSTM or Transformer on top of BERT do not bring in much performance gain for modeling inter-sentential relations.': 'The authors propose to operate on the discourse unit level and discard redundant details in sub-sentences, therefore retaining additional capacity to include more concepts or events, leading to more concise and informative summaries.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:390654e819ca4e397cbe1cca3b5bd352a7adf304,Fact-level Extractive Summarization with Hierarchical Graph Mask on BERT,COLING,2020,"['Ruifeng Yuan', 'Zili Wang', 'Wenjie Li']","Most current extractive summarization models generate summaries by selecting salient sentences. However, one of the problems with sentence-level extractive summarization is that there exists a gap between the human-written gold summary and the oracle sentence labels. In this paper, we propose to extract fact-level semantic units for better extractive summarization. We also introduce a hierarchical structure, which incorporates the multi-level of granularities of the textual information into the model. In addition, we incorporate our model with BERT using a hierarchical graph mask. This allows us to combine BERT’s ability in natural language understanding and the structural information without increasing the scale of the model. Experiments on the CNN/DaliyMail dataset show that our model achieves state-of-the-art results.",The paper proposes a new approach to extractive summarization that focuses on fact-level semantic units rather than individual sentences. The model uses a hierarchical structure to incorporate multiple levels of textual information and is combined with BERT using a hierarchical graph mask to improve natural language understanding. The experiments on the CNN/DaliyMail dataset show that the proposed model achieves state-of-the-art results.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to generate a compressed shorter highlight of a given document that covers the most important information conveyed in the source text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be particularly useful for professionals who need to stay up-to-date with the latest research in their field.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],['Fact-Precision'],https://github.com/Ruifeng-paper/FactExsum-coling2020,https://aclanthology.org/2020.coling-main.493/,"{'There exists a gap between the human-written gold summary and the training objective in sentence-level extractive summarization models.': 'Extract facts, a granularity between phrases and sentences, as the primary textual units to generate summaries. Develop a heuristic algorithm to split a sentence into several smaller units, where each unit is considered as a single fact description. Apply a one-to-one strategy to match each fact in the gold summary to one fact in the source text to obtain the oracle label. Import a hierarchical structure to remedy the information loss after splitting sentences into facts.', 'Overlapping contents and over-extraction in sentence-level extractive summarization models.': 'Extract facts instead of sentences to reduce redundancy and over-extraction.', 'Difficulty in imposing structure information when fine-tuning the BERT model in a downstream task.': 'Propose a graph-based mask algorithm to impose the structure information on BERT directly.', 'Inability to fully utilize the advantage of pretrained language models when separately encoding representations for each granularity with BERT and then capturing the structure information with a graph network stacked upon the encoder.': 'Directly impose the structure information on BERT with a graph-based mask to jointly learn contextual representations of different text granularities within a single BERT.', 'Lack of a comprehensive approach to combining the pretrained language model and the structure information without increasing the scale of the model.': 'Propose a graph-based mask algorithm to impose the structure information on BERT directly, providing a new idea for fine-tuning pretrained models on downstream tasks.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents']"
SP:54a7851c08aee7b24db7d08c09ad80bb252c31a9,Neural Extractive Summarization with Hierarchical Attentive Heterogeneous Graph Network,EMNLP,2020,"['Ruipeng Jia', 'Yanan Cao', 'Hengzhu Tang', 'Fang Fang', 'Cong Cao', 'Shi Wang']","Sentence-level extractive text summarization is substantially a node classification task of network mining, adhering to the informative components and concise representations. There are lots of redundant phrases between extracted sentences, but it is difficult to model them exactly by the general supervised methods. Previous sentence encoders, especially BERT, specialize in modeling the relationship between source sentences. While, they have no ability to consider the overlaps of the target selected summary, and there are inherent dependencies among target labels of sentences. In this paper, we propose HAHSum (as shorthand for Hierarchical Attentive Heterogeneous Graph for Text Summarization), which well models different levels of information, including words and sentences, and spotlights redundancy dependencies between sentences. Our approach iteratively refines the sentence representations with redundancy-aware graph and delivers the label dependencies by message passing. Experiments on large scale benchmark corpus (CNN/DM, NYT, and NEWSROOM) demonstrate that HAHSum yields ground-breaking performance and outperforms previous extractive summarizers.","The paper discusses the challenges of sentence-level extractive text summarization, particularly in modeling redundancy between extracted sentences. The authors propose a new approach called HAHSum, which uses a hierarchical attentive heterogeneous graph to model different levels of information and spotlight redundancy dependencies between sentences. The approach iteratively refines sentence representations with a redundancy-aware graph and delivers label dependencies by message passing. Experiments on large-scale benchmark corpora demonstrate that HAHSum outperforms previous extractive summarizers.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to select subset sentences and assemble them as informative and concise summaries.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding documents, and can be particularly useful for tasks such as information retrieval and document summarization.'}",['method'],['Unit Relationship'],"['CNN/DailyMail', 'NYT', 'Newsroom']",['ROUGE'],"['Informativeness', 'Fluency']",,https://aclanthology.org/2020.emnlp-main.295,"{'Single document extractive summarization aims to balance the salience and redundancy of sentences, but it is difficult to model the dependency exactly.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) to extract sentences by simultaneously balancing salience and redundancy. The model constructs the source article as a hierarchical heterogeneous graph (HHG) with both words and sentences as nodes and different types of edges to represent their relations. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information. The model extracts summary sentences simultaneously instead of using an autoregressive paradigm and a top-k strategy.', 'Previous approaches to extractive summarization utilize autoregressive architecture, which faces error propagation and exposure bias problems, and reinforcement learning, which combines the maximum-likelihood cross-entropy loss with the rewards from policy gradient to directly optimize the evaluation metric for the summarization task.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) that extracts summary sentences simultaneously instead of using an autoregressive paradigm and a top-k strategy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.', 'Previous models generally use top-k strategy as an optimal strategy, which conflicts with the real world where the number of selected sentences varies.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) that is able to extract flexible quantity of sentences with a threshold, instead of top-k strategy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.', 'Previous approaches to extractive summarization are difficult to measure the salience and redundancy simultaneously with error propagation.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) to extract sentences by simultaneously balancing salience and redundancy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.', 'Previous models utilize autoregressive architecture, which just models the unidirectional dependency between sentences, i.e., the state of the current sentence is based on previously sentence labels.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) that extracts summary sentences simultaneously instead of using an autoregressive paradigm and a top-k strategy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.', 'Previous models generally extract three sentences from the source articles (top-3 strategy), although 40% documents in CNN/DM contain more or less than 3-sentences oracle summary.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) that is able to extract flexible quantity of sentences with a threshold, instead of top-k strategy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.', 'Previous models rewrite, compress, or match the extracted salient sentences.': 'The authors propose a hierarchical attentive heterogeneous graph based model (HAHSum) that extracts summary sentences simultaneously instead of using an autoregressive paradigm and a top-k strategy. The model includes an Abstract Layer to learn the semantic representation of each word and a Redundancy Layer to pre-label each sentence and iteratively update the label dependencies by propagating redundancy information.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:da453e74ad0e1b2ea56ba61e8bcc76030400db1c,On Extractive and Abstractive Neural Document Summarization with Transformer Language Models,EMNLP,2020,"['Jonathan Pilault', 'Raymond Li', 'Sandeep Subramanian', 'Christopher Pal']","We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher ROUGE scores. We provide extensive comparisons with strong baseline methods, prior state of the art work as well as multiple variants of our approach including those using only transformers, only extractive techniques and combinations of the two. We examine these models using four different summarization tasks and datasets: arXiv papers, PubMed papers, the Newsroom and BigPatent datasets. We find that transformer based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human generated abstracts. We include a human evaluation, finding that transformers are ranked highly for coherence and fluency, but purely extractive methods score higher for informativeness and relevance. We hope that these architectures and experiments may serve as strong points of comparison for future work.1","The paper presents a method for producing abstractive summaries of long documents using neural abstractive summarization. The method involves performing a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information. The approach produces more abstractive summaries compared to prior work that employs a copy mechanism, while still achieving higher ROUGE scores. The authors provide extensive comparisons with strong baseline methods and multiple variants of their approach, using four different summarization tasks and datasets. They find that transformer-based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human-generated abstracts. A human evaluation shows that transformers are ranked highly for coherence and fluency, but purely extractive methods score higher for informativeness and relevance. The authors hope that their architectures and experiments may serve as strong points of comparison for future work.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress the content while preserving key information and meaning.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they can potentially be used for various purposes such as providing a quick overview of a long document or aiding in information retrieval.'}",['method'],['Unit Selection'],"['arXiv', 'PubMed', 'Newsroom', 'BigPatent']",['ROUGE'],"['Coherence', 'Fluency', 'Informativeness', 'Relevance']",,https://aclanthology.org/2020.emnlp-main.748,"{'Transformer Language Models (TLMs) trained on web text can inadvertently learn to perform abstractive summarization, since a large crawl of web documents may contain some documents which have a “tl;dr” token followed by a summary. However, a model trained from such web-crawl data does not enforce strong conditioning on the text to be summarized, resulting in low summarization quality.': 'The authors explicitly configure autoregressive transformer models to generate summaries in an intentional and focused manner by ordering the passages of an input text, correctly structuring the task definition and training procedure. They also examine the impact of combining this approach with simple but high quality extractive techniques.', 'Memory considerations make it difficult to scale pure language models to long documents. Further, much of the content of a long document is not needed to create a summary.': 'The authors explore a hybrid approach which combines an extractive and abstractive approach. They achieve this by using an initial extractive step that reduces the amount of context for a subsequent abstractive step. They restructure the input to a TLM by reordering the document and inserting standardized delimiters to identify the introduction, extracted sentences, summary, and rest-of-the-article. With this method, the resulting TLM can focus its attention on the relevant content and its model complexity on the summarization task.', 'Typical seq2seq approaches for summarization are not effective for long documents.': 'The authors find that TLMs are surprisingly effective at summarizing long documents, outperforming typical seq2seq approaches, even without using copying/pointing mechanisms, an encoder or additional losses. They extensively compare their hybrid extractive and abstractive approach to long document summarization with different variants of their model, strong and simple baselines as well as with state-of-the-art summarization models.'}",supervised,"['News', 'Scholarly Documents', 'Patents']","['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents', 'robust-evaluation-methods']"
SP:2b285bf04413f6919399c8ef0f6f02529cc11ff6,Conditional Neural Generation using Sub-Aspect Functions for Extractive News Summarization,EMNLP,2020,"['Zhengyuan Liu', 'Ke Shi', 'Nancy F. Chen']","Much progress has been made in text summarization, fueled by neural architectures using large-scale training corpora. However, in the news domain, neural models easily overfit by leveraging position-related features due to the prevalence of the inverted pyramid writing style. In addition, there is an unmet need to generate a variety of summaries for different users. In this paper, we propose a neural framework that can flexibly control summary generation by introducing a set of subaspect functions (i.e. importance, diversity, position). These sub-aspect functions are regulated by a set of control codes to decide which sub-aspect to focus on during summary generation. We demonstrate that extracted summaries with minimal position bias is comparable with those generated by standard models that take advantage of position preference. We also show that news summaries generated with a focus on diversity can be more preferred by human raters. These results suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences, which is useful since it is often impractical to articulate such preferences for different applications a priori.","The paper discusses the challenges of text summarization in the news domain, where neural models easily overfit due to the inverted pyramid writing style and the need to generate a variety of summaries for different users. The authors propose a neural framework that can flexibly control summary generation by introducing subaspect functions (importance, diversity, position) regulated by control codes. They demonstrate that extracted summaries with minimal position bias are comparable to those generated by standard models that take advantage of position preference, and that news summaries generated with a focus on diversity can be more preferred by human raters. The authors suggest that a more flexible neural summarization framework providing more control options could be desirable in tailoring to different user preferences.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to automatically generate a shorter version of the source content while retaining the most important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for a variety of purposes, such as quickly understanding news articles or scientific papers, or for generating application-specific summaries.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'AMI']",['ROUGE'],"['Informativeness', 'Coherence']",,https://aclanthology.org/2020.findings-emnlp.131,"{'Position bias is a major problem in extractive summarization, especially in the news domain, where sentences appearing earlier tend to be more important for summarization tasks. This tendency is common due to the classic textbook writing style of the “inverted pyramid”, but news articles can be presented in various ways, and salient information could also be scattered across the entire article, depending on the chosen writing style of the journalist. Neural models easily overfit on position-related features in extractive summarization tasks, resulting in sub-optimal models with fancy neural architectures that do not generalize well to other domains.': 'The authors propose a research methodology direction to disentangle position bias from important and non-redundant summary content. They adopt control codes on sub-aspects to condition summary generation and provide a systematic approach to investigate and analyze how one might minimize position bias in extractive news summarization in neural modeling. They utilize control codes based on sub-aspects functions to label the training data and implement their conditional generation approach with a neural selector model. Modulation with semantic sub-aspects can reduce systemic bias learned on a news corpus and improve potential generality across domains.', 'Ground-truth construction for summarization becomes an under-constrained assignment without any explicit instructions and targeted applications or user preferences. Therefore, it is challenging for end-to-end models to generate alternative summaries without proper anchoring from reference summaries, making it harder for such models to reach their full potential.': 'The authors propose a flexible neural summarization framework that is able to provide more explicit control options when automatically generating summaries. They follow the spirit of sub-aspect theory and adopt control codes on sub-aspects to condition summary generation. A more flexible summary generation framework could minimize manual labor and generate useful summaries more efficiently.'}",supervised,"['News', 'Meeting Transcripts']",['controlled-and-tailored-summarization']
SP:34183b0857b37e2be343f78d286a58a91535dd9f,Stepwise Extractive Summarization and Planning with Structured Transformers,EMNLP,2020,"['Shashi Narayan', 'Joshua Maynez', 'Jakub Adamek', 'Daniele Pighin', 'Blaz̆ Bratanic', 'Ryan McDonald']","We propose encoder-centric stepwise models for extractive summarization using structured transformers – HiBERT (Zhang et al., 2019) and Extended Transformers (Ainslie et al., 2020). We enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. Our models are not only efficient in modeling the structure of long inputs, but they also do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks. When evaluated on CNN/DailyMail extractive summarization, stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering. This also holds true for Rotowire tableto-text generation, where our models surpass previously reported metrics for content selection, planning and ordering, highlighting the strength of stepwise modeling. Amongst the two structured transformers we test, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges.1","The paper proposes encoder-centric stepwise models for extractive summarization using structured transformers - HiBERT and Extended Transformers. The models enable stepwise summarization by injecting the previously generated summary into the structured transformer as an auxiliary sub-structure. The models are efficient in modeling the structure of long inputs and do not rely on task-specific redundancy-aware modeling, making them a general purpose extractive content planner for different tasks. The stepwise models achieve state-of-the-art performance in terms of Rouge without any redundancy aware modeling or sentence filtering in CNN/DailyMail extractive summarization and Rotowire table-to-text generation. Amongst the two structured transformers tested, stepwise Extended Transformers provides the best performance across both datasets and sets a new standard for these challenges.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to identify and concatenate the most important sentences in a document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be particularly useful for tasks such as information retrieval and decision-making.'}",['method'],['Input Encoding'],['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Readability']",,https://aclanthology.org/2020.emnlp-main.339,"{'Extractive summarization models are prone to contain redundant information.': 'The authors propose using structured transformers to enable stepwise summarization, which injects previously planned summary content as an auxiliary sub-structure to holistically learn document-level coherence properties, such as saliency, redundancy, and ordering, embodied in the gold summaries.', 'Existing models focus on content overlap and length budgets, but not on other dimensions necessary to produce informative and coherent summaries.': 'The proposed models utilize enriched document and summary representations to implicitly learn better extractive plans for producing summaries, such as stepwise summarization.', 'Existing models have limited focus and are either task-specific or not holistic.': 'The proposed models are task-agnostic and can be adapted as an extractive document summarizer or as a content planner for table-to-text generation. They also use structured transformers, which are flexible in terms of content type that can be modeled.', 'Existing models have quadratic attention mechanisms, making them inefficient and unable to process longer inputs.': 'The proposed models use structured encoders, which break the quadratic attention mechanism of transformers, making them more efficient and able to process longer inputs, critical for long inputs and outputs which require non-trivial planning.', 'Existing models for table-to-text generation require dedicated content selection and planning models to generate high-quality summaries.': 'The proposed stepwise framework achieves higher content selection, planning, and ordering scores relative to prior work with task-specific planning mechanisms, demonstrating its effectiveness for table-to-text generation.'}",supervised,"['News', 'Data-to-Text']","['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization']"
SP:0539f8b0b02326452bd1d69cfc0a322b05b6af6c,Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks,COLING,2020,"['Peng Cui', 'Le Hu', 'Yuanchao Liu']","Text summarization aims to compress a textual document to a short summary while keeping salient information. Extractive approaches are widely used in text summarization because of their fluency and efficiency. However, most of existing extractive models hardly capture intersentence relationships, particularly in long documents. They also often ignore the effect of topical information on capturing important contents. To address these issues, this paper proposes a graph neural network (GNN)-based extractive summarization model, enabling to capture intersentence relationships efficiently via graph-structured document representation. Moreover, our model integrates a joint neural topic model (NTM) to discover latent topics, which can provide document-level features for sentence selection. The experimental results demonstrate that our model not only substantially achieves state-of-the-art results on CNN/DM and NYT datasets but also considerably outperforms existing approaches on scientific paper datasets consisting of much longer documents, indicating its better robustness in document genres and lengths. Further discussions show that topical information can help the model preselect salient contents from an entire document, which interprets its effectiveness in long document summarization.","The paper proposes a new approach to extractive text summarization that addresses the limitations of existing models in capturing intersentence relationships and topical information. The proposed model uses a graph neural network to efficiently represent the document structure and a joint neural topic model to discover latent topics for sentence selection. The experimental results show that the proposed model outperforms existing approaches on both short and long document datasets, demonstrating its robustness in different document genres and lengths. The model's effectiveness in long document summarization is attributed to its ability to preselect salient contents using topical information.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to help people rapidly acquire important information from a large sum of documents.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important information contained in a large document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding large documents, and to quickly identify the key points and important information contained within them.'}",['method'],['Unit Relationship'],"['CNN/DailyMail', 'NYT', 'Pubmed', 'arXiv']","['ROUGE', 'Precision@K']",[''],,https://aclanthology.org/2020.coling-main.468,"{'Modeling long-range inter-sentence relationships for summarization remains a challenge.': 'The authors propose a graph-based extractive summarization model that uses a modified graph attention network (GAT) to build a heterogeneous document graph consisting of sentence and topic nodes. This approach efficiently captures inter-sentence relationships and enriches sentence representations with topical information.', 'Pre-trained language models are poor at modeling document-level information, particularly for long documents.': 'The authors encode the entire document with a pre-trained BERT to learn contextual sentence representations and discover latent topics with a joint neural topic model (NTM). This approach effectively captures context features and distills important contents from an entire document.', 'Building an effective document graph for summarization remains an open question.': 'The authors propose a novel graph-based neural extractive summarization model that innovatively incorporates latent topics into graph propagation via a joint neural topic model. This approach builds a topic-sentence document graph that efficiently captures inter-sentence relationships and enriches sentence representations with topical information.'}",supervised,"['News', 'Scholarly Documents']","['efficient-encoding-of-long-documents', 'identifying-important-contents-from-the-document', 'pretraining-and-sample-efficiency']"
SP:826f28a89d2b26483924e621e7c38792e38a129a,DistilSum: Distilling the Knowledge for Extractive Summarization,CIKM,2020,"['Ruipeng Jia', 'Yanan Cao', 'Haichao Shi', 'Fang Fang', 'Yanbing Liu', 'Jianlong Tan']","A popular choice for extractive summarization is to conceptualize it as sentence-level classification, supervised by binary labels. While the common metric ROUGE prefers to measure the text similarity, instead of the performance of classifier. For example, BERTSUMEXT, the best extractive classifier so far, only achieves a precision of 32.9% at the top 3 extracted sentences (P@3) on CNN/DM dataset. It is obvious that current approaches cannot model the complex relationship of sentences exactly with 0/1 targets. In this paper, we introduce DistilSum, which contains teacher mechanism and student model. Teacher mechanism produces high entropy soft targets at a high temperature. Our student model is trained with the same temperature to match these informative soft targets and tested with temperature of 1 to distill for ground-truth labels. Compared with large version of BERTSUMEXT, our experimental result on CNN/DM achieves a substantial improvement of 0.99 ROUGE-L score (text similarity) and 3.95 P@3 score (performance of classifier). Our source code will be available on Github 1.","DistilSum is a new approach to extractive summarization that uses a teacher mechanism and student model to produce high entropy soft targets at a high temperature. The student model is trained to match these targets and then tested with a temperature of 1 to distill for ground-truth labels. Compared to the current best extractive classifier, BERTSUMEXT, DistilSum achieves a substantial improvement in both text similarity and performance of the classifier on the CNN/DM dataset. The source code for DistilSum will be available on Github.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract salient sentences and reduce redundancy.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and to quickly identify relevant information.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT', 'Newsroom']","['ROUGE', 'Accuracy', 'Matthews Correlation Coefficient']",[''],,https://doi.org/10.1145/3340531.3412078,"{'The current approach for single document extractive summarization only selects a subset of sentences from the original article, which results in a low Precision@K score.': 'The authors propose to introduce knowledge distillation to boost the extractive classifier.', 'There is a severe shortage of binary labels in summarization corpus, which bypasses the discriminative features between sentences with label 0.': 'The authors introduce DistilSum, which contains a teacher mechanism and student model to transfer knowledge from teacher to student using soft targets. They propose a greedy smoothing algorithm as a teacher mechanism to produce the soft targets instead of a large trained model.', 'The current approach for extractive summarization does not consider the complexity of sentences.': 'The authors propose to use ALBERT and hierarchical attention to encode sentences into hidden vectors and use another Transformer + MLP as a classifier to address the complexity of sentences.', 'The current approach for extractive summarization does not achieve high performance on CNN/DM, NYT, and Newsroom datasets.': 'The authors validate their proposed architecture on these datasets and show that it significantly outperforms existing methods.'}",supervised,['News'],[]
SP:017bb59b154aea9c4a529b20be23e0559013065e,Goal-Directed Extractive Summarization of Financial Reports,CIKM,2021,"['Yash Agrawal', 'Vivek Anand', 'Manish Gupta', 'S Arunachalam', 'Vasudeva Varma']","Financial reports filed by various companies discuss compliance, risks, and future plans, such as goals and new projects, which directly impact their stock price. Quick consumption of such information is critical for financial analysts and investors to make stock buy/sell decisions and for equity evaluations. Hence, we study the problem of extractive summarization of 10-K reports. Recently, Transformer-based summarization models have become very popular. However, lack of in-domain labeled summarization data is a major roadblock to train such finance-specific summarization models. We also show that zero-shot inference on such pretrained models is not as effective either. In this paper, we address this challenge by modeling 10-K report summarization using a goal-directed setting where we leverage summaries with labeled goal-related data for the stock buy/sell classification goal. Further, we provide improvements by considering a multi-task learning method with an industry classification auxiliary task. Intrinsic evaluation as well as extrinsic evaluation for the stock buy/sell classification and portfolio construction tasks shows that our proposed method significantly outperforms strong baselines.","The paper discusses the importance of extractive summarization of financial reports filed by companies, which impact their stock prices. The lack of in-domain labeled summarization data is a major obstacle to train finance-specific summarization models. The paper proposes a goal-directed approach to modeling 10-K report summarization, leveraging summaries with labeled goal-related data for stock buy/sell classification. The paper also considers a multi-task learning method with an industry classification auxiliary task to provide improvements. The proposed method significantly outperforms strong baselines in intrinsic and extrinsic evaluations for stock buy/sell classification and portfolio construction tasks.","{'What is the purpose of the summaries?': 'The authors are generating summaries of financial documents, specifically 10-K reports, to make it easier for investors to gather important information needed to make investment decisions.', 'Who is the target audience?': 'The summaries are for investors who need to make important decisions about their investments.', 'How will the summaries be used?': 'The summaries will be used to obtain a goal-directed summary which optimizes to predict the stock buy/sell class. They will also be used for intrinsic evaluation of generated summaries and extrinsic evaluation on the stock buy/sell classification task. Finally, they will be used for stock portfolio construction.'}",['method'],"['External Knowledge', 'Auxiliary Tasks']",['10-k Reports'],['ROUGE'],[''],https://tinyurl.com/MHFinSum,https://doi.org/10.1145/3459637.3482113,"{'Summarizing financial documents, specifically 10-K reports, is a challenging task due to their length and complexity.': 'The authors propose to focus on summarizing the Management discussion and analysis (MD&A) section of a 10-K report, which contains the most important forward-looking content. They also use an attention-based classification model to identify summary-worthy sentences.', 'There is a lack of labeled summarization data for financial documents, making evaluation difficult.': 'The authors obtained around 50 documents summarized manually by researchers in the finance domain for intrinsic evaluation of generated summaries. They also assess their summarization system using extrinsic evaluation on the stock buy/sell classification task.', 'A finance-focused summarization dataset is not available to finetune effective Transformer-based summarization methods.': 'The authors propose to use a system that optimizes towards a financial goal, specifically predicting the stock buy/sell class, for which there is a large amount of labeled data available from sources like Yahoo! Finance.', 'The summary needs to be generic enough to contain sentences that indicate whether the stock should be bought or sold as well as sentences that are relevant to the industry sector to which the company belongs.': 'The authors train the model on industry classification (IC) data as an auxiliary task in a multi-task learning setup to help the summary be generic enough to contain both types of sentences.'}",supervised,['Financial Reports'],"['exploiting-the-structure-of-long-documents', 'lack-of-suitable-training-data', 'identifying-important-contents-from-the-document']"
SP:b664a7b6498f0313706ce00df7d2ff629e745154,Deep Differential Amplifier for Extractive Summarization,ACL,2021,"['Ruipeng Jia', 'Yanan Cao', 'Fang Fang', 'Yuchen Zhou', 'Zheng Fang', 'Yanbing Liu', 'Shi Wang']","For sentence-level extractive summarization, there is a disproportionate ratio of selected and unselected sentences, leading to flatting the summary features when optimizing the classification. The imbalanced sentence classification in extractive summarization is inherent, which can’t be addressed by data sampling or data augmentation algorithms easily. In order to address this problem, we innovatively consider the single-document extractive summarization as a rebalance problem and present a deep differential amplifier framework to enhance the features of summary sentences. Specifically, we calculate and amplify the semantic difference between each sentence and other sentences, and apply the residual unit to deepen the differential amplifier architecture. Furthermore, the corresponding objective loss of the minority class is boosted by a weighted cross-entropy. In this way, our model pays more attention to the pivotal information of one sentence, that is different from previous approaches which model all informative context in the source document. Experimental results on two benchmark datasets show that our summarizer performs competitively against state-of-the-art methods. Our source code will be available on Github.","The paper discusses the issue of imbalanced sentence classification in extractive summarization, which cannot be easily addressed by data sampling or augmentation algorithms. To solve this problem, the authors propose a deep differential amplifier framework that calculates and amplifies the semantic difference between each sentence and other sentences, and applies a residual unit to deepen the architecture. The model pays more attention to the pivotal information of one sentence, which is different from previous approaches that model all informative context in the source document. Experimental results show that the proposed summarizer performs competitively against state-of-the-art methods. The source code will be available on Github.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract the most important information and forget the tangential information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the most important information.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT']",['ROUGE'],"['Informativeness', 'Fluency']",,https://aclanthology.org/2021.acl-long.31,"{'It is detrimental to keep tangential information in sentence-level extractive summarization.': 'The authors propose using the Information Bottleneck principle to incorporate a tradeoff between information selection and pruning. They also use length penalty and topic loss in the autoencoding system to augment the reconstruction loss. However, they further propose a heuristic model, DifferSum, to enhance the representation of the summary sentences by calculating and amplifying the semantic difference between each sentence and other sentences, by the subtraction operation.', 'Imbalanced classes inherently result in models that have poor predictive performance, specifically for the minority class.': 'The authors propose using a more appropriate objective function to avoid biasing the data, by making the loss of a minority much greater than the majority. They also propose using the differential amplifier of analog electronics to enhance the representation of the summary sentences. Specifically, they calculate and amplify the semantic difference between each sentence and other sentences, by the subtraction operation. They use the residual unit instead of the second term to make the architecture deeper. DifferSum shows superiority over other extractive methods in compensating the minority class and penalizing the majority ones.'}",supervised,['News'],[]
SP:05f93227ecf057b54ff8027a50df4b3595e5c2e5,Post-Editing Extractive Summaries by Definiteness Prediction,EMNLP,2021,"['Jad Kabbara', 'Jackie Chi Kit Cheung']","Extractive summarization has been the mainstay of automatic summarization for decades. Despite all the progress, extractive summarizers still suffer from shortcomings including coreference issues arising from extracting sentences away from their original context in the source document. This affects the coherence and readability of extractive summaries. In this work, we propose a lightweight postediting step for extractive summaries that centers around a single linguistic decision: the definiteness of noun phrases. We conduct human evaluation studies that show that human expert judges substantially prefer the output of our proposed system over the original summaries. Moreover, based on an automatic evaluation study, we provide evidence for our system’s ability to generate linguistic decisions that lead to improved extractive summaries. We also draw insights about how the automatic system is exploiting some local cues related to the writing style of the main article texts or summary texts to make the decisions, rather than reasoning about the contexts pragmatically.","The paper discusses the limitations of extractive summarization and proposes a postediting step that focuses on the definiteness of noun phrases to improve the coherence and readability of extractive summaries. The proposed system was evaluated through human and automatic evaluation studies, which showed that the system generated improved summaries. The authors also noted that the system relied on local cues rather than pragmatic reasoning to make decisions.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to address the challenge of automatic summarization, which is increasingly pressing with the explosion of information online and elsewhere.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the overall meaning of a source text.', 'How will the summaries be used?': 'The summaries will be used to improve the overall quality of the summary in terms of coherence and readability, and to address issues pertaining to verbosity and coherence that are inherent in extractive summarization.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'PubMed']","['ROUGE', 'Aspect Coverage', 'Aspect-level Sentiment Consistency']","['Coherence', 'Readability', 'Fluency']",,https://aclanthology.org/2021.findings-emnlp.312,"{'Extractive summarization suffers from issues related to coherence and readability, such as selecting a sentence that depends on a non-selected context.': 'The authors propose a lightweight post-editing step following the generation of extractive summaries, which consists of a definiteness prediction model that decides whether articles in the extractive summaries should be kept as is or modified (including the possibility of being removed altogether). The goal of this post-editor is to improve the overall quality of the summary in terms of coherence and readability.', 'Abstractive summarization can lead to problems of factual correctness and consistency.': 'The authors focus on post-editing extractive summaries to form pseudo-extractive outputs, rather than directly developing an abstractive summarizer.', 'It is difficult to evaluate the performance of the proposed method.': 'The authors conduct two studies to understand different aspects of the problem using two English datasets, CNN/DailyMail and PubMed. They examine how often expert judges prefer summaries modified by such a system over the original version of generated extractive summaries, and carry out an annotation study to obtain gold standard annotations on the definiteness of noun phrases in sampled subsets of extractive summaries that are generated by different summarizers for both CNN/DailyMail and PubMed. By comparing their model’s decisions to the collected annotations, they can evaluate its performance using standard classification accuracy.'}",supervised,"['News', 'Scholarly Documents']",['information-loss-and-incoherence-in-extractive-summarization']
SP:26feff43f03192ebce3ea91f9efcd765bdb353bb,Extractive Opinion Summarization in Quantized Transformer Spaces,TACL,2021,"['Stefanos Angelidis', 'Reinald Kim Amplayo', 'Yoshihiko Suhara', 'Xiaolan Wang', 'Mirella Lapata']","We present the Quantized Transformer (QT), an unsupervised system for extractive opinion summarization. QT is inspired by VectorQuantized Variational Autoencoders, which we repurpose for popularity-driven summarization. It uses a clustering interpretation of the quantized space and a novel extraction algorithm to discover popular opinions among hundreds of reviews, a significant step towards opinion summarization of practical scope. In addition, QT enables controllable summarization without further training, by utilizing properties of the quantized space to extract aspect-specific summaries. We also make publicly available SPACE, a large-scale evaluation benchmark for opinion summarizers, comprising general and aspect-specific summaries for 50 hotels. Experiments demonstrate the promise of our approach, which is validated by human studies where judges showed clear preference for our method over competitive","ones. The paper presents the Quantized Transformer, an unsupervised system for extractive opinion summarization that uses a clustering interpretation of the quantized space and a novel extraction algorithm to discover popular opinions among hundreds of reviews. The system also enables controllable summarization without further training by utilizing properties of the quantized space to extract aspect-specific summaries. The authors also introduce SPACE, a large-scale evaluation benchmark for opinion summarizers, and demonstrate the promise of their approach through experiments and human studies.","{'What is the purpose of the summaries?': 'The authors are generating summaries of online reviews to aid in decision-making by providing a condensed version of customer experiences.', 'Who is the target audience?': 'The summaries are for anyone who relies on online reviews to inform their everyday decisions.', 'How will the summaries be used?': ""The summaries will be used to provide a general overview or a more targeted summary of a particular aspect of interest, such as a hotel's location or cleanliness. They will also be used to evaluate the effectiveness of different opinion summarization models.""}",['method'],['Controlled Generation'],['SPACE'],['ROUGE'],"['Informativeness', 'Coherence', 'Conciseness', 'Non-redundancy']",https://github.com/stangelid/qt,https://aclanthology.org/2021.tacl-1.17,"{'Opinion summarization cannot rely on reference summaries for training, because such meta-reviews are very scarce and their crowdsourcing is unfeasible.': 'The authors propose to use unsupervised neural models for popularity-driven summarization, which do not require reference summaries for training.', 'The inherent subjectivity of review text distorts the notion of information importance used in generic summarization.': 'The authors propose to base useful summaries on opinion popularity, which takes into account conflicting opinions expressed for the same entity.', 'Abstractive summarization suffers from issues of text degeneration, hallucinations, and the undesirable use of first-person narrative.': 'The authors propose to turn to extractive summarization, which aims to construct an opinion summary by selecting a few representative input sentences.', 'Previous work used an unrealistically small number of input reviews and only sparingly investigated controllable summarization.': 'The authors propose to use a large-scale corpus for the evaluation of opinion summarizers, which provides a more realistic input to competing models and investigates controllable summarization.', 'Existing methods do not offer a solution to the lack of supervision in opinion summarization.': 'The authors propose to use the Quantized Transformer (QT), an unsupervised neural model inspired by Vector-Quantized Variational Autoencoders (VQ-VAE), which is trained via sentence reconstruction and capable of aspectspecific summarization without further training.'}",supervised,['Opinions'],"['lack-of-suitable-training-data', 'hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:b9f664a22f2822d65c14333dc0b0f76d49e21a82,Considering Nested Tree Structure in Sentence Extractive Summarization with Pre-trained Transformer,EMNLP,2021,"['Jingun Kwon', 'Naoki Kobayashi', 'Hidetaka Kamigaito', 'Manabu Okumura']","Sentence extractive summarization shortens a document by selecting sentences for a summary while preserving its important contents. However, constructing a coherent and informative summary is difficult using a pre-trained BERT-based encoder since it is not explicitly trained for representing the information of sentences in a document. We propose a nested tree-based extractive summarization model on RoBERTa (NeRoBERTa), where nested tree structures consist of syntactic and discourse trees in a given document. Experimental results on the CNN/DailyMail dataset showed that NeRoBERTa outperforms baseline models in ROUGE. Human evaluation results also showed that NeRoBERTa achieves significantly better scores than the baselines in terms of coherence and yields comparable scores to the state-of-the-art models.","The paper proposes a new model called NeRoBERTa for sentence extractive summarization, which uses nested tree structures consisting of syntactic and discourse trees to improve coherence and informativeness of the summary. The model outperforms baseline models in ROUGE and achieves comparable scores to state-of-the-art models in human evaluation. The paper highlights the difficulty of using pre-trained BERT-based encoders for this task and suggests the use of nested tree structures for better performance.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to create a concise summary while keeping the original content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can be used in various applications such as news articles, research papers, and legal documents.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],"['Coherence', 'Informativeness', 'Readability', 'Non-redundancy']",,https://aclanthology.org/2021.emnlp-main.330,"{'BERT-related methods for sentence extraction-based document summarization have room for improvement in their sentence representations.': 'The authors propose a nested tree-based extractive summarization model on RoBERTa (NeRoBERTa) that utilizes nested tree structures of syntactic and discourse dependency trees to represent sentence information and capture relationships between sentences.', 'Previous works that focused on inter-sentence information using discourse graphs still struggle to construct a coherent summary in human evaluation.': 'NeRoBERTa considers both intra- and inter-sentence information (syntactic and discourse graphs) together as a nested tree, which allows for the capture of long-distance interactions between sentences and the extraction of coherent sentences.', 'The use of ""[CLS]"" tokens in BERT and RoBERTa is insufficient to express sentence information.': 'NeRoBERTa explicitly represents sentence information at ""root"" words for each syntactic dependency tree without relying only on ""[CLS]"" tokens, which allows for the capture of keywords in a sentence for considering textual coherence to other sentences.'}",supervised,['News'],"['controlled-and-tailored-summarization', 'identifying-important-contents-from-the-document']"
SP:929e6cde96e81af20e7eaeb329433452ebc53b83,The Effect of Pretraining on Extractive Summarization for Scientific Documents,NAACL,2021,"['Yash Gupta', 'Pawan Sasanka Ammanamanchi', 'Shikha Bordia', 'Arjun Manoharan', 'Deepak Mittal', 'Ramakanth Pasunuru', 'Manish Shrivastava', 'Maneesh Singh', 'Mohit Bansal', 'Preethi Jyothi']","Large pretrained models have seen enormous success in extractive summarization tasks. We investigate, here, the influence of pretraining on a BERT-based extractive summarization system for scientific documents. We derive performance improvements using an intermediate pretraining step that leverages existing summarization datasets and report state-of-theart results on a recently released scientific summarization dataset, SCITLDR. We systematically analyze the intermediate pretraining step by varying the size and domain of the pretraining corpus, changing the length of the input sequence in the target task and varying target tasks. We also investigate how intermediate pretraining interacts with contextualized word embeddings trained on different domains.","The paper explores the impact of pretraining on a BERT-based extractive summarization system for scientific documents. The authors found that an intermediate pretraining step using existing summarization datasets improved performance and achieved state-of-the-art results on a scientific summarization dataset. They also analyzed the effects of varying the size and domain of the pretraining corpus, changing the length of the input sequence, and varying target tasks. Additionally, they investigated how intermediate pretraining interacts with contextualized word embeddings trained on different domains.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific articles to reduce information overload on researchers and facilitate the quick retrieval of relevant papers from vast amounts of scientific literature.', 'Who is the target audience?': 'The summaries are for researchers who need to quickly retrieve relevant information from scientific articles.', 'How will the summaries be used?': 'The summaries will be used to provide a coherent and succinct summary of an article containing the most salient information from the original article. They will be particularly useful for scientific articles that tend to be long and rich in technical content.'}",['analysis'],['External Knowledge'],"['CNN/DailyMail', 'SCITLDR', 'PubMed']",['ROUGE'],[''],,https://aclanthology.org/2021.sdp-1.9,"{'Factual hallucinations in abstractive summarization.': 'Focus on extractive summarization of scientific articles, which ensures factual accuracy and faithfulness to the source document.', 'Lack of exploration of the effect of pretraining on summarization.': 'Explore the benefits of intermediate pretraining using existing summarization datasets for a target task involving the summarization of scientific articles.', 'Low-resource target tasks like SCITLDR.': 'Intermediate pretraining using labeled summarization datasets (even when containing articles that are very different in domain from scientific articles) is very beneficial to low-resource target tasks like SCITLDR. Derive additional benefits by filtering the intermediate pretraining data to only retain a subset of articles (based on a similarity metric) that best matches the target task.', 'Starting with a BERT-based model pretrained on scientific articles offers only a small advantage compared to the standard BERT-based model as an initialization.': 'The effect of intermediate pretraining is much more significant than starting with a BERT-based model pretrained on scientific articles.', 'Diminishing returns with the intermediate pretraining, as we increase the amount of pretraining data.': 'The benefits from intermediate pretraining diminish with access to sufficiently large amounts of finetuning data in the target task.'}",supervised,"['News', 'Scholarly Documents']","['hallucinations-in-the-generated-summaries', 'pretraining-and-sample-efficiency']"
SP:5214f1cfe77ab7fee5ff9c26d3e2b6735f18d72f,Extractive Summarization Considering Discourse and Coreference Relations based on Heterogeneous Graph,EACL,2021,"['Yin Jou Huang', 'Sadao Kurohashi']","Modeling the relations between text spans in a document is a crucial yet challenging problem for extractive summarization. Various kinds of relations exist among text spans of different granularity, such as discourse relations between elementary discourse units and coreference relations between phrase mentions. In this paper, we propose a heterogeneous graph based model for extractive summarization that incorporates both discourse and coreference relations. The heterogeneous graph contains three types of nodes, each corresponds to text spans of different granularity. Experimental results on a benchmark summarization dataset verify the effectiveness of our proposed method.","System: The paper proposes a model for extractive summarization that incorporates both discourse and coreference relations. The model uses a heterogeneous graph containing three types of nodes, each corresponding to text spans of different granularity. Experimental results on a benchmark summarization dataset show that the proposed method is effective.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the information into a shorter summary.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/2021.eacl-main.265,"{'Extractive summarization requires modeling the relations between text spans throughout the document, which is a complex challenge due to the various types of relations that exist between text spans of different granularity.': 'The authors propose a novel heterogeneous graph based model for extractive summarization, which uses a graph structure to model the document with three types of nodes of different granularity: sentence nodes, EDU nodes, and entity nodes. This approach allows for the incorporation of multiple types of relations simultaneously.', 'Previous works have utilized homogeneous graphs with only one type of nodes, which may not be ideal for encoding the various types of relations between text spans.': 'The authors use heterogeneous graphs, which contain multiple node types and/or multiple edge types, to model the document structure. This approach allows for the incorporation of multiple types of relations between text spans.', 'Existing extractive summarizers mostly extract salient sentences, which may not capture all important information in the document.': 'The authors propose a model that extracts salient EDUs instead of sentences. To identify salient EDUs in a certain sentence, they add edges between sentence nodes and their constituent EDU nodes.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'hallucinations-in-the-generated-summaries', 'identifying-important-contents-from-the-document']"
SP:bff5a72f2e6482b68344480c3cc0684dcbb5baf9,Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents,NAACL,2021,['Peng Cui'],"Neural-based summarization models suffer from the length limitation of text encoder. Long documents have to been truncated before they are sent to the model, which results in huge loss of summary-relevant contents. To address this issue, we propose the sliding selector network with dynamic memory for extractive summarization of long-form documents, which employs a sliding window to extract summary sentences segment by segment. Moreover, we adopt memory mechanism to preserve and update the history information dynamically, allowing the semantic flow across different windows. Experimental results on two large-scale datasets that consist of scientific papers demonstrate that our model substantially outperforms previous state-of-the-art models. Besides, we perform qualitative and quantitative investigations on how our model works and where the performance gain comes from.1","The paper proposes a new approach to extractive summarization of long-form documents using a sliding selector network with dynamic memory. This approach addresses the issue of loss of summary-relevant contents due to the length limitation of text encoder in neural-based summarization models. The sliding window extracts summary sentences segment by segment and the memory mechanism preserves and updates history information dynamically, allowing semantic flow across different windows. Experimental results on two large-scale datasets of scientific papers show that this model outperforms previous state-of-the-art models. Qualitative and quantitative investigations are also performed to understand how the model works and where the performance gain comes from.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to distil salient contents from a textual document.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Input Encoding'],"['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/pcui-nlp/SSN_DM,https://aclanthology.org/2021.naacl-main.470,"{'Existing summarization models fail to achieve desired performance when directly applied in long-form documents, such as scientific papers, due to the truncation operation, which inevitably leads to information loss, especially for extractive models because parts of gold sentences would be inaccessible. In addition, the accurate modeling of long texts remains a challenge.': 'The authors propose a novel extractive summarization model for long-form documents that can summarize documents of arbitrary length without truncation loss. They split the input document into multiple windows and encode them with a sliding encoder sequentially. During this process, they introduce a memory to preserve salient information learned from previous windows, which is used to complete and enrich local texts.', 'The use of a sliding window to process documents separately is not suitable for summarization task because the concatenation of summaries that are independently extracted from local contexts is usually inconsistent with the gold summary of the entire document.': 'The authors propose a novel framework (i.e., a sliding encoder combined with dynamic memory) that provides a general solution for summarizing long documents and can be easily extended to other abstractive and extractive summarization models. The local text representations can capture beyond-window contextual information via the memory module, and the previous selection results are also parameterized in the memory block, allowing the collaboration among summary sentences.', 'The supervised signals will have a negative effect on model behaviors because understanding why certain paragraphs should output an empty result without information conveying from previous texts is confused for the model.': 'The proposed model employs a memory mechanism to address context fragmentation, which preserves salient information learned from previous windows and is used to complete and enrich local texts. This allows the model to better understand the context and avoid producing repetitive and noisy summaries.'}",supervised,['Scholarly Documents'],"['efficient-encoding-of-long-documents', 'hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:8fa7f354d0a232003cb028f6ff2209e2dd57aa57,HETFORMER: Heterogeneous Transformer with Sparse Attention for Long-Text Extractive Summarization,EMNLP,2021,"['Ye Liu', 'Jian-Guo Zhang', 'Yao Wan', 'Congying Xia', 'Lifang He', 'Philip S. Yu']","To capture the semantic graph structure from raw text, most existing summarization approaches are built on GNNs with a pre-trained model. However, these methods suffer from cumbersome procedures and inefficient computations for long-text documents. To mitigate these issues, this paper proposes HETFORMER, a Transformer-based pre-trained model with multi-granularity sparse attentions for long-text extractive summarization. Specifically, we model different types of semantic nodes in raw text as a potential heterogeneous graph and directly learn heterogeneous relationships (edges) among nodes by Transformer. Extensive experiments on both singleand multi-document summarization tasks show that HETFORMER achieves stateof-the-art performance in Rouge F1 while using less memory and fewer parameters.","The paper proposes a new approach for extractive summarization called HETFORMER, which is based on a Transformer-based pre-trained model with multi-granularity sparse attentions. The approach models different types of semantic nodes in raw text as a potential heterogeneous graph and directly learns heterogeneous relationships among nodes by Transformer. The experiments show that HETFORMER achieves state-of-the-art performance in Rouge F1 while using less memory and fewer parameters compared to existing methods that use GNNs with pre-trained models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve document summarization tasks.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of a document without having to read the entire document.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'Multi-News']",['ROUGE'],[''],https://github.com/yeliu918/HETFORMER,https://aclanthology.org/2021.emnlp-main.13,"{'Existing approaches combining Transformer-based pre-trained models with GNNs have limitations in adapting to long-text input, as most pre-trained methods truncate longer documents into a small fixed-length sequence, leading to serious information loss.': 'The authors propose HETFORMER, a HETerogeneous transFORMER-based pre-trained model for long-text extractive summarization using multi-granularity sparse attentions. This approach treats tokens, entities, and sentences as different types of nodes and uses multiple sparse masks as different types of edges to represent the relations, preserving the graph structure of the document even with raw textual input.', 'Existing approaches use pre-trained models as a multilayer feature extractor to learn better node features and build multi-layer GNNs on top of extracted features, which have cumbersome networks and tremendous parameters.': 'The authors eschew GNN and instead rely entirely on a sparse attention mechanism to draw heterogeneous graph structural dependencies between input tokens, reducing the computational overhead of fully-connected attention in Transformers.', 'Existing methods using local-global sparse attention in pre-trained models are not enough to capture multi-level granularities of semantics in complex text summarization scenarios.': 'The authors propose a new structured pre-trained method to capture the heterogeneous structure of documents using multi-granularity sparse attentions, which extends the pre-trained method to longer text extractive summarization instead of truncating the document to small inputs.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'controlled-and-tailored-summarization', 'pretraining-and-sample-efficiency']"
SP:44928b583daa7a412752c203ab53ee37c5cbcafc,Flexible Non-Autoregressive Extractive Summarization with Threshold: How to Extract a Non-Fixed Number of Summary Sentences,AAAI,2021,"['Ruipeng Jia', 'Yanan Cao', 'Haichao Shi', 'Fang Fang', 'Pengfei Yin', 'Shi Wang']","Sentence-level extractive summarization is a fundamental yet challenging task, and recent powerful approaches prefer to pick sentences sorted by the predicted probabilities until the length limit is reached, a.k.a. “Top-K Strategy”. This length limit is fixed based on the validation set, resulting in the lack of flexibility. In this work, we propose a more flexible and accurate non-autoregressive method for single document extractive summarization, extracting a non-fixed number of summary sentences without the sorting step. We call our approach ThresSum as it picks sentences simultaneously and individually from the source document when the predicted probabilities exceed a threshold. During training, the model enhances sentence representation through iterative refinement and the intermediate latent variables receive some weak supervision with soft labels, which are generated progressively by adjusting the temperature with a knowledge distillation algorithm. Specifically, the temperature is initialized with high value and drops along with the iteration until a temperature of 1. Experimental results on CNN/DM and NYT datasets have demonstrated the effectiveness of ThresSum, which significantly outperforms BERTSUMEXT with a substantial improvement of 0.74 ROUGE-1 score on CNN/DM.","The paper proposes a non-autoregressive method for extractive summarization called ThresSum, which extracts a non-fixed number of summary sentences without sorting them by predicted probabilities. Instead, ThresSum picks sentences individually from the source document when the predicted probabilities exceed a threshold. During training, the model enhances sentence representation through iterative refinement and weak supervision with soft labels generated progressively by adjusting the temperature with a knowledge distillation algorithm. ThresSum outperforms BERTSUMEXT with a substantial improvement of 0.74 ROUGE-1 score on CNN/DM dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract important information and reduce the length of the original text.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of the document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes such as research, news, and information gathering. They can also be used to improve accessibility for people with reading difficulties or limited time.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'NYT']",['ROUGE'],"['Informativeness', 'Fluency']",,https://ojs.aaai.org/index.php/AAAI/article/view/17552,"{'Redundant phrases between selected sentences.': 'Introduce an autoregressive decoder, reinforcement learning, or a two-stage decoder to allow different sentences to influence each other. ThresSum proposes iterative refinement to fuse redundant information between selected sentences and supervises the process with knowledge distillation.', 'Fixed number or proportion of summary sentences.': 'Instead of using a ""sort"" step and ""pick"" sorted sentences until the length limit is reached, ThresSum proposes a non-autoregressive decoder that predicts the probability scores of sentence vectors and picks sentences simultaneously and individually when the predicted probability exceeds a threshold. ThresSum also introduces iterative refinement to strengthen the encoder and enhance the sentence representation, allowing for a non-fixed number of summary sentences.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:bd2e795c58e7623f9cb797ff8b75eae3fcbbc166,Multiplex Graph Neural Network for Extractive Text Summarization,EMNLP,2021,"['Baoyu Jing', 'Zeyu You', 'Tao Yang', 'Wei Fan', 'Hanghang Tong']","Extractive text summarization aims at extracting the most representative sentences from a given document as its summary. To extract a good summary from a long text document, sentence embedding plays an important role. Recent studies have leveraged graph neural networks to capture the inter-sentential relationship (e.g., the discourse graph) to learn contextual sentence embedding. However, those approaches neither consider multiple types of inter-sentential relationships (e.g., semantic similarity & natural connection), nor model intra-sentential relationships (e.g, semantic & syntactic relationship among words). To address these problems, we propose a novel Multiplex Graph Convolutional Network (MultiGCN) to jointly model different types of relationships among sentences and words. Based on Multi-GCN, we propose a Multiplex Graph Summarization (Multi-GraS) model for extractive text summarization. Finally, we evaluate the proposed models on the CNN/DailyMail benchmark dataset to demonstrate the effectiveness of our method.","The paper proposes a new approach to extractive text summarization, which involves extracting the most representative sentences from a given document. The authors note that sentence embedding is important for creating a good summary, and that recent studies have used graph neural networks to capture inter-sentential relationships. However, these approaches do not consider multiple types of inter-sentential relationships or intra-sentential relationships. To address these issues, the authors propose a Multiplex Graph Convolutional Network (MultiGCN) to model different types of relationships among sentences and words. They then use this approach to create a Multiplex Graph Summarization (Multi-GraS) model for extractive text summarization. The authors evaluate their approach on the CNN/DailyMail benchmark dataset and demonstrate its effectiveness.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to effectively digest overwhelming information, which has always been a fundamental question in natural language processing.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document, such as researchers, journalists, or professionals in various fields.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and analyzing large amounts of text, and to quickly identify relevant information for further investigation or decision-making.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],"['Coverage', 'Non-redundancy', 'Overall Quality']",,https://aclanthology.org/2021.emnlp-main.11,"{'Existing methods for extractive text summarization only involve one type of edges in the constructed graphs, while sentences are often associated with each other via multiple types of relationships.': ""The authors propose a novel Multiplex Graph Convolutional Network (Multi-GCN) to exploit multiple types of relationships among sentences and words. They introduce two types of graphs: the natural connection graph and the semantic graph, which capture different types of relationships between sentences. They argue that jointly modeling different types of edges will improve the model's performance."", 'Existing methods for extractive text summarization do not take advantage of the valuable relational information among words.': 'The authors propose a Multiplex Graph based Summarization (Multi-GraS) framework that takes into account both the syntactic and semantic relationships among words. They argue that this approach can improve the downstream tasks, such as text classification, information retrieval, and text summarization.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:39626ee66bdff796fb2d845b8762ca56d938f96c,OTExtSum: Extractive Text Summarisation with Optimal Transport,NAACL,2022,"['Peggy Tang', 'Kun Hu', 'Rui Yan', 'Lei Zhang', 'Junbin Gao', 'Zhiyong Wang']","Peggy Tang†, Kun Hu†, Rui Yan, Lei Zhang , Junbin Gao‡, Zhiyong Wang† †School of Computer Science, The University of Sydney Gaoling School of Artificial Intelligence, Renmin University of China International Digital Economy Academy ‡The University of Sydney Business School, The University of Sydney {peggy.tang,junbin.gao,zhiyong.wang}@sydney.edu.au, kuhu6123@uni.sydney.edu.au, ruiyan@ruc.edu.cn,leizhang@idea.edu.cn Abstract","

The paper is written by a group of researchers from various institutions, including the University of Sydney and Renmin University of China. The abstract does not provide a clear indication of the topic or focus of the paper, but it does list the authors' affiliations and contact information. Further analysis of the full paper would be necessary to understand its content and purpose.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense them into a short and succinct summary that covers the semantics of the document with the least redundancy. This helps users quickly browse and understand long documents by focusing on their most important sections.', 'Who is the target audience?': 'The summaries are for users who need to quickly browse and understand long documents, especially in domains requiring formal writing such as legal, science, and journalism documents.', 'How will the summaries be used?': 'The summaries will be used to provide users with a condensed version of the document that covers the most important sections and reduces redundancy. This will help users save time and effort in understanding the document.'}",['method'],['Objective Function'],"['Multi-News', 'BillSum', 'PubMed', 'CNN/DailyMail']",['ROUGE'],[''],https://github.com/peggypytang/OTExtSum/,https://aclanthology.org/2022.findings-naacl.85,"{'Existing extractive summarisation methods may not represent the document from a global perspective, resulting in sub-optimal summaries. Learning-based methods are computationally expensive and lack interpretability for the summarisation process, making it difficult to apply them to different domains with different distributions.': 'The authors propose a non-learning based extractive summarisation method, OTExtSum, which formulates extractive summarisation based on the optimal transport theory. They design two optimisation strategies to approximate the extraction vector, making it applicable to different document domains. OTExtSum provides explainable results in terms of the semantic coverage of the summary.', 'Conventional criteria such as relevance and redundancy are not explicitly modelled in extractive summarisation.': 'The authors conceptualize summarisation as moving the ""semantics"" of a given document to its summary, and the ideal summary is obtained at the minimal transportation cost. This ensures the highest semantic coverage of the given document and the least redundancy in the summary.', 'There have been some studies on OT in NLP, but they generally focus on deriving similarities between words, sentences, and documents.': 'The authors for the first time formulate text summarisation as an OT problem that optimally transports the semantic distributions between two texts (e.g., source document and summary candidate).', 'The quality of the generated summary is not easily interpretable.': 'The authors present an interpretable visualisation of the semantic coverage of a generated summary by visualising the transport plan between summary tokens and document tokens.', ""The proposed method's performance is not evaluated against state-of-the-art non-learning based methods."": 'The authors conduct comprehensive experimental results on four widely used datasets, including CNN/DM, MultiNews, BillSum and PubMed, demonstrating that OTExtSum outperforms the state-of-the-art non-learning based methods.'}",unsupervised,"['News', 'Scholarly Documents', 'Legislative Bills']","['information-loss-and-incoherence-in-extractive-summarization', 'pretraining-and-sample-efficiency']"
SP:a4fd0b6a3e156f1e7bb2f36c5b929c326a925a0e,MemSum: Extractive Summarization of Long Documents Using Multi-Step Episodic Markov Decision Processes,ACL,2022,['Nianlong Gu'],"We introduce MemSum (Multi-step Episodic Markov decision process extractive SUMmarizer), a reinforcement-learning-based extractive summarizer enriched at each step with information on the current extraction history. When MemSum iteratively selects sentences into the summary, it considers a broad information set that would intuitively also be used by humans in this task: 1) the text content of the sentence, 2) the global text context of the rest of the document, and 3) the extraction history consisting of the set of sentences that have already been extracted. With a lightweight architecture, MemSum obtains state-of-the-art test-set performance (ROUGE) in summarizing long documents taken from PubMed, arXiv, and GovReport. Ablation studies demonstrate the importance of local, global, and history information. A human evaluation confirms the high quality and low redundancy of the generated summaries, stemming from MemSum’s awareness of extraction history.","MemSum is a reinforcement-learning-based extractive summarizer that considers the text content of the sentence, the global text context of the rest of the document, and the extraction history consisting of the set of sentences that have already been extracted. It obtains state-of-the-art test-set performance in summarizing long documents taken from PubMed, arXiv, and GovReport. Ablation studies demonstrate the importance of local, global, and history information. A human evaluation confirms the high quality and low redundancy of the generated summaries, stemming from MemSum’s awareness of extraction history.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically summarize a long document into a relatively short text while preserving most of the information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a long document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the main points and key information in the document.'}",['method'],['Objective Function'],"['PubMed', 'arXiv', 'GovReport', 'CNN/DailyMail']",['ROC Curve'],"['Coverage', 'Non-redundancy', 'Overall Quality']",https://github.com/nianlonggu/MemSum,https://aclanthology.org/2022.acl-long.450,"{'Extractive summarization models are not aware of the extraction history, leading to redundancy in the summary.': 'The authors propose to model extractive summarization as a multi-step episodic Markov Decision Process (MDP) that is aware of the extraction history. The agent updates the extraction history at each time step before selecting an action, enabling it to consider the content of the partial summary when selecting a sentence.', 'Extractive summarization models tend to repeatedly add sentences with high scores to a summary, regardless of whether similar sentences have been selected before, leading to redundancy and decreased performance.': 'The proposed multi-step episodic MDP-based model with extraction-history awareness allows for more compact summaries and behaves more robustly to redundancies in documents.', 'Extractive summarization models struggle to efficiently encode local and global sentence states for long documents such as scientific papers or reports.': 'The authors design an extraction agent based on LSTM networks and use a reduced number of attention layers of relatively low dimensionality to efficiently encode local and global sentence states, making the model easily trainable and effective for summarizing long documents.', 'The quality of extractive summarization models is often evaluated using metrics such as ROUGE F1, which do not necessarily reflect the quality of the summary.': 'The authors conduct human evaluations and show that their proposed MemSum summaries are of higher quality than those from a competitive approach, especially by virtue of lower redundancy.'}",reinforced,"['News', 'Scholarly Documents', 'Govt. Reports']","['information-loss-and-incoherence-in-extractive-summarization', 'exploiting-the-structure-of-long-documents']"
SP:f1963f32277ef861ac61f92317f7c6c7f000de84,Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization,ACL,2022,"['Faisal Ladhak', 'Esin Durmus', 'He He', 'Claire Cardie', 'Kathleen McKeown']","Despite recent progress in abstractive summarization, systems still suffer from faithfulness errors. While prior work has proposed models that improve faithfulness, it is unclear whether the improvement comes from an increased level of extractiveness of the model outputs as one naive way to improve faithfulness is to make summarization models more extractive. In this work, we present a framework for evaluating the effective faithfulness of summarization systems, by generating a faithfulnessabstractiveness trade-off curve that serves as a control at different operating points on the abstractiveness spectrum. We then show that the baseline system as well as recently proposed methods for improving faithfulness, fail to consistently improve over the control at the same level of abstractiveness. Finally, we learn a selector to identify the most faithful and abstractive summary for a given document, and show that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets. Moreover, we show that our system is able to achieve a better faithfulnessabstractiveness trade-off than the control at the same level of abstractiveness.","

The paper discusses the issue of faithfulness errors in abstractive summarization systems and proposes a framework for evaluating the effectiveness of such systems. The authors generate a faithfulness-abstractiveness trade-off curve to serve as a control and show that current methods for improving faithfulness fail to consistently improve over the control at the same level of abstractiveness. They then introduce a selector to identify the most faithful and abstractive summary for a given document and demonstrate that this system can attain higher faithfulness scores in human evaluations while being more abstractive than the baseline system on two datasets. Additionally, the authors show that their system achieves a better faithfulness-abstractiveness trade-off than the control at the same level of abstractiveness.","{'What is the purpose of the summaries?': 'The authors are generating abstractive summaries of documents in order to improve the faithfulness of summarization systems.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the content of a document, without having to read the entire document.'}",['metric'],"['Objective Function', 'Unit Selection']","['WikiHow', 'Gigaword']",['ROUGE'],"['Coverage', 'Faithfulness']",https://github.com/fladhak/effective-faithfulness,https://aclanthology.org/2022.acl-long.100,"{'Abstractive summarization systems suffer from faithfulness errors, generating information that is not present in the original text.': 'The authors propose a framework for evaluating progress in faithfulness by considering the effective faithfulness, i.e. the improvement in faithfulness over a baseline system (control) operating at the same level of extractiveness. They split the training examples into different groups by the extractiveness of the summary, and train the control models on each group. Each of these models corresponds to a specific tradeoff between abstractiveness and faithfulness, forming a trade-off curve indicating how much faithfulness can be improved solely by increasing extractiveness. Systems that improve effective faithfulness should lie above this curve.', 'It is unclear whether prior improvements in faithfulness mainly arise from increased extractiveness.': 'The authors use their framework to show that the improved faithfulness of recently proposed methods comes mainly from an increased extractiveness.', 'It is unclear whether it is possible to have a system that can be both more abstractive and more faithful than the baseline system.': 'The authors propose a selector that picks the most abstractive output that is faithful to the source from a set of possible summaries. They train this selector on a small set of human-annotated data. Their proposed system is both more abstractive and more faithful than the baseline, and they show that it is able to improve the effective faithfulness, achieving a better trade-off than the control at the same point on the abstractiveness spectrum.'}",supervised,"['News', 'CQA']","['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:149504f8abcd6483f95bffae056b583e9d32eab0,HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information,ACL,2022,"['Qian Ruan', 'Malte Ostendorff', 'Georg Rehm']","Transformer-based language models usually treat texts as linear sequences. However, most texts also have an inherent hierarchical structure, i. e., parts of a text can be identified using their position in this hierarchy. In addition, section titles usually indicate the common topic of their respective sentences. We propose a novel approach to formulate, extract, encode and inject hierarchical structure information explicitly into an extractive summarization model based on a pre-trained, encoderonly Transformer language model (HiStruct+ model), which improves SOTA ROUGEs for extractive summarization on PubMed and arXiv substantially. Using various experimental settings on three datasets (i. e., CNN/DailyMail, PubMed and arXiv), our HiStruct+ model outperforms a strong baseline collectively, which differs from our model only in that the hierarchical structure information is not injected. It is also observed that the more conspicuous hierarchical structure the dataset has, the larger improvements our method gains. The ablation study demonstrates that the hierarchical position information is the main contributor to our model’s SOTA performance.","The paper proposes a new approach to improve extractive summarization models by explicitly incorporating hierarchical structure information into a pre-trained, encoder-only Transformer language model. The proposed HiStruct+ model outperforms a strong baseline on three datasets, including PubMed and arXiv, and the improvement is more significant for datasets with more conspicuous hierarchical structures. The ablation study shows that the hierarchical position information is the main contributor to the model's state-of-the-art performance.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract important sentences and provide a condensed version of the text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, as well as to provide a quick overview of the content for those who need to make decisions based on the information in the document.'}",['method'],"['Unit Relationship', 'Input Encoding']","['CNN/DailyMail', 'PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/QianRuan/histruct,https://aclanthology.org/2022.findings-acl.102,"{'Extractive text summarization of single documents is a task of binary sentence classification with labels indicating whether a sentence should be included in a summary. However, the hierarchical text structure information is not taken into account explicitly by pre-trained language models based on Transformer.': 'The authors propose a novel approach to formulate, extract, encode and inject the hierarchical structure (HiStruct) information explicitly into an extractive summarization model (HiStruct+ model), which consists of a TLM for sentence encoding and two stacked inter-sentence Transformer layers for hierarchical learning and extractive summarization.', 'The HiStruct information utilized in the work includes the section titles and the hierarchical positions of sentences, which are not encoded using existing methods.': 'The authors propose novel methods to formulate the HiStruct information and implement data preprocessing to extract them from the raw datasets.', 'The effectiveness of the proposed HiStruct encoding methods is not evaluated.': 'The HiStruct+ models are evaluated on short documents (i. e., CNN/DailyMail) and long documents (i. e., PubMed and arXiv) with various hierarchical characteristics. The models are compared with the corresponding strong baselines, which differ from the models only in that the HiStruct information is not injected. Using various experimental settings, the models collectively outperform the baselines on the three datasets, indicating the effectiveness of the proposed HiStruct encoding methods.', 'The performance gains of the HiStruct+ models are not analyzed.': 'Ablation studies suggest that the performance gains are mainly contributed by the hierarchical position information of sentences.', 'The data containing the extracted HiStruct information, the best HiStruct+ models, as well as the scripts for preprocessing, training and evaluation are not available.': 'The data containing the extracted HiStruct information, the best HiStruct+ models, as well as the scripts for preprocessing, training and evaluation are available on GitHub.'}",supervised,"['News', 'Scholarly Documents']",['exploiting-the-structure-of-long-documents']
SP:8dc4f4a8f987aa86d01a85fa8f8f53de616d097d,MuchSUM: Multi-channel Graph Neural Network for Extractive Summarization,SIGIR,2022,"['Qianren Mao', 'Hongdong Zhu', 'Junnan Liu', 'Cheng Ji', 'Hao Peng', 'Jianxin Li', 'Lihong Wang', 'Zheng Wang']","Recent studies of extractive text summarization have leveraged BERT for document encoding with breakthrough performance. However, when using a pre-trained BERT-based encoder, existing approaches for selecting representative sentences for text summarization are inadequate since the encoder is not explicitly trained for representing sentences. Simply providing the BERT-initialized sentences to cross-sentential graph-based neural networks (GNNs) to encode semantic features of the sentences is not ideal because doing so fail to integrate other summary-worthy features like sentence importance and positions. This paper presents MuchSUM, a better approach for extractive text summarization. MuchSUM is a multi-channel graph convolutional network designed to explicitly incorporate multiple salient summary-worthy features. Specifically, we introduce three specific graph channels to encode the node textual features, node centrality features, and node position features, respectively, under bipartite word-sentence heterogeneous graphs. Then, a cross-channel convolution operation is designed to distill the common graph representations shared by different channels. Finally, the sentence representations of each channel are fused for extractive summarization. We also investigate three weighted graphs in each channel to infuse edge features for graph-based summarization modeling. Experimental results demonstrate our ∗The corresponding author to this research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. SIGIR ’22, July 11–15, 2022, Madrid, Spain © 2022 Association for Computing Machinery. ACM ISBN 978-1-4503-8732-3/22/07. . . $15.00 https://doi.org/10.1145/3477495.3531906 model can achieve considerable performance compared with some BERT-initialized graph-based extractive summarization systems.","The paper discusses the limitations of using pre-trained BERT-based encoders for extractive text summarization and proposes a new approach called MuchSUM, which is a multi-channel graph convolutional network that incorporates multiple summary-worthy features. The approach introduces three specific graph channels to encode node textual features, node centrality features, and node position features, respectively, under bipartite word-sentence heterogeneous graphs. A cross-channel convolution operation is designed to distill the common graph representations shared by different channels, and the sentence representations of each channel are fused for extractive summarization. The approach also investigates three weighted graphs in each channel to infuse edge features for graph-based summarization modeling. Experimental results demonstrate that the MuchSUM model can achieve considerable performance compared with some BERT-initialized graph-based extractive summarization systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to identify the most representative sentences in a document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, such as news articles or research papers.'}",['method'],['Input Encoding'],['CNN/DailyMail'],['ROUGE'],[''],https://github.com/RingBDStack/MuchSum/,https://doi.org/10.1145/3477495.3531906,"{'Existing extractive text summarization techniques formulate the problem as a sequence labeling task, which ignores the semantic relations among sentences.': 'The authors propose to model summarization graphs to better capture inter-sentence relationships. They introduce MuchSUM, a multi-channel convolutional graph neural network (GNN) that explicitly integrates summary-related features, like sentence semantics and importance and position.', 'Existing BERT-based methods for text summarization still have room for improvement as they model sentences word-by-word, ignoring the semantic relations among sentences.': 'The authors propose to use MuchSUM, which employs pre-trained language models such as BERT to learn sentence representation for text summarization, but also integrates other summary-related features to improve performance.', 'There is no consensus on the best neural graph formulation to leverage the topological centrality of a cross-sentential summarization graph.': 'The authors propose to use a multi-channel GCN for extractive summarization under bipartite word-sentence graphs. They provide a comprehensive study on how to aggregate three kinds of summary-worthy features in an explicit manner based on the multi-channel graph convolution operation.', 'Existing works that apply graph representation learning techniques on various semantic graphs usually rely on external tools to construct the graphs, in which the error propagation problem is serious.': 'The authors propose to use a weighted bipartite graph to aggregate node features of neighbors in word-sentence graphs, which can be optimized by consistency and disparity constraints to ensure specific embeddings in each feature space.'}",supervised,['News'],[]
SP:4ebe903f57e5e87f4cd0fbe61efb1471e17cdc27,SAPGraph: Structure-aware Extractive Summarization for Scientific Papers with Heterogeneous Graph,AACL,2022,"['Siya Qi', 'Lei Li', 'Yiyang Li', 'Jin Jiang', 'Dingxin Hu', 'Yuze Li', 'Yingqi Zhu', 'Yanquan Zhou', 'Marina Litvak', 'Natalia Vanetik']","Scientific paper summarization is always challenging in Natural Language Processing (NLP) since it is hard to collect summaries from such long and complicated text. We observe that previous works tend to extract summaries from the head of the paper, resulting in information incompleteness. In this work, we present SAPGraph1 to utilize paper structure for solving this problem. SAPGraph is a scientific paper extractive summarization framework based on a structure-aware heterogeneous graph, which models the document into a graph with three kinds of nodes and edges based on structure information of facets and knowledge. Additionally, we provide a large-scale dataset of COVID-19-related papers, CORD-SUM. Experiments on CORD-SUM and ArXiv datasets show that SAPGraph generates more comprehensive and valuable summaries compared to previous works.","The paper discusses the challenges of scientific paper summarization in NLP and presents a solution called SAPGraph1. The framework utilizes paper structure to generate more comprehensive and valuable summaries compared to previous works that tend to extract summaries from the head of the paper. SAPGraph is based on a structure-aware heterogeneous graph that models the document into a graph with three kinds of nodes and edges based on structure information of facets and knowledge. The paper also provides a large-scale dataset of COVID-19-related papers, CORD-SUM, for experiments.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific papers, particularly COVID-19-related papers, to help researchers quickly focus on valuable information in the article and be updated about the latest research progress.', 'Who is the target audience?': 'The summaries are for researchers who are overwhelmed by the expanding growth of scientific papers and need to quickly access essential information.', 'How will the summaries be used?': 'The summaries will be used to condense long texts into concise summaries while retaining essential information. They will be generated through extractive summarization methods and will be compared to previous works using metrics such as ROUGE and BERTScore.'}","['corpus', 'method']","['Input Encoding', 'Unit Relationship']","['CORD-SUM', 'arXiv']",['F1 Score'],[''],https://github.com/cece00/SAPGraph,https://aclanthology.org/2022.aacl-main.44,"{'Scientific papers, especially COVID-19-related papers, have grown rapidly in recent years, leading to information overload and difficulty for researchers to keep up with the latest research progress.': 'Automatic summarization can help researchers quickly focus on valuable information in the article and be updated about the latest research progress. The authors propose extractive summarization as a solution, which selects text segments as summaries, making it easier to apply practically and keep grammar correct.', 'Scientific papers have long texts with complicated structures, making it difficult to generate summaries from professional texts like COVID-19-related papers.': 'The authors propose a StructureAware Paper Heterogeneous Graph Network (SAPGraph) for scientific paper summarization. SAPGraph models an entire paper as a heterogeneous graph with three node types: section, sentence, and entity, and is trained with the Graph Neural Network (GNN). Such a design can effectively aggregate information from different facets and improve the diversity and coverage of summaries.', 'Extractive summarization models are prone to obtain summaries with head distribution problems, which means that systems tend to extract summaries from the beginning of the document.': 'SAPGraph successfully utilizes the explicit structure of facets and the implicit structure of knowledge to alleviate the head distribution problem in scientific paper summarization.', 'Long documents always possess several facets with certain logical relations, and the structure of long papers is not well-utilized.': 'The authors deeply consider the facet structure in SAPGraph, inspired by previous works that consider the paper structure and try to manually pick sections as input or consider hierarchical features of a document.', 'Classical deep learning methods simply truncate documents and may therefore discard useful information.': 'Other methods propose a better data structure, such as graph-based models or sliding window in sequence models.', 'Extractive methods are still insufficient at dealing with papers and cannot cover all the critical information that researchers need.': 'SAPGraph outperforms previous works in terms of ROUGE and BERTScore on CORDSUM and ArXiv. Ablation studies show our evaluation on different graph structures, suggesting that SAPGraph can surpass other types of graph construction.', 'There is a lack of summarization datasets compiled of scientific papers about COVID19.': 'The authors provide CORD-SUM, a summarization dataset based on COVID19 Open Research Dataset (CORD-19), which is publicly available for researchers to process the updated CORD-19 dataset.'}",supervised,['Scholarly Documents'],"['information-loss-and-incoherence-in-extractive-summarization', 'exploiting-the-structure-of-long-documents']"
SP:af368c2eb2d04bcf3db5dbe5ac89b2812cbdf60c,Extractive Entity-Centric Summarization as Sentence Selection using Bi-Encoders,AACL,2022,"['Ella Hofmann-Coyle', 'Mayank Kulkarni', 'Lingjue Xie', 'Mounica Maddela', 'Daniel Preoţiuc-Pietro']","Entity-centric summarization is a type of controllable summarization that aims to produce a summary of a document that is specific to a given target entity. Extractive summaries possess multiple advantages over abstractive ones such as preserving factuality and can be directly used in downstream tasks like target-based sentiment analysis or incorporated into search applications. In this paper, we explore methods to solve this task by recasting it as a sentence selection task, as supported by the EntSUM data set. We use methods inspired by information retrieval, where the input to the model is a pair representing a sentence from the original document and the target entity, in place of the query. We explore different architecture variants and loss functions in this framework with results showing an up to 5.8 F1 improvement over past state-of-the-art and outperforming the competitive entity-centric Lead 3 heuristic by 1.1 F1. In addition, we also demonstrate similarly strong results on the related task of salient sentence selection for an entity.","The paper discusses entity-centric summarization, which produces a summary of a document specific to a given target entity. Extractive summaries are preferred over abstractive ones as they preserve factuality and can be used in downstream tasks. The authors explore methods to solve this task by recasting it as a sentence selection task, using methods inspired by information retrieval. They test different architecture variants and loss functions and achieve up to a 5.8 F1 improvement over past state-of-the-art and outperform the entity-centric Lead 3 heuristic by 1.1 F1. The authors also show strong results on the related task of salient sentence selection for an entity.","{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to provide a summary that is specific to a user's information need, which could be a target entity, aspect, or topic."", 'Who is the target audience?': 'The summaries are for users who are interested in summarizing the information they are interested in.', 'How will the summaries be used?': 'The summaries will be used to aid users in interactive applications such as search, through either highlighting or extracting passages in the document. They also have the potential to be used as an intermediary step or auxiliary task in downstream entity-centric tasks, such as entity salience, aspect-based sentiment classification, or information retrieval.'}",['method'],"['Controlled Generation', 'Unit Selection']",['NYT'],['ROUGE'],[''],,https://aclanthology.org/2022.aacl-short.40,"{'Abstractive summarization techniques possess several disadvantages, including lack of factuality and coherence, as well as difficulty in correctly assessing the summary quality automatically.': 'Extractive summarization mitigates these issues by extracting text from the original document and allows for evaluation using standard metrics such as F1.', 'Extractive entity-centric summarization methods have not been extensively studied.': 'The authors present the first in-depth study of extractive entity-centric summarization methods using the EntSUM dataset.', 'There is a need for reliable F1 metrics to compare different approaches to entity-centric summarization.': 'The authors recast the entity-centric extractive summarization task as selecting the summary sentences regarding an entity in a document, allowing for reliable F1 metrics to be computed.', 'Past approaches to entity-centric summarization have not been effective.': 'The authors propose new methods for entity-centric summarization using the biencoder framework with pre-trained Transformer-based models, which significantly outperform past approaches and the challenging entity-centric lead3 baseline in summarization tasks.', 'There is a need for data analysis to gain insight into model behavior.': 'The authors provide data analysis for insight into model behavior as one of their contributions.'}",supervised,['News'],['robust-evaluation-methods']
SP:083be663198dcdfb5f34d734b3f37c9e3f4a1d3b,GRETEL: Graph Contrastive Topic Enhanced Language Model for Long Document Extractive Summarization,COLING,2022,"['Qianqian Xie', 'Jimin Huang']","Recently, neural topic models (NTMs) have been incorporated into pre-trained language models (PLMs), to capture the global semantic information for text summarization. However, in these methods, there remain limitations in how they capture and integrate the global semantic information. In this paper, we propose a novel model, Graph contRastivE Topic Enhanced Language model (GRETEL), that incorporates the graph contrastive topic model with the pre-trained language model, to fully leverage both the global and local contextual semantics for long document extractive summarization. To better capture and incorporate the global semantic information into PLMs, the graph contrastive topic model integrates the hierarchical transformer encoder and the graph contrastive learning to fuse the semantic information from the global document context and the gold summary. To this end, GRETEL encourages the model to efficiently extract salient sentences that are topically related to the gold summary, rather than redundant sentences that cover sub-optimal topics. Experimental results1 on both general domain and biomedical datasets demonstrate that our proposed method outperforms SOTA methods.","The paper proposes a new model called Graph contRastivE Topic Enhanced Language model (GRETEL) that combines the graph contrastive topic model with pre-trained language models (PLMs) to improve text summarization. The graph contrastive topic model integrates the hierarchical transformer encoder and graph contrastive learning to capture and integrate global semantic information from the document context and the gold summary. GRETEL aims to extract salient sentences that are topically related to the gold summary, rather than redundant sentences that cover sub-optimal topics. Experimental results on general domain and biomedical datasets show that GRETEL outperforms state-of-the-art methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the performance of text summarization tasks.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key information in a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the most important information.'}",['method'],"['Input Encoding', 'Input Encoding']","['CNN/DailyMail', 'arXiv', 'PubMed', 'CORD-19', 'S2ORC']",['ROUGE'],[''],https://github.com/xashely/GRETEL_,https://aclanthology.org/2022.coling-1.546,"{'Existing pre-trained language models (PLMs) fail to capture long-range dependencies, limiting their effectiveness in text summarization.': 'The authors propose integrating neural topic models (NTMs) into PLMs to capture global semantics and improve summarization performance.', 'Existing methods for topic inference rely on unsupervised learning and document-word features, leading to sub-optimal topics and redundant sentences in the summary.': 'The authors propose using the semantic information of the gold summary and the global document context to inform topic representations through a graph contrastive topic model (GCTM) empowered by a hierarchical transformer encoder (HTE).', 'Existing methods disregard the sequential and syntactic dependency between words, leading to inaccuracies in topic allocation.': 'The authors propose providing NTMs with contextual representations from PLMs through the HTE, which captures global contextual information missing in the BOW feature.', 'Existing methods focus on sentences with high-frequency words rather than those with high semantic similarity to the gold summary.': 'The authors propose utilizing graph contrastive learning with supervised information from the gold summary to encourage the model to capture better global semantic information and select key sentences that are topically similar to the gold summary.'}",supervised,"['News', 'Scholarly Documents']",[]
SP:b30a5baa2c03d49f4b23366d710a03adaf242cf7,HeterGraphLongSum: Heterogeneous Graph Neural Network with Passage Aggregation for Extractive Long Document Summarization,COLING,2022,"['Tuan-Anh Phan', 'Nam Bui']","Graph Neural Network (GNN)-based models have proven effective in various Natural Language Processing (NLP) tasks in recent years. Specifically, in the case of the Extractive Document Summarization (EDS) task, modeling documents under graph structure is able to analyze the complex relations between semantic units (e.g., word-to-word, word-to-sentence, sentence-to-sentence) and enrich valuable information for the sentence representation. However, long-form document summarization using graph-based approaches is still an open research issue. The main challenge is to represent long documents in a graph structure in an effective way. In this regard, this paper proposes a new heterogeneous graph neural network (HeterGNN) model to improve the performance of long document summarization (HeterGraphLongSum). Specifically, the main idea is to add the passage nodes into the heterogeneous graph structure of word and sentence nodes for enriching the final representation of sentences. In this regard, HeterGraphLongSum includes three types of semantic units such as word, sentence, and passage. Experiments on two benchmark datasets for long documents such as Pubmed and Arxiv indicate promising results of the proposed model for the extractive long document summarization problem. Especially, HeterGraphLongSum is able to achieve state-of-the-art performance without relying on any pre-trained language models (e.g., BERT). The source code is available for further exploitation on the Github1.","The paper discusses the effectiveness of Graph Neural Network (GNN)-based models in Natural Language Processing (NLP) tasks, particularly in Extractive Document Summarization (EDS). However, long-form document summarization using graph-based approaches is still a challenge. The paper proposes a new model called HeterGraphLongSum, which includes three types of semantic units (word, sentence, and passage) to represent long documents in a graph structure. The model achieves promising results for the extractive long document summarization problem without relying on pre-trained language models like BERT. The source code is available on Github for further exploration.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to rewrite them in a shorter version while preserving the main information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and resources when reviewing large amounts of information, such as in research or decision-making processes.'}",['method'],['Input Encoding'],"['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/tuananhphan97vn/HeterGraphLongSum,https://aclanthology.org/2022.coling-1.545,"{'Document summarization is a central problem in NLP, and most existing architectures are built based on sequence-to-sequence techniques, which require a complicated neural network with millions of learnable parameters, leading to significant costs in terms of computation time, perplexity, and resources.': 'The authors propose extractive models, which still gain much attention, and turn EDS into the sequential binary-labeling task. They also incorporate external information, such as pretrained model BERTSum and topic modeling, to improve performances.', 'Long-form document summarization is still a remaining challenge in this research field due to two main reasons: most traditional Seq2Seq methods truncate longer documents into small fixed-length sequences, which leads to information loss problem, especially for the extractive summarization, and representing an effective way for long-text documents into graph structure is still an open research issue.': 'The authors present a new graph-based architecture, which contains three semantic units such as word, sentence, and passage. In particular, the passage nodes are adopted for learning the cross-relations between sentences in different passages. Furthermore, the passage node can be regarded as the local structure of a group of sentence nodes in which the edges between passages and sentences have the possibility to reduce the harm of similar representations of sentences when expanding graph structure with long documents.', 'Most existing architectures for EDS are proposed for short documents (i.e., new articles).': 'The authors propose a novel GNN-based method for modeling long-form documents, focusing on scientific papers, without employing pre-trained encoders (e.g., BERT), which is able to extend to other low-resource languages without any obstacles.', 'There is a need for evaluating the proposed model with benchmark long document datasets.': 'The authors evaluate the proposed model with two benchmark long document datasets such as PubMed and ArXiv and show that their method is able to achieve the state-of-the-art level in this research field.'}",supervised,['Scholarly Documents'],"['efficient-encoding-of-long-documents', 'exploiting-the-structure-of-long-documents']"
SP:f75807525a63a3356e0214f105f2579109c2fc36,Multi Graph Neural Network for Extractive Long Document Summarization,COLING,2022,"['Xuan-Dung Doan', 'Le-Minh Nguyen', 'Nam Bui']","Heterogeneous Graph Neural Networks (HeterGNN) have been recently introduced as an emergent approach for extracting document summarization (EDS) by exploiting the crossrelations between words and sentences. However, applying HeterGNN for long documents is still an open research issue. One of the main majors is the lacking of inter-sentence connections. In this regard, this paper exploits how to apply HeterGNN for long documents by building a graph on sentence-level nodes (homogeneous graph) and combine with HeterGNN for capturing the semantic information in terms of both inter and intra-sentence connections. Experiments on two benchmark datasets of long documents such as PubMed and ArXiv show that our method is able to achieve state-of-theart results in this research field.","System: The paper discusses the use of Heterogeneous Graph Neural Networks (HeterGNN) for document summarization, specifically for long documents. The authors address the issue of lacking inter-sentence connections and propose a solution by building a graph on sentence-level nodes and combining it with HeterGNN to capture semantic information. The experiments conducted on two benchmark datasets show that this method achieves state-of-the-art results in the field of document summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to automatically extract a set of sentences that represent information for the whole document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly identify the most important information.'}",['method'],"['Input Encoding', 'Unit Relationship']","['PubMed', 'arXiv']",['ROUGE'],[''],https://github.com/dungdx34/MTGNN-SUM,https://aclanthology.org/2022.coling-1.512,"{'The inter-sentence connections are not considered in HeterGNN-based models, which might influence the performance, especially in terms of long-form document representation.': 'The authors propose a novel method for enriching the inter-sentences relations by proposing a homogeneous graph neural network (HomoGNN) and incorporating the HeterGNN for final sentence representations.', 'Transformer-based language models are not able to process long pieces of text, and the input length limitation and encoding of long texts are still open challenges in this research field.': 'The authors use the information at the beginning of the sentence [CLS] representation for the inputs of the graph attention layer, inspired by recent state-of-the-art models for long-form document representations such as Longformer, Big-Bird, and Poolingformer.', 'The redundant phrases problem between extracted sentences of the summarization.': 'Jia et al. proposed a hierarchical attentive heterogeneous graph (HAHSum) to improve the redundant phrases problem between extracted sentences of the summarization.'}",supervised,['Scholarly Documents'],['efficient-encoding-of-long-documents']
SP:70d70e1a9258b9d87345f524d359df0896116280,Compressive Document Summarization via Sparse Optimization,IJCAI,2015,"['Jin-ge Yao', 'Xiaojun Wan', 'Jianguo Xiao']","In this paper, we formulate a sparse optimization framework for extractive document summarization. The proposed framework has a decomposable convex objective function. We derive an efficient ADMM algorithm to solve it. To encourage diversity in the summaries, we explicitly introduce an additional sentence dissimilarity term in the optimization framework. We achieve significant improvement over previous related work under similar data reconstruction framework. We then generalize our formulation to the case of compressive summarization and derive a block coordinate descent algorithm to optimize the objective function. Performance on DUC 2006 and DUC 2007 datasets shows that our compressive summarization results are competitive against the state-of-the-art results while maintaining reasonable readability.","

System: The paper presents a sparse optimization framework for extractive document summarization with a decomposable convex objective function. An efficient ADMM algorithm is derived to solve it, and an additional sentence dissimilarity term is introduced to encourage diversity in the summaries. The framework achieves significant improvement over previous related work and is generalized to compressive summarization with a block coordinate descent algorithm. The compressive summarization results are competitive against state-of-the-art results while maintaining reasonable readability, as demonstrated on DUC 2006 and DUC 2007 datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents as a task in the field of text mining and information retrieval.', 'Who is the target audience?': 'The intended audience for the document summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the document summaries will be used.'}",['method'],['Objective Function'],"['DUC 2006', 'DUC 2007']",['ROUGE'],"['Grammaticality', 'Non-redundancy', 'Referential Clarity', 'Focus', 'Coherence']",,http://ijcai.org/Abstract/15/198,"{'Redundancy in extractive summarization approaches has not been well-addressed in previous methods.': 'The authors propose summarization based on data reconstruction with a decomposable row-sparsity regularized optimization problem that can be efficiently solved by modern convex optimization algorithms.', 'Abstractive summarization is far more difficult than extractive summarization that does not need to ensure structural and semantic coherence within a sentence.': 'The authors propose a framework that jointly optimizes sentence selection and word selection for compressive summarization. Grammaticality of compressed sentences is ensured by considering dependency relations during a final generation step.', 'The accompanying gradient descent algorithm in previous summarization based on data reconstruction turns out to be slow in practice, limiting the generalizability of the paradigm.': 'The authors propose an efficient alternating direction method of multipliers to solve the decomposable row-sparsity regularized optimization problem.', 'Extractive approaches are rather limited in terms of the final summaries they can produce.': 'The authors introduce an additional sentence dissimilarity term to encourage diversity in summary sentences, inspired by recent research on exemplar-based data representation.', 'Full constituent parse trees are needed to generate grammatical compressions.': 'Merely an additional lightweight dependency parser is needed to conduct the recursive sentence compression phase to impose grammatical constraints, avoiding less efficient constituent parsing.', 'Previous work of unsupervised document summarization based on data reconstruction has not achieved satisfactory performance.': 'The authors conduct experiments on DUC 2006 and DUC 2007 datasets to show the improvements of their methods over previous work, achieving fairly competitive results against the state-of-the-art approaches while maintaining reasonable readability.'}",unsupervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:a3b52055f17ad008287192541d97b6d80260e401,Optimizing Sentence Modeling and Selection for Document Summarization,IJCAI,2015,"['Wenpeng Yin', 'Yulong Pei']","Extractive document summarization aims to conclude given documents by extracting some salient sentences. Often, it faces two challenges: 1) how to model the information redundancy among candidate sentences; 2) how to select the most appropriate sentences. This paper attempts to build a strong summarizer DivSelect+CNNLM by presenting new algorithms to optimize each of them. Concretely, it proposes CNNLM, a novel neural network language model (NNLM) based on convolutional neural network (CNN), to project sentences into dense distributed representations, then models sentence redundancy by cosine similarity. Afterwards, it formulates the selection process as an optimization problem, constructing a diversified selection process (DivSelect) with the aim of selecting some sentences which have high prestige, meantime, are dis-similar with each other. Experimental results on DUC2002 and DUC2004 benchmark data sets demonstrate the effectiveness of our approach.","The paper proposes a new approach to extractive document summarization, which involves selecting salient sentences from a given document. The approach, called DivSelect+CNNLM, addresses two challenges: modeling information redundancy among candidate sentences and selecting the most appropriate sentences. It introduces a novel neural network language model based on convolutional neural network (CNN) to project sentences into dense distributed representations and models sentence redundancy using cosine similarity. The selection process is formulated as an optimization problem, constructing a diversified selection process (DivSelect) to select sentences with high prestige and dissimilarity. The approach is evaluated on benchmark datasets and shows effectiveness in summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to conclude them with a concise piece of text.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Unit Selection'],"['DUC 2002', 'DUC 2004']",['ROUGE'],[''],,http://ijcai.org/Abstract/15/199,"{'How to model the information overlapping among candidate sentences?': 'The authors propose a novel representation learning approach CNNLM based on convolutional neural network (CNN) that leverages n-gram language model (LM) to convert traditional CNN architecture into an unsupervised learning regime. Given a sentence, CNNLM extracts the sentence representation by hierarchical neural network, then combines that sentence representation with the representations of context words to predict the next word. This kind of prediction-based NNLMs are shown more powerful than traditional counting-based methods in representation learning.', 'How to pick out the most salient sentences?': 'The authors propose to use PageRank to derive the sentence prestige based on pairwise sentence similarities calculated from the sentence representations obtained from CNNLM. Additionally, the authors recognize diversity as a crucial objective in selection and propose a diversified selection algorithm DivSelect that automatically balances the prestige and diversity of the early-selected sentences in a principled way.', 'How to control redundancy in top-ranked sentences?': 'The authors propose to combine prestige and diversity into a unified selection process using the DivSelect algorithm, which is inspired by recent research on diversified ranking. The algorithm balances the prestige and diversity of the early-selected sentences to avoid redundancy.'}",unsupervised,['News'],[]
SP:3e027f9cd9d1054bc80c6e20b40f5cf979c5784d,Krimping texts for better summarization,EMNLP,2015,"['Marina Litvak', 'Sami Shamoon', 'Natalia Vanetik']","Automated text summarization is aimed at extracting essential information from original text and presenting it in a minimal, often predefined, number of words. In this paper, we introduce a new approach for unsupervised extractive summarization, based on the Minimum Description Length (MDL) principle, using the Krimp dataset compression algorithm (Vreeken et al., 2011). Our approach represents a text as a transactional dataset, with sentences as transactions, and then describes it by itemsets that stand for frequent sequences of words. The summary is then compiled from sentences that compress (and as such, best describe) the document. The problem of summarization is reduced to the maximal coverage, following the assumption that a summary that best describes the original text, should cover most of the word sequences describing the document. We solve it by a greedy algorithm and present the evaluation results.","The paper introduces a new approach for automated text summarization using the Minimum Description Length principle and the Krimp dataset compression algorithm. The approach represents a text as a transactional dataset and describes it using frequent sequences of words. The summary is compiled from sentences that compress the document, with the problem of summarization reduced to maximal coverage. The approach is evaluated using a greedy algorithm and the results are presented.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract relevant information in a concise and efficient manner.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in information retrieval, decision-making, and other tasks that require understanding the content of a document.'}",['method'],['Unit Selection'],"['DUC 2002', 'DUC 2004', 'DUC 2007']",['ROUGE'],[''],,https://aclanthology.org/D15-1223,"{'Many unsupervised approaches for extractive text summarization follow the maximal coverage principle, which demands an exponential number of tests for exhaustive solutions.': 'The authors propose using approximation techniques, such as a greedy approach or a global optimization of a target function, to solve the problem.', 'It is common to measure text informativeness by the frequency of its components, but this approach has limitations.': 'The authors propose using the Minimum Description Length (MDL) principle, which defines the best summary as the one that leads to the best compression of the text by providing its shortest and most concise description.', 'There are only a few works on text summarization using MDL in the literature.': 'The authors introduce a new MDL-based approach for extracting relevant sentences into a summary.', 'The problem of summarization is very naturally reduced to the maximal coverage problem.': 'The authors solve the problem by the greedy method which ranks sentences by their coverage of best compressing frequent word sequences and selects the top-ranked sentences to a summary.', 'None of the previous works that applied common data mining techniques for calculating frequent itemsets from transactional data to the text summarization task followed the MDL principle.': 'The authors propose a new approach that represents documents as a sequential transactional dataset and then compresses it by replacing frequent sequences of words by codes. The summary is then compiled from sentences that best compress (or describe) the document content.', 'The effectiveness of the proposed approach is unknown.': 'The authors compare the results of their approach with other unsupervised state-of-the-art summarizers on three different corpora and show that their approach outperforms them.'}",unsupervised,['News'],[]
SP:abe352e588b7ea0e1530a7310c0961b4ce216ed2,AttSum: Joint Learning of Focusing and Summarization with Neural Attention,COLING,2016,"['Ziqiang Cao', 'Wenjie Li', 'Sujian Li', 'Furu Wei', 'Yanran Li']","Query relevance ranking and sentence saliency ranking are the two main tasks in extractive query-focused summarization. Previous supervised summarization systems often perform the two tasks in isolation. However, since reference summaries are the trade-off between relevance and saliency, using them as supervision, neither of the two rankers could be trained well. This paper proposes a novel summarization system called AttSum, which tackles the two tasks jointly. It automatically learns distributed representations for sentences as well as the document cluster. Meanwhile, it applies the attention mechanism to simulate the attentive reading of human behavior when a query is given. Extensive experiments are conducted on DUC query-focused summarization benchmark datasets. Without using any hand-crafted features, AttSum achieves competitive performance. We also observe that the sentences recognized to focus on the query indeed meet the query need.","The paper discusses the challenges of extractive query-focused summarization, specifically the tasks of query relevance ranking and sentence saliency ranking. Previous systems have struggled to perform both tasks effectively, but the proposed system, AttSum, tackles them jointly using distributed representations and an attention mechanism. The system is evaluated on benchmark datasets and achieves competitive performance without the use of hand-crafted features. The authors also observe that the sentences identified as relevant to the query do indeed meet the query's needs.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create brief, well-organized and fluent summaries that answer the need of the query. This is useful in scenarios like news services and search engines.', 'Who is the target audience?': 'The summaries are for users who have a specific query and want to quickly find relevant information from a large document.', 'How will the summaries be used?': 'The summaries will be used to provide users with a quick overview of the document and to help them find the information they need without having to read the entire document. They can be used in various scenarios like news services and search engines.'}",['method'],['Objective Function'],"['DUC 2005', 'DUC 2006', 'DUC 2007']",['ROUGE'],[''],,https://aclanthology.org/C16-1053/,"{'Most current supervised summarization systems often perform the two tasks of measuring the saliency of a sentence and its relevance to a user’s query in isolation. This results in weights for neither query-dependent nor query-independent features being learned well from reference summaries.': 'The isolation problem can be solved with a joint model that combines query relevance ranking and sentence saliency ranking. The authors propose a novel summarization system called AttSum, which joints query relevance ranking and sentence saliency ranking with a neural attention model.', 'When measuring the query relevance, most summarization systems merely make use of surface features like the TF-IDF cosine similarity between a sentence and the query. However, relevance is not similarity.': 'The authors propose using a joint neural network model that considers the relevance and saliency simultaneously. They introduce the weighted-sum pooling over sentence embeddings to represent the document, where the weight is the automatically learned query relevance of a sentence. In this way, the document representation will be biased to the sentence embeddings which match the meaning of both query and documents.', 'The surface features used to measure query relevance are inadequate and further augment the error of the whole summarization system.': 'The authors propose using a joint neural network model that considers the relevance and saliency simultaneously. They introduce the weighted-sum pooling over sentence embeddings to represent the document, where the weight is the automatically learned query relevance of a sentence. In this way, the document representation will be biased to the sentence embeddings which match the meaning of both query and documents.', 'Most previous summarization systems rely on rich hand-crafted features.': 'The authors propose a data-driven model where all the features are learned automatically.', 'The existing summarization systems fail to focus on highly query relevant content.': 'The authors propose AttSum, which outperforms widely-used summarization systems and focuses on highly query relevant content. They conduct qualitative analysis for those sentences with large relevance scores to the query.'}",supervised,['News'],[]
SP:0b80a577138a2fad0831a74dcf27052c02f06465,Summarising the points made in online political debates,ACL,2016,"['Charlie Egan', 'Advaith Siddharthan']","Online communities host growing numbers of discussions amongst large groups of participants on all manner of topics. This user-generated content contains millions of statements of opinions and ideas. We propose an abstractive approach to summarize such argumentative discussions, making key content accessible through ‘point’ extraction, where a point is a verb and its syntactic arguments. Our approach uses both dependency parse information and verb case frames to identify and extract valid points, and generates an abstractive summary that discusses the key points being made in the debate. We performed a human evaluation of our approach using a corpus of online political debates and report significant improvements over a highperforming extractive summarizer.","The paper proposes an abstractive approach to summarize argumentative discussions in online communities. The approach extracts key content through 'point' extraction, where a point is a verb and its syntactic arguments. The approach uses dependency parse information and verb case frames to identify and extract valid points and generates an abstractive summary that discusses the key points being made in the debate. The approach was evaluated using a corpus of online political debates and showed significant improvements over a high-performing extractive summarizer.","{'What is the purpose of the summaries?': 'The authors are generating summaries of online argumentative discussions to make the key content of such discussions accessible.', 'Who is the target audience?': 'The summaries are for retailers to analyze product reviews, consumers to zero in on what products to buy, and social scientists to gain insight on social trends.', 'How will the summaries be used?': 'The summaries will be used to provide a high-level, summarized view of a discussion, grouping information and presenting points and counter-points.'}",['method'],['Unit Selection'],['Internet Argument Corpus'],"['ROUGE', 'BLEU', 'METEOR', 'Relevance']",['Overall Quality'],,https://aclanthology.org/W16-2816,"{'Online argumentative discussions are an untapped resource of ideas, but much of the useful information in discussions is inaccessible due to the size and complexity of the discussions and limitations of summarisers based on sentence extraction.': 'The authors propose a fully automatic and domain neutral unsupervised approach to abstractive summarisation which makes the key content of such discussions accessible. At the core of their approach is the notion of a ‘point’ - a short statement, derived from a verb and its syntactic arguments. Points (and counter-points) from across the corpus are analysed and clustered to derive a summary of the discussion.', 'Retailers, consumers, and social scientists could benefit from a high-level, summarised view of a discussion, grouping information and presenting points and counter-points.': 'The proposed approach provides a summarised view of a discussion, grouping information and presenting points and counter-points, which could be useful for retailers to analyse product reviews, consumers to zero in on what products to buy, and social scientists to gain insight on social trends.', 'Summarisers based on sentence extraction have limitations.': ""The proposed approach is an alternative to summarisers based on sentence extraction and improves significantly on the extractive baseline according to the authors' evaluation using a corpus of political debates.""}",unsupervised,['Forum Discussions'],"['information-loss-and-incoherence-in-extractive-summarization', 'controlled-and-tailored-summarization']"
SP:a33ed7627490f72eb1761d082da6f77faf2426f5,Neural Summarization by Extracting Sentences and Words,ACL,2016,"['Jianpeng Cheng', 'Mirella Lapata']",Traditional approaches to extractive summarization rely heavily on humanengineered features. In this work we propose a data-driven approach based on neural networks and continuous sentence features. We develop a general framework for single-document summarization composed of a hierarchical document encoder and an attention-based extractor. This architecture allows us to develop different classes of summarization models which can extract sentences or words. We train our models on large scale corpora containing hundreds of thousands of document-summary pairs1. Experimental results on two summarization datasets demonstrate that our models obtain results comparable to the state of the art without any access to linguistic annotation.,"System: The paper proposes a new approach to extractive summarization using neural networks and continuous sentence features. The approach includes a hierarchical document encoder and an attention-based extractor, allowing for different classes of summarization models. The models were trained on large scale corpora and achieved results comparable to the state of the art without any linguistic annotation.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to create shorter versions of one or more documents while preserving their information content.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Unit Selection'],"['DUC 2002', 'DailyMail']",['ROUGE'],[''],,https://aclanthology.org/P16-1046,"{'Most extractive methods for automatic summarization rely on human-engineered features to identify salient text units in a document.': 'The authors propose a data-driven approach based on neural networks and continuous sentence features, using a hierarchical document reader and attention-based content extractor to directly select sentences or words for the summary.', 'Lack of training data with labeled summary-worthy sentences and words is a stumbling block for applying neural network models to extractive summarization.': 'The authors retrieve hundreds of thousands of news articles and corresponding highlights from the DailyMail website, using transformation and scoring algorithms to construct large-scale training datasets for sentence and word extraction.', 'Existing approaches to summarization often rely on statistical models or pre-trained sentence embeddings for sentence extraction.': 'The authors use continuous representations and neural networks more directly to perform the summarization task, producing multi-sentence output and jointly selecting summary words and organizing them into sentences.', 'Decoding from a large vocabulary with low-frequency words and named entities can be challenging for summarization models.': 'The authors sidestep this difficulty by having the decoder select output symbols directly from the document of interest, using a ""copy"" mechanism to select sub-sequences in the input sequence for the output.', 'Existing neural attention models for summarization often focus on abstractive sentence compression rather than document summarization.': 'The authors propose a model that summarizes documents rather than individual sentences, producing multi-sentential discourse and achieving performance comparable to state-of-the-art systems with hand-engineered features and linguistic constraints.'}",supervised,['News'],[]
SP:c87fc921aed4c959a03c729e6b7648bbb19d6006,Summarizing Lengthy Questions,IJCNLP,2017,"['Tatsuya Ishigaki', 'Hiroya Takamura', 'Manabu Okumura']","In this research, we propose the task of question summarization. We first analyzed question-summary pairs extracted from a Community Question Answering (CQA) site, and found that a proportion of questions cannot be summarized by extractive approaches but requires abstractive approaches. We created a dataset by regarding the question-title pairs posted on the CQA site as question-summary pairs. By using the data, we trained extractive and abstractive summarization models, and compared them based on ROUGE scores and manual evaluations. Our experimental results show an abstractive method using an encoder-decoder model with a copying mechanism achieves better scores for both ROUGE-2 F-measure and the evaluations by human judges.","System: The paper proposes the task of question summarization and analyzes question-summary pairs from a Community Question Answering site. It finds that some questions require abstractive approaches instead of extractive approaches. The authors created a dataset and trained extractive and abstractive summarization models, comparing them based on ROUGE scores and manual evaluations. The results show that an abstractive method using an encoder-decoder model with a copying mechanism performs better according to both ROUGE-2 F-measure and human judges' evaluations.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to address the issue of lengthy and hard-to-understand questions that often contain peripheral information in addition to the main focus of the question. Summarizing a question helps respondents understand the question.', 'Who is the target audience?': 'The summaries are for respondents who need to understand the question. The authors focus on a Community Question Answering (CQA) site and examine the characteristics of the question summarization task with a CQA dataset as a case study.', 'How will the summaries be used?': 'The summaries will be used to help respondents understand the question. The authors propose a method for creating pairs of a question and its summary, which they refer to as “question-summary” pairs, out of the CQA data. They also propose methods for question summarization and describe an empirical evaluation they conducted.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],"['Grammaticality', 'Focus']",,https://aclanthology.org/I17-1080,"{'Questions can be lengthy and hard to understand due to peripheral information.': 'Propose the task of question summarization to summarize lengthy questions into simple questions that concisely represent the original content.', 'Existing summarization approaches do not assume a question as an input.': 'Develop methods designed for question summarization, including extractive methods based on simple heuristic rules, extractive methods based on sentence classification/regression, and abstractive methods based on neural networks.', 'Lack of evaluation for question summarization methods.': 'Conduct an empirical evaluation of the proposed methods using both human judges and automatic scoring using Recall-Oriented Understudy for Gisting Evaluation (ROUGE).'}",supervised,['CQA'],"['controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:855bf05630e79e99e586bb9bc33fe71ebcbcfb1a,Learning to Extract Coherent Summary via Deep Reinforcement Learning,AAAI,2018,"['Yuxiang Wu', 'Baotian Hu']","Coherence plays a critical role in producing a high-quality summary from a document. In recent years, neural extractive summarization is becoming increasingly attractive. However, most of them ignore the coherence of summaries when extracting sentences. As an effort towards extracting coherent summaries, we propose a neural coherence model to capture the cross-sentence semantic and syntactic coherence patterns. The proposed neural coherence model obviates the need for feature engineering and can be trained in an end-to-end fashion using unlabeled data. Empirical results show that the proposed neural coherence model can efficiently capture the cross-sentence coherence patterns. Using the combined output of the neural coherence model and ROUGE package as the reward, we design a reinforcement learning method to train a proposed neural extractive summarizer which is named Reinforced Neural Extractive Summarization (RNES) model. The RNES model learns to optimize coherence and informative importance of the summary simultaneously. Experimental results show that the proposed RNES outperforms existing baselines and achieves state-of-the-art performance in term of ROUGE on CNN/Daily Mail dataset. The qualitative evaluation indicates that summaries produced by RNES are more coherent and readable.",The paper proposes a neural coherence model to capture cross-sentence semantic and syntactic coherence patterns in order to extract more coherent summaries. The proposed model can be trained in an end-to-end fashion using unlabeled data and is used in combination with the ROUGE package to design a reinforcement learning method to train a neural extractive summarizer called the Reinforced Neural Extractive Summarization (RNES) model. The RNES model learns to optimize coherence and informative importance of the summary simultaneously and outperforms existing baselines in terms of ROUGE on the CNN/Daily Mail dataset. The qualitative evaluation shows that summaries produced by RNES are more coherent and readable.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a more concise and readable version of the original text.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a long document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as news articles, research papers, and legal documents, to provide a brief overview of the content.'}",['method'],['Unit Relationship'],['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Coherence', 'Overall Quality']",,http://arxiv.org/abs/1804.07036,"{'Generating high-quality summaries from long documents is a challenging task, and most recent works on abstractive summarization fail to produce readable, informative, and coherent sentences when dealing with long documents.': 'The authors propose extractive summarization as a more practical approach, which guarantees grammatical correctness and semantic relevance. They use deep neural networks to extract salient sentences, but these methods lack the ability to ensure coherence of the summary. To address this, they incorporate coherence into the neural extractive model via reinforcement learning.', 'It is difficult to include coherence into the objective function of supervised learning models because coherence depends on sentences that are eventually extracted when the inference is performed.': 'The authors use reinforcement learning, which is suitable for this case, to train an agent to maximize the reward by interacting with an environment. They propose a novel neural coherence model that learns to estimate the coherence degree between two sentences by their distributed representation in an end-to-end fashion.', 'Traditional coherence modeling mainly focuses on topical coherence, and the entity grid model depends on the named entity recognition system whose performance may become the bottleneck of the model.': 'The authors propose a neural coherence model that exploits the distributed representation of sentences instead of sparse handcrafted features. The proposed model does not rely on any entity recognition systems and can be trained from scratch in an end-to-end fashion. The neural coherence model can capture the cross-sentence local entity transitions and the discourse relations with multiple layers of convolution and max-pooling.', 'DNN-based methods can identify important sentences from the documents, but they still lack the ability to ensure coherence of the summary.': 'The authors design a novel Reinforced Neural Extractive Summarization (RNES) model that incorporates coherence into neural extractive summarization with reinforcement learning. The output of the neural coherence model is used as immediate rewards during the training of RNES so that it learns to extract coherent summaries. ROUGE score is utilized as the final reward, and hence the proposed RNES model finds a balance between coherence and informative importance of sentences.'}",reinforced,['News'],"['exploiting-the-structure-of-long-documents', 'pretraining-and-sample-efficiency']"
SP:1a9da8b6142acdacda36912eb882c942ff7ac193,Neural Document Summarization by Jointly Learning to Score and Select Sentences,ACL,2018,"['Qingyu Zhou', 'Nan Yang', 'Furu Wei', 'Shaohan Huang', 'Ming Zhou', 'Tiejun Zhao']","Sentence scoring and sentence selection are two main steps in extractive document summarization systems. However, previous works treat them as two separated subtasks. In this paper, we present a novel end-to-end neural network framework for extractive document summarization by jointly learning to score and select sentences. It first reads the document sentences with a hierarchical encoder to obtain the representation of sentences. Then it builds the output summary by extracting sentences one by one. Different from previous methods, our approach integrates the selection strategy into the scoring model, which directly predicts the relative importance given previously selected sentences. Experiments on the CNN/Daily Mail dataset show that the proposed framework significantly outperforms the state-of-the-art extractive summarization models.",The paper presents a new approach to extractive document summarization that combines sentence scoring and selection into a single neural network framework. The approach uses a hierarchical encoder to represent the document sentences and integrates the selection strategy into the scoring model. Experiments on the CNN/Daily Mail dataset show that the proposed framework outperforms existing extractive summarization models.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to automatically extract important content from the text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as providing a quick overview of a document, helping with information retrieval, or assisting with decision-making.'}",['method'],['Objective Function'],['CNN/DailyMail'],"['ROUGE', 'Perplexity', 'Novel n-grams']","['Informativeness', 'Non-redundancy', 'Overall Quality']",https://github.com/magic282/NeuSum,https://aclanthology.org/P18-1061,"{'Traditional approaches to automatic text summarization focus on identifying important content, usually at sentence level, and then extracting them to form an output summary.': 'The authors propose a neural extractive document summarization (NEUSUM) framework that jointly learns to score and select sentences, integrating the two steps into one end-to-end trainable model.', 'Extractive methods for summarization have proven effective in many systems, but text summarization is decomposed into two subtasks, i.e., sentence scoring and sentence selection.': 'The proposed NEUSUM model learns to identify the relative importance of sentences without any handcrafted features, measuring the gain over previously selected sentences. Therefore, each time the model selects one sentence, it scores the sentences considering both sentence saliency and previously selected sentences.', 'Sentence selection adopts a particular strategy to choose content sentence by sentence, such as Maximal Marginal Relevance, Integer Linear Programming, or Submodular functions.': 'The proposed NEUSUM model consists of two parts, i.e., the document encoder and the sentence extractor. The document encoder has a hierarchical architecture, which suits the compositionality of documents. The sentence extractor is built with recurrent neural networks (RNN), which provides two main functionalities. On one hand, the RNN is used to remember the partial output summary by feeding the selected sentence into it. On the other hand, it is used to provide a sentence extraction state that can be used to score sentences with their representations.', 'Previous works on extractive methods for summarization use handcrafted features, such as word probability, TF*IDF weights, sentence position, and sentence length features.': 'The proposed NEUSUM model does not use any handcrafted features, but instead learns to predict the relative gain given the sentence extraction state and the partial output summary.', 'State-of-the-art methods for extractive document summarization are not able to achieve the best results on the CNN/Daily Mail dataset.': 'The proposed NEUSUM model significantly outperforms state-of-the-art methods and achieves the best result on the CNN/Daily Mail dataset.'}",supervised,['News'],"['identifying-important-contents-from-the-document', 'pretraining-and-sample-efficiency']"
SP:6e223814c2ba3c783acd4af76ae793cb2c841cfb,Iterative Document Representation Learning Towards Summarization with Polishing,EMNLP,2018,"['Xiuying Chen', 'Shen Gao', 'Chongyang Tao', 'Yan Song', 'Dongyan Zhao', 'Rui Yan']","In this paper, we introduce Iterative Text Summarization (ITS), an iteration-based model for supervised extractive text summarization, inspired by the observation that it is often necessary for a human to read an article multiple times in order to fully understand and summarize its contents. Current summarization approaches read through a document only once to generate a document representation, resulting in a sub-optimal representation. To address this issue we introduce a model which iteratively polishes the document representation on many passes through the document. As part of our model, we also introduce a selective reading mechanism that decides more accurately the extent to which each sentence in the model should be updated. Experimental results on the CNN/DailyMail and DUC2002 datasets demonstrate that our model significantly outperforms state-of-the-art extractive systems when evaluated by machines and by humans.","ITS is a new model for extractive text summarization that iteratively polishes the document representation on multiple passes through the document, inspired by the observation that humans often need to read an article multiple times to fully understand and summarize its contents. The model also includes a selective reading mechanism that accurately determines the extent to which each sentence should be updated. Experimental results on two datasets show that ITS outperforms state-of-the-art extractive systems when evaluated by both machines and humans.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to maintain the most important ideas from the original article and to remove secondary or redundant concepts.', 'Who is the target audience?': 'The summaries are for anyone who needs to store and digest large amounts of textual data.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main ideas of a document without having to read the entire article. They have significant usage potential in society.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'DUC 2002']","['ROUGE', 'Overlap with LEAD-3']","['Informativeness', 'Coherence']",https://github.com/yingtaomj/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing,https://aclanthology.org/D18-1442,"{'Existing extractive summarization methods generate the summary after only one pass through the document, which can lead to a subpar summarization.': 'The authors propose Iterative Text Summarization (ITS), an iteration-based summary generator that reads through the document multiple times, polishing and updating its internal representation of the document to achieve better understanding and better summarization.', 'Extractive summarization methods rely on human-engineered features or use neural networks to automatically learn features for sentence selection.': 'The authors introduce a novel iterative neural network model that repeatedly polishes the distributed representation of the document instead of generating it once for all. They also propose a selective reading mechanism, which decides how much information should be updated of each sentence based on its relationship with the polished document representation.', 'There is a growing need for storing and digesting large amounts of textual data, and automatic summarization systems have significant usage potential in society.': 'The authors propose ITS as a potential solution to this problem, as it can generate high-quality summaries of large amounts of textual data. They also evaluate their summarization model on representative CNN/DailyMail corpora and benchmark DUC2002 dataset, demonstrating that their model outperforms state-of-the-art extractive systems when evaluated automatically and by human.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:f08b8339840fe9f2e381be9ba8080246677c5b8c,GENERATING WIKIPEDIA BY SUMMARIZING LONG SEQUENCES,ICLR,2018,"['Peter J. Liu', 'Mohammad Saleh', 'Etienne Pot', 'Ben Goodrich', 'Ryan Sepassi', 'Łukasz Kaiser', 'Noam Shazeer']","We show that generating English Wikipedia articles can be approached as a multidocument summarization of source documents. We use extractive summarization to coarsely identify salient information and a neural abstractive model to generate the article. For the abstractive model, we introduce a decoder-only architecture that can scalably attend to very long sequences, much longer than typical encoderdecoder architectures used in sequence transduction. We show that this model can generate fluent, coherent multi-sentence paragraphs and even whole Wikipedia articles. When given reference documents, we show it can extract relevant factual information as reflected in perplexity, ROUGE scores and human evaluations.","The paper discusses a method for generating English Wikipedia articles by summarizing source documents using extractive summarization and a neural abstractive model. The abstractive model uses a decoder-only architecture that can attend to very long sequences, allowing it to generate fluent and coherent multi-sentence paragraphs and even whole articles. The model is able to extract relevant factual information when given reference documents, as reflected in perplexity, ROUGE scores, and human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for multi-document summarization, specifically for the English Wikipedia as a supervised machine learning task.', 'Who is the target audience?': 'The summaries are for generating the first section, or lead, of Wikipedia articles conditioned on reference text.', 'How will the summaries be used?': 'The summaries will be used to generate entire Wikipedia articles and improve the abstractive neural methods for multi-document summarization.'}",['method'],['Unit Selection'],['WikiSum'],['ROUGE'],"['Focus', 'Grammar', 'Non-redundancy', 'Referential Clarity', 'Coherence']",https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum,https://openreview.net/forum?id=Hyg0vbWC-,"{'Prior work on abstractive text summarization has focused on single-document summarization, which requires a significant number of parallel article-summary pairs.': 'The authors propose to tackle the task of multi-document summarization, where the input is a collection of related documents from which a summary is distilled.', 'Limited application of abstractive neural methods in multi-document summarization due to the paucity of large, labeled datasets.': 'The authors consider English Wikipedia as a supervised machine learning task for multi-document summarization, where the input is comprised of a Wikipedia topic and a collection of non-Wikipedia reference documents, and the target is the Wikipedia article text.', 'The Transformer architecture, which has shown success in natural-language sequence transduction tasks, may not perform well in the case of longer input sequences compared to recurrent neural network (RNN) and Transformer encoder-decoder models.': 'The authors modify the Transformer architecture to only consist of a decoder, which performs better in the case of longer input sequences, and show that their modeling improvements allow them to generate entire Wikipedia articles.'}",supervised,['Wikipedia'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data']"
SP:43d063c1d572b97f2a1573f0be388d125eda10dd,Improving Latent Alignment in Text Summarization by Generalizing the Pointer Generator,EMNLP,2019,"['Xiaoyu Shen', 'Yang Zhao', 'Hui Su', 'Dietrich Klakow']","Pointer Generators have been the de facto standard for modern summarization systems. However, this architecture faces two major drawbacks: Firstly, the pointer is limited to copying the exact words while ignoring possible inflections or abstractions, which restricts its power of capturing richer latent alignment. Secondly, the copy mechanism results in a strong bias towards extractive generations, where most sentences are produced by simply copying from the source text. In this paper, we address these problems by allowing the model to “edit” pointed tokens instead of always hard copying them. The editing is performed by transforming the pointed word vector into a target space with a learned relation embedding. On three large-scale summarization dataset, we show the model is able to (1) capture more latent alignment relations than exact word matches, (2) improve word alignment accuracy, allowing for better model interpretation and controlling, (3) generate higherquality summaries validated by both qualitative and quantitative evaluations and (4) bring more abstraction to the generated summaries.1","The paper discusses the limitations of Pointer Generators in modern summarization systems, which are restricted to exact word matches and result in a bias towards extractive generations. The authors propose a solution by allowing the model to ""edit"" pointed tokens, transforming them into a target space with a learned relation embedding. The model is shown to capture more latent alignment relations, improve word alignment accuracy, generate higher quality summaries, and bring more abstraction to the generated summaries. The proposed approach is validated on three large-scale summarization datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of summarization models.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to efficiently post-edit machine-generated summaries and help readers track back the source context when they are interested in specific details.'}",['method'],"['Input Encoding', 'Unit Selection']","['CNN/DailyMail', 'Gigaword', 'XSum']",['ROUGE'],"['Fluency', 'Faithfulness']",https://github.com/chin-gyou/generalized-PG,https://aclanthology.org/D19-1390,"{'Standard pointer generators only capture exact word matches, which restricts their application on highly abstractive datasets where only a few words are exactly copied.': 'The authors propose Generalized Pointer Generator (GPG) which replaces the hard copy component with a more general soft “editing” function. They do this by learning a relation embedding to transform the pointed word into a target embedding. The generalized point mode is encouraged to capture latent alignment which cannot be identified by the standard pointer generator.', 'The hard copy operation biases the model towards extractive summarization, which is undesirable for generating more human-like summaries.': 'The proposed GPG model eliminates the hard copy operation and allows for editing the pointed token instead of always copying exactly. This improves the abstraction of generations.', 'The OOV (out-of-vocabulary) problem restricts the performance of summarization models.': 'The authors utilize the byte-pair encoding (BPE) segmentation to split rare words into sub-units, which eliminates the OOV problem.', 'Pointer generators fail to model alignment relations that are not exact copies, which restricts their controllability and interpretation.': 'The proposed GPG model captures richer latent alignment and improves the word alignment accuracy, enabling better controllability and interpretation. The induced alignment offers useful annotations for people to identify the source correspondence for each target word.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:f7dac5b58ffa603a9bb80030810f876e50b678b8,Countering the Effects of Lead Bias in News Summarization via Multi-Stage Training and Auxiliary Losses,EMNLP,2019,"['Matt Grenander', 'Yue Dong', 'Jackie C. K. Cheung', 'Annie Louis']","Sentence position is a strong feature for news summarization, since the lead often (but not always) summarizes the key points of the article. In this paper, we show that recent neural systems excessively exploit this trend, which although powerful for many inputs, is also detrimental when summarizing documents where important content should be extracted from later parts of the article. We propose two techniques to make systems sensitive to the importance of content in different parts of the article. The first technique employs ‘unbiased’ data; i.e., randomly shuffled sentences of the source document, to pretrain the model. The second technique uses an auxiliary ROUGEbased loss that encourages the model to distribute importance scores throughout a document by mimicking sentence-level ROUGE scores on the training data. We show that these techniques significantly improve the performance of a competitive reinforcement learning based extractive system, with the auxiliary loss being more powerful than pretraining.","The paper discusses how sentence position is a strong feature for news summarization, but recent neural systems excessively exploit this trend, which can be detrimental when summarizing documents where important content is in later parts of the article. The authors propose two techniques to make systems sensitive to the importance of content in different parts of the article: pretraining the model with randomly shuffled sentences and using an auxiliary ROUGE-based loss. These techniques significantly improve the performance of a reinforcement learning-based extractive system, with the auxiliary loss being more powerful than pretraining.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce accurate and grammatical summaries of news articles.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the key information in a news article.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a news article without having to read the entire article.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/D19-1620,"{'Extractive summarization systems in the news domain rely heavily on the position of sentences in the source document, which leads to a bias towards selecting sentences from the beginning of the article.': 'The authors propose using ""unbiased data"" created by permuting the order of sentences in the training articles for pre-training, followed by training on the original (unshuffled) articles.', 'Even the most recent neural methods predominantly pick sentences from the lead, and their content selection performance drops greatly when the position cues are withheld.': ""The authors introduce an auxiliary loss which encourages the model's scores for sentences to mimic an estimated score distribution over the sentences, computed using ROUGE overlap with the gold standard."", 'When summary-worthy sentences appear late in the article, there is a large performance discrepancy between the oracle summary and state-of-the-art summarizers, indicating that learning to balance lead bias with other features of news text is a noteworthy issue to tackle.': 'The authors propose using the techniques mentioned above to improve content selection in the face of this bias, which leads to significantly better ROUGE scores compared to the base systems, especially when the true best sentences appear later in the article.'}",reinforced,['News'],[]
SP:fd361d2fa54fa945ca9904e876e0b87b287fa09d,HIBERT: Document Level Pre-training of Hierarchical Bidirectional Transformers for Document Summarization,ACL,2019,"['Xingxing Zhang', 'Furu Wei', 'Ming Zhou']","Neural extractive summarization models usually employ a hierarchical encoder for document encoding and they are trained using sentence-level labels, which are created heuristically using rule-based methods. Training the hierarchical encoder with these inaccurate labels is challenging. Inspired by the recent work on pre-training transformer sentence encoders (Devlin et al., 2018), we propose HIBERT (as shorthand for HIerachical Bidirectional Encoder Representations from Transformers) for document encoding and a method to pre-train it using unlabeled data. We apply the pre-trained HIBERT to our summarization model and it outperforms its randomly initialized counterpart by 1.25 ROUGE on the CNN/Dailymail dataset and by 2.0 ROUGE on a version of New York Times dataset. We also achieve the state-of-the-art performance on these two datasets.","The paper proposes a new model called HIBERT for document encoding in neural extractive summarization models. It pre-trains the model using unlabeled data and applies it to the summarization model, resulting in better performance compared to randomly initialized models. The proposed model achieves state-of-the-art performance on the CNN/Dailymail and New York Times datasets.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to rewrite them into a shorter form while still retaining their important content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important content of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the important content of a document, such as for decision-making or to determine if a document is relevant to a particular topic.'}",['method'],"['External Knowledge', 'Input Encoding']","['CNN/DailyMail', 'NYT']",['ROUGE'],['Overall Quality'],,https://aclanthology.org/P19-1499/,"{'Extractive models require sentence level labels, which are usually not included in most summarization datasets.': 'Extractive models proposed recently employ hierarchical document encoders and even have neural decoders, which are complex. The authors propose to first pre-train the “complex”’ part (i.e., the hierarchical encoder) of the extractive model on unlabeled data and then learn to classify sentences with their model initialized from the pre-trained encoder.', 'The extractive model overfits to the training set quickly after the second epoch, which indicates the training set may not be fully utilized.': 'The authors propose to pre-train the “complex”’ part (i.e., the hierarchical encoder) of the extractive model on unlabeled data using an unsupervised method called HIBERT (HIerachical Bidirectional Encoder Representations from Transformers).', 'Abstractive models may not generate summaries that are grammatical and convey the same meaning as the original document.': 'The authors suggest that extractive models are more reliable than their abstractive counterparts.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:8fc9198726dd38bc400bb0ae5ccd7aa888bd88d8,An Editorial Network for Enhanced Document Summarization,ACL,2019,"['Edward Moroshko', 'Guy Feigenblat', 'Haggai Roitman', 'David Konopnicki']","We suggest a new idea of Editorial Network – a mixed extractive-abstractive summarization approach, which is applied as a postprocessing step over a given sequence of extracted sentences. We further suggest an effective way for training the “editor"" based on a novel soft-labeling approach. Using the CNN/DailyMail dataset we demonstrate the effectiveness of our approach compared to state-of-the-art extractive-only or abstractiveonly baselines.","

System: The paper proposes a new approach to summarization called the Editorial Network, which combines extractive and abstractive methods. This approach is applied as a postprocessing step to a sequence of extracted sentences. The paper also suggests a novel soft-labeling approach for training the ""editor."" The effectiveness of this approach is demonstrated using the CNN/DailyMail dataset, and it is shown to outperform state-of-the-art extractive-only or abstractive-only baselines.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to condense a given piece of text into a shorter version while preserving the main essence of the original text and keeping the generated summary as readable as possible.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer text, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding longer texts, as well as to provide a quick overview of the main points for decision-making or further research.'}",['method'],['Post Processing'],['CNN/DailyMail'],"['ROUGE', 'WinDiff']",[''],,https://aclanthology.org/D19-5407,"{'Extractive summaries tend to be less fluent, coherent and readable and may include superfluous text.': 'The authors propose abstractive methods that apply natural language paraphrasing and/or compression on a given text. They suggest a common approach based on the encoder-decoder (seq-to-seq) paradigm.', ""Abstractive methods' quality declines over longer textual inputs, which may lead to a higher redundancy."": 'The authors suggest using attention mechanisms, which aim to imitate the attentive reading behaviour of humans. They propose two main types of attention methods, either soft or hard.', 'Abstractive methods are sensitive to vocabulary size, making them more difficult to train and generalize.': 'The authors suggest using attention mechanisms to handle long text sequences in abstractive settings.', ""Previous works' final summary is either entirely extracted or generated using an abstractive process."": 'The authors suggest a new idea of ""Editorial Network"" (EditNet) - a mixed extractive-abstractive summarization approach. A summary generated by EditNet may include sentences that were either extracted, abstracted or of both types. Moreover, per considered sentence, EditNet may decide not to take either of these decisions and completely reject the sentence.', ""The authors want to demonstrate that EditNet's summarization quality is highly competitive to that obtained by both state-of-the-art abstractive-only and extractive-only baselines."": ""The authors use the CNN/DailyMail dataset to demonstrate EditNet's summarization quality.""}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:486868cfb8839beb1330d563cfee5d3c7c142eec,Transformer-based Model for Single Documents Neural Summarization,ACL,2019,"['Elozino Egonmwan', 'Yllias Chali']","We propose a system that improves performance on single document summarization task using the CNN/DailyMail and Newsroom datasets. It follows the popular encoderdecoder paradigm, but with an extra focus on the encoder. The intuition is that the probability of correctly decoding an information significantly lies in the pattern and correctness of the encoder. Hence we introduce, encode – encode – decode. A framework that encodes the source text first with a transformer, then a sequence-to-sequence (seq2seq) model. We find that the transformer and seq2seq model complement themselves adequately, making for a richer encoded vector representation. We also find that paying more attention to the vocabulary of target words during abstraction improves performance. We experiment our hypothesis and framework on the task of extractive and abstractive single document summarization and evaluate using the standard CNN/DailyMail dataset and the recently released Newsroom dataset.","The paper proposes a system that enhances performance on single document summarization tasks using the CNN/DailyMail and Newsroom datasets. The system follows the encoder-decoder paradigm but with a focus on the encoder. The authors introduce a framework that encodes the source text with a transformer and then a sequence-to-sequence model. They find that the transformer and seq2seq model complement each other, resulting in a richer encoded vector representation. Additionally, paying more attention to the vocabulary of target words during abstraction improves performance. The authors experiment with their hypothesis and framework on extractive and abstractive single document summarization tasks and evaluate using the CNN/DailyMail and Newsroom datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract the most important information and present it in a concise form.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes such as information retrieval, document classification, and decision-making.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'Newsroom']",['ROUGE'],[''],,https://aclanthology.org/D19-5607,"{'Identifying salient parts of the document without any guide in the form of a query is a substantial problem to tackle in extractive summarization.': 'The authors propose a neural extractor that uses the recent bidirectional transformer encoder to identify salient parts of the document. They also present a simple approach to reduce bias in the created data.', 'The training data for extractive summarization is not sequentially labelled, making it difficult to train a sequence classification model.': ""The authors improve on Nallapati et al.'s approach to generate labelled data from the abstractive ground-truth summary, resulting in more accurate extractive labels."", 'Abstractive summarization faces challenges like grammatical correctness and repetition of words, especially when generating long-worded sentences.': 'The authors propose a blend of the transformer and seq2seq model for abstractive summarization, which improves coherence and grammatical correctness by learning long-term dependency relations and utilizing multi-head self attention.', 'Information redundancy is a problem in abstractive summarization.': 'The authors propose to extract salient sentences and then abstract, which mitigates the problem of information redundancy and improves performance on two specific datasets.'}",supervised,['News'],['identifying-important-contents-from-the-document']
SP:ff86612ced891b1ad1d689514283a2becca4ce62,Jointly Extracting and Compressing Documents with Summary State Representations,NAACL,2019,"['Afonso Mendes', 'Shashi Narayan', 'Sebastião Miranda', 'Zita Marinho', 'André F. T. Martins', 'Shay B. Cohen']","We present a new neural model for text summarization that first extracts sentences from a document and then compresses them. The proposed model offers a balance that sidesteps the difficulties in abstractive methods while generating more concise summaries than extractive methods. In addition, our model dynamically determines the length of the output summary based on the gold summaries it observes during training, and does not require length constraints typical to extractive summarization. The model achieves state-of-the-art results on the CNN/DailyMail and Newsroom datasets, improving over current extractive and abstractive methods. Human evaluations demonstrate that our model generates concise and informative summaries. We also make available a new dataset of oracle compressive summaries derived automatically from the CNN/DailyMail reference summaries.","The paper presents a new neural model for text summarization that extracts sentences from a document and compresses them to generate concise and informative summaries. The model dynamically determines the length of the output summary based on gold summaries observed during training, and does not require length constraints typical to extractive summarization. The model achieves state-of-the-art results on the CNN/DailyMail and Newsroom datasets, improving over current extractive and abstractive methods. A new dataset of oracle compressive summaries derived automatically from the CNN/DailyMail reference summaries is also made available.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to solve the important NLP problem of text summarization, which has a wide range of applications in data-driven industries such as news, health, and defense.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the informative content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used in various ways, such as for news articles, research papers, or legal documents, to provide a quick overview of the content and help readers decide whether to read the full text.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'Newsroom']","['ROUGE', 'METEOR', 'Cosine Similarity']",['QA'],https://github.com/Priberam/exconsumm,https://aclanthology.org/N19-1397,"{'Extractive summarization systems are wasteful since they cannot trim the original sentences to fit into the summary, and they lack a mechanism to ensure overall coherence.': 'The authors propose a compressive summarization approach that selects a set of sentences from the input document and compresses them by removing unnecessary words while keeping the summaries informative, concise, and grammatical. They achieve this by dynamically modeling the generated summary using a Long Short Term Memory (LSTM) to produce summary state representations, which provide crucial information to iteratively increment summaries based on previously extracted information.', 'Abstractive summarization systems require natural language generation and semantic representation, problems that are inherently harder to solve than just extracting sentences from the original document.': 'The authors propose a middle ground approach, compressive summarization, that combines the benefits of both extractive and abstractive summarization. Their model can be trained in both extractive and compressive settings, allowing for variable length summaries as opposed to fixed lengths in previous extractive systems.', 'Previous summarization systems have limitations in generating informative and concise summaries.': 'The authors present a novel end-to-end neural architecture for EXtractive and COmpressive Neural SUMMarization (EXCONSUMM) and validate it on the CNN/DailyMail and the Newsroom datasets. Their model generates variable-length summaries that correlate well with gold summaries in length and are informative and concise. They also provide a new CNN/DailyMail dataset annotated with automatic compressions for each sentence and a set of compressed oracle summaries. Experimental results show that both the extractive and compressive variants of their model provide state-of-the-art results, and human evaluation further shows that their model is better than previous state-of-the-art systems at generating informative and concise summaries.'}",supervised,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:72abd7fe66a5b56f8501ce04e285eeac1f056666,Single Document Summarization as Tree Induction,NAACL,2019,"['Yang Liu', 'Ivan Titov', 'Mirella Lapata']","In this paper we conceptualize singledocument extractive summarization as a tree induction problem. In contrast to previous approaches (Marcu, 1999; Yoshida et al., 2014) which have relied on linguistically motivated document representations to generate summaries, our model induces a multi-root dependency tree while predicting the output summary. Each root node in the tree is a summary sentence, and the subtrees attached to it are sentences whose content relates to or explains the summary sentence. We design a new iterative refinement algorithm: it induces the trees through repeatedly refining the structures predicted by previous iterations. We demonstrate experimentally on two benchmark datasets that our summarizer1 performs competitively against state-of-the-art methods.","The paper proposes a new approach to single-document extractive summarization, using a multi-root dependency tree to generate summaries. The model is designed to refine its structures through an iterative algorithm, and is shown to perform competitively against existing methods on two benchmark datasets. This approach differs from previous methods that rely on linguistically motivated document representations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to automatically generate a shorter version of a document while retaining its most important information.', 'Who is the target audience?': 'The summaries are for various information access applications, such as tools which digest textual content (e.g., news, social media, reviews), answer questions, or provide recommendations.', 'How will the summaries be used?': 'The summaries will be used to provide a shorter version of a document while retaining its most important information for various information access applications.'}",['method'],"['Input Encoding', 'Objective Function']","['CNN/DailyMail', 'NYT']",['ROUGE'],"['QA', 'Overall Quality', 'Informativeness', 'Fluency', 'Succinctness']",https://github.com/nlpyang/SUMO,https://aclanthology.org/N19-1173,"{'Existing extractive summarization approaches rely on recurrent neural networks to model the document and obtain a vector representation for each sentence, without taking the structure of the document into account.': 'The authors propose a new framework that uses structured attention as both the objective and attention weights for extractive summarization. Their model represents documents as multiroot dependency trees where each root node is a summary sentence, and the subtrees attached to it are sentences whose content is related to and covered by the summary sentence.', 'Existing neural-based extractive models lack interpretability and are not able to rationalize their predictions.': ""The authors' proposed model brings more interpretability in the summarization process by helping explain how document content contributes to the model’s decisions."", 'The reliance on a parser which is both expensive to obtain and error-prone presents a major obstacle to the widespread use of discourse structure for summarization.': 'The authors recognize the merits of structure-aware representations for various NLP tasks and propose a new framework that learns to induce document-level structures through repeatedly refining the trees predicted by previous iterations, without relying on a parser.', 'Existing models for solving iterative inference problems do not consider structure refinement for tree induction problems.': 'The authors propose a new iterative structure refinement algorithm, which allows the model to infer complex trees that go beyond simple parent-child relations and is conceptually related to recently proposed models for solving iterative inference problems.', 'The authors aim to demonstrate the effectiveness of their proposed approach.': 'The authors conduct large-scale evaluation studies (both automatic and human-based) which demonstrate that their approach performs competitively against state-of-the-art methods while being able to rationalize model predictions.'}",supervised,['News'],['lack-of-suitable-training-data']
SP:511bf7b7ebebcfa61e4e47bc7da06684f74578d8,Inducing Document Structure for Aspect-based Summarization,ACL,2019,"['Lea Frermann', 'Alexandre Klementiev']","Automatic summarization is typically treated as a 1-to-1 mapping from document to summary. Documents such as news articles, however, are structured and often cover multiple topics or aspects; and readers may be interested in only some of them. We tackle the task of aspect-based summarization, where, given a document and a target aspect, our models generate a summary centered around the aspect. We induce latent document structure jointly with an abstractive summarization objective, and train our models in a scalable synthetic setup. In addition to improvements in summarization over topic-agnostic baselines, we demonstrate the benefit of the learnt document structure: we show that our models (a) learn to accurately segment documents by aspect; (b) can leverage the structure to produce both abstractive and extractive aspectbased summaries; and (c) that structure is particularly advantageous for summarizing long documents. All results transfer from synthetic training documents to natural news articles from CNN/Daily Mail and RCV1.","The paper discusses aspect-based summarization, which generates a summary centered around a specific aspect of a document. The authors induce latent document structure and train their models in a scalable synthetic setup, resulting in improvements in summarization over topic-agnostic baselines. The models accurately segment documents by aspect and can produce both abstractive and extractive aspect-based summaries. The learned document structure is particularly advantageous for summarizing long documents, and the results transfer from synthetic training documents to natural news articles from CNN/Daily Mail and RCV1.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents for aspect-based summarization, which involves generating a summary specific to a target aspect.', 'Who is the target audience?': 'The summaries are for users who may be interested in specific aspects of a document or document collection, such as opinions on battery life in smartphone reviews or the effect of a body builder running for governor on his sports career.', 'How will the summaries be used?': 'The summaries will be used to provide users with a quick and specific overview of the aspects they are interested in, and can also be leveraged for other purposes such as document segmentation and model interpretability.'}",['method'],"['Unit Relationship', 'Input Encoding']",['CNN/DailyMail'],"['ROUGE', 'METEOR']","['Aspect Accuracy', 'Aspect Diversity', 'Fluency', 'Informativeness']",https://github.com/ColiLea/aspect_based_summarization,https://aclanthology.org/P19-1630,"{'Abstractive summarization systems treat documents as unstructured and generate a single generic summary per document.': 'Incorporating document structure into abstractive summarization systems is beneficial for at least three reasons: it increases model interpretability, can be leveraged for other purposes such as document segmentation, and helps alleviate performance bottlenecks associated with summarization of long documents by learning to focus only on the segments relevant to the topic of interest.', 'Users may be interested only in some topics of a long document or document collection.': 'The authors develop models for aspect-based summarization, where given a document and a target aspect, their systems generate a summary specific to the aspect.', 'Data sparsity problem in aspect-based summarization.': 'The authors propose a scalable synthetic training setup that leverages aspect labels associated with each article in the CNN/Daily Mail dataset and constructs synthetic multi-aspect documents by interleaving paragraphs of articles pertaining to different aspects, and pairing them with the original summary of one of the included articles.', 'Lack of supervision such as pre-trained topics or aspect-segmentation of documents.': ""The authors' setup requires no supervision such as pre-trained topics or aspect-segmentation of documents."", 'Weakness of encoder-decoder summarization models.': ""The authors' models induce meaningful latent structure, which allows them to generate abstractive and extractive aspect-driven summaries, segment documents by aspect, and generalize to long documents. Associating model attention with aspects also improves model interpretability."", 'Lack of a sizable data set for aspect-based summarization.': 'The authors adopt a scalable, synthetic training setup and show that their models generalize from synthetic to natural documents, outperforming recent aspect-agnostic summarization models in both cases.', 'Difficulty in evaluating aspect-based summarization models.': ""The authors' evaluation shows that their generated summaries are more aspect-relevant and meaningful compared to aspect agnostic baselines, and that their models produce both extractive and abstractive summaries of high quality for long documents. They also show that their models, trained on synthetic documents, generalize to natural documents from the Reuters and the CNN/Daily Mail corpus, through both automatic and human evaluation.""}",supervised,['News'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:eb58a473ed66a42440f2aaf43c8c54f2f7952363,Cross-Task Knowledge Transfer for Query-Based Text Summarization,ACL,2019,"['Elozino Egonmwan', 'Vittorio Castelli', 'Md Arafat Sultan']","We demonstrate the viability of knowledge transfer between two related tasks: machine reading comprehension (MRC) and querybased text summarization. Using an MRC model trained on the SQuAD1.1 dataset as a core system component, we first build an extractive query-based summarizer. For better precision, this summarizer also compresses the output of the MRC model using a novel sentence compression technique. We further leverage pre-trained machine translation systems to abstract our extracted summaries. Our models achieve state-of-the-art results on the publicly available CNN/Daily Mail and Debatepedia datasets, and can serve as simple yet powerful baselines for future systems. We also hope that these results will encourage research on transfer learning from large MRC corpora to query-based summarization.","System: The paper explores the possibility of transferring knowledge between machine reading comprehension (MRC) and query-based text summarization. The authors use an MRC model trained on the SQuAD1.1 dataset to build an extractive query-based summarizer, which compresses the output of the MRC model using a new sentence compression technique. They also use pre-trained machine translation systems to abstract the extracted summaries. The models achieve state-of-the-art results on the CNN/Daily Mail and Debatepedia datasets, and can serve as powerful baselines for future systems. The authors hope that their results will encourage further research on transfer learning from large MRC corpora to query-based summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to select the most relevant points for a given query and arrange them into a concise and coherent snippet of text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document in response to a query.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a document in response to a query, without having to read the entire document.'}",['method'],['Auxiliary Tasks'],"['CNN/DailyMail', 'Debatepedia']",['ROUGE'],[''],,https://aclanthology.org/D19-5810,"{'Existing approaches for query-based single-document text summarization train models using summarization data corpora, which are of moderate size.': 'The authors propose methods to directly produce extractive and abstractive query-based summaries from pretrained machine reading comprehension (MRC) and machine translation (MT) modules, which have large corpora available for related tasks. This approach outperforms existing methods and suggests a novel route to query-based summarization.', 'There is a lack of exploration of transfer learning among tasks other than query-based summarization.': 'The authors show how existing off-the-shelf components for tasks other than query-based summarization are competitive with the state-of-the-art in the field, even without model adaptation or transfer learning. They hope to encourage researchers to more closely examine transfer learning among these tasks.', 'Query-based extractive summarizers trained for specific datasets do not yield optimal results.': 'The authors show how processing the output of an MRC system with a simple rule-based sentence compression module that operates on the dependency parse of the answer sentence yields better results than query-based extractive summarizers trained for the specific dataset.', 'Query-based abstractive summarizers trained for specific datasets do not yield optimal results.': 'The authors demonstrate how a sequence-to-sequence model that uses two machine translation engines, applied to the output of the above solution, yields better results than query-based abstractive summarizers trained for the specific dataset.'}",unsupervised,"['News', 'CQA']","['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:c7966c88f3b2d1c0c81df50821050deb4af74985,Read what you need: Controllable Aspect-based Opinion Summarization of Tourist Reviews,SIGIR,2020,"['Rajdeep Mukherjee', 'Hari Chandana Peruri', 'Uppada Vishnu', 'Pawan Goyal', 'Sourangshu Bhattacharya', 'Niloy Ganguly']","Manually extracting relevant aspects and opinions from large volumes of user-generated text is a time-consuming process. Summaries, on the other hand, help readers with limited time budgets to quickly consume the key ideas from the data. State-of-the-art approaches for multi-document summarization, however, do not consider user preferences while generating summaries. In this work, we argue the need and propose a solution for generating personalized aspect-based opinion summaries from large collections of online tourist reviews. We let our readers decide and control several attributes of the summary such as the length and specific aspects of interest among others. Specifically, we take an unsupervised approach to extract coherent aspects from tourist reviews posted on TripAdvisor. We then propose an Integer Linear Programming (ILP) based extractive technique to select an informative subset of opinions around the identified aspects while respecting the user-specified values for various control parameters. Finally, we evaluate and compare our summaries using crowdsourcing and ROUGE-based metrics and obtain competitive results.","The paper discusses the time-consuming process of manually extracting relevant aspects and opinions from large volumes of user-generated text. It proposes a solution for generating personalized aspect-based opinion summaries from online tourist reviews, allowing readers to control various attributes of the summary. The approach involves an unsupervised method to extract coherent aspects and an Integer Linear Programming (ILP) based extractive technique to select informative opinions around those aspects while respecting user-specified values. The authors evaluate and compare their summaries using crowdsourcing and ROUGE-based metrics and obtain competitive results.","{'What is the purpose of the summaries?': 'The authors are generating summaries of tourist reviews to extract relevant knowledge from them and provide a concise and digestible summary of opinions.', 'Who is the target audience?': 'The summaries are for future travelers and local service providers who can benefit from the wide range of opinionated information for shaping their decisions.', 'How will the summaries be used?': ""The summaries can be customized according to reader's preferences and used to control several attributes of the summary such as its length and specific aspects of interest it must focus on. They can be used to provide personalized and controllable summaries of tourist reviews.""}","['corpus', 'method']","['Controlled Generation', 'Objective Function']",['TripAdvisor'],['ROUGE'],"['Aspect Coverage', 'Readability', 'Diversity']",https://github.com/rajdeep345/ControllableSumm,https://doi.org/10.1145/3397271.3401269,"{'Manually going through all reviews and extracting relevant knowledge from them is an overwhelming task.': 'The authors propose an unsupervised and controllable summarization framework which extracts aspect-based opinion summaries from huge corpora of tourist reviews, the shape and content of which can be customized according to reader’s preferences.', 'State-of-the-art approaches for multi-document summarization do not consider different levels of information needs of readers.': 'The authors propose a controllable summarization framework that allows readers to customize the shape and content of summaries to suit their varying interests and time budgets.', 'Supervised methods for opinion summarization depend on large annotated datasets of document-summary pairs to train their models, making them difficult to adapt across domains.': 'The authors propose an unsupervised extractive summarization framework built on top of an unsupervised aspect extraction module which makes their method generalizable to any domain.', 'State-of-the-art methods for opinion summarization do not allow for personalization while generating summaries from diverse range of opinionated text.': 'The authors propose a controllable summarization framework that allows readers to customize several attributes of the summary, such as its length and specific aspects of interest it must focus on.', 'There is a lack of controllable summarization techniques that are unsupervised in nature.': 'The authors propose an unsupervised and extractive summarization framework that allows readers to control several attributes of the summary, such as its length and specific aspects of interest it must focus on.', 'There is a need for a dataset to evaluate the proposed framework.': 'The authors create a dataset consisting of user reviews posted on TripAdvisor and conduct experiments to evaluate their proposed framework. They achieve competitive performance on a variety of evaluation measures when compared against their baseline methods for unsupervised summarization.'}",unsupervised,['Reviews'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:6c8e1241e297d9b9b814145f0676df106bb4321b,Copy or Rewrite: Hybrid Summarization with Hierarchical Reinforcement Learning,AAAI,2020,"['Liqiang Xiao', 'Lu Wang', 'Hao He', 'Yaohui Jin']","Jointly using the extractive and abstractive summarization methods can combine their complementary advantages, generating both informative and concise summary. Existing methods that adopt an extract-then-abstract strategy have achieved impressive results, yet they suffer from the information loss in the abstraction step because they compress all the selected sentences without distinguish. Especially when the whole sentence is summary-worthy, salient content would be lost by compression. To address this problem, we propose HYSUM, a hybrid framework for summarization that can flexibly switch between copying sentence and rewriting sentence according to the degree of redundancy. In this way, our approach can effectively combine the advantages of two branches of summarization, juggling informativity and conciseness. Moreover, we based on Hierarchical Reinforcement Learning, propose an end-to-end reinforcing method to bridge together the extraction module and rewriting module, which can enhance the cooperation between them. Automatic evaluation shows that our approach significantly outperforms the state-of-the-arts on the CNN/DailyMail corpus. Human evaluation also demonstrates that our generated summaries are more informative and concise than popular models.","The paper proposes a hybrid framework for summarization called HYSUM that combines extractive and abstractive methods to generate informative and concise summaries. Existing extract-then-abstract methods suffer from information loss in the abstraction step, but HYSUM can switch between copying and rewriting sentences based on redundancy to effectively combine the advantages of both methods. The paper also proposes an end-to-end reinforcing method based on Hierarchical Reinforcement Learning to enhance cooperation between the extraction and rewriting modules. Automatic and human evaluations show that HYSUM outperforms existing models on the CNN/DailyMail corpus.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long articles to provide a shorter and more concise version while maintaining the most important content.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the main points of a long article without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as research, news, or personal interest, to quickly grasp the main ideas of a long article.'}",['method'],['Unit Selection'],['CNN/DailyMail'],"['ROUGE', 'Coverage']","['Informativeness', 'Conciseness', 'Readability']",,https://ojs.aaai.org/index.php/AAAI/article/view/6470,"{'Extractive methods select the most salient sentences from the source article as the summary, which are precise at content selection making the result informative but suffer from high redundancy since it does not edit the sentences.': 'The authors propose a hybrid framework that can flexibly switch between copy (original) and rewriting according to the degree of sentence redundancy. By distinguishingly copying the succinct sentences and rewriting the redundant ones, the information loss would be reduced.', 'Abstractive methods can generate more concise summary via compressing and paraphrasing, while current models are weak at content selection and easy to lose crucial information.': 'The authors propose a hybrid framework that can effectively combine the strengths of both extractive and abstractive summarization methods, generating informative and concise summaries.', 'Existing works use the extract-then-abstract framework that suffers from an information loss in the abstract stage, since all the sentence is compressed and pruned without a distinguish.': 'The authors propose a two-step approach that first extracts the salience sentences from the input article, with a copy-or-write mechanism to distinguish the sentences according to the redundancy. Then, the final summary is generated by correspondingly copying or rewriting the selected sentences.', 'Existing training methods lack an effective reinforcement learning framework to bridge together two modules.': 'The authors propose an end-to-end training method based on Hierarchical Reinforcement Learning to enhance the cooperation of two modules and dynamically adapt them to each other during training.', 'There is a need for a summarization method that is more aligned with how humans summarize a long article.': 'The authors propose a strategy that can improve the performance because it is more aligned with how humans summarize a long article. Figure 1 shows the human behavior in summarization that some redundancy sentences are rewritten but others are kept unchanged.', 'There is a need for a summarization method that achieves a new state-of-the-art on CNN/DailyMail corpus.': ""The authors' method achieves a new state-of-the-art on CNN/DailyMail corpus, and human evaluation also verifies the informativeness and conciseness of their results.""}",reinforced,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:77e2938bf8974c954f74b065c8b9b152fc2ffbae,Few-Shot Learning for Opinion Summarization,EMNLP,2020,"['Arthur Bražinskas', 'Mirella Lapata', 'Ivan Titov']","Opinion summarization is the automatic creation of text reflecting subjective information expressed in multiple documents, such as user reviews of a product. The task is practically important and has attracted a lot of attention. However, due to the high cost of summary production, datasets large enough for training supervised models are lacking. Instead, the task has been traditionally approached with extractive methods that learn to select text fragments in an unsupervised or weakly-supervised way. Recently, it has been shown that abstractive summaries, potentially more fluent and better at reflecting conflicting information, can also be produced in an unsupervised fashion. However, these models, not being exposed to actual summaries, fail to capture their essential properties. In this work, we show that even a handful of summaries is sufficient to bootstrap generation of the summary text with all expected properties, such as writing style, informativeness, fluency, and sentiment preservation. We start by training a conditional Transformer language model to generate a new product review given other available reviews of the product. The model is also conditioned on review properties that are directly related to summaries; the properties are derived from reviews with no manual effort. In the second stage, we fine-tune a plug-in module that learns to predict property values on a handful of summaries. This lets us switch the generator to the summarization mode. We show on Amazon and Yelp datasets that our approach substantially outperforms previous extractive and abstractive methods in automatic and human evaluation.","The paper discusses the task of opinion summarization, which involves creating text that reflects subjective information expressed in multiple documents, such as user reviews of a product. The lack of large datasets for training supervised models has led to the use of extractive methods that select text fragments in an unsupervised or weakly-supervised way. However, recent research has shown that abstractive summaries can also be produced in an unsupervised fashion. The paper presents a method that uses a handful of summaries to bootstrap the generation of summary text with expected properties such as writing style, informativeness, fluency, and sentiment preservation. The approach involves training a conditional Transformer language model to generate a new product review given other available reviews of the product, and fine-tuning a plug-in module that predicts property values on a handful of summaries. The approach outperforms previous extractive and abstractive methods in automatic and human evaluation on Amazon and Yelp datasets.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of user opinions expressed in online resources to create digests, search, and report generation.', 'Who is the target audience?': 'The summaries are for various information access applications.', 'How will the summaries be used?': 'The summaries will be used for creating digests, search, and report generation.'}",['method'],['External Knowledge'],"['Amazon Product Reviews', 'Yelp Reviews']",['ROUGE'],"['Fluency', 'Conciseness', 'Non-redundancy', 'Informativeness', 'Sentiment']",https://github.com/abrazinskas/FewSum,https://aclanthology.org/2020.emnlp-main.337,"{'Lack of large annotated corpora for training deep models in opinion-summarization domain.': 'Propose a few-shot learning framework that can bootstrap generation of formal summary text using a tiny number of annotated instances.', 'Unsupervised abstractive multi-document models are unable to learn key characteristics of actual summaries.': 'Estimate a property-aware model on a large collection of reviews and adapt the model using a few annotator-created summaries, effectively switching the generator to the summarization regime.', 'Reviews in a large unannotated collection vary a lot and only a subset of them is appropriate for summaries.': 'Define properties of unannotated data that are directly related to the end task of summarization and condition the Transformer conditional language model (CLM) on these properties in training. Fine-tune parts of the model jointly with a tiny plug-in network on a handful of human-written summaries.', 'Naive fine-tuning of multi-million parameter models on small corpora leads to rapid over-fitting and poor generalization.': 'Use a few-shot learning framework that is less prone to over-fitting on small datasets and can successfully learn to control dynamics of a large CLM by providing property values that force generation of summaries.', 'Lack of cross-domain adaption in summarization systems.': 'Show that the proposed few-shot learning framework allows for successful cross-domain adaption.'}",supervised,['Opinions'],"['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:368b4506f6efbdbadd57df34a01911ce0060ceeb,Interactive Text Ranking with Bayesian Optimization: A Case Study on Community QA and Summarization,TACL,2020,"['Edwin Simpson', 'Yang Gao', 'Iryna Gurevych']","For many NLP applications, such as question answering and summarization, the goal is to select the best solution from a large space of candidates to meet a particular user’s needs. To address the lack of user or task-specific training data, we propose an interactive text ranking approach that actively selects pairs of candidates, from which the user selects the best. Unlike previous strategies, which attempt to learn a ranking across the whole candidate space, our method uses Bayesian optimization to focus the user’s labeling effort on high quality candidates and integrate prior knowledge to cope better with small data scenarios. We apply our method to community question answering (cQA) and extractive multidocument summarization, finding that it significantly outperforms existing interactive approaches. We also show that the ranking function learned by our method is an effective reward function for reinforcement learning, which improves the state of the art for interactive","text ranking. The paper proposes an interactive text ranking approach that uses Bayesian optimization to focus on high-quality candidates and integrate prior knowledge to address the lack of user or task-specific training data. The approach significantly outperforms existing interactive approaches in community question answering and extractive multidocument summarization. The ranking function learned by the method is also an effective reward function for reinforcement learning, improving the state of the art for interactive text ranking.","{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to address the challenge of NLP systems not being trained to solve a user's specific problem in text ranking tasks that are highly specific to an individual user's topic of interest."", 'Who is the target audience?': 'The summaries are for users who need to rank summaries or answers to non-factoid questions.', 'How will the summaries be used?': 'The summaries will be used to propose an interactive text ranking approach that efficiently gathers user feedback and combines it with predictions from pretrained, generic models to minimize the amount of effort the user must expend to train a ranker.'}",['method'],"['Unit Selection', 'Objective Function']","['DUC 2001', 'DUC 2002', 'DUC 2004']",['ROUGE'],[''],,https://direct.mit.edu/tacl/article-abstract/doi/10.1162/tacl_a_00344/96467,"{'Many text ranking tasks are highly specific to an individual user’s topic of interest, which presents a challenge for NLP systems that have not been trained to solve that user’s problem.': 'The authors propose an interactive text ranking approach that efficiently gathers user feedback and combines it with predictions from pretrained, generic models.', 'To minimize the amount of effort the user must expend to train a ranker, we learn from pairwise preference labels, in which the user compares two candidates and labels the best one.': 'The authors use pairwise preference labels to train the model and propose an interactive method for ranking texts that replaces the standard uncertainty-based acquisition functions with acquisition functions for Bayesian optimization (BO).', 'Many active learning strategies aim to learn a good ranking model for all candidates, which may waste labels on sorting poor candidates.': 'The authors propose a BO active learning strategy that minimizes the number of labels needed to find the best candidate, in contrast to uncertainty-based strategies that attempt to learn the entire ranking function.', 'Previous interactive text ranking methods either do not exploit prior information, combine heuristics with user feedback after active learning is complete, or require expensive re-training of a non-Bayesian method.': 'The authors learn the ranking function itself using a Bayesian approach, which integrates prior predictions from a generic model that is not tailored to the user.', 'The aim is to find the best candidate and those with low quality can simply be disregarded rather than ranked precisely.': 'The authors propose a BO active learning strategy that is better suited to tasks such as question answering, summarization, or translation, where the aim is to find the best candidate and those with low quality can simply be disregarded rather than ranked precisely.'}",reinforced,['CQA'],['controlled-and-tailored-summarization']
SP:58ee566c707a89463fdc8784a992441520acbf54,Compressive Summarization with Plausibility and Salience Modeling,EMNLP,2020,"['Shrey Desai', 'Jiacheng Xu', 'Greg Durrett']","Compressive summarization systems typically rely on a crafted set of syntactic rules to determine what spans of possible summary sentences can be deleted, then learn a model of what to actually delete by optimizing for content selection (ROUGE). In this work, we propose to relax the rigid syntactic constraints on candidate spans and instead leave compression decisions to two data-driven criteria: plausibility and salience. Deleting a span is plausible if removing it maintains the grammaticality and factuality of a sentence, and spans are salient if they contain important information from the summary. Each of these is judged by a pre-trained Transformer model, and only deletions that are both plausible and not salient can be applied. When integrated into a simple extraction-compression pipeline, our method achieves strong in-domain results on benchmark summarization datasets, and human evaluation shows that the plausibility model generally selects for grammatical and factual deletions. Furthermore, the flexibility of our approach allows it to generalize cross-domain: our system fine-tuned on only 500 samples from a new domain can match or exceed an in-domain extractive model trained on much more data.1","The paper proposes a new approach to compressive summarization that uses data-driven criteria of plausibility and salience to determine which spans of sentences can be deleted. A pre-trained Transformer model judges each criterion, and only deletions that are both plausible and not salient are applied. The approach achieves strong in-domain results on benchmark summarization datasets and can generalize cross-domain with fine-tuning on only 500 samples. Human evaluation shows that the plausibility model generally selects for grammatical and factual deletions.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to offer a tradeoff between the robustness of extractive models and the flexibility of abstractive models.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of a document without having to read the entire document. They can also be used to compare and analyze multiple documents.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'NYT', 'WikiHow', 'XSum', 'Reddit-TIFU']",['ROUGE'],"['Grammaticality', 'Factuality']",https://github.com/shreydesai/cups,https://aclanthology.org/2020.emnlp-main.507,"{'End-to-end learning-based compressive methods are not straightforward to train.': 'The authors propose a summarization system that compresses text in a more data-driven way. They create a small set of high-recall constituency-based compression rules that cover the space of legal deletions. These rules are used to propose candidate spans, and the ultimate deletion decisions are controlled by two data-driven models capturing different facets of the compression process.', 'Deriving oracles based on ROUGE optimizes only for content selection, not grammaticality or factuality of the summary.': 'The authors model plausibility and salience of span deletions. Plausibility is a domain-independent requirement that deletions maintain grammaticality and factuality, and salience is a domain-dependent notion that deletions should maximize content selection (from the standpoint of ROUGE). They leverage a pre-existing sentence compression dataset to learn plausibility, which transfers well to the summarization settings they consider.', 'Past approaches require significant engineering, such as creating a highly specific list of syntactic compression rules to identify permissible deletions. Such manually specified, hand-curated rules are fundamentally inflexible and hard to generalize to new domains.': 'The authors create a small set of high-recall constituency-based compression rules that cover the space of legal deletions. These rules are used to propose candidate spans, and the ultimate deletion decisions are controlled by two data-driven models capturing different facets of the compression process. This approach is more data-driven and flexible than past approaches.', 'The authors want to examine the cross-domain generalizability of their approach.': 'The authors conduct out-of-domain experiments to examine the cross-domain generalizability of their approach. They hold their plausibility model constant and adapt the extraction and salience models to a new setting with a small number of examples. They demonstrate that their compressive system can match or exceed the ROUGE of an in-domain extractive model trained on tens of thousands of document-summary pairs.'}",supervised,"['News', 'CQA', 'Social Media']",[]
SP:63bf0cad24bb848a15733a8af827089936347136,News Editorials: Towards Summarizing Long Argumentative Texts,COLING,2020,"['Shahbaz Syed', 'Roxanne El Baff', 'Khalid Al-Khatib', 'Johannes Kiesel', 'Benno Stein', 'Martin Potthast']","The automatic summarization of argumentative texts has hardly been explored. This paper takes a further step in this direction, targeting news editorials, i.e., opinionated articles with a well-defined argumentation structure. With Webis-EditorialSum-2020, we present a corpus of 1330 carefully curated summaries for 266 news editorials. We evaluate these summaries based on a tailored annotation scheme, where a high-quality summary is expected to be thesis-indicative, persuasive, reasonable, concise, and self-contained. Our corpus contains at least three high-quality summaries for about 90% of the editorials, rendering it a valuable resource for the development and evaluation of summarization technology for long argumentative texts. We further report details of both, an in-depth corpus analysis, and the evaluation of two extractive summarization models.","The paper discusses the lack of exploration in automatic summarization of argumentative texts and presents a new corpus of 1330 summaries for 266 news editorials. The summaries are evaluated based on a specific annotation scheme and aim to be thesis-indicative, persuasive, reasonable, concise, and self-contained. The corpus contains at least three high-quality summaries for about 90% of the editorials, making it useful for the development and evaluation of summarization technology for long argumentative texts. The paper also reports on an in-depth corpus analysis and the evaluation of two extractive summarization models.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to contribute to the research on automatic summarization of argumentative texts, specifically editorials, which has been neglected so far.', 'Who is the target audience?': 'The summaries are for researchers and developers working on automatic summarization, as well as anyone interested in studying editorials and their structure.', 'How will the summaries be used?': ""The summaries will be used to evaluate unsupervised extractive summarization models and their ability to identify an editorial's core message (the thesis). They will also be used to analyze the structure and content of editorials and to develop new approaches for summarizing them.""}",['corpus'],['Unit Selection'],['Webis-EditorialSum-2020'],"['ROUGE', 'METEOR']","['Thesis-relevance', 'Persuasiveness', 'Reasonableness', 'Self-containedness']",https://github.com/webis-de/COLING-20,https://aclanthology.org/2020.coling-main.470,"{'News summarization approaches often fail at argumentative news articles, such as editorials, due to their different structure and goals compared to news reports.': 'The authors propose to contribute to closing this gap by taking effective steps toward editorial summarization.', 'Research on automatic (news) summarization has so far neglected argumentative texts in general, and the genre of editorials in particular.': 'The authors define an annotation scheme tailored to editorial summaries, requiring a high-quality summary to be thesis-indicative, persuasive, reasonable, concise, and self-contained.', 'There is a lack of a corpus of editorial summaries for research and development.': 'The authors create a corpus of 1330 summaries for 266 news editorials (five summaries each), manually acquired and evaluated by operationalizing the proposed annotation scheme.', 'There is a need to analyze each summary of the corpus with respect to content overlap, distribution of evidence types, adherence to the editorial structure, and annotator indications regarding summary quality.': 'The authors analyze each summary of the corpus with respect to these factors.', 'There is a need to evaluate unsupervised extractive summarization models in comparison to the acquired references, and their potential to identify an editorial’s core message (the thesis).': 'The authors evaluate two unsupervised extractive summarization models (four variants total) in comparison to the acquired references, and their potential to identify an editorial’s core message (the thesis).'}",unsupervised,['Opinions'],"['exploiting-the-structure-of-long-documents', 'controlled-and-tailored-summarization']"
SP:bed6f7386da645cbd3d10a1dd820a1aae2afae6b,Summarizing Long-Form Document with Rich Discourse Information,CIKM,2021,"['Tianyu Zhu', 'Wen Hua', 'Jianfeng Qu', 'Xiaofang Zhou']","The development of existing extractive summarization models for long-form document summarization is hindered by two factors: 1) the computation of the summarization model will dramatically increase due to the sheer size of the input long document; 2) the discourse structural information in the long-form document has not been fully exploited. To address the two deficiencies, we propose HEROES, a novel extractive summarization model for summarizing long-form documents with rich discourse structural information. In particular, the HEROES model consists of two modules: 1) a content ranking module that ranks and selects salient sections and sentences to compose a short digest that empowers complex summarization models and serves as its input; 2) an extractive summarization module based on a heterogeneous graph with nodes from different discourse levels and elaborately designed edge connections to reflect the discourse hierarchy of the document and restrain the semantic drifts across section boundaries. Experimental results on benchmark datasets show that HEROES can achieve significantly better performance compared with various strong baselines.","The paper proposes a new extractive summarization model called HEROES to address the deficiencies of existing models for summarizing long-form documents. The two main deficiencies are the increase in computation due to the size of the input document and the lack of exploitation of discourse structural information. HEROES consists of two modules: a content ranking module that selects important sections and sentences to create a short digest, and an extractive summarization module based on a heterogeneous graph with nodes from different discourse levels and designed edge connections to reflect the discourse hierarchy of the document. Experimental results show that HEROES outperforms various strong baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the original document into a concise summary while retaining the main information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long-form document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used as a quick reference or to determine if a document is relevant to a particular topic before reading the full document. They can also be used to compare and contrast multiple documents on the same topic.'}",['method'],"['Unit Relationship', 'Unit Selection']","['PubMed', 'arXiv']",['ROUGE'],[''],,https://doi.org/10.1145/3459637.3482396,"{'Memory concerns make it difficult to scale extractive models to long-form documents. The common practice to address the memory issue is to truncate the input document keeping the first k sections or sentences. However, this treatment filters sections and sentences solely based on their positions without considering their informativeness, which may result in missing summary-worthy sentences.': 'The authors propose a content ranking module for coarse filtering that ranks sections and their contained sentences with regard to their usefulness for extracting the final summary. The top-ranked sections and sentences, considered as more relevant, are collected as a succinct digest and constitute the input of the downstream summarization model.', 'Existing extractive approaches for long-form document summarization derive sentence features exclusively based on the word-sentence hierarchy, which essentially ignore the document structure and treat the document as a long flat sequence of sentences, failing to capture relations among sentences and sections.': 'The authors construct a heterogeneous graph composing word-, sentence-, section-level nodes with edge connections mirroring the intrinsic word-sentence-section discourse hierarchy in documents, and resort to Graph Attention Network to learn fine-grained representations for these semantic nodes. This effectively addresses the problem of ignoring the discourse structure and captures relations among sentences and sections.', 'In the prolix narrative, the semantics of the document may drift from section to section. Sequential models cannot naturally deal with semantic drifts like this, as it may obtain confusing document representation by sequentially processing sentences from different sections with different semantics.': 'The authors deactivate sentence connections that conceptually cross section boundaries and designate section nodes as a relay for cross-section information exchange between sentences. The introduction of the section node, cohesively representing the semantics of its contained sentences, alleviates the noisy and distracting connections between sentences across sections.', 'Oracle summary-worthy sentences tend to be crowded at the beginning of news articles while distributed more evenly in scientific papers. When these positional cues are hindered in long-form documents, it conceivably requires an in-depth understanding of the source document for the summarization model to identify and locate salient sentences.': 'The authors turn to the hypothesis that important information tends to appear near section boundaries. By checking the distance to section boundary for sentences in the oracle extraction, they empirically find that sentences closer to section boundaries are biased towards a greater probability of being summary-worthy. Therefore, they construct the boundary distance feature as compensation and exploit it as an indispensable clue for the extractive model.'}",supervised,['Scholarly Documents'],['efficient-encoding-of-long-documents']
SP:37ce596aee9fb556e6a77628d0501822055d3166,Demoting the Lead Bias in News Summarization via Alternating Adversarial Learning,ACL,2021,"['Linzi Xing', 'Wen Xiao', 'Giuseppe Carenini']","In news articles the lead bias is a common phenomenon that usually dominates the learning signals for neural extractive summarizers, severely limiting their performance on data with different or even no bias. In this paper, we introduce a novel technique1 to demote lead bias and make the summarizer focus more on the content semantics. Experiments on two news corpora with different degrees of lead bias show that our method can effectively demote the model’s learned lead bias and improve its generality on out-ofdistribution data, with little to no performance loss on in-distribution data.","System: This paper introduces a new technique to reduce lead bias in news articles and improve the performance of neural extractive summarizers on data with different or no bias. The experiments conducted on two news corpora show that this technique effectively reduces the model's learned lead bias and improves its generality on out-of-distribution data, without any significant loss in performance on in-distribution data.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce a short summary by selecting a set of representative sentences, which has shown great potential in real-world applications.', 'Who is the target audience?': 'The summaries are for real-world applications, including news and scientific paper summarization.', 'How will the summaries be used?': 'The summaries will be used to select the most important sentences from a document to form the summary by considering their content salience, informativeness, and redundancy.'}",['method'],['Unit Selection'],"['CNN/DailyMail', 'XSum']",['ROUGE'],[''],,https://aclanthology.org/2021.acl-short.119,"{'Neural extractive summarizers can learn to exploit biases in the data, such as the lead bias in news, which can dominate the actual content of the sentence in model prediction.': 'The authors propose a method to train an extractive summarizer for news that balances the lead bias with the content of the sentences, resulting in a model that can be applied more effectively when the target documents belong to news datasets in which the lead bias is present in rather different degrees.', 'Learning a summarizer reflecting the biases in the training dataset can be problematic when the model is applied to deal with documents coming from a mixture of datasets with different degrees of such biases.': 'The authors propose an alternating adversarial learning technique to demote the summarizer lead bias, but also maintain the performance on the in-distribution data. They introduce a position prediction component as an adversary, and optimize it along with the neural extractive summarizer in an alternating manner.', 'Previous solutions to address the lead bias in news summarization include pretraining the summarizer on an automatic generated ""unbiased"" corpus or training the summarizer on multiple news datasets with different degrees of lead bias, but these solutions have limitations.': 'The authors propose a model-independent solution that only requires one type of news dataset as training input.', 'The lead bias in news summarization can limit the generalizability of the summarizer.': 'The authors\' proposed ""debiasing"" method can effectively demote the lead bias learned by the neural news summarizer and improve its generalizability, while still mostly maintaining the model\'s performance on the data with a similar lead bias.'}",supervised,['News'],[]
SP:525ecb49aff0610cd7a897f08e956a4b718c15c8,Globalizing BERT-based Transformer Architectures for Long Document Summarization,EACL,2021,"['Quentin Grail', 'Julien Perez', 'Eric Gaussier']","Fine-tuning a large language model on downstream tasks has become a commonly adopted process in the Natural Language Processing (NLP) (Wang et al., 2019). However, such a process, when associated with the current transformer-based (Vaswani et al., 2017) architectures, shows several limitations when the target task requires to reason with long documents. In this work, we introduce a novel hierarchical propagation layer that spreads information between multiple transformer windows. We adopt a hierarchical approach where the input is divided in multiple blocks independently processed by the scaled dot-attentions and combined between the successive layers. We validate the effectiveness of our approach on three extractive summarization corpora of long scientific papers and news articles. We compare our approach to standard and pre-trained language-model-based summarizers and report state-of-the-art results for long document summarization and comparable results for smaller document summarization.","The paper discusses the limitations of using current transformer-based architectures for fine-tuning large language models on downstream tasks that require reasoning with long documents. To address this issue, the authors introduce a novel hierarchical propagation layer that spreads information between multiple transformer windows. They validate the effectiveness of their approach on three extractive summarization corpora of long scientific papers and news articles and report state-of-the-art results for long document summarization and comparable results for smaller document summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to address the limitations of current approaches that are only evaluated on tasks composed of relatively short input text.', 'Who is the target audience?': 'The summaries are for tasks that require a global understanding of long documents, such as extractive summarization.', 'How will the summaries be used?': 'The proposed architecture interweaves recurrent hierarchical modules with transformer layers and exploits pre-trained language models like BERT to build informative representations in the context of extractive summarization.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'PubMed', 'arXiv']",['ROUGE'],[''],,https://aclanthology.org/2021.eacl-main.154/,"{'The current language model pre-training approach is limited to short input text, making it difficult to reason with longer documents.': 'The authors propose a simple adaptation of the multi-layer transformer architecture that can scale to long documents by independently applying a transformer network on small blocks of text and sharing information among the blocks between two successive layers.', 'The transformer self-attention memory quadratically increases with the number of input tokens, making it technically impossible to compute on document-scale sequences.': 'The proposed solution of applying a transformer network on small blocks of text instead of a long sequence addresses this problem.', 'The current solutions for dealing with long documents, such as limiting the input sequence or applying the model on a sliding window, are not feasible for tasks that require a global understanding of long documents.': 'The proposed solution of independently applying a transformer network on small blocks of text and sharing information among the blocks between two successive layers addresses this problem.', 'Extractive summarization requires a global understanding of long documents, making it difficult to use current solutions.': 'The proposed architecture is able to build informative representations in the context of extractive summarization by interweaving recurrent hierarchical modules with transformer layers and exploiting pre-trained language models like BERT.'}",supervised,"['News', 'Scholarly Documents']",['efficient-encoding-of-long-documents']
SP:94deb4a70c45f0e6433b13482720988a731fe87e,Contextualized Rewriting for Text Summarization,AAAI,2021,"['Guangsheng Bao', 'Yue Zhang']","Extractive summarization suffers from irrelevance, redundancy and incoherence. Existing work shows that abstractive rewriting for extractive summaries can improve the conciseness and readability. These rewriting systems consider extracted summaries as the only input, which is relatively focused but can lose important background knowledge. In this paper, we investigate contextualized rewriting, which ingests the entire original document. We formalize contextualized rewriting as a seq2seq problem with group alignments, introducing group tag as a solution to model the alignments, identifying extracted summaries through content-based addressing. Results show that our approach significantly outperforms non-contextualized rewriting systems without requiring reinforcement learning, achieving strong improvements on ROUGE scores upon multiple extractive summarizers.","The paper discusses the limitations of extractive summarization and the potential benefits of abstractive rewriting. However, abstractive rewriting systems only consider extracted summaries as input, which can result in the loss of important background knowledge. To address this issue, the authors propose a contextualized rewriting approach that takes in the entire original document. They formalize this approach as a seq2seq problem with group alignments and introduce group tags to model the alignments. The system identifies extracted summaries through content-based addressing and achieves significant improvements on ROUGE scores compared to non-contextualized rewriting systems without requiring reinforcement learning.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract salient text segments and provide a summary of the input document.', 'Who is the target audience?': 'The summaries are for anyone who needs a quick and concise understanding of the input document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of the input document without having to read the entire document. They can also be used for information retrieval and to aid in decision-making processes.'}",['method'],['Input Encoding'],['CNN/DailyMail'],['ROUGE'],[''],https://github.com/baoguangsheng/ctx-rewriter-for-summ,https://doi.org/10.48550/arXiv.2207.05948,"{'Extractive summarizers tend to contain irrelevant and redundant phrases.': 'Postediting methods have been investigated, including grammar tree trimming and rule-based methods, to reduce irrelevant content within sentences and enhance coherence.', 'Extracted sentences can be weak in their coherence with regard to discourse relations and cross-sentence anaphora.': 'Abstractive models have been used for rewriting extracted outputs sentence by sentence, which effectively improves the conciseness and readability of the summary.', 'Existing abstractive rewriting systems take extracted summaries as the only input, which limits the ability to infer factual details from the original document.': 'The authors propose contextualized rewriting by using the full input document as a context for rewriting extractive summary sentences. They use a neural representation model to encode the whole input document, representing the extractive summary as a part of the document representation. They also use content-based addressing to inform the rewriter of the current sentence being rewritten.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:0c4730e50e041dce9d5f619024d53d2889387eb3,AUTOSUMM: Automatic Model Creation for Text Summarization,EMNLP,2021,"['Sharmila Reddy Nangi', 'Atharv Tyagi', 'Jay Mundra', 'Sagnik Mukherjee', 'Snehal Raj', 'Aparna Garimella', 'Niyati Chhaya']","Recent efforts to develop deep learning models for text generation tasks such as extractive and abstractive summarization have resulted in state-of-the-art performances on various datasets. However, obtaining the best model configuration for a given dataset requires an extensive knowledge of deep learning specifics like model architecture, tuning parameters etc., and is often extremely challenging for a non-expert. In this paper, we propose methods to automatically create deep learning models for the tasks of extractive and abstractive text summarization. Based on the recent advances in Automated Machine Learning and the success of large language models such as BERT and GPT-2 in encoding knowledge, we use a combination of Neural Architecture Search (NAS) and Knowledge Distillation (KD) techniques to perform model search and compression using the vast knowledge provided by these language models to develop smaller, customized models for any given dataset. We present extensive empirical results to illustrate the effectiveness of our model creation methods in terms of inference time and model size, while achieving near state-of-the-art performances in terms of accuracy across a range of datasets.","The paper proposes methods to automatically create deep learning models for extractive and abstractive text summarization tasks, which have shown state-of-the-art performances on various datasets. The methods use a combination of Neural Architecture Search and Knowledge Distillation techniques, leveraging the knowledge provided by large language models such as BERT and GPT-2 to develop smaller, customized models for any given dataset. The proposed methods achieve near state-of-the-art performances in terms of accuracy while reducing inference time and model size.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to simplify computationally expensive tasks and make them accessible to non-experts.', 'Who is the target audience?': 'The summaries are for anyone who needs to perform complex NLP tasks such as extraction and generation, but lacks ML expertise.', 'How will the summaries be used?': 'The summaries will be used to create efficient and customized machine learning models for a given dataset, specifically for extractive and abstractive summarization tasks.'}",['method'],['Input Encoding'],"['CNN/DailyMail', 'NYT', 'XSum', 'Gigaword', 'Contract']",['ROUGE'],[''],,https://aclanthology.org/2021.emnlp-main.798,"{'Machine learning models for NLP tasks require experienced engineering resources and expertise, making it difficult for non-experts.': 'The authors propose Automated Machine Learning as a strategy to automate the pipeline for model creation, including automated generation of the model itself, making it accessible to non-experts.', 'Deep learning models for NLP tasks have thousands of parameters and require large datasets and computational resources for training.': 'The authors propose algorithms for autogeneration of ML models for complex NLP tasks such as extraction and generation, using a combination of neural architecture search and task-specific knowledge distillation from large language models.', 'The need for ML expertise creates a bottleneck in the creation of robust models for several downstream NLP tasks.': 'The authors propose feeding off the knowledge available in large pretrained models to auto-generate new, smaller, customized models for a custom dataset.', 'There is a lack of effort towards automatically building customized and compressed models for text generation tasks, specifically summarization.': 'The authors propose a method to create machine learning models that are efficient and customized to a given dataset for the tasks of extractive and abstractive summarization, using a combination of neural architecture search and task-specific knowledge distillation from large language models. Additionally, they propose an alternate method for summarization model generation using Transformer distillation, which is superior in terms of performance and resource utilization. They conduct extensive experiments and present results illustrating the effectiveness of the proposed methods for extractive and abstractive summarization on a range of datasets, and compare their models in terms of model creation efficiency, model size, inference time, and performance, with the state-of-the-art models.'}",supervised,"['News', 'Legal Proceedings']",['pretraining-and-sample-efficiency']
SP:418410925c0356f8d9ca2acc2f4e2eb27379ce2c,SUBSUME: A Dataset for Subjective Summary Extraction from Wikipedia Documents,EMNLP,2021,"['Nishant Yadav', 'Matteo Brucato', 'Anna Fariha', 'Oscar Youngquist', 'Julian Killingback', 'Alexandra Meliou', 'Peter J. Haas']","Many applications require generation of summaries tailored to the user’s information needs, i.e., their intent. Methods that express intent via explicit user queries fall short when query interpretation is subjective. Several datasets exist for summarization with objective intents where, for each document and intent (e.g., “weather”), a single summary suffices for all users. No datasets exist, however, for subjective intents (e.g., “interesting places”) where different users will provide different summaries. We present SUBSUME, the first dataset for evaluation of SUBjective SUMmary Extraction systems. SUBSUME contains 2,200 (document, intent, summary) triplets over 48 Wikipedia pages, with ten intents of varying subjectivity, provided by 103 individuals over Mechanical Turk. We demonstrate statistically that the intents in SUBSUME vary systematically in subjectivity. To indicate SUBSUME’s usefulness, we explore a collection of baseline algorithms for subjective extractive summarization and show that (i) as expected, example-based approaches better capture subjective intents than query-based ones, and (ii) there is ample scope for improving upon the baseline algorithms, thereby motivating further research on this challenging problem.","The paper discusses the need for tailored summaries based on the user's intent and how existing methods fall short when query interpretation is subjective. While several datasets exist for summarization with objective intents, no datasets exist for subjective intents where different users will provide different summaries. The authors present SUBSUME, the first dataset for evaluation of subjective summary extraction systems, containing 2,200 triplets over 48 Wikipedia pages with ten intents of varying subjectivity. The paper explores baseline algorithms for subjective extractive summarization and shows that example-based approaches better capture subjective intents than query-based ones, motivating further research on this challenging problem.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to allow users to express their summarization intent more effectively, especially in cases where the intent is subjective.', 'Who is the target audience?': 'The summaries are for users who want to summarize many documents with the same intent, but find it difficult to communicate subjective intents via traditional query-based systems.', 'How will the summaries be used?': 'The summaries will be used to evaluate and compare different summarization systems, including example-based and query-based approaches, and to motivate further research on this challenging problem.'}",['corpus'],['Controlled Generation'],['SUBSUME'],['ROUGE'],[''],https://github.com/afariha/SubSumE,https://par.nsf.gov/servlets/purl/10315098,"{'Traditional non-generic extractive summarization systems do not effectively model subjective intents expressed by users through queries or natural-language questions.': 'The authors propose an example-based approach to summarization, where users provide a few example summaries to communicate their subjective intents more effectively.', 'Query-based summarization systems fail to capture very subjective intents, such as finding ""places that I like"".': 'Summarization by example allows users to express very subjective intents precisely where typical methods fail.', 'Constructing the correct query for even an objective intent can be frustrating for users.': 'Providing a few examples of what they want is often more comfortable for users than providing specifications of what they want.', 'Evaluating example-based summarization systems requires a more complex evaluation dataset than those available for query-based systems.': 'The authors present SUBSUME, the first dataset for evaluating SUBjective SUMmary Extraction systems, which includes 8 different, manually curated summaries produced by the same user for every user-intent pair.', 'Existing summarization datasets provide only one summary per user-intent pair.': 'SUBSUME includes multiple summaries for each user-intent pair, allowing for more comprehensive evaluation of example-based summarization systems.', 'There is a need to compare and improve upon baseline algorithms for example-based summarization systems.': 'The authors empirically compare several baselines on intents with increasing subjectivity using SUBSUME, exposing evidence that an example-based approach better captures subjective intent than a naive approach that simply inputs an ambiguous intent into a query-based summarizer, and motivating further research on this challenging problem.'}",supervised,['Wikipedia'],['information-loss-and-incoherence-in-extractive-summarization']
SP:317514bbb6b36899ef77d2a198f3affc56f9b165,Leveraging Information Bottleneck for Scientific Document Summarization,EMNLP,2021,"['Jiaxin Ju', 'Ming Liu', 'Huan Yee Koh', 'Yuan Jin', 'Lan Du', 'Shirui Pan']","This paper presents an unsupervised extractive approach to summarize scientific long documents based on the Information Bottleneck principle. Inspired by previous work which uses the Information Bottleneck principle for sentence compression, we extend it to document level summarization with two separate steps. In the first step, we use signal(s) as queries to retrieve the key content from the source document. Then, a pre-trained language model conducts further sentence search and edit to return the final extracted summaries. Importantly, our work can be flexibly extended to a multi-view framework by different signals. Automatic evaluation on three scientific document datasets verifies the effectiveness of the proposed framework. The further human evaluation suggests that the extracted summaries cover more content aspects than previous systems.","The paper presents an unsupervised extractive approach to summarize scientific long documents using the Information Bottleneck principle. The approach involves using signals as queries to retrieve key content from the source document, followed by a pre-trained language model to conduct further sentence search and editing to return the final extracted summaries. The framework can be extended to a multi-view framework by different signals. The proposed framework was evaluated on three scientific document datasets and was found to be effective. Human evaluation suggests that the extracted summaries cover more content aspects than previous systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the salient information from the source document into a shorter format.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a scientific document without reading the entire document.', 'How will the summaries be used?': ""The summaries can be used to quickly determine if a document is relevant to a particular research topic or to provide a brief overview of a document's main findings.""}",['method'],"['Objective Function', 'Unit Selection']","['PubMed', 'arXiv', 'COVID-19']",['ROUGE'],"['Fluency', 'Faithfulness', 'Coverage', 'Conciseness']",https://github.com/Jiaxin-Ju/Unsupervised_IB_Summ,https://aclanthology.org/2021.findings-emnlp.345,"{'Extractive summarization methods are mostly unsupervised and rely on n-grams overlap, graph-based methods for sentence ranking, or latent semantic analysis technique to identify important sentences. These unsupervised systems have been surpassed by neural-based models in respect of performance and popularity.': 'The authors propose a multi-view information bottleneck framework that can effectively incorporate multiple guided signals for the scientific document summarization task.', 'Traditional extractive summarization methods are not suitable for long-document summarization settings.': ""The authors' framework applies the information bottleneck principle on the document level rather than the sentence level, where pruning unrelated information will only work on the selected important sentences."", 'None of the previous works utilize explicit guidance to aid the model in summarizing a source text.': 'The authors propose a multi-view information bottleneck framework that can effectively incorporate multiple guided signals extracted from the input source document such as keywords, highlighted sentences, and others to aid the model architecture in summarizing the input document.', 'Previous works only utilize a single signal to aid the model architecture in summarizing the input document.': ""The authors' framework can be flexibly extended to a multi-view architecture by incorporating more self-defined correlated signals."", ""The experiments from the work of Dou et al. (2021) have empirically shown that summarization through multiple guided signals can achieve significant improvements to the system with a single signal, but the authors' multi-view framework yielded less satisfactory results in their experiment."": 'The authors believe that their multi-view framework has fruitful potential for further study.'}",unsupervised,['Scholarly Documents'],['identifying-important-contents-from-the-document']
SP:2299775e5efa0e8e382be2df7658015837b84bd2,Hierarchical Heterogeneous Graph Attention Network for Syntax-Aware Summarization,AAAI,2022,"['Zixing Song', 'Irwin King']","The task of summarization often requires a non-trivial understanding of the given text at the semantic level. In this work, we essentially incorporate the constituent structure into the single document summarization via the Graph Neural Networks to learn the semantic meaning of tokens. More specifically, we propose a novel hierarchical heterogeneous graph attention network over constituency-based parse trees for syntax-aware summarization. This approach reflects psychological findings that humans will pinpoint specific selection patterns to construct summaries hierarchically. Extensive experiments demonstrate that our model is effective for both the abstractive and extractive summarization tasks on five benchmark datasets from various domains. Moreover, further performance improvement can be obtained by virtue of stateof-the-art pre-trained models.","The paper proposes a new approach to summarization that incorporates the constituent structure of the text using Graph Neural Networks. They use a hierarchical heterogeneous graph attention network over constituency-based parse trees for syntax-aware summarization, which reflects how humans construct summaries hierarchically. The model is effective for both abstractive and extractive summarization tasks on five benchmark datasets from various domains, and further performance improvement can be obtained using state-of-the-art pre-trained models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense complex input to a concise expression while retaining the core information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding documents, and can be applied in various domains for both abstractive and extractive tasks.'}",['method'],"['Input Encoding', 'Unit Relationship']","['CNN/DailyMail', 'NYT', 'Reddit-TIFU', 'WikiHow', 'PubMed']",['ROUGE'],"['Fluency', 'Informativeness', 'Succinctness']",,https://ojs.aaai.org/index.php/AAAI/article/view/21385,"{'Existing graph-based methods for text summarization suffer from semantic deviation from the input text as the graphs constructed in these models are mostly at the statistical level, ignoring rich syntactic and semantic information for summarization.': 'The authors propose to guide the neural summarization system with a tree-like text graph that embodies syntactic information so that it can identify summary-worthy content and compose summaries that preserve the vital meaning of the source texts. They choose the constituency parsing tree of the sentence as the text graph for the input of GNN, which can reflect the semantic relationship between tokens.', 'Previous methods based on constructed complicated semantic graphs suffer from relatively higher computational costs.': 'The authors propose to use the syntactic graph, which is generally easier to obtain than the semantic graph, and alleviate the computational issue in previous methods.', 'The syntactic structure is beneficial for generating compressed yet informative summaries, but previous methods do not incorporate it effectively.': 'The authors propose a generic syntax-aware heterogeneous graph attention network to learn the representation for each type of node in the constructed tree-like graph. This proposed GNN model consists of two types of layers: syntax-aware graph attention layer and hierarchical graph pooling layer.', 'There is a lack of research on incorporating constituency syntax for text summarization based on GNN.': 'The authors propose a novel heterogeneous graph attention network for syntax-aware summarization based on the constituency tree. They conduct extensive experiments on five datasets from various domains under abstractive and extractive settings to demonstrate its effectiveness.', 'The performance of graph-based models in NLP tasks can be further improved.': 'The authors investigate the potentially increased performance with the initiation of some SOTA pretrained models and further push the boundary for the graph-based models in NLP tasks.'}",supervised,"['News', 'Social Media', 'CQA', 'Scholarly Documents']",[]
SP:7f660adc201fd19957f8e3b6eddb186bcf6944e7,"TSTR: Too Short to Represent, Summarize with Details! Intro-Guided Extended Summary Generation",NAACL,2022,"['Sajad Sotudeh', 'Nazli Goharian']","Many scientific papers such as those in arXiv and PubMed data collections have abstracts with varying lengths of 50–1000 words and average length of approximately 200 words, where longer abstracts typically convey more information about the source paper. Up to recently, scientific summarization research has typically focused on generating short, abstractlike summaries following the existing datasets used for scientific summarization. In domains where the source text is relatively long-form, such as in scientific documents, such summary is not able to go beyond the general and coarse overview and provide salient information from the source document. The recent interest to tackle this problem motivated curation of scientific datasets, arXiv-Long and PubMed-Long, containing human-written summaries of 400600 words, hence, providing a venue for research in generating long/extended summaries. Extended summaries facilitate a faster read while providing details beyond coarse information. In this paper, we propose TSTR, an extractive summarizer that utilizes the introductory information of documents as pointers to their salient information. The evaluations on two existing large-scale extended summarization datasets indicate statistically significant improvement in terms of ROUGE and average ROUGE (F1) scores (except in one case) as compared to strong baselines and state-of-theart. Comprehensive human evaluations favor our generated extended summaries in terms of cohesion and completeness.","The paper discusses the challenges of generating long/extended summaries for scientific papers, which provide more detailed information than traditional abstracts. The authors propose an extractive summarizer called TSTR that uses introductory information as pointers to salient information. The evaluations on two large-scale datasets show significant improvement in ROUGE and average ROUGE scores compared to strong baselines and state-of-the-art methods. Human evaluations also favor TSTR-generated extended summaries in terms of cohesion and completeness.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific papers to provide a more detailed and informative overview of the content for readers.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the key information in a scientific paper, including researchers, students, and professionals.', 'How will the summaries be used?': 'The summaries can be used to quickly assess the relevance of a paper, to gain a general understanding of the content, or to identify specific details without having to read the entire paper.'}",['method'],['Input Encoding'],"['PubMed', 'arXiv']",['ROUGE'],"['Cohesion', 'Completeness']",https://github.com/Georgetown-IR-Lab/TSTRSum,https://aclanthology.org/2022.naacl-main.25,"{'Most works in scientific paper summarization have focused on generating short and abstract-like summaries, which might not be adequate for longer documents such as scientific papers.': 'The authors propose generating extended summaries of 400-600 terms on average, which convey more detailed information and are more appealing for longer documents.', 'Long documents such as scientific papers are usually framed in a specific structure, with introductory information followed by supplemental information, but most summarization models do not take this structure into account.': 'The authors propose incorporating the most important introductory information into the summarization model, which guides the model to pick salient detailed non-introductory information to augment the final extended summary.', 'The importance of the role of introduction in scientific papers has been shown in previous studies, but it has not been fully utilized in summarization models.': 'The authors validate their hypothesis by testing their proposed approach on two publicly available large-scale extended summarization datasets, and demonstrate statistically significant improvements over strong baselines and state-of-the-art models.', 'The proposed model needs to be evaluated in terms of cohesion and completeness.': 'The authors conduct an extensive human evaluation, which reveals the advantage of the proposed model in terms of cohesion and completeness.'}",supervised,['Scholarly Documents'],['exploiting-the-structure-of-long-documents']
SP:cec40f9c126b9d4dd12223288f410a84ff2fc589,SEHY: A Simple yet Effective Hybrid Model for Summarization of Long Scientific Documents,AACL,2022,"['Zhihua Jiang', 'Junzhan Yang', 'Dongning Rao']","Long-document summarization has been recently recognized as one of the most important natural language processing (NLP) tasks, yet one of the least solved ones. Extractive approaches attempt to choose salient sentences via understanding the whole document, but long documents cover numerous subjects with varying details and will not ease content understanding. Instead, abstractive approaches elaborate to generate related tokens while suffering from truncating the source document due to their input sizes. To this end, we propose a Simple yet Effective HYbrid approach, which we call SEHY, that exploits the discourse information of a document to select salient sections instead sentences for summary generation. On the one hand, SEHY avoids the fulltext understanding; on the other hand, it retains salient information given the length limit. In particular, we design two simple strategies for training the extractor: extracting sections incrementally and based on salience-analysis. Then, we use strong abstractive models to generate the final summary. We evaluate our approach on a large-scale scientific paper dataset: arXiv. Further, we discuss how the disciplinary class (e.g., computer science, math or physics) of a scientific paper affects the performance of SEHY as its writing style indicates, which is unexplored yet in existing works. Experimental results show the effectiveness of our approach and interesting findings on arXiv and its subsets generated in this paper.",The paper discusses the challenges of long-document summarization and proposes a Simple yet Effective HYbrid approach (SEHY) that selects salient sections instead of sentences for summary generation. The approach exploits discourse information and avoids fulltext understanding while retaining salient information within the length limit. The paper also presents two strategies for training the extractor and evaluates the approach on a large-scale scientific paper dataset. The authors also discuss how the disciplinary class of a scientific paper affects the performance of SEHY. Experimental results show the effectiveness of the approach and interesting findings on arXiv and its subsets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents, such as scientific papers, to address the challenge of content understanding. Long documents cover numerous subjects with varying details, making it difficult for readers to comprehend the content. Summaries provide a concise representation of the main ideas in the document, making it easier for readers to understand the content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a long document, such as researchers, students, or professionals in various fields. Summaries can save time and effort by providing a quick overview of the main ideas in the document.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as to quickly understand the content of a long document, to identify relevant information for a specific task, or to compare the content of different documents. The summaries can also be used as input for further analysis or as a basis for decision-making.'}",['method'],"['Unit Relationship', 'Unit Selection']",['arXiv'],['F1 Score'],[''],,https://aclanthology.org/2022.findings-aacl.9,"{'Extractive summarization approaches select important units such as phrases or sentences from the original text, but long documents cover numerous subjects with varying details and will not ease content understanding.': 'The authors propose a hybrid approach that combines an extractive model and an abstractive model to generate summaries. They also propose a novel section-based extraction strategy that selects salient sections instead of sentences for summary generation.', 'Training an extractive model may be expensive due to the complex salience analysis, and an abstractive model may generate inappropriate summary words due to the dependence on extracted sentences.': ""The authors propose a simple yet effective extractive approach that uses section-based extraction instead of sentence-based extraction. This approach not only decreases the training cost of the extractor but also enhances the input-sequence's coherence to the generator."", 'Transformer-based models suffer from the quadratic dependency on the sequence length due to their full attention mechanism, which limits their performance on long documents.': 'The authors propose using section-based extraction to reduce the input sequence length and alleviate the quadratic dependency issue. They also use strong abstractive models to generate the final summary.', 'Extracted sentences from the extractive model are often difficult to maintain the coherence of the source document, leading to poor semantic representations by the abstractive model.': ""The authors propose using section-based extraction to maintain the coherence of the source document and enhance the input-sequence's coherence to the generator."", 'Existing works on summarizing scientific papers do not distinguish their disciplinary properties, which may affect the writing styles and summary sentences.': 'The authors propose exploring the writing styles of scientific papers in different disciplines and estimating the equivalent result when summarizing different scientific papers. They also propose two section-based extraction strategies based on salience analysis and without concerning the salience to capture the writing styles of scientific papers.'}",supervised,['Scholarly Documents'],"['information-loss-and-incoherence-in-extractive-summarization', 'efficient-encoding-of-long-documents', 'exploiting-the-structure-of-long-documents']"
SP:b8888df0161e855073d6b953dbecd26314b71f43,COLO: A Contrastive Learning based Re-ranking Framework for One-Stage Summarization,COLING,2022,"['Chenxin An', 'Ming Zhong', 'Zhiyong Wu', 'Qin Zhu', 'Xuanjing Huang', 'Xipeng Qiu']","Traditional training paradigms for extractive and abstractive summarization systems always only use token-level or sentence-level training objectives. However, the output summary is always evaluated from summary-level which leads to the inconsistency in training and evaluation. In this paper, we propose a Contrastive Learning based re-ranking framework for onestage summarization called COLO. By modeling a contrastive objective, we show that the summarization model is able to directly generate summaries according to the summary-level score without additional modules and parameters. Extensive experiments demonstrate that COLO boosts the extractive and abstractive results of one-stage systems on CNN/DailyMail benchmark to 44.58 and 46.33 ROUGE-1 score while preserving the parameter efficiency and inference efficiency. Compared with state-ofthe-art multi-stage systems, we save more than 100 GPU training hours and obtaining 3⇥ ⇠ 8⇥ speed-up ratio during inference while maintaining comparable results.","The paper proposes a new framework called COLO for one-stage summarization that uses contrastive learning to generate summaries directly based on summary-level scores, without additional modules or parameters. The framework improves extractive and abstractive results on the CNN/DailyMail benchmark while maintaining parameter and inference efficiency. Compared to state-of-the-art multi-stage systems, COLO saves more than 100 GPU training hours and has a 3-8x speed-up ratio during inference while achieving comparable results.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide a condensed version of the information contained in the document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used in a variety of ways, such as for decision-making, research, or to quickly get up to speed on a topic.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum', 'Reddit-TIFU', 'PubMed', 'SSN']",['ROUGE'],"['Fluency', 'Informativeness']",,https://aclanthology.org/2022.coling-1.508,"{'There is an inherent gap between the sentence-level scoring and the summary-level evaluation in extractive summarization, which can result in high-scoring sentences that do not make a qualified summary when combined. Similarly, the previous training paradigm for abstractive summarization models can be viewed as a token-level scoring process, which does not perform summary-level optimization.': 'The authors propose a Contrastive Learning based re-ranking framework for one-stage summarization called COLO for both extractive and abstractive approach. They introduce a summary-level optimization strategy in addition to the traditional sentence-level (for extractive systems) or token-level loss (for abstractive systems).', 'State-of-the-art summarization systems use an additional module (called re-ranker) and follow a two-stage paradigm, which trades efficiency for accuracy and greatly harms the inference efficiency, especially for the highly efficient extractive systems.': 'The authors propose a novel sampling method that can be equipped to any one-stage summarization systems so that it can re-score candidates without the second stage. They propose an online sampling approach, drawing positive and negative samples from a dynamic distribution of model outputs during training, which ultimately eliminates the requirement for additional modules in the overall framework.', 'Two-stage summarization systems may be unacceptable in real-world scenarios that require timely feedback.': 'COLO achieves comparable performance to two-stage systems without additional pre-trained model and greatly improves decoding speed to meet the needs of real-world applications.'}",supervised,"['News', 'Social Media', 'Scholarly Documents']",['controlled-and-tailored-summarization']
SP:0a7f8cc9a26084d5a6b3d740f9ab6f720da2341b,Scientific Article Summarization Using Citation-Context and Article's Discourse Structure,EMNLP,2015,"['Arman Cohan', 'Nazli Goharian']","We propose a summarization approach for scientific articles which takes advantage of citation-context and the document discourse model. While citations have been previously used in generating scientific summaries, they lack the related context from the referenced article and therefore do not accurately reflect the article’s content. Our method overcomes the problem of inconsistency between the citation summary and the article’s content by providing context for each citation. We also leverage the inherent scientific article’s discourse for producing better summaries. We show that our proposed method effectively improves over existing summarization approaches (greater than 30% improvement over the best performing baseline) in terms of ROUGE scores on TAC2014 scientific summarization dataset. While the dataset we use for evaluation is in the biomedical domain, most of our approaches are general and therefore adaptable to other domains.",The paper proposes a new approach to summarizing scientific articles that takes into account citation-context and the document discourse model. The method overcomes the problem of inconsistency between citation summaries and the article's content by providing context for each citation. The approach leverages the inherent scientific article's discourse for producing better summaries and shows a significant improvement over existing summarization approaches in terms of ROUGE scores on a scientific summarization dataset. The method is adaptable to other domains beyond the biomedical domain used for evaluation.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to facilitate the problem of researchers keeping up with the developments in their respective fields due to the expanding rate at which articles are being published.', 'Who is the target audience?': 'The summaries are for readers who want a concise and informative representation of contributions or findings of an article.', 'How will the summaries be used?': 'The summaries will be used to provide a technical summary of the paper which includes important findings, contributions or impacts of a paper to the community. They will also be used to overcome the shortcomings of existing scientific summaries and improve the performance of summarization methods.'}",['method'],['Unit Relationship'],['TAC 2014 Biomedical Summarization Benchmark'],"['Precision', 'Recall', 'F1 Score', 'NPMI']",[''],https://github.com/acohan/scientific-summ,http://arxiv.org/abs/1704.06619,"{'Researchers find it difficult to keep up with the developments in their respective fields due to the expanding rate at which articles are being published.': 'Scientific summarization aims to facilitate this problem by providing readers with concise and informative representation of contributions or findings of an article.', 'Abstracts cannot be considered as an accurate scientific summary by themselves as they do not include all the contributions and impacts of the paper.': 'Citation based summaries are proposed as a better alternative to abstracts. Contributions stated in the citations are usually more focused than the abstract and contain additional information that is not in the abstract.', 'Citations may not accurately represent the content of the referenced article as they are biased towards the viewpoint of the citing authors. Moreover, citations may address a contribution or a finding regarding the referenced article without referring to the assumptions and data under which it was obtained.': 'The authors propose an approach to overcome the shortcomings of existing scientific summaries by extracting citation-context in the reference article for each citation. The final summary is formed by maximizing both novelty and informativeness of the sentences in the summary.'}",supervised,['Scholarly Documents'],[]
SP:ed1295236af63765c2d9b89d04038dcc61ec88ce,Summarizing Student Responses to Reflection Prompts,EMNLP,2015,"['Wencan Luo', 'Diane Litman']","We propose to automatically summarize student responses to reflection prompts and introduce a novel summarization algorithm that differs from traditional methods in several ways. First, since the linguistic units of student inputs range from single words to multiple sentences, our summaries are created from extracted phrases rather than from sentences. Second, the phrase summarization algorithm ranks the phrases by the number of students who semantically mention a phrase in a summary. Experimental results show that the proposed phrase summarization approach achieves significantly better summarization performance on an engineering course corpus in terms of ROUGE scores when compared to other summarization methods, including MEAD, LexRank and MMR.","The paper proposes a new algorithm for summarizing student responses to reflection prompts. Unlike traditional methods, the algorithm creates summaries from extracted phrases rather than sentences, and ranks the phrases by the number of students who mention them. Experimental results show that this approach outperforms other summarization methods in terms of ROUGE scores.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to address the challenge of summarizing student responses to reflection prompts for large courses, which is an onerous task for humans and poses challenges for existing summarization methods.', 'Who is the target audience?': 'The summaries are for instructors to enhance interaction with students.', 'How will the summaries be used?': 'The summaries will be used to identify the concepts mentioned by more students, which should get more attention from the instructor. The authors have also built a mobile application called CourseMIRROR that utilizes the proposed summarization algorithm.'}",['method'],['Unit Selection'],['CourseMirror'],['ROUGE'],[''],,https://aclanthology.org/D15-1227,"{'Summarizing student responses to reflection prompts for large courses is an onerous task for humans.': 'The authors propose a phrase summarization method that extracts phrases instead of sentences, making it easier to read and browse like keywords, and fit better on small devices when compared to sentences.', 'The linguistic units of student inputs range from single words to multiple sentences.': 'The authors adopt a metric clustering paradigm with a semantic distance to estimate the student coverage of each phrase in the summary, allowing similar phrases to be grouped together even if they are in different textual forms.', 'The authors assume that the concepts (represented as phrases) mentioned by more students should get more attention from the instructor.': 'The authors introduce the notion of student coverage, defined as the number of students who semantically mention a particular phrase. The more student coverage a phrase has, the more important it is.'}",unsupervised,['Student Responses'],['controlled-and-tailored-summarization']
SP:2fb8ff99fdc026be3d4f31763c122f39ee573429,Movie Script Summarization as Graph-based Scene Extraction,NAACL,2015,"['Philip John Gorinski', 'Mirella Lapata']","In this paper we study the task of movie script summarization, which we argue could enhance script browsing, give readers a rough idea of the script’s plotline, and speed up reading time. We formalize the process of generating a shorter version of a screenplay as the task of finding an optimal chain of scenes. We develop a graph-based model that selects a chain by jointly optimizing its logical progression, diversity, and importance. Human evaluation based on a question-answering task shows that our model produces summaries which are more informative compared to competitive baselines.","System: The paper discusses the task of movie script summarization and how it can improve script browsing, provide a general idea of the plotline, and reduce reading time. The authors propose a graph-based model that selects an optimal chain of scenes by considering logical progression, diversity, and importance. Human evaluation shows that their model produces more informative summaries compared to other methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of screenplays to enhance script browsing, give readers a rough idea of the script’s content and plotline, and speed up reading time.', 'Who is the target audience?': 'The summaries are for producers, directors, and script readers who need to navigate through a vast number of scripts available.', 'How will the summaries be used?': 'The summaries will be used to analyze screenplays, sort the hopeful from the hopeless, and determine whether the script merits further consideration.'}",['method'],['Input Encoding'],['ScriptBase'],['ROUGE'],['QA'],,https://aclanthology.org/N15-1113,"{'There is a lack of script reading aids that can automatically grade the quality of the script, generate synopses and loglines, identify main characters and their stories, or facilitate browsing.': 'The authors explore whether current NLP technology can be used to address some of these tasks, specifically focusing on script summarization.', 'It is difficult for producers and directors to navigate through the vast number of scripts available.': 'Production companies, agencies, and studios hire script readers to analyze screenplays and generate coverage reports consisting of a logline, a synopsis, comments explaining its appeal or problematic aspects, and a final verdict as to whether the script merits further consideration.', 'It is unclear what makes a good script summary.': 'The authors define a script summary as a chain of scenes which conveys a narrative and smooth transitions from one scene to the next, incorporates diversity, and focuses on important scenes and characters. They formalize the problem of selecting a good summary chain using a graph-theoretic approach.', 'There is a need for novel methods for analyzing script content, such as identifying important characters and their interactions.': 'The authors propose several novel methods for analyzing script content and perform a large-scale human evaluation study using a question-answering task. Experimental results show that their method produces more informative summaries compared to several competitive baselines.'}",unsupervised,['Movie Scripts'],"['controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:3182b085108360b29a537a1306678a742c714899,Concept-based Summarization using Integer Linear Programming: From Concept Pruning to Multiple Optimal Solutions,EMNLP,2015,"['Florian Boudin', 'Hugo Mougard', 'Benoit Favre']","In concept-based summarization, sentence selection is modelled as a budgeted maximum coverage problem. As this problem is NP-hard, pruning low-weight concepts is required for the solver to find optimal solutions efficiently. This work shows that reducing the number of concepts in the model leads to lower ROUGE scores, and more importantly to the presence of multiple optimal solutions. We address these issues by extending the model to provide a single optimal solution, and eliminate the need for concept pruning using an approximation algorithm that achieves comparable performance to exact inference.","System: The paper discusses the challenges of sentence selection in concept-based summarization, which is modelled as a budgeted maximum coverage problem. To find optimal solutions efficiently, low-weight concepts need to be pruned. However, reducing the number of concepts leads to lower ROUGE scores and multiple optimal solutions. The authors propose an extension to the model that provides a single optimal solution and eliminates the need for concept pruning using an approximation algorithm that achieves comparable performance to exact inference.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to extract important information in a concise manner.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading large amounts of text, and to quickly identify relevant information for further analysis or decision-making.'}",['method'],['Unit Selection'],"['DUC 2004', 'TAC 2008']",['ROUGE'],[''],https://github.com/boudinfl/sume,https://aclanthology.org/D15-1220,"{'Pruning low-weight concepts is required for the ILP solver to find optimal solutions efficiently, but reducing the number of concepts in the model results in lower ROUGE scores and allows different sentences to have the same score, leading to multiple optimal summaries.': 'The authors evaluate the impact of concept pruning on running time, ROUGE scores, and the number of optimal solutions. They show that multiple optimal solutions cause a substantial amount of variation in ROUGE scores, which could lead to incorrect conclusions.', 'Only results corresponding to the first optimal solution found by the solver are reported, and no previous work has mentioned the problem of multiple optimal solutions.': 'The authors extend the model to address the problem of multiple optimal solutions and develop a fast approximation algorithm that achieves near-optimal performance. They sidestep the need for concept pruning and show that their approach outperforms the original model in terms of ROUGE scores and the number of optimal solutions.'}",unsupervised,['News'],['robust-evaluation-methods']
SP:6f11cedf554bff695e4520afef3a15dbd79297e3,Summarizing topical contents from PubMed documents using a thematic analysis,EMNLP,2015,"['Sun Kim', 'Lana Yeganova', 'John Wilbur']","Improving the search and browsing experience in PubMedr is a key component in helping users detect information of interest. In particular, when exploring a novel field, it is important to provide a comprehensive view for a specific subject. One solution for providing this panoramic picture is to find sub-topics from a set of documents. We propose a method that finds sub-topics that we refer to as themes and computes representative titles based on a set of documents in each theme. The method combines a thematic clustering algorithm and the Pool Adjacent Violators algorithm to induce significant themes. Then, for each theme, a title is computed using PubMed document titles and theme-dependent term scores. We tested our system on five disease sets from OMIMr and evaluated the results based on normalized point-wise mutual information and MeSHr terms. For both performance measures, the proposed approach outperformed LDA. The quality of theme titles were also evaluated by comparing them with manually created titles.","

System: The paper proposes a method for improving the search and browsing experience in PubMed by finding sub-topics or themes from a set of documents and computing representative titles for each theme. The method combines a thematic clustering algorithm and the Pool Adjacent Violators algorithm to induce significant themes. The system was tested on five disease sets from OMIM and outperformed LDA in terms of performance measures. The quality of theme titles was also evaluated by comparing them with manually created titles.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to address the problem of users being overwhelmed by the abundance and diversity of information in PubMed. Many queries retrieve thousands of documents, making it difficult for users to browse the results and identify the information most relevant to their topic of interest.', 'Who is the target audience?': 'The summaries are for users of PubMed who are searching for information on a particular topic. The summaries aim to group the retrieved documents into meaningful thematic clusters or themes, making it easier for users to identify the information most relevant to their topic of interest.', 'How will the summaries be used?': 'The summaries will be used to help users of PubMed browse the results of their queries more efficiently and identify the information most relevant to their topic of interest. The authors propose a method for automatically generating titles for each theme, which will further improve the user perception of clustering results.'}",['method'],['Input Encoding'],['PubMed PAV-EM'],['ROUGE'],[''],,https://aclanthology.org/D15-1094/,"{'With the abundance and diversity of information in PubMed, many queries retrieve thousands of documents making it difficult for users to browse the results and identify the information most relevant to their topic of interest.': 'The authors propose to automatically group the retrieved documents into meaningful thematic clusters or themes using EM-based thematic clustering and Pool Adjacent Violators (PAV) algorithm to evaluate the quality of clusters.', 'Most existing algorithms produce clusters that are not self-descriptive, which makes it difficult for users to understand the content of the cluster.': 'The authors propose to utilize PubMed document titles and cluster-related term scores to automatically obtain a title for each theme, resulting in thematic clusters of documents with cluster titles.', 'Some existing clustering methods produce unstable or weak clusters, and there is no obvious way to evaluate the quality of clusters effectively and efficiently.': 'The authors propose to combine EM-based thematic clustering with PAV algorithm to evaluate the quality of clusters.', 'Some existing methods perform document clustering and cluster-dependent keyword identification simultaneously, but they have limitations such as producing hard clustering or being computationally expensive.': 'The authors propose a new method that utilizes PubMed document titles and cluster-related term scores to automatically obtain a title for each theme, which is different from existing methods that treat document clustering and cluster-dependent keyword extraction as separate problems.', 'Topic modeling is an alternative approach to discovering hidden thematic structure of a document collection, but it is not a document clustering scheme in nature, and the title of the cluster may not be evident.': 'The authors propose a new method that utilizes PubMed document titles and cluster-related term scores to automatically obtain a title for each theme, which is different from topic modeling that only provides a list of keywords representing a topic.'}",unsupervised,['Scholarly Documents'],['controlled-and-tailored-summarization']
SP:e6c8ff55c707b8872d96159e8659d44c734cfd34,Using Relevant Public Posts to Enhance News Article Summarization,COLING,2016,"['Chen Li', 'Zhongyu Wei', 'Yang Liu', 'Yang Jin', 'Fei Huang']","A news article summary usually consists of 2-3 key sentences that reflect the gist of that news article. In this paper we explore using public posts following a new article to improve automatic summary generation for the news article. We propose different approaches to incorporate information from public posts, including using frequency information from the posts to re-estimate bigram weights in the ILP-based summarization model and to re-weight a dependency tree edge’s importance for sentence compression, directly selecting sentences from posts as the final summary, and finally a strategy to combine the summarization results generated from news articles and posts. Our experiments on data collected from Facebook show that relevant public posts provide useful information and can be effectively leveraged to improve news article summarization results.","The paper explores using public posts on social media to improve automatic summary generation for news articles. Different approaches are proposed, including using frequency information from posts to re-estimate bigram weights and re-weighting a dependency tree edge's importance for sentence compression. The experiments conducted on Facebook data show that relevant public posts can be effectively leveraged to improve news article summarization results.","{'What is the purpose of the summaries?': 'The authors are generating summaries of news articles to make information easier to digest for readers who are often overwhelmed by the large amount of online information.', 'Who is the target audience?': 'The summaries are for readers of news articles from online news providers or disseminators like CNN, USAToday, Yahoo, etc.', 'How will the summaries be used?': 'The summaries will be used to alleviate the manual work of producing high-quality summaries for many popular topics. The authors propose using relevant public posts, specifically Facebook public posts, to improve the summarization of a single news article.'}",['method'],['External Knowledge'],"['NYT', 'Facebook Posts']","['ROUGE', 'nDCG']",[''],,https://aclanthology.org/C16-1054,"{'Manually generating high quality summaries for many popular topics is time consuming.': 'Automatic summarization for related news articles is proposed to alleviate the manual work.', 'How to use relevant public posts to improve summarization of a single news article.': 'The authors propose to use Facebook public posts related to a news article to help summarize a popular topic. They explore various ways of using post information to boost summarization performance, including leveraging lexical frequency information, extracting sentences from posts, and combining summarization results generated from news articles and posts.', 'Lack of a data set of news articles, human-generated summaries, and related public posts.': 'The authors collect 190 popular news topics from Facebook, each with a news article, a human-generated summary, and hundreds to thousands of related public posts, creating the first data set of this kind.', 'Generating both extractive and abstractive summaries.': 'The proposed approach involves generating both extractive and abstractive summaries using an integer linear programming (ILP) based method.'}",unsupervised,"['News', 'Social Media']",['controlled-and-tailored-summarization']
SP:fa97d78fa5fb48fb481c17d0ad3e3ec7a550083b,Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints,ACL,2016,"['Greg Durrett', 'Taylor Berg-Kirkpatrick', 'Dan Klein']","We present a discriminative model for single-document summarization that integrally combines compression and anaphoricity constraints. Our model selects textual units to include in the summary based on a rich set of sparse features whose weights are learned on a large corpus. We allow for the deletion of content within a sentence when that deletion is licensed by compression rules; in our framework, these are implemented as dependencies between subsentential units of text. Anaphoricity constraints then improve cross-sentence coherence by guaranteeing that, for each pronoun included in the summary, the pronoun’s antecedent is included as well or the pronoun is rewritten as a full mention. When trained end-to-end, our final system1 outperforms prior work on both ROUGE as well as on human judgments of linguistic quality.","The paper presents a model for single-document summarization that combines compression and anaphoricity constraints. The model selects textual units for the summary based on learned weights from a large corpus. Compression rules allow for content deletion within a sentence, and anaphoricity constraints ensure cross-sentence coherence by including pronoun antecedents or rewriting pronouns as full mentions. The final system outperforms prior work on both ROUGE and human judgments of linguistic quality.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to tackle the single-document summarization problem, which is generally viewed as more difficult than multi-document summarization.', 'Who is the target audience?': 'The summaries are generated for readers who want to quickly understand the important content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used to improve content selection and ensure linguistic clarity and referential structure in summarization tasks. They can also be used to reorder summaries and ensure coherence, represent content for sentence fusion or abstraction, and optimize for ROUGE subject to constraints with end-to-end learning.'}",['method'],"['Controlled Generation', 'Objective Function']",['NYT'],"['ROUGE', 'Perplexity']",[''],,https://aclanthology.org/P16-1188,"{'Single-document summarization is viewed as more difficult than multi-document summarization due to the lack of redundancy across multiple input documents as a guide and the difficulty in content selection without simple positional information.': 'The authors tackle the single-document problem by training an expressive summarization model on a large naturally occurring corpus - the New York Times Annotated Corpus - learning to select important content with lexical features. They allow more aggressive compression of individual sentences by combining two different formalisms - one syntactic and the other discursive. They incorporate a model of anaphora resolution and give their system the ability to rewrite pronominal mentions, further increasing expressivity. They incorporate constraints from coreference ensuring that critical pronoun references are clear in the final summary and constraints from syntactic and discourse parsers ensuring that sentence realizations are well-formed. They demonstrate an efficient inference procedure using an ILP-based approach.', 'Past approaches to the single-document task have typically been heuristic in nature.': 'The authors train their full system end-to-end on a large-scale dataset, allowing them to learn a high-capacity structured model of the summarization process, contrasting with past approaches to the single-document task which have typically been heuristic in nature.', 'Imposing discursive and referential constraints improves human judgments of linguistic clarity and referential structure, but it is unclear how well the system performs compared to other methods.': 'The authors focus their evaluation on the New York Times Annotated corpus and show that their system outperforms a document prefix baseline, a bigram coverage baseline adapted from a strong multi-document system, and a discourse-informed method from prior work. They also show that their system outperforms the method of Yoshida et al. (2014) and approaches the clarity of a sentence-extractive baseline, while still achieving substantially higher ROUGE score than either method. These results indicate that their model has the expressive capacity to extract important content, but is sufficiently constrained to ensure fluency is not sacrificed as a result.', 'Past work has explored various kinds of structure for summarization.': ""Similar to these approaches, the authors appeal to structures from upstream NLP tasks (syntactic parsing, RST parsing, and coreference) to restrict their model's capacity to generate. However, they go further by optimizing for ROUGE subject to these constraints with end-to-end learning.""}",unsupervised,['News'],"['exploiting-the-structure-of-long-documents', 'robust-evaluation-methods']"
SP:17e9f60d729de32505c2039b2fedac5f3c505ad3,Automatic Summarization of Student Course Feedback,NAACL,2016,"['Wencan Luo', 'Fei Liu', 'Zitao Liu', 'Diane Litman']","Student course feedback is generated daily in both classrooms and online course discussion forums. Traditionally, instructors manually analyze these responses in a costly manner. In this work, we propose a new approach to summarizing student course feedback based on the integer linear programming (ILP) framework. Our approach allows different student responses to share co-occurrence statistics and alleviates sparsity issues. Experimental results on a student feedback corpus show that our approach outperforms a range of baselines in terms of both ROUGE scores and human evaluation.","

System: The paper proposes a new approach to summarizing student course feedback using the integer linear programming (ILP) framework. This approach allows different student responses to share co-occurrence statistics and alleviates sparsity issues. The experimental results on a student feedback corpus show that this approach outperforms a range of baselines in terms of both ROUGE scores and human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of student feedback to extract representative sentences and create a textual summary.', 'Who is the target audience?': 'The summaries are for instructors who want to analyze student feedback and adjust their teaching strategies.', 'How will the summaries be used?': 'The summaries will be used to reveal complex teaching problems, create more effective teaching and learning experiences, and provide insights for instructors to adjust their teaching strategies.'}",['method'],['Objective Function'],['CourseMirror'],['ROUGE'],[''],https://engineering.purdue.edu/coursemirror/download/dataset/,https://aclanthology.org/N16-1010,"{'Text-based student feedback is often manually analyzed by teaching evaluation centers in a costly manner, which does not scale well.': 'The authors propose to automatically summarize the student feedback produced in online and offline environments using an extractive summarization task.', 'One of the challenges of summarizing student feedback is its lexical variety, where different expressions communicate the same or similar meanings.': 'The authors propose a new approach to summarizing student feedback, which extends the standard ILP framework by approximating the co-occurrence matrix using a low-rank alternative. This allows sentences authored by different students to share co-occurrence statistics.', '97% of the bigrams appear only once or twice in the student feedback corpus, making it difficult to summarize.': 'The authors propose their new approach to summarizing student feedback, which allows for partial containment of similar expressions in different sentences.', 'The current approach to summarizing student feedback is not as effective as desired.': ""The authors' proposed approach produces better results on the student feedback summarization task in terms of both ROUGE scores and human evaluation.""}",unsupervised,['Student Responses'],[]
SP:5a15fc5e39cd027f7bfabf2c28ea08cb3ad39a52,Generating Coherent Summaries of Scientific Articles Using Coherence Patterns,EMNLP,2016,"['Daraksha Parveen', 'Mohsen Mesgar', 'Michael Strube']","Previous work on automatic summarization does not thoroughly consider coherence while generating the summary. We introduce a graph-based approach to summarize scientific articles. We employ coherence patterns to ensure that the generated summaries are coherent. The novelty of our model is twofold: we mine coherence patterns in a corpus of abstracts, and we propose a method to combine coherence, importance and non-redundancy to generate the summary. We optimize these factors simultaneously using Mixed Integer Programming. Our approach significantly outperforms baseline and state-of-the-art systems in terms of coherence (summary coherence assessment) and relevance (ROUGE scores).","

System: The paper introduces a new approach to automatic summarization of scientific articles that takes into account coherence. The approach uses a graph-based model and coherence patterns mined from a corpus of abstracts to generate summaries that are coherent, important, and non-redundant. The approach is optimized using Mixed Integer Programming and outperforms baseline and state-of-the-art systems in terms of coherence and relevance.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to assist researchers in having an informative and coherent gist of long scientific articles.', 'Who is the target audience?': 'The summaries are for researchers who need to quickly understand the important information in long scientific articles.', 'How will the summaries be used?': 'The summaries will be used as a tool to help researchers save time and effort in reading and analyzing long scientific articles.'}",['method'],['Unit Relationship'],"['PLOS Medicine', 'DUC 2002']",['ROUGE'],['Coherence'],,https://aclanthology.org/D16-1074,"{'Coherence has not been thoroughly considered in previous work on automatic summarization.': 'The authors focus on the coherence aspect of summarization and use discourse entities as the unit of information that relate sentences. They extract sentences which refer to important and unique entities and also connect the extracted sentences in a coherent manner using linguistically motivated coherence patterns.', 'Single sentence connectivity in the input document is not sufficient to generate coherent summaries.': 'The authors model coherence patterns by subgraphs of the graph representation of documents, where nodes represent sentences and edges represent entity connections among sentences. They show that the frequency of coherence patterns can be used as features for coherence.', 'Extracting non-adjacent sentences which are already coherent is a challenge.': 'The authors apply coherence patterns to long scientific articles to extract (possibly) non-adjacent sentences which are already coherent. They obtain coherence patterns by analyzing a corpus of abstracts of articles from biomedicine and apply the most frequent coherence patterns to input documents.', 'Importance and non-redundancy are important factors to consider in summarization.': 'The authors capture importance, non-redundancy, and coherence in an objective function maximized by Mixed Integer Programming (MIP).', 'Evaluating the effectiveness of the proposed method is necessary.': 'The authors evaluate their method on two different datasets: PLOS Medicine and DUC 2002. They extract frequent coherence patterns from all abstracts in the PubMed corpus and generate summaries of unseen scientific articles of the PLOS Medicine dataset. They also extract coherence patterns from the human summaries of DUC 2005 and evaluate their model on DUC 2002 to compare with state-of-the-art systems. Their experimental results show that using coherence patterns for summarization produces more informative and coherent summaries compared to several baseline methods and state-of-the-art methods based on ROUGE scores and human judgments.'}",unsupervised,"['News', 'Scholarly Documents']",['information-loss-and-incoherence-in-extractive-summarization']
SP:14004876a47a0da17d9b2ab0851b6aa10b6f3441,Contextualizing Citations for Scientific Summarization using Word Embeddings and Domain Knowledge,SIGIR,2017,"['Arman Cohan', 'Nazli Goharian']","Citation texts are sometimes not very informative or in some cases inaccurate by themselves; they need the appropriate context from the referenced paper to re ect its exact contributions. To address this problem, we propose an unsupervised model that uses distributed representation of words as well as domain knowledge to extract the appropriate context from the reference paper. Evaluation results show the e ectiveness of our model by signi cantly outperforming the state-of-the-art. We furthermore demonstrate how an e ective contextualization method results in improving citation-based summarization of the scienti c articles.",The paper proposes an unsupervised model that uses distributed representation of words and domain knowledge to extract context from referenced papers to reflect their exact contributions. The model significantly outperforms the state-of-the-art and improves citation-based summarization of scientific articles. The paper highlights the importance of appropriate context for citation texts and presents a solution to address this problem.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific papers to enhance downstream tasks in IR/NLP such as search and summarization.', 'Who is the target audience?': 'The summaries are for readers who want to better understand the context for the ideas, methods or findings stated in the citation text.', 'How will the summaries be used?': 'The summaries will be used to provide useful information about the referenced paper and to enhance scientific summarization.'}",['method'],['External Knowledge'],['TAC 2014 Biomedical Summarization Benchmark'],['ROUGE'],[''],,https://doi.org/10.1145/3077136.3080740,"{'Citation texts might lack the appropriate context from the reference article, and details of the methods, assumptions or conditions for the obtained results are often not mentioned.': 'The authors propose an approach for addressing such concerns by adding the appropriate context from the reference article to the citation texts. Enriching the citation texts with relevant context from the reference paper helps the reader to better understand the context for the ideas, methods or findings stated in the citation text.', 'In many cases, the citing author might misunderstand or misquote the referenced paper and ascribe contributions to it that are not intended in that form.': 'The authors propose to address this problem by utilizing a retrieval model that captures terminology variations and paraphrasing between the citation text and its relevant reference context. The model utilizes word embeddings and domain-specific knowledge to find the appropriate context of citations.', 'Traditional IR models that rely on term matching for finding the relevant information are ineffective due to discourse and terminology variations between the citing and the referenced authors.': 'The authors propose a retrieval model that utilizes word embeddings and domain-specific knowledge to capture terminology variations and paraphrasing between the citation text and its relevant reference context.', 'The lack of accurate dissemination of knowledge in life sciences has a direct impact on human lives.': 'The authors propose an approach for addressing the concerns related to citation texts in life sciences by adding the appropriate context from the reference article to the citation texts.'}",unsupervised,['Scholarly Documents'],[]
SP:ae543ffe0733d44d3e5855f5cb1e183e41f07fb2,Coarse-to-Fine Attention Models for Document Summarization,EMNLP,2017,"['Jeffrey Ling', 'Alexander M. Rush']","Sequence-to-sequence models with attention have been successful for a variety of NLP problems, but their speed does not scale well for tasks with long source sequences such as document summarization. We propose a novel coarse-to-fine attention model that hierarchically reads a document, using coarse attention to select top-level chunks of text and fine attention to read the words of the chosen chunks. While the computation for training standard attention models scales linearly with source sequence length, our method scales with the number of top-level chunks and can handle much longer sequences. Empirically, we find that while coarse-tofine attention models lag behind state-ofthe-art baselines, our method achieves the desired behavior of sparsely attending to subsets of the document for generation.","The paper proposes a new approach to document summarization using a coarse-to-fine attention model that hierarchically reads a document. This approach selects top-level chunks of text using coarse attention and then reads the words of the chosen chunks using fine attention. Unlike standard attention models, this method scales with the number of top-level chunks and can handle longer sequences. While it may lag behind state-of-the-art baselines, the proposed method achieves the desired behavior of sparsely attending to subsets of the document for generation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to reduce the amount of computation performed on the source and to extract only the necessary information for generating a summary.', 'Who is the target audience?': 'The intended audience for the document summaries is not specified in the given paper.', 'How will the summaries be used?': 'The paper does not specify how the document summaries will be used.'}",['method'],['Unit Selection'],['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/W17-4505,"{'Existing sequence-to-sequence methods are computationally limited by the length of source and target sequences.': 'Use a two-layer hierarchical attention to prune down the length of the source sequence in an intelligent way. Divide the document into chunks of text, sparsely attend to one or a few chunks at a time using hard attention, then apply the usual full attention over those chunks – this method is called coarse-to-fine attention.', 'Not every word of the source will be necessary for generating a summary, and so we would like to reduce the amount of computation performed on the source.': 'Use the coarse-to-fine attention method to sparsely read the source sequence.', 'The performance of coarse-to-fine attention is not as good as standard attention.': 'Through experiments, show that coarse-to-fine attention does show the desired behavior of sparsely reading the source sequence.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:af70b4100c4d7228c53827bc99a05b68c190b951,Low-Resource Neural Headline Generation,EMNLP,2017,"['Ottokar Tilk', 'Tanel Alumäe']","Recent neural headline generation models have shown great results, but are generally trained on very large datasets. We focus our efforts on improving headline quality on smaller datasets by the means of pretraining. We propose new methods that enable pre-training all the parameters of the model and utilize all available text, resulting in improvements by up to 32.4% relative in perplexity and 2.84 points in ROUGE.","System: This paper discusses the challenges of improving headline quality on smaller datasets using neural headline generation models. The authors propose a new method that allows for pre-training all parameters of the model and utilizing all available text. This approach resulted in significant improvements in perplexity and ROUGE scores, with up to a 32.4% relative improvement in perplexity and 2.84 points in ROUGE.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to automatically generate a headline based on the text of the document using artificial neural networks.', 'Who is the target audience?': 'The summaries are for anyone who needs a condensed version of the document, such as news articles or research papers.', 'How will the summaries be used?': 'The summaries will be used to provide a brief overview of the document in a shorter format, often limited to a single sentence, and written in a different style than the original document.'}",['method'],"['External Knowledge', 'Auxiliary Tasks']",['CNN/DailyMail'],['ROUGE'],[''],,https://aclanthology.org/W17-4503,"{'NHG models are generally trained to generate headlines based on just a few first sentences of the documents, leaving the rest of the text unutilized.': 'Pre-training subsets of the model on full documents to alleviate the problem of unutilized text.', 'The decoder component of NHG models can be regarded as a language model (LM) whose predictions are biased by the external information from the encoder. As a LM it sees only headlines during training, which is a small fraction of text compared to the documents.': 'Supplementing the training data of the decoder with documents via pre-training might enable it to learn more about words and language structure.', 'Previous work has used pre-training before, but it is not fully explored how much pretraining helps and what is the optimal way to do it. Another problem is that in previous work only a subset of parameters (usually just embeddings) is pre-trained leaving the rest of the parameters randomly initialized.': 'LM pre-training for fully initializing the encoder and decoder, combining LM pre-training with distant supervision pre-training using filtered sentences of the documents as noisy targets to pre-train all the parameters of the NHG model, and analyzing the effect of pre-training different components of the NHG model.'}",supervised,['News'],"['efficient-encoding-of-long-documents', 'pretraining-and-sample-efficiency']"
SP:e482bfed63a2e173513ebaf0d440eee705703729,Automatic Text Summarization Using Reinforcement Learning with Embedding Features,IJCNLP,2017,"['Gyoung Ho Lee', 'Kong Joo Lee']","An automatic text summarization system can automatically generate a short and brief summary that contains a main concept of an original document. In this work, we explore the advantages of simple embedding features in Reinforcement leaning approach to automatic text summarization tasks. In addition, we propose a novel deep learning network for estimating Qvalues used in Reinforcement learning. We evaluate our model by using ROUGE scores with DUC 2001, 2002, Wikipedia, ACL-ARC data. Evaluation results show that our model is competitive with the previous models.","

System: The paper discusses the use of simple embedding features in a Reinforcement learning approach to automatic text summarization. The authors propose a new deep learning network for estimating Qvalues used in Reinforcement learning and evaluate their model using ROUGE scores with various datasets. The results show that their model is competitive with previous models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for extractive text summarization tasks.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['method'],['Objective Function'],"['ACL-ARC', 'WIKI', 'DUC 2001', 'DUC 2002']",['ROUGE'],[''],,https://aclanthology.org/I17-2033,"{'Maximal marginal relevance (MMR) cannot take into account the quality of a whole summary because of its greediness.': 'Use optimization techniques such as integer linear programming (ILP) to infer the scores of sentences with consideration of the quality of a whole summary.', 'ILP has a very large time complexity, making it not applicable for text summarization tasks.': 'Use a Reinforcement Learning method as an alternative approach to optimize a score function in extractive text summarization task.', 'Previous studies mainly exploited handcrafted complex features in RL-based automatic text summarization, which are difficult and time-consuming to choose, re-implement, and re-generate for new domains and applications.': 'Explore the advantages of simple embedding features in RL approach to automatic text summarization tasks, as embedding is one of the simplest deep learning techniques to build features that represent words, sentences, or documents.', 'The relevance of a candidate sentence for an entire document as well as the naturalness of a generated summary are not considered in estimating Q-values used in RL.': 'Propose a novel deep learning network for estimating Q-values used in RL that is devised to consider the relevance of a candidate sentence for an entire document as well as the naturalness of a generated summary.', 'The performance of previous studies that rely on as many features as possible is not comparable to the proposed model.': 'Evaluate the proposed model by using ROUGE scores and show that its performance is comparable to that of the previous studies which rely on as many features as possible.'}",reinforced,"['News', 'Scholarly Documents', 'Wikipedia']",[]
SP:fbec6e7bd74d6f34f0a0fe6b368027ec22f425e6,Vocabulary Tailored Summary Generation,COLING,2018,"['Kundan Krishna', 'Aniket Murhekar', 'Saumitra Sharma', 'Balaji Vasan Srinivasan']","Neural sequence-to-sequence models have been successfully extended for summary generation. However, existing frameworks generate a single summary for a given input and do not tune the summaries towards any additional constraints/preferences. Such a tunable framework is desirable to account for linguistic preferences of the specific audience who will consume the summary. In this paper, we propose a neural framework to generate summaries constrained to vocabularydefined linguistic preferences of a target audience. The proposed method accounts for the generation context by tuning the summary words at the time of generation. Our evaluations indicate that the proposed approach tunes summaries to the target vocabulary while still maintaining a superior summary quality against a state-of-the-art word embedding based lexical substitution algorithm, suggesting the feasibility of the proposed approach. We demonstrate two applications of the proposed approach to generate understandable summaries with simpler words, and readable summaries with shorter words.","The paper proposes a neural framework for generating summaries that are tailored to the linguistic preferences of a specific audience. Existing frameworks do not take into account such preferences, but the proposed method tunes the summary words at the time of generation to match the target vocabulary. The evaluations show that the proposed approach maintains a superior summary quality compared to a word embedding based lexical substitution algorithm. The paper demonstrates two applications of the proposed approach to generate summaries with simpler or shorter words for better readability.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to present the most relevant and important information in a long text in a succinct form.', 'Who is the target audience?': 'The summaries are for anyone who prefers a quick consumption of the information in a long article.', 'How will the summaries be used?': 'The summaries will be used to retain the important points of an input document while presenting them in a concise form.'}",['method'],['Controlled Generation'],['CNN/DailyMail'],['ROUGE'],['Informativeness'],,https://aclanthology.org/C18-1068,"{'Extractive summarization is unable to produce “human-like” summaries because it only selects sentences/textual units from the input article and puts them together into a summary.': 'The authors propose efforts towards “abstractive” summarization which paraphrases the input article. They propose a neural network based summary generator that generates summaries by encoding the entire source article and generating the summary word-by-word.', 'It is desirable to tune the summaries to the linguistic preferences of the readers, but post-processing based approaches lose the contextual information from the source article once the summary has been constructed.': 'The authors propose modifying the generation probability of the next word in accordance with the vocabulary-based preferences. This approach does not require re-training a neural network and relies on modifying the summary generation procedure on a pre-trained network.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'controlled-and-tailored-summarization']"
SP:d614d3060516611d0a45c91e8ae0dae724d95cdf,ScisummNet: A Large Annotated Corpus and Content-Impact Models for Scientific Paper Summarization with Citation Networks,AAAI,2019,"['Michihiro Yasunaga', 'Jungo Kasai', 'Rui Zhang', 'Alexander R. Fabbri', 'Irene Li', 'Dan Friedman', 'Dragomir R. Radev']","Scientific article summarization is challenging: large, annotated corpora are not available, and the summary should ideally include the article’s impacts on research community. This paper provides novel solutions to these two challenges. We 1) develop and release the first large-scale manually-annotated corpus for scientific papers (on computational linguistics) by enabling faster annotation, and 2) propose summarization methods that integrate the authors’ original highlights (abstract) and the article’s actual impacts on the community (citations), to create comprehensive, hybrid summaries. We conduct experiments to demonstrate the efficacy of our corpus in training data-driven models for scientific paper summarization and the advantage of our hybrid summaries over abstracts and traditional citation-based summaries. Our large annotated corpus and hybrid methods provide a new framework for scientific paper summarization research.","The paper discusses the challenges of scientific article summarization and proposes solutions to these challenges. The authors develop and release a large-scale manually-annotated corpus for scientific papers on computational linguistics and propose summarization methods that integrate the authors' original highlights and the article's actual impacts on the community to create comprehensive, hybrid summaries. The authors conduct experiments to demonstrate the efficacy of their corpus in training data-driven models for scientific paper summarization and the advantage of their hybrid summaries over abstracts and traditional citation-based summaries. The large annotated corpus and hybrid methods provide a new framework for scientific paper summarization research.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to tackle the problem of scientific article summarization, which is less explored compared to news article or other general summarization.', 'Who is the target audience?': 'The summaries are for researchers and scientists who need to quickly grasp the major aspects of a scientific paper without reading the whole text.', 'How will the summaries be used?': ""The summaries will be used as a resource for supervised scientific paper summarization, and the proposed hybrid summarization methods can incorporate both the authors' and research community's insights to produce more comprehensive summaries than abstracts.""}",['corpus'],['Objective Function'],['CL-SciSumm'],['ROUGE'],"['Coverage', 'Coherence']",,https://doi.org/10.1609/aaai.v33i01.33017386,"{'Scientific article summarization is less explored and differs from news article or other general summarization due to their length, technical content, and structured sections with citations.': 'Develop automatic summarizers for scientific articles and encourage research in scientific article summarization.', 'Existing shared tasks for scientific paper summarization have small datasets, preventing the application of data-driven approaches such as neural networks.': 'Create a novel dataset and summarization method that expands the existing CL-SciSumm project and provides the largest manually-annotated dataset for scientific paper summarization.', 'The abstract of a paper may fail to convey the actual impact of the paper on the research community, and the significance of a paper may change over time.': 'Propose two novel summarization models for scientific papers that capture both the papers’ content highlighted by the authors and impact perceived by the research community (hybrid summarization).', 'Annotation or crowdsourcing for scientific papers is not realistic due to their length and technical content.': 'For each of the 1,000 papers in the dataset, experts in CL/NLP read its abstract and incoming citation sentences to create a gold summary, enabling faster annotation.', 'The authority of each work in the research community is not reflected in the summarization.': 'Exploit the citation counts of the reference paper and its citing papers as an additional feature in the summarization models.', 'The existing benchmark dataset for scientific paper summarization has limited gold summaries.': 'Use the proposed dataset to train neural summarizers and outperform all prior participants in the shared task.'}",supervised,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'lack-of-suitable-training-data']"
SP:35d2ddf96880a1b456cec732fcf2670e3bf6d82e,Better Rewards Yield Better Summaries: Learning to Summarise Without References,EMNLP,2019,"['Florian Böhm', 'Yang Gao', 'Christian M. Meyer', 'Ori Shapira', 'Ido Dagan', 'Iryna Gurevych']","Reinforcement Learning (RL) based document summarisation systems yield state-of-the-art performance in terms of ROUGE scores, because they directly use ROUGE as the rewards during training. However, summaries with high ROUGE scores often receive low human judgement. To find a better reward function that can guide RL to generate human-appealing summaries, we learn a reward function from human ratings on 2,500 summaries. Our reward function only takes the document and system summary as input. Hence, once trained, it can be used to train RL-based summarisation systems without using any reference summaries. We show that our learned rewards have significantly higher correlation with human ratings than previous approaches. Human evaluation experiments show that, compared to the state-of-the-art supervised-learning systems and ROUGE-as-rewards RL summarisation systems, the RL systems using our learned rewards during training generate summaries with higher human ratings. The learned reward function and our source code are available at https://github.com/yg211/ summary-reward-no-reference.","The paper discusses the limitations of using ROUGE scores as rewards in Reinforcement Learning (RL) based document summarisation systems, as high ROUGE scores do not necessarily correspond to high human judgement. To address this, the authors learn a reward function from human ratings on 2,500 summaries, which only takes the document and system summary as input. The learned rewards are shown to have significantly higher correlation with human ratings than previous approaches. The authors conduct human evaluation experiments and find that RL systems using their learned rewards generate summaries with higher human ratings compared to state-of-the-art supervised-learning systems and ROUGE-as-rewards RL summarisation systems. The learned reward function and source code are available at https://github.com/yg211/summary-reward-no-reference.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to build document summarisation systems.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a long document or multiple documents on the same topic.', 'How will the summaries be used?': 'The summaries will be used to guide both extractive and abstractive RL-based summarisers to generate summaries with significantly higher human ratings than the state-of-the-art systems.'}","['method', 'metric']",['Objective Function'],['CNN/DailyMail'],"['Accuracy', 'Precision', 'Recall', 'F1 Score']","['Informativeness', 'Conciseness']",https://github.com/yg211/summary-reward-no-reference,https://aclanthology.org/D19-1307,"{'ROUGE performs poorly at summary level, making it difficult to distinguish between ""good"" and ""bad"" summaries.': 'The authors learn a reward function directly from human ratings, which only takes the document and the generated summary as input. This reward function can be used to train RL-based summarisation systems without any reference summaries.', 'Most large-scale summarisation datasets only have one reference summary available for each input document, making it challenging to use ROUGE as an RL reward.': 'The authors use a dataset compiled by Chaganty et al. (2018), which includes human ratings on 2,500 summaries for 500 news articles from CNN/DailyMail. This dataset does not require reference summaries to compute the scores.', 'ROUGE cannot reliably identify human-appealing summaries.': 'The authors study the summary-level correlation between ROUGE and human judgement on 2,500 summaries and show that ROUGE performs poorly. They formulate the reward learning problem as either a regression or a preference learning problem and explore multiple text encoders and neural architectures to build the reward learning model. They show that their learned reward correlates significantly better with human judgements than ROUGE.', 'RL-based summarisation systems rely on summary-level ROUGE scores to guide the optimisation direction, which can mislead the RL agents.': 'The authors use their learned reward function to guide both extractive and abstractive RL-based summarisers to generate summaries with significantly higher human ratings than the state-of-the-art systems.'}",reinforced,['News'],['robust-evaluation-methods']
SP:2b192d04e5cff03de477d1cf6a06888368ab6361,Towards Annotating and Creating Sub-Sentence Summary Highlights,EMNLP,2019,"['Kristjan Arumae', 'Parminder Bhatia', 'Fei Liu']","Highlighting is a powerful tool to pick out important content and emphasize. Creating summary highlights at the sub-sentence level is particularly desirable, because sub-sentences are more concise than whole sentences. They are also better suited than individual words and phrases that can potentially lead to disfluent, fragmented summaries. In this paper we seek to generate summary highlights by annotating summary-worthy sub-sentences and teaching classifiers to do the same. We frame the task as jointly selecting important sentences and identifying a single most informative textual unit from each sentence. This formulation dramatically reduces the task complexity involved in sentence compression. Our study provides new benchmarks and baselines for generating highlights at the sub-sentence level.","The paper discusses the benefits of creating summary highlights at the sub-sentence level and proposes a method for generating them by annotating summary-worthy sub-sentences and teaching classifiers to do the same. The task is framed as jointly selecting important sentences and identifying a single most informative textual unit from each sentence, which reduces the complexity involved in sentence compression. The study provides new benchmarks and baselines for generating highlights at the sub-sentence level.","{'What is the purpose of the summaries?': 'The authors are generating summaries to emphasize salient content in an unobtrusive manner.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The highlights can be overlaid on the source document, allowing them to be interpreted in context. The number of highlights is controllable by limiting sentence selection. The highlights are guaranteed to be true-to-the-original, while system abstracts can sometimes “hallucinate” facts and distort the original meaning.'}",['method'],['Unit Selection'],['CNN/DailyMail'],"['ROUGE', 'Novel n-grams']",[''],,http://arxiv.org/abs/1910.07659,"{'Highlighting at an appropriate level of granularity is important to emphasize salient content in an unobtrusive manner. A small collection of keywords may be insufficient to deliver the main points of an article, while highlighting whole sentences often provide superfluous information.': 'The authors propose generating sub-sentence highlights by jointly selecting representative sentences from a document and identifying a single most informative textual unit from each sentence.', 'Extractive and compressive summarization methods can render summaries ungrammatical and fragmented due to multiple interdependent decisions on word deletion.': 'The authors investigate an alternative formulation of sub-sentence highlighting that can dramatically reduce the task complexity involved in sentence compression.', 'Adjusting summary length in an end-to-end, abstractive system can be difficult, and system abstracts can sometimes “hallucinate” facts and distort the original meaning.': 'Generating sub-sentence highlights is advantageous over abstraction as the highlights can be overlaid on the source document, allowing them to be interpreted in context, and are guaranteed to be true-to-the-original.', 'Generating highlights at the sub-sentence level has not been thoroughly investigated in the past.': 'The authors introduce a new task formulation of creating sub-sentence summary highlights and examine the feasibility of using neural extractive summarization with a multi-termed objective to identify summary sentences and their most informative sub-sentence units.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'exploiting-the-structure-of-long-documents', 'hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:0c5dea304045b765f6684ce822d7b558a9248c88,Neural Review Summarization Leveraging User and Product Information,CIKM,2019,"['Hui Liu', 'Xiaojun Wan']","Product review summarization is a special form of text summarization, which gives a brief summary of an online product review. It is useful for both sellers to get feedback and consumers to make purchase decisions. Compared to traditional well-studied text summarization, product review summarization is highly personalized and targeted. Users have their own styles to write reviews and summaries, and products have different aspects to focus on. In this paper, we explore different ways to leverage the user and product information to help review summarization. Experiments show that our approaches are very effective and our models outperform the strong summarization baselines with a large margin.","The paper discusses product review summarization, which is a personalized and targeted form of text summarization that provides a brief summary of an online product review. The authors explore different ways to use user and product information to improve review summarization and demonstrate that their approaches are highly effective and outperform existing summarization methods. This technique is useful for both sellers and consumers in making purchase decisions.","{'What is the purpose of the summaries?': 'The authors are generating summaries of product reviews to help consumers conclude their reviews automatically, help other consumers make reasonable purchase decisions, and give the sellers product feedback concisely.', 'Who is the target audience?': 'The summaries are for consumers who are looking to make informed purchase decisions based on the reviews of others.', 'How will the summaries be used?': 'The summaries will be used to provide a concise and personalized overview of the product reviews, allowing consumers to quickly and easily understand the key aspects of the product and make informed purchasing decisions.'}",['method'],"['External Knowledge', 'Input Encoding']",['Amazon Product Reviews'],['ROUGE'],[''],https://github.com/PKULiuHui/ReviewSum,https://doi.org/10.1145/3357384.3358161,"{'Online product reviews are expanding rapidly, and consumers often write reviews about the products they purchase. However, these reviews can be lengthy and difficult to read, making it challenging for other consumers to make informed purchase decisions.': 'The authors propose product review summarization, which aims to generate a short version of the original review. This can help consumers conclude their reviews automatically, help other consumers make reasonable purchase decisions, and give the sellers product feedback concisely.', 'Product review summarization is highly personalized and targeted, as users have their styles to write reviews and summaries, and products have different aspects to focus on.': 'The authors explore different ways to leverage the user and product information to help review summarization. They refer to user and product as attributes in the following of this paper.', 'Existing text summarization techniques may not be effective for product review summarization, as it requires personalized and targeted summaries.': 'The authors propose four neural models to address the review summarization task. The first three introduce the attribute information into the encoder and decoder respectively. The last is a novel model that can fuse the text and attribute information with a memory network to generate the final summary.', 'It is unclear whether incorporating user and product information into the summarization process will improve the efficacy of the models.': 'Experiments show the efficacy of the proposed models. The first three simple models prove the usefulness of attribute information. And the last novel model outperforms other models with a large margin.'}",supervised,['Reviews'],['controlled-and-tailored-summarization']
SP:26f2462f8e0e577822c660845a5efb687b343a9a,Global Optimization under Length Constraint for Neural Text Summarization,ACL,2019,"['Takuya Makino', 'Tomoya Iwakura', 'Hiroya Takamura', 'Manabu Okumura']","We propose a global optimization method under length constraint (GOLC) for neural text summarization models. GOLC increases the probabilities of generating summaries that have high evaluation scores, ROUGE in this paper, within a desired length. We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN/Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers. The experimental results show that a state-ofthe-art neural summarization model optimized with GOLC generates fewer overlength summaries while maintaining the fastest processing speed; only 6.70% overlength summaries on CNN/Daily and 7.8% on long summary of Mainichi, compared to the approximately 20% to 50% on CNN/Daily Mail and 10% to 30% on Mainichi with the other optimization methods. We also demonstrate the importance of the generation of in-length summaries for post-editing with the dataset Mainich that is created with strict length constraints. The experimental results show approximately 30% to 40% improved post-editing time by use of inlength summaries.","The paper proposes a global optimization method called GOLC for neural text summarization models that increases the probabilities of generating summaries with high evaluation scores within a desired length. The method is compared to two other optimization methods on two datasets and the results show that GOLC generates fewer overlength summaries while maintaining the fastest processing speed. The importance of generating in-length summaries for post-editing is also demonstrated, with approximately 30% to 40% improved post-editing time by use of in-length summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create a short and coherent summary of a given text.', 'Who is the target audience?': 'The summaries are for editors who need to summarize a source text under a length constraint by reordering and paraphrasing.', 'How will the summaries be used?': 'The summaries will be used to improve post-editing time and to generate summaries that satisfy the length constraint.'}",['method'],"['Objective Function', 'Controlled Generation']",['CNN/DailyMail'],['ROUGE'],"['Informativeness', 'Readability']",,https://aclanthology.org/P19-1099,"{'Most abstractive summarization methods are not able to control the summary length.': 'Kikuchi et al. (2016) and Liu et al. (2018) proposed abstractive summarization models with a capability of summary length control. They proposed to enforce the desired length in the decoding of training and generation. However, their models leave much room for improvement.', 'The summarization performance of existing abstractive summarization models with length control is still worse than other state-of-the-art models.': 'The authors address this issue by incorporating global training based on a minimum risk training (MRT) under the length constraint. They propose a global optimization under length constraint (GOLC) for neural summarization models. They show that neural summarization models trained with GOLC can control the output length better than the existing methods.', 'How to use MRT under a length constraint was an open problem.': 'The authors propose a method to use MRT under a length constraint for neural summarization models.', 'Existing abstractive summarization models with length control sometimes fail to control the output length.': ""The authors' training procedure makes use of overlength summaries. While the probabilities of generating summaries that satisfy the length constraint increase, overlength summaries are penalized and hence the probabilities of generating such summaries decrease."", 'The importance of generating in-length summaries for post-editing is not well understood.': 'The authors demonstrate the importance of generating in-length summaries for post-editing. The experimental results of post-editing generated summaries showed that generated in-length summaries contributed to an approximately 30% to 40% improved post-editing time.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:a9e5a89647f41fa9958ed440fe24bdd4a09e9271,From Arguments to Key Points: Towards Automatic Argument Summarization,ACL,2020,"['Roy Bar-Haim', 'Lilach Eden', 'Roni Friedman', 'Yoav Kantor', 'Dan Lahav', 'Noam Slonim']","Generating a concise summary from a large collection of arguments on a given topic is an intriguing yet understudied problem. We propose to represent such summaries as a small set of talking points, termed key points, each scored according to its salience. We show, by analyzing a large dataset of crowd-contributed arguments, that a small number of key points per topic is typically sufficient for covering the vast majority of the arguments. Furthermore, we found that a domain expert can often predict these key points in advance. We study the task of argument-to-key point mapping, and introduce a novel large-scale dataset for this task. We report empirical results for an extensive set of experiments with this dataset, showing promising performance.","The paper proposes a method for generating concise summaries from a large collection of arguments on a given topic by representing them as a small set of key points, each scored according to its salience. The authors analyze a large dataset of crowd-contributed arguments and find that a small number of key points per topic is typically sufficient for covering the vast majority of the arguments. They also show that a domain expert can often predict these key points in advance. The paper introduces a novel large-scale dataset for the task of argument-to-key point mapping and reports promising empirical results for an extensive set of experiments with this dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to help decision makers make informed decisions by providing them with a concise summary of the arguments for and against a proposal.', 'Who is the target audience?': 'The summaries are for governments, businesses, and individuals who need to make decisions on a daily basis.', 'How will the summaries be used?': 'The summaries will be used to provide decision makers with a short list of key points that summarize the arguments for and against a proposal. They can also be used for interactive exploration of large argument collections and for novelty detection.'}",['corpus'],"['Unit Relationship', 'Unit Selection']",['ArgKP'],['Precision'],[''],https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml,https://aclanthology.org/2020.acl-main.371/,"{'When making important decisions, individuals, businesses, and governments need to gather information about the pros and cons of a proposal, which can result in hundreds or thousands of arguments per topic, making it impossible to read and digest such large amounts of information.': 'The authors propose summarizing the arguments supporting each side of the debate by mapping them to a short list of talking points, termed key points, which are general enough to match a significant portion of the arguments, yet informative enough to make a useful summary.', 'The proposed method raises a fundamental question: can a small number of key points effectively summarize massive amounts of arguments collected from a large population?': 'The authors give a positive answer to this question, based on extensive analysis over 28 controversial topics and 7,000 crowd-contributed pro and con arguments for these topics. Furthermore, they found that a domain expert can compose a short, comprehensive list of key points even without looking at the arguments themselves.', 'The authors need a dataset for the argument-to-keypoint mapping task.': 'The authors develop the ArgKP dataset for the argument-to-keypoint mapping task, comprising about 24,000 (argument, key point) pairs labeled as matching/non-matching. This is the first dataset for this task and is much larger and far more comprehensive than datasets developed for related tasks.', 'The authors need to evaluate and analyze a variety of classification methods for the argument-to-keypoint mapping task.': 'The authors perform empirical evaluation and analysis of a variety of classification methods for the argument-to-keypoint mapping task, achieving promising results.'}",supervised,['Arguments'],[]
SP:ad7d2b81884eb661fb48ca2ff38b51162149ea1e,Systematically Exploring Redundancy Reduction in Summarizing Long Documents,AACL,2020,"['Wen Xiao', 'Giuseppe Carenini']","Our analysis of large summarization datasets indicates that redundancy is a very serious problem when summarizing long documents. Yet, redundancy reduction has not been thoroughly investigated in neural summarization. In this work, we systematically explore and compare different ways to deal with redundancy when summarizing long documents. Specifically, we organize the existing methods into categories based on when and how the redundancy is considered. Then, in the context of these categories, we propose three additional methods balancing non-redundancy and importance in a general and flexible way. In a series of experiments, we show that our proposed methods achieve the state-of-the-art with respect to ROUGE scores on two scientific paper datasets, Pubmed and arXiv, while reducing redundancy significantly. 1",The paper explores the problem of redundancy in neural summarization and proposes three new methods to balance non-redundancy and importance when summarizing long documents. The authors organize existing methods into categories based on when and how redundancy is considered and show that their proposed methods achieve state-of-the-art ROUGE scores while significantly reducing redundancy on two scientific paper datasets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to shorten them while maintaining the most important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used to quickly grasp the main points of a document, to decide whether to read the full document, or to compare and contrast multiple documents on the same topic.'}",['analysis'],"['Unit Relationship', 'Objective Function']","['PubMed', 'arXiv']",['ROUGE'],[''],http://www.cs.ubc.ca/cs-research/lci/research-groups/natural-language-processing/,https://aclanthology.org/2020.aacl-main.51,"{'Extractive summarization methods tend to be less coherent and more redundant than abstractive ones.': 'Abstractive methods can be used to generate new sentences by sentence fusion and compression, which helps detect and remove redundancy.', 'Redundancy is a more serious problem when summarizing long documents than short ones.': 'The authors propose new methods that explicitly and flexibly reduce redundancy in the sentence scoring and sentence selection phase for long documents.', 'Existing neural extractive summarization models over-emphasize sentence importance and pay little attention to reducing redundancy in the selection phase.': 'The authors re-implement existing methods and propose new ones that balance the trade-off between importance and redundancy in the sentence selection phase.', 'Existing neural methods for reducing redundancy either do so implicitly or inflexibly and only focus on short documents.': 'The authors systematically organize existing methods into three categories and compare them with respect to the informativeness and redundancy of the generated summary for long documents.', 'The effectiveness of the Trigram Blocking technique on the summarization of long documents has not been tested.': 'The authors test the effectiveness of the Trigram Blocking technique on long documents and propose new methods that outperform it.', 'There are unclear connections between all the proposed neural models, limited focus on short documents, and spotty evaluations.': 'The authors perform a fair comparison by re-implementing all methods on a common basic model and propose new methods that achieve state-of-the-art performance on ROUGE scores and reduce redundancy significantly.'}",supervised,['Scholarly Documents'],[]
SP:df78f6721f760e3bcadd59e62795969138c911d2,Weakly-Supervised Opinion Summarization by Leveraging External Information,AAAI,2020,"['Chao Zhao', 'Snigdha Chaturvedi']","Opinion summarization from online product reviews is a challenging task, which involves identifying opinions related to various aspects of the product being reviewed. While previous works require additional human effort to identify relevant aspects, we instead apply domain knowledge from external sources to automatically achieve the same goal. This work proposes ASPMEM, a generative method that contains an array of memory cells to store aspect-related knowledge. This explicit memory can help obtain a better opinion representation and infer the aspect information more precisely. We evaluate this method on both aspect identification and opinion summarization tasks. Our experiments show that ASPMEM outperforms the state-of-the-art methods even though, unlike the baselines, it does not rely on human supervision which is carefully handcrafted for the given tasks.","The paper proposes a generative method called ASPMEM for opinion summarization from online product reviews. ASPMEM contains an array of memory cells to store aspect-related knowledge, which helps obtain a better opinion representation and infer aspect information more precisely. The method is evaluated on both aspect identification and opinion summarization tasks and outperforms state-of-the-art methods without relying on human supervision. The proposed method uses domain knowledge from external sources to automatically identify relevant aspects, eliminating the need for additional human effort.","{'What is the purpose of the summaries?': 'The authors are generating summaries of user opinions to provide a concise and digestible summary of the overwhelming number of opinions available on the internet.', 'Who is the target audience?': 'The summaries are for users who find it difficult to read and process a large number of opinions on a product.', 'How will the summaries be used?': 'The summaries will be used to provide an overview of popular opinions and reflect their diversity, as well as to focus on the various aspects and sentiment polarities of the target product.'}",['method'],['External Knowledge'],['OPOSUM'],['ROUGE'],[''],https://github.com/zhaochaocs/AspMem,https://ojs.aaai.org/index.php/AAAI/article/view/6512,"{'Opinion summarization needs to cover a range of popular opinions and reflect their diversity, which is different from the general task of multi-document summarization.': 'The authors propose a three-step pipeline to create an opinion summary by mining product-related aspects and identifying sentences related to those aspects, analyzing the sentiment of the identified sentences, and summarizing the results.', 'Previous methods for aspect identification and opinion summarization require human-annotated data and suffer from the inability to adapt across different domains or product categories.': 'The authors propose utilizing knowledge sourced from existing external information about the target product, such as feature descriptions, to reduce the risk of biased or unrepresentative human-assigned aspects and make the model easy to adapt to different product categories.', 'Pure unsupervised methods for aspect identification and opinion summarization struggle to detect aspect-related segments of reviews with high precision and recall.': 'The authors propose a generative approach that relies on the aspect-aware memory (ASPMEM) to better leverage external knowledge during aspect identification and opinion summarization. ASPMEM is an array of memory cells to store aspect-related knowledge obtained from external information, which cooperate with the model throughout learning to judge the relevance of review sentences to the product aspects. The relevance is then combined with the sentiment strength to determine the salience of an opinion, and a subset of salient opinions is extracted to create the final summary.', 'Information redundancy in the summary.': 'The authors formalize the subset selection process as an Integer Linear Programming (ILP) problem, which maximizes the collective salience scores of the selected sentences while minimizing information redundancy.'}",supervised,['Opinions'],"['lack-of-suitable-training-data', 'identifying-important-contents-from-the-document']"
SP:9d306724929b25e801cb4e403ceb09516f76edc8,Quantitative Argument Summarization and Beyond: Cross-Domain Key Point Analysis,EMNLP,2020,"['Roy Bar-Haim', 'Yoav Kantor', 'Lilach Eden', 'Roni Friedman', 'Dan Lahav', 'Noam Slonim']","When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on multi-document summarization has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects: first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond argumentation data. Using models trained on publicly available argumentation datasets, we achieve promising results in two additional domains: municipal surveys and user reviews. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.","The paper discusses the importance of not only extracting salient points when summarizing a collection of views, arguments or opinions, but also quantifying their prevalence. The traditional approach of creating textual summaries lacks this quantitative aspect. The paper proposes a method for automatic extraction of key points, which enables fully automatic analysis and achieves performance comparable to a human expert. The applicability of key point analysis goes beyond argumentation data, as demonstrated by promising results in municipal surveys and user reviews. The paper also presents an in-depth evaluation of argument-to-key point matching models, where previous results are substantially outperformed.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress textual collections into short summaries that rely on their inherent redundancy.', 'Who is the target audience?': 'The summaries are for text analytics applications across a variety of domains, such as responses to open-ended questions in surveys, user reviews on products and services, and posts in online discussion forums.', 'How will the summaries be used?': 'The summaries will be used to capture most of the relevant information in the input clusters while removing redundancies. They will also be used to quantify the prevalence of each of the points included in the summary and allow users to drill down to view the comments that were mapped to a specific point in the summary.'}",['method'],['Unit Selection'],['ArgKP'],"['ROUGE', 'Perplexity']",[''],,https://aclanthology.org/2020.emnlp-main.3,"{'The need for summarizing views, arguments, and opinions on a given topic is common to many text analytics applications, across a variety of domains.': 'The authors propose Multi-Document Summarization (MDS) algorithms to create short textual summaries from document clusters sharing the same topic.', 'In many cases, it is desirable to quantify the prevalence of each of the points included in the summary.': 'The authors propose key point analysis as a summarization framework that matches each argument to a short list of key points, defined as high-level arguments.', 'Key points were manually composed by an expert in previous work.': 'The authors develop a method for automatic key point extraction, allowing fully automatic key point analysis.', 'The applicability of key point analysis in additional domains beyond argumentation is unknown.': 'The authors demonstrate promising results on two datasets: municipal surveys and user reviews, using the same argument matching and argument quality models that were trained on argumentation data.', 'The accuracy and run time of pre-trained Transformer models for argument matching need to be compared.': 'The authors conduct an extensive comparison of pre-trained Transformer models for argument matching, resulting in substantial improvement over the best results reported by Bar-Haim et al.'}",supervised,['Forum Discussions'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:010ac74c759601ca728e502fe77012f40afed4fd,A Joint Model for Structure-based News Genre Classification with Application to Text Summarization,ACL,2021,"['Zeyu Dai', 'Ruihong Huang']","Journalists usually organize and present the contents of a news article following a welldefined structure. In this paper, we propose a novel joint model for structure-based news genre classification that simultaneously identifies one of four commonly used news structures (including Inverted Pyramid and three other structures) for a news article as well as recognizes a sequence of news elements within the article that define the corresponding news structure. Experiments show that the joint model consistently outperforms its variants that perform two tasks independently, which supports our motivation that preserving the two-way dependencies and constraints between a type of news structure and its sequence of news elements enables the model to better predict both of them. Although being not perfect, the system predicted news structure type and news elements have improved the performance of text summarization when incorporated into a recent neural network system.","The paper proposes a joint model for structure-based news genre classification that identifies one of four commonly used news structures and recognizes a sequence of news elements within the article that define the corresponding news structure. The joint model consistently outperforms its variants that perform two tasks independently, which supports the idea that preserving the two-way dependencies and constraints between a type of news structure and its sequence of news elements enables the model to better predict both of them. The system's predicted news structure type and news elements have improved the performance of text summarization when incorporated into a recent neural network system.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve text summarization performance and to locate key event descriptions of a news story.', 'Who is the target audience?': 'The summaries are for NLP tasks and applications such as text summarization, text segmentation, discourse analysis, information extraction, and text quality assessment.', 'How will the summaries be used?': 'The summaries will be used to recognize both the news structure type of a news article as well as its corresponding news elements, and to improve text summarization performance on news articles of a particular news structure, such as the Kabob structure.'}",['method'],"['Auxiliary Tasks', 'Objective Function']",['News Genre'],['ROUGE'],[''],https://github.com/ZeyuDai/Fine-grained_Structure-based_News_Genre_Categorization,https://aclanthology.org/2021.findings-acl.295,"{'Journalists use different news structures to organize and report news, and recognizing these structures can benefit many NLP tasks and applications.': 'The authors define five news elements and four news structures based on their different ways of selecting and organizing news elements. They also create a dataset with annotated news structures and elements for structure-based news genre categorization.', 'While previous work has conducted news structure classification, it has not attempted to recognize annotated news elements within a news article yet.': 'The authors propose to recognize both the news structure type of a news article and its corresponding news elements using a joint model that learns paragraph and document representations for predicting both a news structure type and a sequence of news element tags for its paragraphs.', 'News articles with the Kabob structure bring additional difficulty to locate the correct paragraphs for extracting summary.': 'The authors use system predicted news structure and news element tags to improve text summarization, especially for news articles with the Kabob structure, which covers roughly 28% of news articles based on the annotated News Genre dataset. They show that incorporating news genre tags as word features into an extractive summarization system improves the ROUGE scores consistently for all four types of news structure genres, with the Kabob structure receiving the largest improvements.'}",supervised,['News'],[]
SP:89be3aba4f4e653563a23228b3c9eede3a4c5483,Bringing Structure into Summaries: a Faceted Summarization Dataset for Long Scientific Documents,ACL,2021,"['Rui Meng', 'Khushboo Thaker', 'Lei Zhang', 'Yue Dong', 'Xingdi Yuan', 'Tong Wang', 'Daqing He']","Faceted summarization provides briefings of a document from different perspectives. Readers can quickly comprehend the main points of a long document with the help of a structured outline. However, little research has been conducted on this subject, partially due to the lack of large-scale faceted summarization datasets. In this study, we present FacetSum, a faceted summarization benchmark built on Emerald journal articles, covering a diverse range of domains. Different from traditional documentsummary pairs, FacetSum provides multiple summaries, each targeted at specific sections of a long document, including the purpose, method, findings, and value. Analyses and empirical results on our dataset reveal the importance of bringing structure into summaries. We believe FacetSum will spur further advances in summarization research and foster the development of NLP systems that can leverage the structured information in both long texts and summaries.","System: The paper discusses faceted summarization, which provides multiple summaries of a long document from different perspectives, each targeting specific sections such as purpose, method, findings, and value. The lack of large-scale faceted summarization datasets has hindered research in this area, but the authors present FacetSum, a benchmark built on Emerald journal articles covering diverse domains. The study's analyses and empirical results highlight the importance of structured summaries, and the authors believe FacetSum will drive further advances in summarization research and NLP systems that can leverage structured information in both long texts and summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense a long piece of text into a short summary without losing salient information.', 'Who is the target audience?': 'The summaries are for readers who want to quickly understand the main points of a scientific publication.', 'How will the summaries be used?': 'The summaries can effectively facilitate comprehension and provide much additional clarity for improved comprehension. They can be used by databases and publishers such as MEDLINE and Emerald.'}","['corpus', 'method']",['Controlled Generation'],['FacetSum'],['ROUGE'],[''],https://github.com/hfthair/emerald_crawler,https://aclanthology.org/2021.acl-short.137,"{'Summaries are often framed as a linear, structure-less sequence of sentences in the flourishing array of summarization studies.': 'The authors postulate that a primary reason for this absence of structure lies in the lack of a high-quality, large-scale dataset with structured summaries. They propose the FacetSum dataset to address this issue.', 'Existing studies in faceted summarization are often conducted with rather limited amount of data that are grossly insufficient to meet today’s ever-growing model capacity.': 'The authors aim to address this issue by providing the FacetSum dataset, which consists of 60,024 scientific articles collected from Emerald journals, each associated with a structured abstract that summarizes the article from distinct aspects including purpose, method, findings, and value.', 'Summaries often lack clarity and fail to provide much additional information for improved comprehension.': 'The authors propose that a well-structured summary, such as the structured abstract, can effectively facilitate comprehension and provide much additional clarity for improved comprehension. They argue that the structure therein has long been adopted by databases and publishers such as MEDLINE and Emerald.', 'Summaries often lose salient information when condensing a long piece of text into a short summary.': 'The authors propose that a well-structured summary, such as the structured abstract, can effectively condense a long piece of text into a short summary without losing salient information. They argue that research has shown that a well-structured summary can effectively facilitate comprehension.'}",supervised,['Scholarly Documents'],"['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:a8fd2ab57a6fdebedde20286cad12242773980c9,Utility of Missing Concepts inQuery-biased Summarization,SIGIR,2021,"['Sheikh Muhammad Sarwar', 'Felipe Moraes', 'Jiepu Jiang', 'James Allan']","Query-biased Summarization (QBS) aims to produce a querydependent summary of a retrieved document to reduce the human effort for inspecting the full-text content. Typical summarization approaches extract document snippets that overlap with the query and show them to searchers. Such QBS methods show relevant information in a document but do not inform searchers what is missing. Our study focuses on reducing user effort in finding relevant documents by exposing the information in the query that is missing in the retrieved results. We use a classical approach, DSPApprox, to find terms or phrases relevant to a query. Then, we identify which terms or phrases are missing in a document, present them in a search interface, and ask crowd workers to judge document relevance based on snippets and missing information. Experimental results show both benefits and limitations of our method compared with traditional ones that only show relevant snippets.","The paper discusses a new approach to query-biased summarization (QBS) that aims to reduce user effort in finding relevant documents. The approach identifies missing information in a retrieved document and presents it in a search interface for crowd workers to judge document relevance based on snippets and missing information. The method, called DSPApprox, uses classical approaches to find terms or phrases relevant to a query. The experimental results show both benefits and limitations of the method compared with traditional ones that only show relevant snippets.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to present the content adaptively for a search query.', 'Who is the target audience?': 'The summaries are for searchers who view the summary of each search result first and then click on the result link to access the full content.', 'How will the summaries be used?': 'The summaries will be used to help searchers estimate the relevance of a document and make better click decisions.'}",['analysis'],['Unit Selection'],['Aquaint'],"['ROUGE', 'Set-Pairwise-ROUGE']",['Relevance'],,https://doi.org/10.1145/3404835.3463121,"{'Search result snippets do not always help a user make the correct click decisions.': 'The authors propose to design the summary more critically by displaying the relevant concepts that are missing in the result, in addition to showing the matched query terms in a document.', 'Commercial search engines such as Google show missing query terms but not the missing concepts associated with a search query.': 'The authors design and evaluate a technique for generating and presenting missing concepts in QBS using a popular query topic modeling method DSPApprox to learn query-related unigrams and phrases and then compare them to a document’s content to identify missing concepts.', 'There is no published study that provides models to generate missing concepts and evaluates their effectiveness for helping users’ click decisions.': 'The authors conduct a crowd-sourcing user study to evaluate query-biased summaries, with and without showing the missing terms, and present their method, experiment, and findings in the article.'}",unsupervised,['News'],[]
SP:d7cf9872fe3899cd29158f122c1e402a807a474a,LenAtten: An Effective Length Controlling Unit For Text Summarization,ACL,2021,"['Zhongyi Yu', 'Zhenghao Wu', 'Hao Zheng', 'Zhe XuanYuan', 'Jefferson Fong', 'Weifeng Su']","Fixed length summarization aims at generating summaries with a preset number of words or characters. Most recent researches incorporate length information with word embeddings as the input to the recurrent decoding unit, causing a compromise between length controllability and summary quality. In this work, we present an effective length controlling unit Length Attention (LenAtten) to break this trade-off. Experimental results show that LenAtten not only brings improvements in length controllability and ROGUE scores but also has great generalization ability. In the task of generating a summary with the target length, our model is 732 times better than the bestperforming length controllable summarizer in length controllability on the CNN/Daily Mail dataset. 1","The paper discusses fixed length summarization and the trade-off between length controllability and summary quality. The authors introduce a new length controlling unit called LenAtten, which improves length controllability and ROGUE scores while maintaining great generalization ability. The experimental results show that their model is significantly better than the best-performing length controllable summarizer on the CNN/Daily Mail dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a short and coherent summary while preserving the main ideas of the original documents.', 'Who is the target audience?': 'The summaries are for users who want to get customizable summaries by setting different desired lengths.', 'How will the summaries be used?': 'The summaries can be used to get universal user experiences on multiple platforms and devices, reduce post-editing time for news editors, and further improve summary quality.'}",['method'],"['Controlled Generation', 'Input Encoding']",['CNN/DailyMail'],['SUM-QE'],[''],https://github.com/X-AISIG/LenAtten,https://aclanthology.org/2021.findings-acl.31,"{'Previous studies on fixed length text summarization (FLS) have limited success in controlling the length of output summaries while maintaining high summary quality.': 'The authors propose a novel length controlling unit called Length Attention (LenAtten) that can generate high-quality summaries with a preset number of characters, successfully breaking the trade-off between length controllability and summary quality.', 'FLS is a rising research topic required in many scenarios, such as generating titles and abstracts for news articles with different numbers of characters, but manual rewriting of summaries is time-consuming.': 'FLS can automatically generate required summaries by simply inputting the desired output length, which can help news editors to reduce post-editing time and further improve summary quality.', 'Recent researches in FLS apply length information to either the decoder or the optimization objective function, but these systems have to make a compromise between length controllability and summary quality.': 'LenAtten is a novel length controlling unit with great generalization capability that can generate high-quality summaries with a preset number of characters, breaking the trade-off between length controllability and summary quality. Experimental results show that the length controllability of the proposed method is the new state-of-the-art on the examined datasets.'}",supervised,['News'],['robust-evaluation-methods']
SP:680914a5b2ff84afec53f5e0fcc162761ba7aeb8,Word Graph Guided Summarization for Radiology Findings,ACL,2021,"['Jinpeng Hu', 'Jianling Li', 'Zhihong Chen', 'Yaling Shen', 'Yan Song', 'Xiang Wan', 'Tsung-Hui Chang']","Radiology reports play a critical role in communicating medical findings to physicians. In each report, the impression section summarizes essential radiology findings. In clinical practice, writing impression is highly demanded yet time-consuming and prone to errors for radiologists. Therefore, automatic impression generation has emerged as an attractive research direction to facilitate such clinical practice. Existing studies mainly focused on introducing salient word information to the general text summarization framework to guide the selection of the key content in radiology findings. However, for this task, a model needs not only capture the important words in findings but also accurately describe their relations so as to generate highquality impressions. In this paper, we propose a novel method for automatic impression generation, where a word graph is constructed from the findings to record the critical words and their relations, then a Word Graph guided Summarization model (WGSUM) is designed to generate impressions with the help of the word graph. Experimental results on two datasets, OPENI and MIMIC-CXR, confirm the validity and effectiveness of our proposed approach, where the state-of-the-art results are achieved on both datasets. Further experiments are also conducted to analyze the impact of different graph designs to the performance of our method.1","The paper discusses the challenges faced by radiologists in writing impression sections of radiology reports, which summarize essential findings and are critical for communicating medical information to physicians. Automatic impression generation has emerged as an attractive research direction to facilitate this clinical practice. The paper proposes a novel method for automatic impression generation, where a word graph is constructed from the findings to record critical words and their relations, and a Word Graph guided Summarization model (WGSUM) is designed to generate impressions with the help of the word graph. Experimental results on two datasets confirm the validity and effectiveness of the proposed approach, achieving state-of-the-art results. Further experiments are conducted to analyze the impact of different graph designs on the performance of the method.","{'What is the purpose of the summaries?': 'The authors are generating summaries of radiology reports to ease the workload of radiologists by summarizing the most critical observations in the impression section.', 'Who is the target audience?': 'The summaries are for clinicians who need to quickly locate the most prominent observations in radiology reports.', 'How will the summaries be used?': 'The summaries will be used to improve the automatic impression generation (AIG) process, which is an essential part of delivering critical findings to clinicians.'}",['method'],['Input Encoding'],"['OPENI', 'MIMIC-CXR']",['ROUGE'],"['Accuracy', 'Completeness', 'Conciseness', 'Readability']",,https://aclanthology.org/2021.findings-acl.441,"{'Previous methods for automatic impression generation (AIG) mainly focus on identifying important words in the findings section, but less attention is paid to leveraging the relation information among them.': 'The authors propose to enhance AIG via a summarization model integrated with a word graph by leveraging salient words and their relations in the findings section. The word graph is constructed by identifying important words and building connections among them via different typed relations.', 'The importance of recognizing the relations among words in the findings section is crucial for generating accurate impressions.': 'The authors propose a Word Graph guided Summarization model (WGSUM) that integrates information from the word graph into the backbone decoder (e.g., LSTM or Transformer) to enrich the decoder input as extra knowledge and guide the decoder to update its hidden states.', 'The performance of previous AIG methods is not optimal on benchmark datasets.': 'Experimental results show that WGSUM outperforms all baselines on two benchmark datasets, achieving state-of-the-art performance in comparison with previous studies. Further analyses investigate how different types of edges in the graph affect the performance of the proposed model.'}",supervised,['Medical Reports'],[]
SP:d883bec1badaf3fcd4b496c370e6e88c76db9a2d,PASS: Perturb-and-Select Summarizer for Product Reviews,ACL,2021,"['Nadav Oved', 'Ran Levy']","The product reviews summarization task aims to automatically produce a short summary for a set of reviews of a given product. Such summaries are expected to aggregate a range of different opinions in a concise, coherent and informative manner. This challenging task gives rise to two shortcomings in existing work. First, summarizers tend to favor generic content that appears in reviews for many different products, resulting in template-like, less informative summaries. Second, as reviewers often disagree on the pros and cons of a given product, summarizers sometimes yield inconsistent, self-contradicting summaries. We propose the PASS system (Perturb-and-Select Summarizer) that employs a large pre-trained Transformer-based model (T5 in our case), which follows a few-shot fine-tuning scheme. A key component of the PASS system relies on applying systematic perturbations to the model’s input during inference, which allows it to generate multiple different summaries per product. We develop a method for ranking these summaries according to desired criteria, coherence in our case, enabling our system to almost entirely avoid the problem of selfcontradiction. We compare our system against strong baselines on publicly available datasets, and show that it produces summaries which are more informative, diverse and coherent.1","The paper discusses the challenges of automatically producing concise and informative summaries for product reviews, including the tendency for summarizers to favor generic content and the potential for self-contradicting summaries due to reviewer disagreements. The authors propose the PASS system, which uses a pre-trained Transformer-based model and applies systematic perturbations to generate multiple summaries per product. The system also includes a method for ranking the summaries based on coherence. The authors compare their system to other methods and show that it produces more informative, diverse, and coherent summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of product reviews to address the challenge of surfacing opinions from customer reviews in a concise yet reliable fashion.', 'Who is the target audience?': 'The summaries are for customers who are shopping online and want to quickly understand the opinions of other customers about a product.', 'How will the summaries be used?': 'The summaries will be used to help customers make informed purchasing decisions by providing them with a concise and reliable summary of the opinions of other customers about a product.'}",['method'],"['External Knowledge', 'Controlled Generation']",['Amazon Product Reviews'],['ROUGE'],"['Informativeness', 'Coherence', 'Relevance']",,https://aclanthology.org/2021.acl-long.30,"{'Existing product reviews summarizers tend to mix generic statements with informative content, and summaries may repeat themselves across products.': 'Use generic content sparingly and devise the Set-Pairwise-ROUGE metric to estimate the similarity between summaries generated for different products, and propose the notion of cross product diversity of summaries as CPDiversity.', 'Factual consistency is undefined in the context of product reviews summarization, and self-contradicting summaries may be generated due to reviews disagreeing on some product aspects or even disagreeing entirely.': 'Measure the self-consistency of the summary instead of factual consistency, and assume that a summary has to convey the majority opinion of the reviews and do so in a self-consistent manner.', 'Low CPDiversity and self-inconsistency in existing product reviews summarizers.': ""Propose a method that leverages strong pre-trained models for product reviews summarization in a few-shot setup, employ an input perturbation method that drops k reviews out of the input and concatenates the remaining reviews in random order, and cast the original summary generation problem as a ranking problem. Train a more general coherence summary ranker using human annotated coherence scores and select the top ranked summary as the system's output.""}",supervised,['Reviews'],['hallucinations-in-the-generated-summaries']
SP:d32f06b85080a652d8a030c7452fcce937834ff5,Decision-Focused Summarization,EMNLP,2021,"['Chao-Chun Hsu', 'Chenhao Tan']","Relevance in summarization is typically defined based on textual information alone, without incorporating insights about a particular decision. As a result, to support risk analysis of pancreatic cancer, summaries of medical notes may include irrelevant information such as a knee injury. We propose a novel problem, decision-focused summarization, where the goal is to summarize relevant information for a decision. We leverage a predictive model that makes the decision based on the full text to provide valuable insights on how a decision can be inferred from text. To build a summary, we then select representative sentences that lead to similar model decisions as using the full text while accounting for textual non-redundancy. To evaluate our method (DecSum), we build a testbed where the task is to summarize the first ten reviews of a restaurant in support of predicting its future rating on Yelp. DecSum substantially outperforms text-only summarization methods and model-based explanation methods in decision faithfulness and representativeness. We further demonstrate that DecSum is the only method that enables humans to outperform random chance in predicting which restaurant will be better rated in the future.","The paper proposes a new approach to summarization called decision-focused summarization, which aims to summarize relevant information for a particular decision. They use a predictive model to make the decision based on the full text and then select representative sentences that lead to similar model decisions while accounting for non-redundancy. The method, called DecSum, is evaluated on a testbed where the task is to summarize restaurant reviews to predict future ratings on Yelp. DecSum outperforms other summarization methods in decision faithfulness and representativeness and enables humans to outperform random chance in predicting which restaurant will be better rated in the future.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to potentially support human decision making by identifying the most relevant information for these decisions.', 'Who is the target audience?': 'The summaries are for doctors, investors, and other individuals who need to make decisions based on a large amount of information.', 'How will the summaries be used?': 'The summaries will be used to help individuals make more informed decisions by providing them with the most relevant information from the input documents.'}",['method'],"['Controlled Generation', 'Auxiliary Tasks']",['Yelp Reviews'],"['ROUGE', 'Novel n-grams']",['Usefulness'],https://github.com/ChicagoHAI/decsum,https://aclanthology.org/2021.emnlp-main.10,"{'Typical summarization methods in NLP define relevance based on the textual information exclusively, which can be counter-productive for decision making.': 'The authors propose leveraging a supervised decision model for extractive decision-focused summarization, which can encode valuable insights about how the decision can be inferred from text. They also propose novel desiderata for decision-focused summarization, including decision faithfulness and decision representativeness, in addition to textual non-redundancy.', 'Text-only summarization methods and model-based explanation methods do not aim to select sentences that represent the whole decision distribution.': 'The authors design a method that optimizes decision representativeness, in addition to other desiderata, to select sentences that are representative of the overall decision distribution.', 'It is challenging to evaluate the effectiveness of the proposed approach in supporting human decision making.': 'The authors formulate a future rating prediction task on Yelp, inspired by investment decisions, and show that their proposed approach (DecSum) outperforms text-only summarization methods and model-based explanation methods in decision faithfulness and decision representativeness. Human evaluation further shows that DecSum is the only method that enables humans to statistically outperform random chance in predicting which restaurant will be rated better in the future.'}",supervised,['Reviews'],[]
SP:0c9792432a08fd5e58ecf135d6e27911cb8f73fb,Enhancing Scientific Papers Summarization with Citation Graph,AAAI,2021,"['Chenxin An', 'Ming Zhong', 'Yiran Chen', 'Danqing Wang', 'Xipeng Qiu', 'Xuanjing Huang']","Previous work for text summarization in scientific domain mainly focused on the content of the input document, but seldom considering its citation network. However, scientific papers are full of uncommon domain-specific terms, making it almost impossible for the model to understand its true meaning without the help of the relevant research community. In this paper, we redefine the task of scientific papers summarization by utilizing their citation graph and propose a citation graph-based summarization model (CGSUM) which can incorporate the information of both the source paper and its references. In addition, we construct a novel scientific papers summarization dataset Semantic Scholar Network (SSN) which contains 141K research papers in different domains and 661K citation relationships. The entire dataset constitutes a large connected citation graph. Extensive experiments show that our model can achieve competitive performance when compared with the pretrained models even with a simple architecture. The results also indicates the citation graph is crucial to better understand the content of papers and generate high-quality summaries.",The paper proposes a new approach to scientific paper summarization that utilizes the citation network of the papers. The authors argue that previous approaches have focused too much on the content of the papers and have not taken into account the importance of the citation network. They introduce a new model called CGSUM that incorporates both the source paper and its references. They also construct a new dataset called Semantic Scholar Network (SSN) that contains 141K research papers and 661K citation relationships. The experiments show that the proposed model outperforms pretrained models even with a simple architecture and that the citation graph is crucial for generating high-quality summaries.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically compress a document into a shorter version while preserving a concise description of the content.', 'Who is the target audience?': 'The summaries are for researchers who need to quickly understand the content of scientific papers.', 'How will the summaries be used?': 'The summaries will be used to assist researchers in quickly understanding the content of scientific papers, especially in fields where papers are long and complex.'}",['method'],['External Knowledge'],['SSN'],['ROUGE'],[''],,https://ojs.aaai.org/index.php/AAAI/article/view/17482,"{'Generating a good abstract for a scientific paper is a challenging task, especially for beginner researchers, due to the length and complexity of scientific papers.': ""The authors propose to augment the task of scientific paper summarization with the use of citation graphs, which can assist in generating high-quality summaries. They construct a large-scale summarization dataset with citation relationships between papers and propose a citation graph-based summarization model that incorporates the document and relevant citation graph when generating summaries. They also introduce a novel ROUGE credit method to instruct the model on how to write summaries with the help of other papers' abstracts in the same research community."", 'Previous methods for generating abstracts for scientific papers do not utilize the information of references, which can be helpful in summarizing scientific papers.': 'The authors propose to use the information of reference papers to help generate better summaries for scientific papers. They highlight the importance of the citation graph and believe that it can assist in generating high-quality summaries. They construct a large-scale summarization dataset with citation relationships between papers and propose a citation graph-based summarization model that incorporates the document and relevant citation graph when generating summaries.', 'Current large-scale scientific summarization datasets do not provide citation relationships between papers.': 'The authors construct a scientific papers summarization dataset Semantic Scholar Network (SSN) which contains 141K papers and 661K citation relationships extracted from the Semantic Scholar Open Research Corpus (S2ORC) (Lo et al. 2020). Their dataset is a huge connected citation graph, and each paper has class labels denoting its research field. They divide the enhanced summarization task into 2 settings: (1) transductive: during training, models can access to all the nodes and edges in the whole dataset including papers (excluding abstracts) in the test set. (2) inductive: papers in the test set are from a totally new graph which means all test nodes cannot be used during training.', 'The same expression always has different writing styles in different papers, even some academic definitions that do not appear in the original text can be found in other papers.': ""The authors propose to encourage models to learn from reference papers, which can help them understand the true meaning of concepts and better understand the entire research community. They construct a citation graph-based summarization model that incorporates the document and relevant citation graph when generating summaries. They also introduce a novel ROUGE credit method to instruct the model on how to write summaries with the help of other papers' abstracts in the same research community.""}",supervised,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'lack-of-suitable-training-data']"
SP:c667e134b7e4c314ec10bca832a4887ca547632d,MIRANEWS: Dataset and Benchmarks for Multi-Resource-Assisted News Summarization,EMNLP,2021,"['Xinnuo Xu', 'Ondřej Dušek', 'Shashi Narayan', 'Verena Rieser', 'Ioannis Konstas']","One of the most challenging aspects of current single-document news summarization is that the summary often contains ‘extrinsic hallucinations’, i.e., facts that are not present in the source document, which are often derived via world knowledge. This causes summarization systems to act more like open-ended language models tending to hallucinate facts that are erroneous. In this paper, we mitigate this problem with the help of multiple supplementary resource documents assisting the task. We present a new dataset MIRANEWS and benchmark existing summarization models.1 In contrast to multi-document summarization, which addresses multiple events from several source documents, we still aim at generating a summary for a single document. We show via data analysis that it’s not only the models which are to blame: more than 27% of facts mentioned in the gold summaries of MIRANEWS are better grounded on assisting documents than in the main source articles. An error analysis of generated summaries from pretrained models fine-tuned on MIRANEWS reveals that this has an even bigger effects on models: assisted summarization reduces 55% of hallucinations when compared to single-document summarization models trained on the main article only.","The paper discusses the problem of 'extrinsic hallucinations' in single-document news summarization, where the summary contains facts not present in the source document. The authors propose using multiple supplementary resource documents to mitigate this problem and present a new dataset called MIRANEWS to benchmark existing summarization models. They show that more than 27% of facts mentioned in the gold summaries of MIRANEWS are better grounded on assisting documents than in the main source articles. The authors also conduct an error analysis of generated summaries from pretrained models fine-tuned on MIRANEWS, revealing that assisted summarization reduces 55% of hallucinations when compared to single-document summarization models trained on the main article only.","{'What is the purpose of the summaries?': 'The authors are generating summaries of news articles to tackle the problem of extrinsic hallucinations in current abstractive summarization models.', 'Who is the target audience?': 'The summaries are for readers who want a brief overview of a news article.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the main points of a news article without having to read the entire article.'}",['corpus'],['External Knowledge'],['MIRANEWS'],['ROUGE'],[''],,https://aclanthology.org/2021.findings-emnlp.133,"{'Current research on abstractive summarization is focused on single-document news summarization, which leads to extrinsic hallucinations in the generated summaries.': 'The authors introduce a new task, Multi-Resource-Assisted News Summarization, and a novel dataset (MIRANEWS) that includes multiple assisting news articles from different news resources for a document-summary pair. They also introduce new referenceless metrics to evaluate extrinsic hallucinations and confirm that introducing assisting documents offers better grounding to more than 27% of facts mentioned in the reference summaries.', 'Human-written summaries contain up to 36% external facts which are not faithful, and facts which are present are often re-phrased or shortened in the summary in ways which require world knowledge.': 'The authors tackle the problem of extrinsic hallucinations by incorporating background knowledge within a generated summary through the use of assisting documents from alternative news resources covering the same news event. This approach complements the background knowledge in an easier to learn, more direct, and explainable way.', 'Summarization models are agnostic to data divergence issues between the source and target texts, leading to open-ended language models and extrinsic hallucinations.': 'The authors show that modeling assisting documents effectively introduces external facts in the summaries that are grounded on the assisting documents, resulting in 55% less counterfactual hallucinations than SDS systems.'}",supervised,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:55ed0c44a653362d932984526d6c8104de4d9aec,Graph Enhanced Contrastive Learning for Radiology Findings Summarization,ACL,2022,"['Jinpeng Hu', 'Zhuo Li', 'Zhihong Chen', 'Zhen Li', 'Xiang Wan', 'Tsung-Hui Chang']","The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is timeconsuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder, and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on OpenI and MIMIC-CXR confirm the effectiveness of our proposed method.1","The paper proposes a unified framework for automatic impression generation in radiology reports that leverages both extra knowledge and the original findings in an integrated way. The proposed method encodes each input finding using a text encoder and constructs a graph through its entities and dependency tree. A graph encoder is then adopted to model relation information in the constructed graph. Finally, contrastive learning is introduced to emphasize key words in the findings. The experimental results on OpenI and MIMIC-CXR confirm the effectiveness of the proposed method.","{'What is the purpose of the summaries?': 'The authors are generating summaries of radiology reports to provide a quick and concise overview of the most critical observations.', 'Who is the target audience?': 'The summaries are for communication between radiologists and physicians.', 'How will the summaries be used?': 'The summaries will be used to facilitate communication and decision-making between radiologists and physicians.'}",['method'],"['External Knowledge', 'Input Encoding']","['OPENI', 'MIMIC-CXR']","['ROUGE', 'Jaccard Similarity', 'Exact Matches']","['Accuracy', 'Completeness', 'Conciseness', 'Readability']",https://github.com/jinpeng01/AIG_CL,https://aclanthology.org/2022.acl-long.320,"{'The process of summarizing findings in radiology reports is time-consuming and prone to errors for inexperienced radiologists.': 'The authors propose automatic impression generation (AIG) as a solution to this problem.', 'Existing AIG methods only leverage extra knowledge and findings separately, relying heavily on the quality of extra knowledge, and not exploring the further relationships between extra knowledge and findings.': 'The authors propose a unified framework that integrates both findings and extra knowledge in an appropriate way to leverage critical information (i.e., key words and their relations).', 'The relation information among key words in findings is not modeled in existing methods.': 'The authors propose a graph encoder (e.g., graph neural networks) to model the relation information among key words.', 'The importance of key words in findings is not emphasized in existing methods.': 'The authors introduce contrastive learning to emphasize key words in findings, mapping positive samples (constructed by masking non-key words) closer and pushing apart negative ones (constructed by masking key words).', 'Existing AIG methods do not achieve state-of-the-art results.': ""The authors' proposed approach achieves state-of-the-art results compared to existing studies on two prevailing datasets (i.e., OpenI and MIMIC-CXR).""}",supervised,['Medical Reports'],[]
SP:1316032e285662e8edb775ff4c3a2248d46b57d6,Comparative Opinion Summarization via Collaborative Decoding,ACL,2022,"['Hayate Isoä', 'Xiaolan Wangä', 'Stefanos AngelidisÅ', 'Yoshihiko Suharaä']","Opinion summarization focuses on generating summaries that reflect popular subjective information expressed in multiple online reviews. While generated summaries offer general and concise information about a particular hotel or product, the information may be insufficient to help the user compare multiple different choices. Thus, the user may still struggle with the question “Which one should I pick?” In this paper, we propose the comparative opinion summarization task, which aims at generating two contrastive summaries and one common summary from two different candidate sets of reviews. We develop a comparative summarization framework COCOSUM, which consists of two base summarization models that jointly generate contrastive and common summaries. Experimental results on a newly created benchmark COCOTRIP show that COCOSUM can produce higher-quality contrastive and common summaries than stateof-the-art opinion summarization models. The dataset and code are available at https:// github.com/megagonlabs/cocosum.","The paper proposes a new task called comparative opinion summarization, which generates two contrastive summaries and one common summary from two different sets of reviews to help users compare multiple choices. The authors develop a framework called COCOSUM, which consists of two base summarization models that jointly generate the summaries. Experimental results show that COCOSUM produces higher-quality summaries than existing opinion summarization models. The dataset and code are available for use.","{'What is the purpose of the summaries?': 'The authors are generating summaries of customer reviews to help users with decision-making in various domains.', 'Who is the target audience?': 'The summaries are for users who need to compare a few choices in depth by carefully reading the reviews to make a final decision.', 'How will the summaries be used?': 'The summaries will be used to generate two contrastive summaries and one common summary from two sets of reviews about two entities, so that the user can easily understand distinctive and common opinions about multiple entities.'}",['method'],"['Objective Function', 'Controlled Generation']",['COCOTRIP'],['ROUGE'],"['Content Overlap', 'Faithfulness', 'Coherence', 'Informativeness', 'Non-redundancy']",https://github.com/megagonlabs/cocosum,https://aclanthology.org/2022.findings-acl.261,"{'It is time-consuming and difficult for users to detect differences and similarities between multiple candidates based on scattered information in different reviews.': 'The authors propose the task of comparative opinion summarization, which generates two contrastive summaries and one common summary from two sets of reviews about two entities. This allows users to easily understand distinctive and common opinions about multiple entities.', 'Existing opinion summarization techniques are designed to generate a single-entity opinion summary that reflects popular opinions for each entity, without taking into account contrastive and common opinions that are uniquely (commonly) mentioned in each entity.': 'The authors develop a comparative opinion summarization framework COCOSUM, which consists of two base summarization models for contrastive and common opinion summary generation. This framework employs a novel Collaborative Decoding (Co-decoding) algorithm that takes two review sets as input to compare and contrast the token probability distributions of the models to generate more distinctive summaries.', 'The model has to correctly distinguish what contrastive and common opinions from input reviews of two entities are.': 'The authors address this issue by developing COCOSUM, which implements a novel Co-decoding algorithm that facilitates generating distinctive and entity-pair specific summaries by aggregating the token probability distributions of the models.', 'There is a lack of a benchmark for comparative opinion summarization.': 'The authors create and release a comparative opinion summarization benchmark COCOTRIP that contains manually written reference summaries for 48 entity pairs.'}",supervised,['Reviews'],['robust-evaluation-methods']
SP:be17a09eb26a21734119037546fdd17b5e97d55e,Focus on the Action: Learning to Highlight and Summarize Jointly for Email To-Do Items Summarization,ACL,2022,"['Kexun Zhang', 'Jiaao Chen', 'Diyi Yang']","Automatic email to-do item generation is the task of generating to-do items from a given email to help people overview emails and schedule daily work. Different from prior research on email summarization, to-do item generation focuses on generating action mentions to provide more structured summaries of email text. Prior work either requires large amount of annotation for key sentences with potential actions or fails to pay attention to nuanced actions from these unstructured emails, and thus often lead to unfaithful summaries. To fill these gaps, we propose a simple and effective learning to highlight and summarize framework (LHS) to learn to identify the most salient text and actions, and incorporate these structured representations to generate more faithful to-do items. Experiments show that our LHS model outperforms the baselines and achieves the state-ofthe-art performance in terms of both quantitative evaluation and human judgement. We also discussed specific challenges that current models faced with email to-do summarization.","The paper discusses the task of automatic email to-do item generation, which involves generating action mentions from emails to help people schedule their daily work. The authors propose a learning to highlight and summarize framework (LHS) to identify the most salient text and actions and generate more faithful to-do items. The LHS model outperforms baseline models and achieves state-of-the-art performance in both quantitative evaluation and human judgement. The paper also highlights specific challenges that current models face with email to-do summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of emails to help people overview overwhelming numbers of emails they receive every day and schedule their daily work.', 'Who is the target audience?': 'The summaries are for people who receive a large number of emails and need help organizing their tasks.', 'How will the summaries be used?': 'The summaries will be used to provide more structured summaries from email communications, which requires identifying important tasks to be performed among all the action items and aligning them with the right users.'}",['method'],['Unit Selection'],['SmartToDo'],"['ROUGE', 'BERTScore', 'SARI', 'Readability', 'Precision', 'Recall', 'F1 Score']","['Factualness', 'Succintness', 'Informativeness']",,https://aclanthology.org/2022.findings-acl.323,"{'Extra annotations are usually needed for the first stage to learn the classifiers which require extra cost/expertise and are often hard to obtain in low-resourced settings.': 'The authors propose a learning to highlight and summarize (LHS) model that learns the important sentence identification module and to-do summarization module concurrently in an end-to-end manner to focus on the most salient actions.', 'Any information loss in the identification stage might lead to bigger noises in the to-do generation stage.': 'The LHS model uses an unsupervised approach to extract the salient sentences and actions by comparing them to the ground truth to-do. It also extracts action triplets from the text and constructs an action graph to encode the structural information in the unstructured text.', 'Directly extracting actions from less-structured text usually leads to unfaithful summaries that mismatch the relations between users and actions.': 'The LHS model incorporates structured action representations to generate more faithful todos. During training, the model learns to generate to-do items and identify highlights jointly. During prediction, the model utilizes the predicted highlights by modifying the attention distribution accordingly.', 'Extrinsic hallucinations involving named entities are common in automatic summarization tasks.': 'The authors propose a perturbation technique based on person names to reduce the extrinsic hallucinations.'}",supervised,['Emails'],[]
SP:76598e1bf9ba7e2a821b8698d92debd30c42a99d,Semantic Overlap Summarization among Multiple Alternative Narratives: An Exploratory Study,COLING,2022,"['Naman Bansal', 'Mousumi Akter', 'Shubhra Kanti Karmaker']","In this paper, we introduce an important yet relatively unexplored NLP task called Semantic Overlap Summarization (SOS), which entails generating a single summary from multiple alternative narratives which can convey the common information provided by those narratives. As no benchmark dataset is readily available for this task, we created one by collecting 2, 925 alternative narrative pairs from the web and then, went through the tedious process of manually creating 411 different reference summaries by engaging human annotators. As a way to evaluate this novel task, we first conducted a systematic study by borrowing the popular ROUGE metric from text-summarization literature and discovered that ROUGE is not suitable for our task. Subsequently, we conducted further human annotations to create 200 document-level and 1, 518 sentence-level ground-truth overlap labels. Our experiments show that the sentencewise annotation technique with three overlap labels, i.e., {Absent (A), Partially-Present (PP), and Present (P)}, yields a higher correlation with human judgment and higher inter-rater agreement compared to the ROUGE metric.",The paper introduces a new NLP task called Semantic Overlap Summarization (SOS) which involves generating a summary from multiple alternative narratives. The authors created a benchmark dataset by collecting alternative narrative pairs and manually creating reference summaries. They found that the popular ROUGE metric is not suitable for evaluating this task and instead used a sentencewise annotation technique with three overlap labels. Their experiments showed that this technique yielded higher correlation with human judgment and higher inter-rater agreement compared to the ROUGE metric.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of multiple alternative narratives with different perspectives to address the pressing need for automatic summarization in the information explosion era.', 'Who is the target audience?': 'The summaries are for anyone who needs to digest multinarratives at scale and speed, including those in education, health, business intelligence, content analysis, and privacy domains.', 'How will the summaries be used?': 'The summaries will be used to convey the common information provided by multiple alternate narratives by cross-verifying their information contents against each other. They will also be used for research on the Semantic Overlap Summarization (SOS) task, for which the authors have created and released the first benchmark dataset.'}",['corpus'],"['Data Augmentation', 'Controlled Generation']",['AllSides'],['ROUGE'],[''],,https://aclanthology.org/2022.coling-1.541,"{'There is no current baseline method or an existing dataset that exactly matches the SOS task.': 'The authors formally introduce Semantic Overlap Summarization (SOS) as a new NLP task and create a benchmark dataset consisting of 2,925 alternative narrative pairs for facilitating research on the SOS task.', 'It is unclear which evaluation metric is suitable for properly evaluating the SOS task.': 'The authors experiment with ROUGE, a widely popular metric for evaluating text summarization tasks, and demonstrate that it is not suitable for the evaluation of the SOS task. They also conduct further human experiments, which show that sentence-level evaluation is the proper way to evaluate the SOS task.', 'The authors need to create ground-truth reference summaries and overlap labels for the benchmark dataset.': 'The authors manually create 411 different ground-truth reference summaries and conduct further human annotations to create 200 document-level and 1,518 sentence-level ground-truth overlap labels to construct the benchmark dataset.'}",supervised,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:211dd747f1308dd1b8b3b0ded0f6c25597b97e16,Generation of Patient After-Visit Summaries to Support Physicians,COLING,2022,"['Pengshan Cai', 'Fei Liu', 'Adarsha Bajracharya', 'Joe Sills', 'Alok Kapoor', 'Weisong Liu', 'Dan Berlowitz', 'David Levy', 'Richeek Pradhan', 'Hong Yu']","An after-visit summary (AVS) is a summary note given to patients after their clinical visit. It recaps what happened during their clinical visit and guides patients’ disease self-management. Studies have shown that a majority of patients found after-visit summaries useful. However, many physicians face excessive workloads and do not have time to write clear and informative summaries. In this paper, we study the problem of automatic generation of after-visit summaries and examine whether those summaries can convey the gist of clinical visits. We report our findings on a new clinical dataset that contains a large number of electronic health record (EHR) notes and their associated summaries. Our results suggest that generation of lay language after-visit summaries remains a challenging task. Crucially, we introduce a feedback mechanism that alerts physicians when an automatic summary fails to capture the important details of the clinical notes or when it contains hallucinated facts that are potentially detrimental to the summary quality. Automatic and human evaluation demonstrates the effectiveness of our approach in providing writing feedback and supporting physicians.1","The paper discusses the problem of physicians not having enough time to write clear and informative after-visit summaries for patients, and explores the possibility of using automatic generation of summaries. The study uses a clinical dataset to examine whether automatic summaries can effectively convey the important details of clinical visits. The results suggest that generating lay language after-visit summaries is still a challenging task, but a feedback mechanism is introduced to alert physicians when automatic summaries fail to capture important details or contain potentially detrimental information. Automatic and human evaluation shows the effectiveness of this approach in providing writing feedback and supporting physicians.","{'What is the purpose of the summaries?': 'The authors are generating summaries of clinical visits to help patients understand their visits and manage their diseases.', 'Who is the target audience?': 'The summaries are for patients who have limited health literacy and may not understand their clinical visits.', 'How will the summaries be used?': 'The summaries will be used to provide patients with concise and easy-to-read information about their clinical visits, helping them to better manage their health. The authors propose an error alerting mechanism to detect and correct errors in the summaries, allowing physicians to edit or correct system-generated summaries.'}",['method'],['Unit Selection'],['MIMIC-III'],"['ROUGE', 'BERTScore', 'SARI']","['Adequacy', 'Faithfulness', 'Readability', 'Ease of Revision']",https://github.com/pengshancai/AVS_gen,https://aclanthology.org/2022.coling-1.544,"{'Many patients do not understand their clinical visits.': 'Automatic generation of after-visit summaries to summarize patients’ clinical visits and help their disease self-management.', 'After-visit summaries frequently contain missing content and hallucinated content.': 'Build systems to facilitate detection and correction of those types of errors, allowing physicians to correct or edit system generated summaries. A novel alerting mechanism is proposed to report errors, including missing medical events and hallucinations.', 'Physicians face excessive workloads and do not have time to complete the summaries in a timely manner.': 'Automatic generation of after-visit summaries to unburden physicians with complex information workflows.', 'Existing automatic metrics are not adequate for evaluating the quality of generated AVS.': 'Conduct a qualitative assessment of system outputs with medical practitioners.', 'Patients with limited health literacy may struggle to understand medical terminology.': 'Generate after-visit summaries in lay person language that is easy for patients to read and comprehend.'}",supervised,['Medical Reports'],"['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:2468b8772fa721c2be25659521dd537f38f77476,ENTSUM: A Data Set for Entity-Centric Summarization,ACL,2022,"['Mounica Maddela', 'Mayank Kulkarni']","Controllable summarization aims to provide summaries that take into account userspecified aspects and preferences to better assist them with their information need, as opposed to the standard summarization setup which build a single generic summary of a document. We introduce a human-annotated data set (ENTSUM) for controllable summarization with a focus on named entities as the aspects to control. We conduct an extensive quantitative analysis to motivate the task of entity-centric summarization and show that existing methods for controllable summarization fail to generate entity-centric summaries. We propose extensions to state-of-the-art summarization approaches that achieve substantially better results on our data set. Our analysis and results show the challenging nature of this task and of the proposed data set.12","The paper discusses controllable summarization, which aims to provide summaries that take into account user-specified aspects and preferences. The authors introduce a human-annotated data set (ENTSUM) for controllable summarization with a focus on named entities as the aspects to control. They conduct an extensive analysis and show that existing methods for controllable summarization fail to generate entity-centric summaries. The authors propose extensions to state-of-the-art summarization approaches that achieve substantially better results on their data set. The paper highlights the challenging nature of this task and the proposed data set.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to extract key information from a large document and present it to the user with the role of assisting them to digest the core information in the document faster and more easily.', 'Who is the target audience?': 'The summaries are for readers of the document who have distinct information needs.', 'How will the summaries be used?': 'The summaries will be used to enable the wide-spread usability of summarization technology and to facilitate benchmarking and development of controllable summarization methods.'}","['corpus', 'method']","['Controlled Generation', 'Unit Selection']",['ENTSUM'],"['ROUGE', 'BERTScore']",[''],https://github.com/bloomberg/entsum,https://aclanthology.org/2022.acl-long.237,"{'Generating a single summary for a document is not suitable for all readers of the document.': 'Various setups for summarization were proposed such that user preferences can be taken into account in the summarization process. These include providing guidance signals such as summary length, allowing users to provide terms of interest such as aspects or entities, or providing users the flexibility to interact with the summary and explore new facets of interest.', 'Most summarization data sets are obtained using opportunistic methods such as using abstracts written by editors or librarians when indexing documents, which are by default generic and not applicable to controllable summarization.': 'The authors introduce a new data set for controllable summarization focusing on entities as control aspects given these are usually key aspects in documents and their summaries. The data set consists of 2,788 human-generated entity-centric summaries across 645 documents that are obtained using a strict quality control process mechanism involving several intermediate annotation steps.', 'Methods proposed to date for controllable summarization fail at entity-centric summarization.': 'The authors propose adaptations of state-of-the-art extractive and abstractive summarization methods that significantly improve performance when compared to generic summaries.', 'There is a lack of quantitative data set analysis that highlights the challenges and distinctiveness of entity-centric summarization.': 'The authors provide quantitative data set analysis that highlights the challenges and distinctiveness of entity-centric summarization.', 'Small scale human annotations used in initial research in this area can be prone to biases or qualitative issues, offer only relative quality measurement and do not allow for replicable comparisons between multiple methods or model tuning.': 'The authors introduce the first annotated data set for controllable summarization with entities as targets for control (ENTSUM - Entity SUMmarization) that can be used for replicable comparisons between multiple methods or model tuning.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:c375fcb7a4dd39c077ebc2cefc70e6121d961af9,QSG Transformer: Transformer withQuery-Attentive Semantic Graph forQuery-Focused Summarization,SIGIR,2022,"['Choongwon Park', 'Youngjoong Ko']","Query-Focused Summarization (QFS) is a task that aims to extract essential information from a long document and organize it into a summary that can answer a query. Recently, Transformer-based summarization models have been widely used in QFS. However, the simple Transformer architecture cannot utilize the relationships between distant words and information from a query directly. In this study, we propose the QSG Transformer, a novel QFS model that leverages structure information on Query-attentive Semantic Graph (QSG) to address these issues. Specifically, in the QSG Transformer, QSG node representation is improved by a proposed query-attentive graph attention network, which spreads the information of the query node into QSG using Personalized PageRank, and it is used to generate a summary that better reflects the information from the relationships of a query and document. The proposed method is evaluated on two QFS datasets, and it achieves superior performances over the state-of-the-art models.","The paper discusses the task of Query-Focused Summarization (QFS) and the limitations of Transformer-based summarization models in utilizing relationships between distant words and query information. To address these issues, the authors propose the QSG Transformer, a novel QFS model that leverages structure information on Query-attentive Semantic Graph (QSG). The QSG node representation is improved by a query-attentive graph attention network, which spreads the information of the query node into QSG using Personalized PageRank. The proposed method achieves superior performance over state-of-the-art models on two QFS datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to answer specific queries from the essential information of the source document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the essential information of a source document in response to a specific query.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the essential information of a source document in response to a specific query, without having to read the entire document.'}",['method'],"['Unit Relationship', 'Input Encoding']","['Debatepedia', 'PubMedQA']",['ROUGE'],[''],,https://doi.org/10.1145/3477495.3531901,"{'The simple Transformer has difficulty in directly reflecting relationships between important distant words just on the self-attention mechanism.': 'The authors propose the QSG Transformer, a novel QFS model with Query-attentive Semantic Graph (QSG) that effectively utilizes relation information between distant words and query information using QSG. It uses two encoders to understand the query and document input; the context encoder interprets textual sequential meaning on the Transformer, and the graph encoder does structural meaning on QSG.', 'The simple Transformer does not have any function to properly focus on the query information for QFS.': 'The authors propose query-attentive GAT and auxiliary task to get improved node representations reflecting the query information. In the graph encoder of the QSG Transformer, one of the link analysis algorithms, Personalized PageRank (PPR) is applied to graph attention network (GAT) to obtain node representations that better reflect the query and document relationships. Query-attentive node representations are obtained by weighted aggregation of the neighbor’s message using PPR importance scores. Furthermore, an auxiliary self-supervised task is added to strengthen the robustness of the node representations. The auxiliary task aims to classify the shortest path length (e.g., N-hops) from query nodes to others.'}",supervised,"['Arguments', 'CQA']",['controlled-and-tailored-summarization']
SP:e12185c023a885c719642360cbc99b03e3a164af,Quantifying Appropriateness of Summarization Data for Curriculum Learning,EACL,2021,"['Ryuji Kano', 'Takumi Takahashi', 'Toru Nishino', 'Motoki Taniguchi', 'Tomoki Taniguchi', 'Tomoko Ohkuma']","Much research has reported the training data of summarization models are noisy; summaries often do not reflect what is written in the source texts. We propose an effective method of curriculum learning to train summarization models from such noisy data. Curriculum learning is used to train sequence-to-sequence models with noisy data. In translation tasks, previous research quantified noise of the training data using two models trained with noisy and clean corpora. Because such corpora do not exist in summarization fields, we propose a model that can quantify noise from a single noisy corpus. We conduct experiments on three summarization models; one pretrained model and two non-pretrained models, and verify our method improves the performance. Furthermore, we analyze how different curricula affect the performance of pretrained and nonpretrained summarization models. Our result on human evaluation also shows our method improves the performance of summarization models.",The paper proposes a method of curriculum learning to train summarization models from noisy data. They use sequence-to-sequence models and propose a model that can quantify noise from a single noisy corpus. They conduct experiments on three summarization models and show that their method improves performance. They also analyze how different curricula affect the performance of pretrained and nonpretrained summarization models. Human evaluation results also show that their method improves the performance of summarization models.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to advance the field of summarization using sequence-to-sequence models.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as information retrieval, document categorization, and content recommendation.'}",['method'],[],[],[],[],,https://aclanthology.org/2021.eacl-main.119,"{'Summarization datasets contain inappropriate pairs of source texts and summaries, which can lead to noisy training data and reduced performance of summarization models.': 'The authors propose an Appropriateness Estimator, a noise-estimating model that can be trained from a single noisy corpus. The model distinguishes appropriate pairs of source and target texts from clearly inappropriate pairs, and predicts the appropriateness of data. This is applied to curriculum learning, gradually changing the training data from inappropriate to appropriate pairs.', 'Summarization models leverage titles as summaries, but titles can be too general or contain information not written in the source texts, leading to further noise in the training data.': 'The authors propose the use of their Appropriateness Estimator to improve the quality of the training data and reduce noise in the summaries generated by the models.', 'There is a lack of datasets in the summarization field for estimating noise of data and applying curriculum learning.': 'The authors propose the use of their Appropriateness Estimator as a solution for estimating noise of data and applying curriculum learning, which can be trained from a single noisy corpus.', 'The performance of pretrained and non-pretrained summarization models can be affected by different curricula.': 'The authors analyze how three different curricula affect the performance of pretrained and non-pretrained summarization models, and conclude that training with small fine data in the last phase is important for pretrained models, while generalization with various data in the beginning phase is important for non-pretrained models. They also conduct human evaluation to verify the effectiveness of their proposed method.'}",,"['Emails', 'Social Media']","['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:de7e8f172cd800da0c80a319a831bf5085d4e4b2,NEWSROOM: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies,NAACL,2018,"['Max Grusky', 'Mor Naaman', 'Yoav Artzi']","We present NEWSROOM, a summarization dataset of 1.3 million articles and summaries written by authors and editors in newsrooms of 38 major news publications. Extracted from search and social media metadata between 1998 and 2017, these high-quality summaries demonstrate high diversity of summarization styles. In particular, the summaries combine abstractive and extractive strategies, borrowing words and phrases from articles at varying rates. We analyze the extraction strategies used in NEWSROOM summaries against other datasets to quantify the diversity and difficulty of our new data, and train existing methods on the data to evaluate its utility and challenges. The dataset is available online at summari.es.","The paper introduces NEWSROOM, a dataset of 1.3 million articles and summaries from 38 major news publications, extracted from search and social media metadata between 1998 and 2017. The summaries demonstrate a high diversity of summarization styles, combining abstractive and extractive strategies. The authors analyze the extraction strategies used in NEWSROOM summaries and compare them to other datasets to evaluate its diversity and difficulty. They also train existing methods on the data to evaluate its utility and challenges. The dataset is available online at summari.es.","{'What is the purpose of the summaries?': 'The authors are developing learning methods for automatic summarization, but they are constrained by the limited high-quality data available for training and evaluation.', 'Who is the target audience?': 'The summaries are written by humans, for common readers, and with the explicit purpose of summarization.', 'How will the summaries be used?': 'The summaries will be used to create a dataset called NEWSROOM, which is a nearly two decade-long snapshot representing how single-document summarization is used in practice across a variety of sources, writers, and topics. The dataset will be used to better understand the summarization problem and to develop more effective summarization models.'}",['corpus'],[],[],[],[],https://lil.nlp.cornell.edu/newsroom/index.html,https://aclanthology.org/N18-1065/,"{'The development of learning methods for automatic summarization is constrained by the limited high-quality data available for training and evaluation.': 'The authors propose the use of NEWSROOM, a dataset with 1.3 million news articles and human-written summaries, as a large-scale high-quality resource for summarization.', 'Identifying large, high-quality resources for summarization has called for creative solutions in the past.': 'The authors distinguish NEWSROOM from other resources by its combination of size and diversity, as well as the fact that the summaries were written with the explicit goal of concisely summarizing news articles over almost two decades.', 'The diversity of summarization strategies used by writers poses a challenge for developing effective summarization models.': 'The authors explore NEWSROOM to better understand the dataset and how summarization is used in practice by newsrooms, focusing on a key dimension of extractiveness and abstractiveness. They develop measures to quantify extractiveness and use these measures to subdivide the data into extractive, mixed, and abstractive subsets, displaying the broad set of summarization techniques practiced by different publishers.', 'The challenges posed by NEWSROOM call for further analysis and evaluation of summarization models.': 'The authors analyze the performance of three summarization models as baselines for NEWSROOM and design and execute a benchmark human evaluation protocol to quantify the output summaries relevance and quality. Their experiments demonstrate that NEWSROOM presents an open challenge for summarization systems, while providing a large resource to enable data-intensive learning methods.'}",,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:4e7f55e67c5d1b99761dbfde1ae5886bddb1eaaf,Intrinsic Evaluation of Summarization Datasets,EMNLP,2020,"['Rishi Bommasani', 'Claire Cardie']","High quality data forms the bedrock for building meaningful statistical models in NLP. Consequently, data quality must be evaluated either during dataset construction or post hoc. Almost all popular summarization datasets are drawn from natural sources and do not come with inherent quality assurance guarantees. In spite of this, data quality has gone largely unquestioned for many recent summarization datasets. We perform the first large-scale evaluation of summarization datasets by introducing 5 intrinsic metrics and applying them to 10 popular datasets. We find that data usage in recent summarization research is sometimes inconsistent with the underlying properties of the datasets employed. Further, we discover that our metrics can serve the additional purpose of being inexpensive heuristics for detecting generically low quality examples.","The paper discusses the importance of high quality data for building statistical models in natural language processing (NLP), and the need to evaluate data quality during dataset construction or post hoc. It highlights that popular summarization datasets are often drawn from natural sources without quality assurance guarantees, and that data quality has gone largely unquestioned in recent summarization research. The authors introduce 5 intrinsic metrics and apply them to 10 popular datasets, finding that data usage in recent summarization research is sometimes inconsistent with the underlying properties of the datasets employed. They also discover that their metrics can serve as inexpensive heuristics for detecting low quality examples.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the quality of summarization datasets.', 'Who is the target audience?': 'The summaries are for evaluating the quality of summarization datasets used in recent research.', 'How will the summaries be used?': 'The summaries will be used to introduce 5 intrinsic metrics and apply them to 10 popular datasets to evaluate data quality and detect low quality examples.'}",['analysis'],[],[],[],[],https://github.com/rishibommasani/SummarizationEvaluationEMNLP2020,https://aclanthology.org/2020.emnlp-main.649,"{'Data quality is crucial for building meaningful statistical models in NLP.': 'Data quality must be evaluated either during dataset construction or post hoc.', 'Popular summarization datasets are drawn from natural sources and do not come with inherent quality assurance guarantees.': 'Perform a large-scale evaluation of summarization datasets by introducing 5 intrinsic metrics and applying them to 10 popular datasets.', 'Data quality has gone largely unquestioned for many recent summarization datasets.': 'Evaluate the data usage in recent summarization research and compare it with the underlying properties of the datasets employed.', 'Data usage in recent summarization research is sometimes inconsistent with the underlying properties of the datasets employed.': 'Use the 5 intrinsic metrics to identify inconsistencies in data usage and improve the quality of the datasets.', 'Generically low quality examples can be difficult to detect.': 'Use the 5 intrinsic metrics as inexpensive heuristics for detecting generically low quality examples.'}",,"['News', 'Scholarly Documents', 'Social Media', 'Meeting Transcripts', 'Movie Scripts']","['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:1bbc4439b58e8e9e91b160399f916a801e7de50d,A Novel Wikipedia based Dataset for Monolingual and Cross-Lingual Summarization,EMNLP,2021,"['Mehwish Fatima', 'Michael Strube']","Cross-lingual summarization is a challenging task for which there are no cross-lingual scientific resources currently available. To overcome the lack of a high-quality resource, we present a new dataset for monolingual and cross-lingual summarization considering the English-German pair. We collect high-quality, real-world cross-lingual data from Spektrum der Wissenschaft, which publishes humanwritten German scientific summaries of English science articles on various subjects. The generated Spektrum dataset is small; therefore, we harvest a similar dataset from the Wikipedia Science Portal to complement it. The Wikipedia dataset consists of English and German articles, which can be used for monolingual and cross-lingual summarization. Furthermore, we present a quantitative analysis of the datasets and results of empirical experiments with several existing extractive and abstractive summarization models. The results suggest the viability and usefulness of the proposed dataset for monolingual and crosslingual summarization.","The paper discusses the challenge of cross-lingual summarization and the lack of available resources for this task. To address this issue, the authors present a new dataset for monolingual and cross-lingual summarization in the English-German pair. They collected high-quality cross-lingual data from Spektrum der Wissenschaft and complemented it with a similar dataset from the Wikipedia Science Portal. The authors also conducted experiments with various summarization models and found that the proposed dataset is useful for monolingual and cross-lingual summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific texts to explore the crosslingual summarization (CLS) task using scientific English documents to generate German summaries for local readers.', 'Who is the target audience?': 'The summaries are for local readers who may not be proficient in English and need a summary of scientific texts in German.', 'How will the summaries be used?': 'The summaries will be used to facilitate the understanding of scientific texts for local readers who may not be proficient in English. The authors also aim to encourage new avenues of research in the less explored areas of CLS.'}",['corpus'],[],[],[],[],,https://aclanthology.org/2021.newsum-1.5.pdf,"{'The absence of real cross-lingual datasets in recent CLS studies conducted on existing monolingual news datasets and off-the-shelf machine translation (MT) systems may introduce noise into pseudo-cross-lingual summarization (PCLS) data.': 'The authors address this issue by developing a summarization dataset containing scientific texts of the English-German language pair from two resources, Spektrum der Wissenschaft (SPEKTRUM) and the Wikipedia Science Portal (WSP).', 'CLS studies rely on only news data, and the trained summarization models may not work well for other domains such as scientific texts.': 'The authors explore the CLS task by using scientific English documents to generate German summaries for the local readers, and collect a primary dataset from SPEKTRUM consisting of 1,510 English science articles with human-written German summaries.', 'There is no study on scientific text for CLS to date.': 'The authors address this gap by developing a summarization dataset containing scientific texts of the English-German language pair from two resources, SPEKTRUM and WSP, and exploring the CLS task by using scientific English documents to generate German summaries for the local readers.', 'Most CLS studies intend to generate the summaries in English from a local language but not vice versa to facilitate the local readers.': 'The authors address this issue by generating German summaries for the local readers from scientific English documents.', 'The authors aim to evaluate the usability of their dataset for MS and CLS.': 'The authors perform an empirical evaluation with several extractive baselines and existing abstractive summarization models to validate the usability of their dataset for MS and CLS. Moreover, linguistic quality is evaluated on a subset of the output summaries of the MS and CLS experiments by human judges.'}",,['Wikipedia'],['lack-of-suitable-training-data']
SP:26dcb454dae424735b2df8aa013347ada0c8792d,How Domain Terminology Affects Meeting Summarization Performance,COLING,2020,"['Jia Jin Koay', 'Alexander Roustai', 'Xiaojin Dai', 'Dillon Burns', 'Alec Kerrigan', 'Fei Liu']","Meetings are essential to modern organizations. Numerous meetings are held and recorded daily, more than can ever be comprehended. A meeting summarization system that identifies salient utterances from the transcripts to automatically generate meeting minutes can help. It empowers users to rapidly search and sift through large meeting collections. To date, the impact of domain terminology on the performance of meeting summarization remains understudied, despite that meetings are rich with domain knowledge. In this paper, we create gold-standard annotations for domain terminology on a sizable meeting corpus; they are known as jargon terms. We then analyze the performance of a meeting summarization system with and without jargon terms. Our findings reveal that domain terminology can have a substantial impact on summarization performance. We publicly release all domain terminology to advance research in meeting summarization.1","The paper discusses the importance of meetings in organizations and the need for a meeting summarization system to help users quickly search and sift through large meeting collections. The authors analyze the impact of domain terminology, or jargon terms, on the performance of meeting summarization and find that it can have a substantial impact. They create gold-standard annotations for jargon terms on a sizable meeting corpus and publicly release all domain terminology to advance research in meeting summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of meeting recordings to assist in browsing meeting archives and to make large archives of meetings substantially more efficient to browse, search and facilitate information sharing.', 'Who is the target audience?': 'The summaries are for users who need to navigate through meeting recordings and want to quickly identify the most important content of the meeting discussion.', 'How will the summaries be used?': 'The summaries will be used to aid users in navigating through meeting recordings and to make large archives of meetings substantially more efficient to browse, search and facilitate information sharing.'}",['corpus'],[],[],[],[],https://github.com/ucfnlp/meeting-domain-terminology,https://aclanthology.org/2020.coling-main.499,"{'There is an explosion of meetings being held and recorded every day, making it difficult to comprehend and browse through meeting archives.': 'Develop summarization techniques to assist in browsing meeting archives by creating a meeting summarization system that takes a meeting recording and its transcript as input and produces a concise text summary as output, which preserves the most important content of the meeting discussion.', 'Most prior work on neural text summarization has focused on written texts, while recent years have seen a growing interest in summarizing spoken texts, especially in the context of meetings.': 'Investigate how domain terminology impacts meeting summarization performance, especially in the context of neural extractive summarization, and favor extractive over abstractive models.', 'Jargon is ubiquitous in meeting discussions, and without a thorough study of technical jargon in the meeting domain, it is unclear how best to optimize a meeting summarizer to incorporate domain knowledge.': 'Compile a collection of jargon terms from a meeting corpus containing multi-party conversations on the topic of speech and signal processing and create gold-standard annotations for domain terminology on a large meeting corpus.', 'There is a pressing need to understand how domain terminology affects the meeting summarization performance.': 'Analyze the performance of a meeting summarization system with and without jargon and determine the impact of domain terminology on summarization performance.'}",,['Meeting Transcripts'],[]
SP:2bb9e3334536a46f3d30338ec866cd3b748b4700,TLDR9+: A Large Scale Resource for Extreme Summarization of Social Media Posts,EMNLP,2021,"['Sajad Sotudeh', 'Hanieh Deilamsalehy', 'Franck Dernoncourt', 'Nazli Goharian']","Recent models in developing summarization systems consist of millions of parameters and the model performance is highly dependent on the abundance of training data. While most existing summarization corpora contain data in the order of thousands to one million, generation of large-scale summarization datasets in order of couple of millions is yet to be explored. Practically, more data is better at generalizing the training patterns to unseen data. In this paper, we introduce TLDR9+ —a largescale summarization dataset— containing over 9 million training instances extracted from Reddit discussion forum (https://github. com/sajastu/reddit_collector). This dataset is specifically gathered to perform extreme summarization (i.e., generating onesentence summary in high compression and abstraction) and is more than twice larger than the previously proposed dataset. We go one step further and with the help of human annotations, we distill a more finegrained dataset by sampling High-Quality instances from TLDR9+ and call it TLDRHQ dataset. We further pinpoint different state-ofthe-art summarization models on our proposed datasets.",The paper discusses the importance of training data in developing summarization systems and introduces a new large-scale summarization dataset called TLDR9+ containing over 9 million training instances extracted from Reddit discussion forum. The dataset is specifically gathered for extreme summarization and is more than twice larger than the previously proposed dataset. The authors also distill a more fine-grained dataset called TLDRHQ by sampling high-quality instances from TLDR9+ with the help of human annotations. The paper further evaluates different state-of-the-art summarization models on the proposed datasets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide a concise sequence of text that conveys the most important points of the associated source.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading longer documents, and can be utilized for various applications such as information retrieval and content summarization.'}",['corpus'],[],[],[],[],https://github.com/sajastu/reddit_collector,https://arxiv.org/abs/2110.01159,"{'The performance of neural models for text summarization is bound to the abundance of training data due to the massive model complexity.': 'Large-scale corpora are necessary for training large and complex models.', 'Training deep neural networks on social media datasets is challenging due to the specific writing style of social media content such as informal language and massive noise within such content.': 'TLDR, a common practice on social media platforms that aims at removing unnecessary information from lengthy posts, can be utilized for generating data collections that can be used for training deep neural networks.', 'Existing summarization datasets in social and non-social media domains are not suitable for extreme summarization tasks, where the aim is to produce one to two summary sentences in extreme compression and high abstraction.': 'The authors introduce their dataset, TLDR9+, with over 9 million instances, which is more than twice larger than the previous dataset. They further sample high-quality instances in virtue of human annotations from TLDR9+ to construct TLDRHQ yielding 1.7 million instances in the hope of providing firm grounds for future work.', 'Social media posts are inherently noisy, making it challenging to obtain high-quality instances for training deep neural networks.': 'The authors consider applying a heuristic method to cut out low-quality instances from the initial set, which ultimately results in 1.7 million high-quality instances. They employ human annotators to help obtain a more fine-grained dataset (i.e., TLDRHQ).', 'There is a need for establishing various state-of-the-art extractive and abstractive summarization models on the proposed datasets.': 'The authors establish various state-of-the-art extractive and abstractive summarization models on their proposed datasets and carry out an analysis over the results on both datasets to shed lights on future direction.'}",,['Social Media'],"['information-loss-and-incoherence-in-extractive-summarization', 'pretraining-and-sample-efficiency']"
SP:6b3fd41216355c4985170c6b8e6f4deee8006879,An Exploration of Post-Editing Effectiveness in Text Summarization,NAACL,2022,"['Vivian Lai', 'Alison Smith-Renner', 'Ke Zhang', 'Ruijia Cheng', 'Wenjuan Zhang', 'Joel Tetreault', 'Alejandro Jaimes']","Automatic summarization methods are efficient but can suffer from low quality. In comparison, manual summarization is expensive but produces higher quality. Can humans and AI collaborate to improve summarization performance? In similar text generation tasks (e.g., machine translation), human-AI collaboration in the form of “post-editing” AIgenerated text reduces human workload and improves the quality of AI output. Therefore, we explored whether post-editing offers advantages in text summarization. Specifically, we conducted an experiment with 72 participants, comparing post-editing provided summaries with manual summarization for summary quality, human efficiency, and user experience on formal (XSum news) and informal (Reddit posts) text. This study sheds valuable insights on when post-editing is useful for text summarization: it helped in some cases (e.g., when participants lacked domain knowledge) but not in others (e.g., when provided summaries include inaccurate information). Participants’ different editing strategies and needs for assistance offer implications for future human-AI summarization systems.","The paper discusses the potential benefits of human-AI collaboration in text summarization through post-editing. The study conducted with 72 participants compared post-editing provided summaries with manual summarization for summary quality, human efficiency, and user experience on formal and informal text. The results suggest that post-editing can be useful in some cases, but not in others, and participants' different editing strategies and needs for assistance offer implications for future human-AI summarization systems.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide short overviews of long documents or document collections, allowing readers to understand the content without the need to read full documents.', 'Who is the target audience?': 'The summaries are for readers who want to easily understand the extent of the work and decide whether the paper is relevant to them.', 'How will the summaries be used?': 'The summaries will be used to improve efficiency and quality over manual methods of text summarization.'}",['analysis'],[],[],[],[],https://github.com/vivlai/post-editing-effectiveness-summarization,https://aclanthology.org/2022.naacl-main.35,"{'Human summarization is time-consuming and requires heavy cognitive load.': 'Machine models have been explored to generate summaries automatically.', 'Training models require large, high-quality summarization datasets that are expensive to curate.': 'Human-AI collaboration can be used to improve summarization performance.', 'Studies of post-editing for summarization have been very limited.': 'The authors performed a large-scale human subject experiment investigating the utility of post-editing provided summaries in text summarization for informal (Reddit) and formal (news) datasets.', 'It is unclear whether post-editing can actually improve efficiency or quality over manual methods, as well as the effects on users’ experience.': 'The authors show how post-editing impacts summary quality, efficiency, and user experience— where it is useful and where it is not.', 'There is a lack of large, human-evaluated summarization datasets.': 'The authors create and make public two new datasets, each with 502360 human-evaluated summaries for news and Reddit posts—either written manually or post-edited on provided summaries.'}",,"['News', 'Social Media']",['lack-of-suitable-training-data']
SP:515663b333903d351edc70a996d392c3cf1bbff2,Comparative Document Summarisation via Classification,AAAI,2019,"['Umanga Bista', 'Alexander Mathews', 'Minjeong Shin', 'Aditya Krishna Menon', 'Lexing Xie']","This paper considers extractive summarisation in a comparative setting: given two or more document groups (e.g., separated by publication time), the goal is to select a small number of documents that are representative of each group, and also maximally distinguishable from other groups. We formulate a set of new objective functions for this problem that connect recent literature on document summarisation, interpretable machine learning, and data subset selection. In particular, by casting the problem as a binary classification amongst different groups, we derive objectives based on the notion of maximum mean discrepancy, as well as a simple yet effective gradient-based optimisation strategy. Our new formulation allows scalable evaluations of comparative summarisation as a classification task, both automatically and via crowd-sourcing. To this end, we evaluate comparative summarisation methods on a newly curated collection of controversial news topics over 13months.We observe that gradient-based optimisation outperforms discrete and baseline approaches in 15 out of 24 different automatic evaluation settings. In crowd-sourced evaluations, summaries from gradient optimisation elicit 7% more accurate classification from human workers than discrete optimisation. Our result contrasts with recent literature on submodular data subset selection that favours discrete optimisation. We posit that our formulation of comparative summarisation will prove useful in a diverse range of use cases such as comparing content sources, authors, related topics, or distinct view points.","The paper discusses extractive summarization in a comparative setting, where the objective is to select a small number of documents that represent each group and distinguish them from other groups. The authors propose a new set of objective functions that connect recent literature on document summarization, interpretable machine learning, and data subset selection. They cast the problem as a binary classification among different groups and derive objectives based on the maximum mean discrepancy and a gradient-based optimization strategy. The authors evaluate comparative summarization methods on a newly curated collection of controversial news topics over 13 months and find that gradient-based optimization outperforms discrete and baseline approaches in 15 out of 24 different automatic evaluation settings. In crowd-sourced evaluations, summaries from gradient optimization elicit 7% more accurate classification from human workers than discrete optimization. The authors suggest that their formulation of comparative summarization will be useful in comparing content sources, authors, related topics, or distinct viewpoints.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for comparative summarisation, which involves selecting representative documents from different groups and highlighting differences between them.', 'Who is the target audience?': 'The summaries are for users who want to compare and contrast different groups of documents, such as news articles on a particular topic.', 'How will the summaries be used?': 'The summaries will be used to answer user questions about the differences and similarities between groups of documents, such as what is new on a particular topic or what are the key articles covering a particular issue. They will be evaluated using automatic and crowd-sourced evaluations to determine their effectiveness.'}","['corpus', 'method']",[],[],[],[],https://github.com/computationalmedia/compsumm,https://doi.org/10.1609/aaai.v33i01.330120,"{'Existing methods for extractive summarisation do not consider differences between groups of documents, which is important for comparative summarisation.': 'The authors propose a novel formulation of the problem in terms of two competing classification tasks, where the aim is to select documents that represent each group but also highlight differences between groups.', 'Evaluating summaries using traditional approaches is difficult to scale and not suitable for new tasks and datasets.': 'The authors design automatic and crowd-sourced evaluations for comparative summaries, which can be used to evaluate summarisation as a classification task.', 'The connections and distinctions between different approaches to comparative summarisation have not been clearly articulated.': 'The authors provide a clear articulation of the different approaches and show how their proposed framework encompasses existing nearest neighbour objectives for summarisation.', 'Discrete greedy optimisation of submodular objectives is favored in the body of work on dataset selection and summarisation due to approximation guarantees.': 'The authors hypothesize that the comparative summarisation problem is particularly amenable to gradient-based optimization due to the small number of prototypes needed, and show that gradient-based approaches can further improve solutions found by greedy approaches.'}",,['Opinions'],"['controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:f3270f829b114c49a57ba2052a8a2f5c5c6401b5,LipKey: A Large-Scale News Dataset for Absent Keyphrases Generation and Abstractive Summarization,COLING,2022,"['Fajri Koto', 'Timothy Baldwin', 'Jey Han Lau']","Summaries, keyphrases, and titles are different ways of concisely capturing the content of a document. While most previous work has released the datasets of keyphrases and summarization separately, in this work, we introduce LipKey, the largest news corpus with human-written abstractive summaries, absent keyphrases, and titles. We jointly use the three elements via multi-task training and training as joint structured inputs, in the context of document summarization. We find that including absent keyphrases and titles as additional context to the source document improves transformer-based summarization models.1","System: The paper discusses the importance of summaries, keyphrases, and titles in capturing the content of a document. The authors introduce LipKey, a news corpus with human-written abstractive summaries, absent keyphrases, and titles. They use multi-task training and joint structured inputs to improve transformer-based summarization models by including absent keyphrases and titles as additional context to the source document.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to investigate the three elements of presenting key content in different ways, including summaries, keyphrases, and titles, in the context of single-document abstractive summarization.', 'Who is the target audience?': 'The target audience for the summaries is not explicitly stated in the paper. However, the authors aim to study how absent keyphrases and titles can be incorporated into summarization systems, which suggests that the summaries may be used for various NLP applications.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used. However, the authors hope that their work will contribute to the development of more effective summarization systems that can utilize absent keyphrases and titles to improve the quality of abstractive summaries.'}",['corpus'],[],[],[],[],https://github.com/fajri91/LipKey,https://aclanthology.org/2022.coling-1.303,"{'Previous work has mainly utilized present keyphrases (i.e. keyphrases that are directly drawn from the source text) through unsupervised and supervised methods for summarization.': 'The authors aim to study how absent keyphrases (i.e. keyphrases that do not match any words in the source text) can be incorporated into summarization systems. Compared to present keyphrases used in previous work, absent keyphrases potentially better complement abstractive summarization methods.', 'Previous work has been hindered by the unavailability of a large annotated dataset with gold-standard summaries and keyphrases, thus opting for present keyphrase extraction.': 'The authors release a novel news dataset that consists of highly absent keyphrases, abstractive summaries, and titles to investigate the three elements in the context of single-document abstractive summarization.', 'Previous summarization datasets such as CNNDM, NYT, and XSUM do not include keyphrases and titles.': 'The authors present a novel large-scale dataset containing both titles and keyphrases to study their utility in summarization.', 'The dataset of Koto et al. (2020a) is based on the time period 2000–2010, at which point Liputan6 did not include keyphrases.': 'The authors crawl Liputan62 to obtain a new dataset of 105K news articles with titles, abstractive summaries, and absent keyphrases, all authored by journalists, based on the time period 2019–2021.', 'The lack of language diversity in NLP.': 'The fact that the dataset is in Indonesian contributes to language diversity in NLP.'}",,['News'],[]
SP:563834e2221446736331a2706777c529f703ef2a,WikiSum: Coherent Summarization Dataset for Efficient Human-Evaluation,ACL,2021,"['Nachshon Cohen', 'Oren Kalinsky', 'Yftah Ziser', 'Alessandro Moschitti']","Recent works have made significant advances on summarization tasks, facilitated by summarization datasets. Several existing datasets have the form of coherent-paragraph summaries. However, these datasets were curated from academic documents written for experts, making the essential step of assessing the summarization output through human-evaluation very demanding. To overcome these limitations, we present a dataset1 based on article summaries appearing on the WikiHow website, composed of howto articles and coherent-paragraph summaries written in plain language. We compare our dataset attributes to existing ones, including readability and world-knowledge, showing our dataset makes human evaluation significantly more manageable and effective. A human evaluation conducted on PubMed and the proposed dataset reinforces our findings.","

The paper discusses the challenges of evaluating summarization output from existing datasets, which are often curated from academic documents written for experts. To address this issue, the authors present a new dataset based on article summaries from the WikiHow website, which are written in plain language and focused on how-to articles. The authors compare their dataset to existing ones and show that it makes human evaluation more manageable and effective. A human evaluation conducted on PubMed and the proposed dataset supports their findings.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to understand and improve the quality of summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating summarization systems and providing insights that can go unnoticed using automatic evaluation methods.', 'How will the summaries be used?': 'The summaries will be used to establish a baseline on the proposed dataset and benchmark recent summarization systems.'}",['corpus'],[],[],[],[],https://github.com/mmautner/readability,https://aclanthology.org/2021.acl-short.28,"{'Automatic evaluation of summarization systems using the ROUGE metric is challenging and often inconsistent with human evaluation.': 'Conduct a human evaluation to understand and improve the quality of summarization systems.', 'Existing coherent-paragraph summarization datasets consist of academic papers and cannot be considered easy to read, requiring unique expertise and coming at a high cost.': 'Present WikiSum, a new summarization dataset from the WikiHow knowledge base, written in simple English and providing summaries in the form of coherent paragraphs.', 'Evaluating summarization samples requires unique expertise, takes time, and comes at a high cost.': 'Provide articles and summaries that are easy to read and require less world knowledge to understand, as well as conducting a human-evaluation of the summarization dataset to reinforce results.', 'Automatic evaluation methods can miss insights that can be gained through human evaluation.': 'Use the critical property of simple English in WikiSum to help with the challenging task of evaluating summarization systems and provide insights that can go unnoticed using automatic evaluation methods.'}",,['Wikipedia'],['exploiting-the-structure-of-long-documents']
SP:4a98b785fb038794e957a99c9523a04d9ff8ecfb,SoLSCSum: A Linked Sentence-Comment Dataset for Social Context Summarization,CIKM,2016,"['Minh-Tien Nguyen', 'Minh-Le Nguyen']","This paper presents a dataset named SoLSCSum for social context summarization. The dataset includes 157 open-domain articles along with their comments collected from Yahoo News. The articles and their comments were manually annotated by two annotators to extract standard summaries. The inter-annotator agreement is 74.5% and Cohen’s Kappa is 0.5845. To illustrate the potential use of our dataset, a learning to rank model was trained by using a set of local and cross features. Experimental results demonstrate that: (1) our model trained by Ranking SVM obtains significant improvements from 5.5% to 14.8% of ROUGE-1 over state-of-theart baselines in document summarization and (2) our dataset can be used to train summary methods such as SVM.","The paper introduces a new dataset called SoLSCSum for social context summarization, consisting of 157 open-domain articles and their comments from Yahoo News that were manually annotated by two annotators to extract standard summaries. The dataset has a high inter-annotator agreement and can be used to train summary methods such as SVM. The paper also demonstrates the potential use of the dataset by training a learning to rank model with local and cross features, which achieved significant improvements in document summarization over state-of-the-art baselines.","{'What is the purpose of the summaries?': 'The authors are generating summaries of web documents to utilize social information and provide a perspective viewpoint regarding an event.', 'Who is the target audience?': 'The summaries are for anyone who wants to quickly understand the important information and opinions related to a web document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading through lengthy web documents and to gain a better understanding of the content and opinions related to an event.'}",['corpus'],[],[],[],[],,https://doi.org/10.1145/2983323.2983376,"{'Released datasets do not contain both annotation and social information, which challenges the evaluation of summarization systems that consider both sentences and social messages.': 'The authors present a new open-domain dataset that bridges the information from comments to support sentences in generating the summarization. The dataset was collected from Yahoo News and annotated by two annotators.', 'Existing datasets containing web documents and tweets were collected without annotation, making it challenging to train supervised methods like SVM.': 'The authors present a new annotated dataset that can be used to train supervised methods.', 'Tweets are short messages and usually written in informal form, which may not be efficient enough to reflect the content of a document. Additionally, summarization systems need a lot of effort to remove unnecessary information of tweets, e.g. noise.': 'The authors collect comments from Yahoo News, which are longer and more formal than tweets, to provide a better reflection of the content of a document. They also annotate the comments to remove unnecessary information and noise.'}",,['News'],['lack-of-suitable-training-data']
SP:695b765e09734db5359ffb69e57cd81e9663f7f1,NEWTS: A Corpus for News Topic-Focused Summarization∗,ACL,2022,"['Seyed Ali Bahrainian', 'Sheridan Feucht', 'Carsten Eickhoff']","Text summarization models are approaching human levels of fidelity. Existing benchmarking corpora provide concordant pairs of full and abridged versions of Web, news or, professional content. To date, all summarization datasets operate under a one-size-fits-all paradigm that may not reflect the full range of organic summarization needs. Several recently proposed models (e.g., plug and play language models) have the capacity to condition the generated summaries on a desired range of themes. These capacities remain largely unused and unevaluated as there is no dedicated dataset that would support the task of topic-focused summarization. This paper introduces the first topical summarization corpus NEWTS, based on the wellknown CNN/Dailymail dataset, and annotated via online crowd-sourcing. Each source article is paired with two reference summaries, each focusing on a different theme of the source document. We evaluate a representative range of existing techniques and analyze the effectiveness of different prompting methods.","The paper discusses how text summarization models are improving and how existing benchmarking corpora may not reflect the full range of summarization needs. The paper introduces a new topical summarization corpus called NEWTS, which is based on the CNN/Dailymail dataset and annotated via online crowd-sourcing. Each source article is paired with two reference summaries, each focusing on a different theme of the source document. The paper evaluates existing techniques and analyzes the effectiveness of different prompting methods.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide tailored summaries matching the interests of the reader in various settings.', 'Who is the target audience?': 'The summaries are for journalists, analysts, physicians, or any other form of personalized summarization targeting explicitly defined or implicitly mined preference parameters.', 'How will the summaries be used?': 'The summaries will be used to evaluate existing models and prompting techniques for controlled text generation for summarization.'}",['corpus'],[],[],[],[],https://github.com/ali-bahrainian/NEWTS,https://aclanthology.org/2022.findings-acl.42,"{'Existing summarization benchmarks assume a one-size-fits-all paradigm under which model output is evaluated based on similarity to general-purpose reference summaries reflecting the full content of the original document, which might not reflect the full range of summarization needs anymore.': 'The authors propose the introduction of NEWTS, a NEWs Topic-focused Summarization corpus for the controlled generation of text, which contains human-written topical reference summaries collected via online crowdsourcing. This dataset allows for the evaluation of text generation models that can be tailored to specific topic distributions, sentiment polarity, or other personalized summarization targeting explicitly defined or implicitly mined preference parameters.', 'Despite increased efforts and interest in controlled summarization, no dataset exists on which these models can be evaluated.': 'The authors introduce NEWTS, the first dataset of topic-based abstractive summarization, which is based on documents from the well-known CNN/Dailymail dataset and adds new topic-focused summaries. This dataset allows for the evaluation of existing models and prompting techniques for controlled text generation for summarization.', 'Tailored summaries matching the interests of the reader may be required in manifold settings, such as the summarization of complex event streams with a focus on regions, entities or topics of interest for journalists or analysts, understanding reviews or opinions from different perspectives, the summarization of electronic health records with a focus on the medical sub-specialty of the physician reader, or any other form of personalized summarization targeting explicitly defined or implicitly mined preference parameters.': 'The authors propose the use of text generation models that offer the potential of steering the generation process to conform to specific topic distributions or sentiment polarity, such as Plug and Play Language Models (PPLM), which let us condition the generation process on themes of interest and text style transfer controls selected attributes, such as politeness, emotions, or humor of the generated text.'}",,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:452eff9aa00a43f48415ce7fc4def744859b3242,EMAILSUM: Abstractive Email Thread Summarization,EACL,2021,"['Shiyue Zhang', 'Asli Celikyilmaz', 'Jianfeng Gao', 'Mohit Bansal']","Recent years have brought about an interest in the challenging task of summarizing conversation threads (meetings, online discussions, etc.). Such summaries help analysis of the long text to quickly catch up with the decisions made and thus improve our work or communication efficiency. To spur research in thread summarization, we have developed an abstractive Email Thread Summarization (EMAILSUM) dataset, which contains humanannotated short (<30 words) and long (<100 words) summaries of 2,549 email threads (each containing 3 to 10 emails) over a wide variety of topics. We perform a comprehensive empirical study to explore different summarization techniques (including extractive and abstractive methods, single-document and hierarchical models, as well as transfer and semisupervised learning) and conduct human evaluations on both short and long summary generation tasks. Our results reveal the key challenges of current abstractive summarization models in this task, such as understanding the sender’s intent and identifying the roles of sender and receiver. Furthermore, we find that widely used automatic evaluation metrics (ROUGE, BERTScore) are weakly correlated with human judgments on this email thread summarization task. Hence, we emphasize the importance of human evaluation and the development of better metrics by the community.1","The paper discusses the importance of summarizing conversation threads to improve work and communication efficiency. To aid in research on thread summarization, the authors developed an abstractive Email Thread Summarization dataset and conducted a study on different summarization techniques. The study revealed challenges in current abstractive summarization models, such as understanding the sender's intent and identifying the roles of sender and receiver. The authors also found that widely used automatic evaluation metrics are weakly correlated with human judgments, emphasizing the importance of human evaluation and the development of better metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve work efficiency and provide practical benefits, specifically for email threads.', 'Who is the target audience?': 'The summaries are for anyone who needs to read through email threads, such as workers who spend more than 3 hours on business emails per day.', 'How will the summaries be used?': 'The summaries will be used to improve work efficiency by allowing people to quickly understand the main points of previous discussions or newly included discussion threads without having to read through the entire conversation.'}",['corpus'],[],[],[],[],https://github.com/ZhangShiyue/EmailSum,https://aclanthology.org/2021.acl-long.537,"{'Automatic summarization has mainly focused on single-document summarization tasks, such as news document summarization.': 'The authors propose to explore diverse summarization tasks, including email thread summarization, which is a special type of dialogue that involves multiple speakers and contains technical information.', 'Email threads are much longer than conversational dialog turns, and workers spend a significant amount of time reading through entire conversations before replying to the latest email.': 'The authors propose to automatically summarize email threads to improve work efficiency and provide practical benefits.', 'Email thread summarization has been much less studied compared to other summarization tasks, partially due to the lack of large labeled email thread datasets.': 'The authors collect human-written short and long abstractive summaries of 2,549 email threads to create a new dataset (EMAILSUM) that is 64x larger than previously labeled email thread datasets.', 'The small size of the EMAILSUM dataset makes it challenging to train effective summarization models.': 'The authors explore different summarization techniques, including extractive and abstractive summarization methods, single-document and hierarchical models, transfer learning, and semi-supervised learning, and find that utilizing pretrained language models and semi-supervised learning with unlabelled email threads significantly improve summarization performance.', 'Automatic metrics for evaluating email thread summarization models are poorly correlated with human judgment.': 'The authors conduct a human evaluation analysis to better understand how well the models perform and investigate the correlation between automatic metrics and human judgment, highlighting the importance of human evaluation in this task and the need for better metrics to be proposed.'}",,['Emails'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:0a21c3e81fa6ff86e520501d34a1727afec21355,Rigid Formats Controlled Text Generation,ACL,2020,"['Piji Li', 'Haisong Zhang', 'Xiaojiang Liu', 'Shuming Shi']","Neural text generation has made tremendous progress in various tasks. One common characteristic of most of the tasks is that the texts are not restricted to some rigid formats when generating. However, we may confront some special text paradigms such as Lyrics (assume the music score is given), Sonnet, SongCi (classical Chinese poetry of the Song dynasty), etc. The typical characteristics of these texts are in three folds: (1) They must comply fully with the rigid predefined formats. (2) They must obey some rhyming schemes. (3) Although they are restricted to some formats, the sentence integrity must be guaranteed. To the best of our knowledge, text generation based on the predefined rigid formats has not been well investigated. Therefore, we propose a simple and elegant framework named SongNet to tackle this problem. The backbone of the framework is a Transformer-based auto-regressive language model. Sets of symbols are tailor-designed to improve the modeling performance especially on format, rhyme, and sentence integrity. We improve the attention mechanism to impel the model to capture some future information on the format. A pre-training and fine-tuning framework is designed to further improve the generation quality. Extensive experiments conducted on two collected corpora demonstrate that our proposed framework generates significantly better results in terms of both automatic metrics and the human evaluation.1","The paper discusses the challenges of generating text in rigid formats such as lyrics, sonnets, and classical Chinese poetry, which require adherence to strict formatting and rhyming schemes while maintaining sentence integrity. The authors propose a framework called SongNet, which is a Transformer-based auto-regressive language model that uses tailor-designed symbols to improve modeling performance. The attention mechanism is also improved to capture future information on the format. The framework is pre-trained and fine-tuned, and experiments show that it generates better results than existing methods in terms of both automatic metrics and human evaluation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide an overview of the progress made in natural language generation, specifically in the area of generating free text and rigid format controlled text.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of natural language generation who are interested in the recent advancements in generating text with predefined rigid formats.', 'How will the summaries be used?': 'The summaries will be used to gain an understanding of the current state-of-the-art in natural language generation and to identify potential areas for further research and development.'}",['corpus'],[],[],[],[],http://github.com/lipiji/SongNet,https://aclanthology.org/2020.acl-main.68,"{'Most natural language generation models treat format constraints as latent information and cannot generate satisfying results according to arbitrary new defined formats.': 'The authors propose a simple and elegant framework named SongNet to address this challenging problem. The backbone of the framework is a Transformer-based auto-regressive language model. They introduce sets of tailor-designed indicating symbols to improve the modeling performance, especially for the robustness of the format, rhyme, as well as sentence integrity. They improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity. A pretraining and fine-tuning framework is designed to further improve the generation quality.', 'Special text paradigms such as Lyrics, Sonnet, SongCi, etc. have predefined rigid formats that must be complied with fully.': 'The authors propose SongNet to generate text that complies fully with predefined rigid formats. They introduce sets of tailor-designed indicating symbols to improve the modeling performance, especially for the robustness of the format, rhyme, as well as sentence integrity. They improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity.', 'The arrangement of the content must obey the defined rhyming schemes.': 'The authors propose SongNet to generate text that obeys the defined rhyming schemes. They introduce sets of tailor-designed indicating symbols to improve the modeling performance, especially for the robustness of the format, rhyme, as well as sentence integrity. They improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity.', 'Even though the format is rigid, the sentence integrity must always be guaranteed.': 'The authors propose SongNet to generate text that guarantees sentence integrity even when the format is rigid. They introduce sets of tailor-designed indicating symbols to improve the modeling performance, especially for the robustness of the format, rhyme, as well as sentence integrity. They improve the attention mechanism to impel the model to capture the future information on the format to further enhance sentence integrity.'}",,['Sonnets'],[]
SP:8453a88953efb699a16b1ae3ead406c98755786e,SummScreen: A Dataset for Abstractive Screenplay Summarization,ACL,2022,"['Mingda Chen', 'Zewei Chu', 'Sam Wiseman', 'Kevin Gimpel']","We introduce SUMMSCREEN, a summarization dataset comprised of pairs of TV series transcripts and human written recaps. The dataset provides a challenging testbed for abstractive summarization for several reasons. Plot details are often expressed indirectly in character dialogues and may be scattered across the entirety of the transcript. These details must be found and integrated to form the succinct plot descriptions in the recaps. Also, TV scripts contain content that does not directly pertain to the central plot but rather serves to develop characters or provide comic relief. This information is rarely contained in recaps. Since characters are fundamental to TV series, we also propose two entity-centric evaluation metrics. Empirically, we characterize the dataset by evaluating several methods, including neural models and those based on nearest neighbors. An oracle extractive approach outperforms all benchmarked models according to automatic metrics, showing that the neural models are unable to fully exploit the input transcripts. Human evaluation and qualitative analysis reveal that our nonoracle models are competitive with their oracle counterparts in terms of generating faithful plot events and can benefit from better content selectors. Both oracle and non-oracle models generate unfaithful facts, suggesting future research directions.1","The paper introduces a summarization dataset called SUMMSCREEN, which consists of pairs of TV series transcripts and human-written recaps. The dataset poses a challenge for abstractive summarization due to plot details being scattered throughout the transcript and the presence of content that does not directly relate to the central plot. The paper proposes two entity-centric evaluation metrics and evaluates several methods, including neural models and those based on nearest neighbors. An oracle extractive approach outperforms all benchmarked models, indicating that neural models are unable to fully exploit the input transcripts. Human evaluation and qualitative analysis show that non-oracle models are competitive with their oracle counterparts but generate unfaithful facts, suggesting future research directions.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to produce a concise expression of the key points of the input document through abstractive summarization.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any particular audience.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they are intended to be a challenging testbed for abstractive summarization research.'}",['corpus'],[],[],[],[],https://github.com/mingdachen/SummScreen,https://aclanthology.org/2022.acl-long.589,"{'Few datasets exist for abstractive summarization of narrative text, which focuses on entities and dialogue among entities, with plot details often communicated indirectly via dialogue.': 'The authors build SUMMSCREEN, an abstractive summarization dataset combining TV series transcripts and episode recaps.', 'The relationship between character dialogue and plot details is not straightforward. Plot events are often expressed indirectly in dialogue, and dialogue contains other information that is not directly relevant to the plot, such as character development and humor. Also, a typical episode has multiple subplots that proceed in parallel, with consecutive scenes often describing different subplots.': 'Solving SUMMSCREEN requires drawing information from utterances across a wide range of the input and integrating the information to form concise plot descriptions.', 'Many details may be omitted from the transcript itself due to the fact that actual TV episodes ground their scripts with audio-visual accompaniment.': 'The authors propose two entity-centric metrics to evaluate the quality of generated plot summaries. One is based on bags of characters, which measures the overlap of the characters that appear in both the generated and reference recaps. The other metric measures character relations: the overlap of cooccurrences of character pairs in generations and recaps.', 'The benchmarked methods are unable to fully exploit the input transcripts.': 'The authors empirically evaluate several types of methods on SUMMSCREEN, including nearest neighbor models, neural abstractive summarization models, and hybrid models, which use the nearest neighbor models as content selectors followed by abstractive summarization. They find that oracle extractive approaches outperform all models on all the automatic metrics, suggesting that improving content selection may be a promising research direction.', 'Neural models tend to generate generic summaries, hybrid models can benefit from better content selection, and hybrid models sometimes generate unfaithful details.': 'The authors suggest that hybrid models may be promising approaches for future research, based on human evaluations that show their non-oracle hybrid models are competitive with their oracle counterparts in terms of generating faithful plot events.'}",,['Movie Scripts'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:19831fa462fc7e309114346c5f91f102f027c593,Towards Personalized Review Summarization via User-Aware Sequence Network,AAAI,2019,"['Junjie Li', 'Haoran Li', 'Chengqing Zong']","We address personalized review summarization, which generates a condensed summary for a user’s review, accounting for his preference on different aspects or his writing style. We propose a novel personalized review summarization model named User-aware Sequence Network (USN) to consider the aforementioned users’ characteristics when generating summaries, which contains a user-aware encoder and a useraware decoder. Specifically, the user-aware encoder adopts a user-based selective mechanism to select the important information of a review, and the user-aware decoder incorporates user characteristic and user-specific word-using habits into word prediction process to generate personalized summaries. To validate our model, we collected a new dataset Trip, comprising 536,255 reviews from 19,400 users. With quantitative and human evaluation, we show that USN achieves state-ofthe-art performance on personalized review summarization. Introduction Review summarization aims to generate a condensed summary for a review or multiple reviews (Hu and Liu 2004; Ganesan 2010; Carenini, Cheung, and Pauls 2013; Gerani et al. 2014; Lu and Wang 2016). As this task can alleviate the information overload problem, it has been widely studied. This paper addresses personalization issues of review summarization1, which have not been discussed in previous research. Given a review, different users may care about different contents according to their own experiences or thoughts. Figure 1 illustrates the motivation with a hotel review sample. Bob may travel on business and he cares about location and room more than price, while John may travel on a tight budget and care about price more. What’s more, different users have their own writing styles. Alice often summarizes reviews with the words which can explicitly express her emotions, such as “love” or “hate”, while Bob and John don’t do that. Actually, personalized review summarization is applicable to a wide range of online consumer review platforms, Copyright c © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. In this paper, we focus on single-review summarization and we leave adapting our model to multi-review summarization scenario to future work. Review: The hotel is right next to the airport (my room had a view of the runways) but the noise is pretty well dampened so that is not an issue at all. Very convenient to the airport obviously, but also the main highways. Room was clean and comfortable, no complaints there. The price is a little high, but it is ok for me. Summary: very quite room in a great location.","

The paper discusses personalized review summarization, which generates a condensed summary for a user's review, accounting for their preference on different aspects or writing style. The proposed model, User-aware Sequence Network (USN), considers the user's characteristics when generating summaries, containing a user-aware encoder and decoder. The user-aware encoder selects important information of a review, and the user-aware decoder incorporates user characteristics and word-using habits to generate personalized summaries. The model was validated using a new dataset, and achieved state-of-the-art performance on personalized review summarization. The paper focuses on single-review summarization and leaves adapting the model to multi-review summarization scenarios for future work. The review provided is about a hotel near the airport, with a clean and comfortable room and a slightly high price. The summary generated is ""very quite room in a great location.""","{'What is the purpose of the summaries?': 'The authors are generating summaries of reviews to alleviate the problem of information overload and to provide condensed summaries for users.', 'Who is the target audience?': 'The summaries are for different users who may have different preferences and interests in the content of the reviews.', 'How will the summaries be used?': 'The summaries can be used by users to choose products or services based on their preferences and interests. They can also be used to generate personalized summaries for different readers.'}","['corpus', 'method']",[],[],[],[],https://github.com/Junjieli0704/USN,https://doi.org/10.1609/aaai.v33i01.33016690,"{'Personalization issues of review summarization have not been discussed in previous research.': ""The authors propose a User-aware Sequence Network (USN) for personalized review summarization, which considers users' different preferences on review content and writing styles."", 'Different users may care about different contents according to their own experiences or thoughts.': 'The authors design two kinds of user-based representations for personalized review summarization, including user embedding and user-specific vocabulary memory.', 'Classical review summarization systems only summarize reviews based on review contents and show the same summaries to all readers.': ""Personalized review summarization can consider readers' preference and generate different summaries of reviews for different readers."", 'It is difficult to evaluate personalized review summarization.': 'The authors collect a new personalized review summarization dataset named Trip from Tripadvisor website and conduct quantitative and human evaluation to show that USN achieves state-of-the-art performance on personalized review summarization.'}",,['Reviews'],['controlled-and-tailored-summarization']
SP:ef84e5b1816d46a907a808599d9c4c188bec4fce,A Statistical Analysis of Summarization Evaluation Metrics Using Resampling Methods,TACL,2021,"['Daniel Deutsch', 'Rotem Dror', 'Dan Roth']","The quality of a summarization evaluation metric is quantified by calculating the correlation between its scores and human annotations across a large number of summaries. Currently, it is unclear how precise these correlation estimates are, nor whether differences between two metrics’ correlations reflect a true difference or if it is due to mere chance. In this work, we address these two problems by proposing methods for calculating confidence intervals and running hypothesis tests for correlations using two resampling methods, bootstrapping and permutation. After evaluating which of the proposed methods is most appropriate for summarization through two simulation experiments, we analyze the results of applying these methods to several different automatic evaluation metrics across three sets of human annotations. We find that the confidence intervals are rather wide, demonstrating high uncertainty in the reliability of automatic metrics. Further, although many metrics fail to show statistical improvements over ROUGE, two recent works, QAEval and BERTScore, do so in some evaluation settings.1","The paper discusses the challenges in evaluating the quality of summarization evaluation metrics and proposes methods for calculating confidence intervals and running hypothesis tests for correlations using two resampling methods, bootstrapping and permutation. The authors evaluate the proposed methods through simulation experiments and apply them to several automatic evaluation metrics across three sets of human annotations. They find that confidence intervals are wide, indicating high uncertainty in the reliability of automatic metrics. However, two recent works, QAEval and BERTScore, show statistical improvements over ROUGE in some evaluation settings.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the quality of summarization models.', 'Who is the target audience?': 'The summaries are for researchers who want to compare the effectiveness of different summarization models.', 'How will the summaries be used?': 'The summaries will be used to determine which automatic metrics are the best approximation of human judgments and to evaluate the effectiveness of different summarization models.'}",['analysis'],[],[],[],[],https://github.com/CogComp/stat-analysis-experiments,https://aclanthology.org/2021.tacl-1.67,"{'Manually annotating summary quality is costly and time-consuming, making it difficult to accurately estimate the quality of a summary and compare summarization models.': 'Researchers have developed automatic metrics that approximate human judgments, but there is no standard practice in summarization for calculating confidence intervals (CIs) for the correlation values or running hypothesis tests on the difference between two metrics’ correlations. The authors propose methods for calculating CIs and running hypothesis tests for summarization metrics using resampling techniques of bootstrapping and permutation. They propose three different bootstrapping and permutation techniques for resampling matrices, each of which makes different assumptions about whether the systems or inputs are constant or variable in the calculation.', 'The summarization community has relatively low certainty in how similarly automatic metrics rank summaries with respect to humans.': 'The authors analyze the results of estimating CIs and applying hypothesis testing to a set of summarization metrics using annotations on English single- and multi-document datasets. They find that the CIs for the metrics’ correlations are all rather wide, indicating low certainty. Additionally, the hypothesis tests reveal that QAEval and BERTScore emerge as the best metrics in several experimental settings, whereas no other metric consistently achieves statistically better performance than ROUGE.', 'There is no standard practice in summarization for calculating confidence intervals (CIs) for the correlation values or running hypothesis tests on the difference between two metrics’ correlations.': 'The authors propose methods for calculating CIs and running hypothesis tests for summarization metrics using resampling techniques of bootstrapping and permutation. They perform two simulations to evaluate which resampling methods are most appropriate for summarization and demonstrate the usefulness of their methods through these simulations.'}",,['News'],['robust-evaluation-methods']
SP:2d14e3034879e978be0f585476407001f4a3a33d,Point at the Triple: Generation of Text Summaries from Knowledge Base Triples (Extended Abstract),IJCAI,2020,"['Pavlos Vougiouklis', 'Elena Simperl']","We investigate the problem of generating natural language summaries from knowledge base triples. Our approach is based on a pointer-generator network, which, in addition to generating regular words from a fixed target vocabulary, is able to verbalise triples in several ways. We undertake an automatic and a human evaluation on single and opendomain summaries generation tasks. Both show that our approach significantly outperforms other data-driven baselines.","System: The paper discusses a method for generating natural language summaries from knowledge base triples using a pointer-generator network. The network can generate regular words and verbalize triples in multiple ways. The approach was evaluated through automatic and human evaluations on single and open-domain summaries generation tasks, and it outperformed other data-driven baselines significantly.","{'What is the purpose of the summaries?': 'The authors are generating summaries of structured-data records in a human-readable way to capture their content.', 'Who is the target audience?': 'The summaries are for anyone who needs to understand the content of structured-data records, such as knowledge graphs.', 'How will the summaries be used?': 'The summaries can be used to provide a quick and easy-to-understand overview of the content of structured-data records, which can be useful in various applications, such as information retrieval and decision-making.'}",['method'],[],[],[],[],,https://doi.org/10.24963/ijcai.2020/711,"{'NLG systems struggle to verbalise rare or previously unseen entities, which are represented as placeholder tokens in the output and are meant to be replaced in a post-processing step. This introduces a degree of stochastic behaviour when multiple relations from the input match the predicted placeholders.': 'The authors propose an approach inspired by pointer-generator networks which jointly learn to verbalise the entities from pointed triples in several ways, copy the label or the number in the case that the pointed triple consists of either infrequent entities or numbers, and generate words or other human-readable realisations of entities from a fixed vocabulary.', 'NLG systems only report their performance on one domain, people’s biographies.': ""The authors create a dataset encompassing the entirety of Wikipedia rather than just the biographies to demonstrate their model's ability to generalise on a much more challenging task."", 'NLG systems struggle to scale to open-domain tasks.': 'The authors evaluate their approach in both the widely cited task of biographies generation and the generation of open-domain Wikipedia summaries, and their systems outperform a variety of competing baselines of different natures.', 'NLG systems may generate summaries with contradictions.': 'The authors run a user study in which they explore the fluency and coverage of the summaries, as well as the presence of contradictions.'}",,['Biographies'],[]
SP:b5a148153a7ae4fd06bb324e4f6273d02434d3ab,Summarizing Relationships for Interactive Concept Map Browsers,EMNLP,2019,"['Abram Handler', 'Prem Ganeshkumar', 'Brendan O’Connor', 'Mohamed AlTantawy', 'Slobodan Milosevic']","Concept maps are visual summaries, structured as directed graphs: important concepts from a dataset are displayed as vertexes, and edges between vertexes show natural language descriptions of the relationships between the concepts on the map. Thus far, preliminary attempts at automatically creating concept maps have focused on building static summaries. However, in interactive settings, users will need to dynamically investigate particular relationships between pairs of concepts. For instance, a historian using a concept map browser might decide to investigate the relationship between two politicians in a news archive. We present a model which responds to such queries by returning one or more short, importance-ranked, natural language descriptions of the relationship between two requested concepts, for display in a visual interface. Our model is trained on a new public dataset, collected for this task. Code and data are available at: https://github.com/slanglab/ concept_maps_newsum19","The paper discusses concept maps, which are visual summaries of important concepts from a dataset displayed as vertexes with edges showing natural language descriptions of relationships between concepts. While previous attempts at creating concept maps have been static, the paper presents a model that responds to queries by returning short, importance-ranked, natural language descriptions of the relationship between two requested concepts for display in a visual interface. The model is trained on a new public dataset and code and data are available at a specific GitHub link.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create visual concept maps that summarize important concepts from a corpus.', 'Who is the target audience?': 'The concept maps are for users who want to query relationships between concepts in an interactive setting.', 'How will the summaries be used?': 'The concept maps will be used as a visual network with labeled edges that summarize the relationships between queried concepts.'}","['corpus', 'method']",[],[],[],[],https://github.com/slanglab/concept_maps_newsum19,https://aclanthology.org/D19-5414,"{'The authors note that initial attempts to generate English-language concept maps within natural language processing have focused on creating static diagrams which summarize collections of documents. However, in interactive settings, users will want to query relationships with a concept map interface, rather than simply read over fixed output from a summarization system.': 'The authors propose an interactive system that includes both concepts in a visual network, along with a labeled edge that summarizes their relationship. They aim to select the best extractive, natural language summary statement which summarizes the relationship between a pair of input query concepts, denoted (t1) and (t2).', 'The authors note that there is no existing supervision to guide the selection of the best extractive, natural language summary statement which summarizes the relationship between a pair of input query concepts.': 'The authors collect a new dataset of annotated summary statements, which they use to supervise a new model for this task. Their study thus presents a full system for summarizing the relationship between an arbitrary pair of query concepts, extending prior work on relational summarization and concept maps.'}",,['News'],['controlled-and-tailored-summarization']
SP:f88b17155fa8758aacd18b205b31a509aa486e3c,BillSum: A Corpus for Automatic Summarization of US Legislation,EMNLP,2019,"['Anastassia Kornilova', 'Vlad Eidelman']","Automatic summarization methods have been studied on a variety of domains, including news and scientific articles. Yet, legislation has not previously been considered for this task, despite US Congress and state governments releasing tens of thousands of bills every year. In this paper, we introduce BillSum, the first dataset for summarization of US Congressional and California state bills (https://github.com/ FiscalNote/BillSum). We explain the properties of the dataset that make it more challenging to process than other domains. Then, we benchmark extractive methods that consider neural sentence representations and traditional contextual features. Finally, we demonstrate that models built on Congressional bills can be used to summarize California bills, thus, showing that methods developed on this dataset can transfer to states without human-written summaries.","The paper introduces BillSum, the first dataset for summarization of US Congressional and California state bills. The authors explain the challenges in processing this type of data and benchmark extractive methods that consider neural sentence representations and traditional contextual features. They also demonstrate that models built on Congressional bills can be used to summarize California bills, showing that methods developed on this dataset can transfer to states without human-written summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense the input document into a shorter text while retaining the salient information of the original.', 'Who is the target audience?': 'The summaries are for political scientists, legal scholars, politicians, lawyers, citizens, and individuals who need to quickly process long and technical documents.', 'How will the summaries be used?': 'The summaries will be used to identify the key details of the documents and to encourage research into automatic legislative summarization.'}",['corpus'],[],[],[],[],https://github.com/FiscalNote/BillSum,http://arxiv.org/abs/1910.00523,"{'The growing number of publicly available legal documents makes it difficult for individuals to quickly process them and identify key details.': 'Encourage the adoption of computational tools and automatic summarization methods to condense the documents into shorter texts while retaining salient information.', 'State and local legislatures do not have human-written summaries for bills like the Congressional Research Service (CRS) provides for US bills.': 'Introduce the BillSum dataset, which contains a primary corpus of 22,218 US Congressional bills and reference summaries split into a train and a test set, as well as an additional test set of 1,237 California bills and reference summaries.', 'Current automatic summarization methods are not well-suited to summarize technical legislative language.': 'Establish several benchmarks and encourage the development of new methods that are better suited to summarize technical legislative language.'}",,['Legislative Bills'],"['information-loss-and-incoherence-in-extractive-summarization', 'exploiting-the-structure-of-long-documents']"
SP:12f93a36c73be88898f37bfcbbbaf83b1cd8811e,How well do you know your summarization datasets?,ACL,2021,"['Priyam Tejaswin', 'Dhruv Naik', 'Pengfei Liu']","State-of-the-art summarization systems are trained and evaluated on massive datasets scraped from the web. Despite their prevalence, we know very little about the underlying characteristics (data noise, summarization complexity, etc.) of these datasets, and how these affect system performance and the reliability of automatic metrics like ROUGE. In this study, we manually analyse 600 samples from three popular summarization datasets. Our study is driven by a six-class typology which captures different noise types (missing facts, entities) and degrees of summarization difficulty (extractive, abstractive). We follow with a thorough analysis of 27 state-of-the-art summarization models and 5 popular metrics, and report our key insights: (1) Datasets have distinct data quality and complexity distributions, which can be traced back to their collection process. (2) The performance of models and reliability of metrics is dependent on sample complexity. (3) Faithful summaries often receive low scores because of the poor diversity of references. We release the code, annotated data and model outputs.1","The paper discusses the lack of understanding of the characteristics of datasets used to train and evaluate summarization systems, and how they affect system performance and reliability of metrics. The authors manually analyze 600 samples from three popular summarization datasets and classify them into six categories based on noise types and summarization difficulty. They then analyze 27 state-of-the-art summarization models and 5 popular metrics, and report their findings on the distinct data quality and complexity distributions of datasets, the dependence of model performance and metric reliability on sample complexity, and the low scores received by faithful summaries due to poor diversity of references. The authors also release the code, annotated data, and model outputs.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to explore the underlying characteristics of different datasets and how they impact model performance and metric reliability.', 'Who is the target audience?': 'The summaries are for researchers in the field of automatic summarization.', 'How will the summaries be used?': 'The summaries will be used to inform data collection and preprocessing methods, explain model performance and metrics, and help researchers choose datasets and metrics more carefully.'}",['analysis'],[],[],[],[],https://github.com/priyamtejaswin/howwelldoyouknow,https://aclanthology.org/2021.findings-acl.303,"{'The authors note that while there have been major improvements in automatic summarization, few studies have focused on the underlying characteristics of different datasets, and how these impact model performance and metric reliability.': 'The authors perform intrinsic and model-centric evaluation of three popular summarization datasets (Gigaword, CNN/DM and XSum) to identify and quantify the different types of ""noise"" that could occur and penalize models, and to determine whether samples have different levels of difficulty.', 'The authors note that there is no information about the noise in the dataset, and the quantity and impact of noise on performance is unknown.': 'The authors perform manual inspection to identify and quantify the different types of noise that could occur and penalize models.', 'The authors note that the degree of summarization complexity and its impact on model performance is unknown.': 'The authors define a six-class typology to cover varying degrees of summarization difficulty and proceed to answer research questions related to the impact of these properties on model performance and metric reliability.', 'The authors note that metric reliability is complexity dependent, and they are interested in knowing if the metrics are more correlated with human judgment for simpler samples than complex ones.': 'The authors investigate metric reliability and explore inter-metric agreement and alignment with human judgment under different conditions. They also evaluate different models on a variety of metrics (automatic and human-judgment) to determine if the performance is consistent across metrics.'}",,['News'],[]
SP:60493830771ce8e8849c1fd0018cf63fa4b48d58,Topic Concentration in Query Focused Summarization Datasets,AAAI,2016,"['Tal Baumel', 'Raphael Cohen', 'Michael Elhadad']","Query-Focused Summarization (QFS) summarizes a document cluster in response to a specific input query. QFS algorithms must combine query relevance assessment, central content identification, and redundancy avoidance. Frustratingly, state of the art algorithms designed for QFS do not significantly improve upon generic summarization methods, which ignore query relevance, when evaluated on traditional QFS datasets. We hypothesize this lack of success stems from the nature of the dataset. We define a task-based method to quantify topic concentration in datasets, i.e., the ratio of sentences within the dataset that are relevant to the query, and observe that the DUC 2005, 2006 and 2007 datasets suffer from very high topic concentration. We introduce TD-QFS, a new QFS dataset with controlled levels of topic concentration. We compare competitive baseline algorithms on TD-QFS and report strong improvement in ROUGE performance for algorithms that properly model query relevance as opposed to generic summarizers. We further present three new and simple QFS algorithms, RelSum, ThresholdSum, and TFIDF-KLSum that outperform state of the art QFS algorithms on the TD-QFS dataset by a large margin.","The paper discusses Query-Focused Summarization (QFS), which summarizes a document cluster in response to a specific input query. The authors note that current state-of-the-art algorithms for QFS do not significantly improve upon generic summarization methods, which ignore query relevance, when evaluated on traditional QFS datasets. They hypothesize that this is due to the high topic concentration in these datasets. To address this, they introduce a new QFS dataset with controlled levels of topic concentration and compare algorithms on this dataset. They report strong improvement in performance for algorithms that properly model query relevance and present three new QFS algorithms that outperform state-of-the-art methods on the new dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of document clusters in response to a specific input query.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document cluster in response to a specific query.', 'How will the summaries be used?': 'The summaries can be used to quickly identify the central content of a document cluster in response to a specific query, without having to read through all the documents in the cluster.'}",['corpus'],[],[],[],[],,http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11939,"{'State of the art algorithms designed for QFS do not significantly improve upon generic summarization methods, which ignore query relevance, when evaluated on traditional QFS datasets.': 'The authors hypothesize that this lack of success stems from the nature of the dataset. They introduce a new task-based method to quantify topic concentration in datasets and introduce a new QFS dataset with controlled levels of topic concentration.', 'The traditional QFS datasets suffer from very high topic concentration.': 'The authors introduce a new QFS dataset called TD-QFS with controlled levels of topic concentration.', 'The performance of QFS algorithms can be improved by properly modeling query relevance.': 'The authors compare competitive baseline algorithms on TD-QFS and report strong improvement in ROUGE performance for algorithms that properly model query relevance as opposed to generic summarizers. They further present three new and simple QFS algorithms, RelSum, ThresholdSum, and TFIDF-KLSum that outperform state of the art QFS algorithms on the TD-QFS dataset by a large margin.'}",,['Medical Reports'],[]
SP:77bcaad14228cfe0e57faeedfa31adf2ffdf68bb,Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization,ACL,2022,"['Meng Cao', 'Yue Dong', 'Jackie Chi', 'Kit Cheung']","State-of-the-art abstractive summarization systems often generate hallucinations; i.e., content that is not directly inferable from the source text. Despite being assumed incorrect, we find that much hallucinated content is factual, namely consistent with world knowledge. These factual hallucinations can be beneficial in a summary by providing useful background information. In this work, we propose a novel detection approach that separates factual from non-factual hallucinations of entities. Our method utilizes an entity’s prior and posterior probabilities according to pre-trained and finetuned masked language models, respectively. Empirical results suggest that our approach outperforms five baselines and strongly correlates with human judgments. Furthermore, we show that our detector, when used as a reward signal in an off-line reinforcement learning (RL) algorithm, significantly improves the factuality of summaries while maintaining the level of abstractiveness.1","The paper discusses how abstractive summarization systems often generate content that is not directly inferable from the source text, known as ""hallucinations."" However, the authors found that much of this hallucinated content is factual and can provide useful background information in a summary. They propose a novel detection approach to separate factual from non-factual hallucinations of entities, using pre-trained and finetuned masked language models. Their approach outperforms five baselines and strongly correlates with human judgments. The authors also show that their detector, when used as a reward signal in an off-line reinforcement learning algorithm, significantly improves the factuality of summaries while maintaining the level of abstractiveness.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the efficiency of information retrieval and comprehension.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document, such as researchers, students, and professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and analyzing large amounts of text, as well as to improve the accuracy and factuality of generated summaries. They can also be used to train and improve abstractive summarization systems.'}","['corpus', 'analysis']",[],[],[],[],https://github.com/mcao516/EntFA,https://aclanthology.org/2022.acl-long.236,"{'Abstractive summarization systems are prone to hallucinating content that is not supported by the source document.': 'The authors propose a method to classify entities according to whether they are hallucinations and whether they are factual (if hallucinated). They focus on entities (e.g., persons, locations, dates, cardinal numbers) because they are necessary to express the most salient pieces of information in a summary. They use the prior and posterior probabilities of an entity being in a summary to predict its hallucination status and factuality.', 'Previous studies commonly assume that hallucination is an undesirable behavior in abstractive summarization systems.': 'The authors argue that not all hallucinations should be treated equally; in particular, factual hallucinations may be less deleterious or even potentially beneficial to be included in a summary, as opposed to non-factual ones.', 'Due to the lack of fine-grained hallucination annotation, it is difficult to evaluate the proposed method.': 'The authors create an entity-level hallucination and factuality annotation on the XSUM dataset. They evaluate their detection method on this annotated dataset as well as annotations from Maynez et al. (2020).', 'The factuality of generated summaries is often low, even when the underlying dataset is noisy.': 'The authors show that their detector, when used as a reward signal in training neural-based summarizers with the off-line RL algorithm, significantly improves the factuality of generated summaries while maintaining the level of abstractiveness.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:1ca239d12770ff8e7dc8ebe44787c0671d4fdadb,Generating a Structured Summary of Numerous Academic Papers: Dataset and Method,IJCAI,2022,"['Shuaiqi LIU', 'Jiannong Cao', 'Zhiyuan Wen']","Writing a survey paper on one research topic usually needs to cover the salient content from numerous related papers, which can be modeled as a multi-document summarization (MDS) task. Existing MDS datasets usually focus on producing the structureless summary covering a few input documents. Meanwhile, previous structured summary generation works focus on summarizing a single document into a multi-section summary. These existing datasets and methods cannot meet the requirements of summarizing numerous academic papers into a structured summary. To deal with the scarcity of available data, we propose BigSurvey, the first large-scale dataset for generating comprehensive summaries of numerous academic papers on each topic. We collect target summaries from more than seven thousand survey papers and utilize their 430 thousand reference papers’ abstracts as input documents. To organize the diverse content from dozens of input documents and ensure the efficiency of processing long text sequences, we propose a summarization method named category-based alignment and sparse transformer (CAST). The experimental results show that our CAST method outperforms various advanced summarization methods.","The paper discusses the challenges of summarizing numerous academic papers into a structured summary and proposes a solution called BigSurvey, which is a large-scale dataset for generating comprehensive summaries of academic papers on each topic. The authors utilize target summaries from over 7,000 survey papers and their 430,000 reference papers' abstracts as input documents. They also propose a summarization method called category-based alignment and sparse transformer (CAST), which outperforms various advanced summarization methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of academic papers to help researchers quickly browse key information in numerous papers on the same research topic.', 'Who is the target audience?': 'The summaries are for researchers who are interested in a particular research topic and need to review numerous papers on that topic.', 'How will the summaries be used?': 'The summaries can be used as a supplement to human-written summaries to cover the latest papers and more research topics at a low cost. They can also be used to generate comprehensive, well-organized, and non-redundant summaries for numerous papers on the same research topic.'}","['corpus', 'method']",[],[],[],[],https://github.com/StevenLau6/BigSurvey,https://doi.org/10.48550/arXiv.2302.04580,"{'The growing number of academic papers makes it difficult for researchers to read through numerous papers on a research topic.': 'Multidocument summarization (MDS) techniques can be utilized to automatically produce summaries as a supplement to human-written summaries.', 'Writing a survey paper needs a lot of time and effort, making it difficult to cover the latest papers and all the research topics.': 'To cover the latest papers and more research topics at a low cost, people can flexibly adjust the input papers and let the summarization methods produce summaries for these papers.', 'Scarcity of available data for MDS.': 'The authors propose BigSurvey, the first large-scale dataset for numerous academic papers summarization. It contains more than seven thousand survey papers and their 434 thousand reference papers’ abstracts.', 'It is challenging for a summary to organize and present the diverse content from dozens of input documents.': 'The authors propose a structured summary that contains multiple sections summarizing particular aspects of input content. They also propose the category-based alignment (CA) to align each section of the structured summary with a set of input sentences classified as the same type.', 'Long input sequences can reduce the efficiency of summarization models.': 'The authors propose a method named category-based alignment and sparse transformer (CAST) that uses the transformer with the sparse attention mechanism for abstractive summarization.', 'The need for benchmarking advanced extractive and abstractive summarization methods on the BigSurvey dataset.': 'The authors benchmark various summarization methods on their dataset and find that adding the category-based alignment can bring extra performance gains for various methods.'}",,['Scholarly Documents'],"['efficient-encoding-of-long-documents', 'lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:2c41e7935baea216d1beca1760bfb0ae3ae3ab47,A Corpus of Very Short Scientific Summaries,CONLL,2020,"['Yifan Chen', 'Tamara Polajnar', 'Colin Batchelor', 'Simone Teufel']","We present a new summarisation task, taking scientific articles and producing journal tableof-contents entries in the chemistry domain. These are oneor two-sentence author-written summaries that present the key findings of a paper. This is a first look at this summarisation task with an open access publication corpus consisting of titles and abstracts, as input texts, and short author-written advertising blurbs, as the ground truth. We introduce the dataset and evaluate it with state-of-the-art summarisation methods.",System: The paper introduces a new task of summarizing scientific articles in the chemistry domain into one or two-sentence table of contents entries. The authors use an open access publication corpus and evaluate their approach using state-of-the-art summarization methods.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to create a corpus that can be used to test the usefulness of deep learning models in producing a latent semantic representation of chemical texts.', 'Who is the target audience?': ""The summaries are for readers of scientific journals who are looking for a clear and concise summary of a paper's main contribution."", 'How will the summaries be used?': ""The summaries will be used to aid in the journal editing process and potentially in tasks like plagiarism detection or semantic search and discovery. They will also be used to compare models' abilities to accurately substitute multiword terms for chemical formulae or an accurate hyponym like ketone, without ontological knowledge.""}",['corpus'],[],[],[],[],http://rsc.li/RSCsum,https://aclanthology.org/2020.conll-1.12,"{'Lack of clear and concise summaries of chemistry papers in the table of contents of journals.': 'The authors propose to use titles and abstracts from chemistry papers published by the Royal Society of Chemistry as input in this initial study to create short summaries for the table of contents.', 'Lack of domain-specific resources for NLP pipelines in chemistry.': 'The authors introduce a summarisation corpus to address this problem and hope that it will be the first of many resources that will aid researchers in this field.', 'Difficulty in accurately substituting multiword terms for chemical formulae or an accurate hyponym like ketone, without ontological knowledge.': 'The authors aim to produce representations that can accurately substitute multiword terms for chemical formulae or an accurate hyponym like ketone, and this corpus is one in a set of tools that will help them compare models’ abilities to do this.'}",,['Scholarly Documents'],['lack-of-suitable-training-data']
SP:1fd4c298d23909c53b8f6eff7f4be940782f33b8,A Closer Look at Data Bias in Neural Extractive Summarization Models,EMNLP,2019,"['Ming Zhong', 'Danqing Wang', 'Pengfei Liu', 'Xipeng Qiu', 'Xuanjing Huang']","In this paper, we take stock of the current state of summarization datasets and explore how different factors of datasets influence the generalization behaviour of neural extractive summarization models. Specifically, we first propose several properties of datasets, which matter for the generalization of summarization models. Then we build the connection between priors residing in datasets and model designs, analyzing how different properties of datasets influence the choices of model structure design and training methods. Finally, by taking a typical dataset as an example, we rethink the process of the model design based on the experience of the above analysis. We demonstrate that when we have a deep understanding of the characteristics of datasets, a simple approach can bring significant improvements to the existing stateof-the-art model.",System: The paper discusses the current state of summarization datasets and how different factors of datasets affect the generalization behavior of neural extractive summarization models. The authors propose several properties of datasets that matter for the generalization of summarization models and analyze how different properties of datasets influence the choices of model structure design and training methods. They demonstrate that a deep understanding of dataset characteristics can lead to significant improvements in existing models.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to explore the impact of dataset characteristics on the generalization ability of neural extractive summarization models.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of natural language processing and machine learning.', 'How will the summaries be used?': 'The summaries will be used to diagnose the weakness of existing learning methods and to guide the design of more reasonable models for text summarization tasks. They will also encourage future research on how dataset characteristics influence the behavior of neural networks.'}",['analysis'],[],[],[],[],,https://aclanthology.org/D19-5410,"{""The authors note that despite the success of neural network-based models on summarization tasks, there is a lack of understanding of the impact of dataset characteristics on the models' generalization ability."": 'The authors explore two types of factors (constituent factors and style factors) that affect the generalization of neural summarization models and diagnose the weakness of existing models.', 'The authors seek to understand how different properties of datasets influence the choices of model structure design and training schemas.': 'The authors propose some measures and examine their abilities to explain how different model architectures, training schemas, and pretraining strategies react to various properties of datasets.'}",,"['News', 'Scholarly Documents']",['pretraining-and-sample-efficiency']
SP:d10edda72ec12a15eca3dab29f67691e4cf5e881,BrailleSUM: A News Summarization System for the Blind and Visually Impaired People,ACL,2015,"['Xiaojun Wan', 'Yue Hu']","In this article, we discuss the challenges of document summarization for the blind and visually impaired people and then propose a new system called BrailleSUM to produce better summaries for the blind and visually impaired people. Our system considers the factor of braille length of each sentence in news articles into the ILPbased summarization method. Evaluation results on a DUC dataset show that BrailleSUM can produce shorter braille summaries than existing methods, meanwhile, it does not sacrifice the content quality of the summaries.",System: The paper discusses the challenges of document summarization for the blind and visually impaired people and proposes a new system called BrailleSUM. The system takes into account the length of each sentence in news articles and uses an ILP-based summarization method. Evaluation results show that BrailleSUM can produce shorter braille summaries without sacrificing content quality.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to make it easier for blind and visually impaired people to read news articles.', 'Who is the target audience?': 'The summaries are for blind and visually impaired people who cannot read ordinary news documents like sighted people.', 'How will the summaries be used?': 'The summaries will be translated into braille format and used by blind and visually impaired people to read news articles with less burden on their fingertips.'}",['method'],[],[],[],[],,https://aclanthology.org/P15-2095/,"{'Blind and visually impaired people cannot directly or conveniently read ordinary news documents like sighted people.': 'Translate news documents into Braille using special equipment such as refreshable braille displays and braille embosser.', 'Most daily news documents are written for sighted people, and it is necessary to first translate the news documents into Braille.': 'Develop a system called BrailleSUM to produce better summaries for blind and visually impaired people.', 'Reading a braille text by touching each braille cell with fingertips is more difficult and inconvenient than reading a normal text with eyes.': 'Produce shorter braille summaries to reduce the burden on blind and visually impaired people when reading with their fingertips.', 'Existing summarization systems focus on content quality and fluency of summaries, but they are produced for sighted people, not for blind and visually impaired people.': 'Consider the factor of braille length of each sentence in news articles into the ILP-based summarization method to produce better summaries for blind and visually impaired people.', 'The major challenge of document summarization for blind and visually impaired people is producing shorter braille summaries while maintaining content quality and fluency.': 'Develop BrailleSUM, a system that can produce much shorter braille summaries than existing methods without sacrificing content quality.'}",,['News'],[]
SP:65de68289ecc0e9b9cba0cfc09b65abe29e7083b,SummEval: Re-evaluating Summarization Evaluation,TACL,2021,"['Alexander R. Fabbri', 'Wojciech Kryściński', 'Bryan McCann', 'Caiming Xiong', 'Richard Socher', 'Dragomir Radev']","The scarcity of comprehensive up-to-date studies on evaluation metrics for text summarization and the lack of consensus regarding evaluation protocols continue to inhibit progress. We address the existing shortcomings of summarization evaluation methods along five dimensions: 1) we re-evaluate 14 automatic evaluation metrics in a comprehensive and consistent fashion using neural summarization model outputs along with expert and crowdsourced human annotations; 2) we consistently benchmark 23 recent summarization models using the aforementioned automatic evaluation metrics; 3) we assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format; 4) we implement and share a toolkit that provides an extensible and unified API for evaluating summarization models across a broad range of automatic metrics; and 5) we assemble and share the largest and most diverse, in terms of model types, collection of human judgments of modelgenerated summaries on the CNN/Daily Mail dataset annotated by both expert judges and crowd-source workers. We hope that this work will help promote a more complete evaluation protocol for text summarization as well as advance research in developing evaluation metrics that better correlate with human","judgments. The paper addresses the lack of consensus and comprehensive studies on evaluation metrics for text summarization. The authors re-evaluate 14 automatic evaluation metrics and benchmark 23 recent summarization models using these metrics. They also assemble the largest collection of summaries generated by models trained on the CNN/DailyMail news dataset and share it in a unified format. Additionally, they implement and share a toolkit for evaluating summarization models across a broad range of automatic metrics and assemble the largest and most diverse collection of human judgments of model-generated summaries on the CNN/Daily Mail dataset. The authors hope that their work will promote a more complete evaluation protocol for text summarization and advance research in developing evaluation metrics that better correlate with human judgments.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress long documents into a short, fluent, and human-readable form that preserves the most salient information from the source document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries will be used to help people quickly understand the main points of a long document without having to read the entire document.'}",['analysis'],[],[],[],[],https://github.com/Yale-LILY/SummEval,https://doi.org/10.1162/tacl_a_00373,"{'Existing work in text summarization vastly differs in their evaluation protocol, limiting model comparisons to only a few baselines and offering inconsistent human evaluations with prior work.': 'The authors propose re-evaluating 14 automatic evaluation metrics in a comprehensive and consistent fashion using outputs from recent neural summarization models along with expert and crowd-sourced human annotations.', 'Despite problems associated with the ROUGE metric when used outside of its original setting, it has remained the default automatic evaluation metric in text summarization.': 'The authors propose releasing a toolkit of 14 evaluation metrics with an extensible and unified API to promote the reporting of additional metrics in papers.', 'The lack of easy-to-use resources for evaluation, both in the form of simplified evaluation toolkits and large collections of model outputs, partially causes the shortcomings of the current evaluation protocol.': 'The authors propose releasing aligned summarization model outputs from 23 papers (44 model outputs) published between 2017 and 2019 trained on the CNN/DailyMail dataset to allow for large-scale comparisons of recent summarization models.', 'Many of the currently used metrics in text summarization were developed and assessed using datasets that contain human judgments for model outputs scoring on a lower scale compared to current summarization systems, putting into question the true performance of those metrics in the new setting.': 'The authors propose collecting and releasing expert, as well as crowd-sourced, human judgments for 16 model outputs on 100 articles over 4 dimensions to further research into human-correlated evaluation metrics.'}",,['News'],['robust-evaluation-methods']
SP:db63e7a61837b4453ac86b204b40ad4d5c44d1b6,AnswerSumm: A Manually-Curated Dataset and Pipeline for Answer Summarization,NAACL,2022,"['Alexander R. Fabbri', 'Xiaojian Wu', 'Srini Iyer', 'Haoran Li', 'Mona Diab']","Community Question Answering (CQA) fora such as Stack Overflow and Yahoo! Answers contain a rich resource of answers to a wide range of community-based questions. Each question thread can receive a large number of answers with different perspectives. One goal of answer summarization is to produce a summary that reflects the range of answer perspectives. A major obstacle for this task is the absence of a dataset to provide supervision for producing such summaries. Recent works propose heuristics to create such data, but these are often noisy and do not cover all answer perspectives present. This work introduces a novel dataset of 4,631 CQA threads for answer summarization curated by professional linguists. Our pipeline gathers annotations for all subtasks of answer summarization, including relevant answer sentence selection, grouping these sentences based on perspectives, summarizing each perspective, and producing an overall summary. We analyze and benchmark state-of-the-art models on these subtasks and introduce a novel unsupervised approach for multi-perspective data augmentation that boosts summarization performance according to automatic evaluation. Finally, we propose reinforcement learning rewards to improve factual consistency and answer coverage and analyze areas for improvement.","The paper discusses the challenge of answer summarization in Community Question Answering (CQA) fora such as Stack Overflow and Yahoo! Answers, where each question thread can receive a large number of answers with different perspectives. The absence of a dataset to provide supervision for producing such summaries is a major obstacle. The paper introduces a novel dataset of 4,631 CQA threads for answer summarization curated by professional linguists. The pipeline gathers annotations for all subtasks of answer summarization, including relevant answer sentence selection, grouping these sentences based on perspectives, summarizing each perspective, and producing an overall summary. The paper also introduces a novel unsupervised approach for multi-perspective data augmentation that boosts summarization performance according to automatic evaluation. Finally, the paper proposes reinforcement learning rewards to improve factual consistency and answer coverage and analyzes areas for improvement.",{},['corpus'],[],[],[],[],https://github.com/Alex-Fabbri/AnswerSumm,https://aclanthology.org/2022.naacl-main.180,"{'There is a need for text summarization to distill relevant information into a concise form, especially in the context of Community Question Answering (CQA) fora where a person can get an abundance of answers to sift through. Ideally, an answer summary should cover multiple perspectives found in the answers.': 'The authors propose a pipeline for multiperspective abstractive answer summarization, which includes subtasks such as selection of answer sentences relevant to the question, grouping these sentences based on perspectives, summarizing each perspective, and producing an overall fused summary. They also introduce the largest human-annotated dataset for answer summarization, containing components for sentence relevance, clustering, cluster summarization, and global answer summarization. They propose a data augmentation pipeline to further boost summarization performance and introduce entailment-based and semantic area RL rewards to ensure capturing all factually relevant perspectives.'}",,['CQA'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:1e7d2060915a13215561db15f618bb3472c6e5c8,"Mitigating Data Scarceness through Data Synthesis, Augmentation and Curriculum for Abstractive Summarization",EMNLP,2021,"['Ahmed Magooda', 'Diane Litman']","This paper explores three simple data manipulation techniques (synthesis, augmentation, curriculum) for improving abstractive summarization models without the need for any additional data. We introduce a method of data synthesis with paraphrasing, a data augmentation technique with sample mixing, and curriculum learning with two new difficulty metrics based on specificity and abstractiveness. We conduct experiments to show that these three techniques can help improve abstractive summarization across two summarization models and two different small datasets. Furthermore, we show that these techniques can improve performance when applied in isolation and when combined.","System: This paper discusses three techniques for improving abstractive summarization models without requiring additional data. These techniques include data synthesis with paraphrasing, data augmentation with sample mixing, and curriculum learning with two new difficulty metrics. The experiments conducted show that these techniques can improve summarization performance across two models and two small datasets, both when applied in isolation and when combined.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to highlight their contributions and findings.', 'Who is the target audience?': 'The summaries are for anyone interested in the research, including other researchers, practitioners, and the general public.', 'How will the summaries be used?': 'The summaries will be used to provide a brief overview of the research and its contributions, making it easier for readers to understand the main points without having to read the entire paper.'}",['method'],[],[],[],[],,https://aclanthology.org/2021.findings-emnlp.175,"{'Training complex neural models requires large amounts of data, but data annotation is challenging in many domains.': 'Data manipulation techniques such as synthesis and augmentation can be used to handle data differently during training.', 'Prior work on the synthesis of textual data has focused on back translation and word replacement, which can expose the model to grammatically or logically incorrect input.': 'The authors propose a different approach to data synthesis through paraphrasing.', 'Data manipulation through synthesis involves input-level manipulation, which can lead to incorrect input.': 'The authors explore a second approach to data manipulation based on augmentation, which moves data manipulation from the input side to any part of the model, making the model more resilient to over-fitting.', 'Training models with large amounts of data can be inefficient and time-consuming.': 'The authors integrate curriculum learning into the training process, which reorders training samples based on external criteria, making the model more efficient without the need for external data.', 'Curriculum learning requires difficulty metrics for curriculum construction.': 'The authors introduce new difficulty metrics based on specificity and abstractiveness for curriculum construction.', 'Data scarcity is a significant issue in training complex neural models.': 'The authors explore combining multiple techniques, such as synthesis and curriculum, to overcome the data scarcity issue.'}",,"['Student Responses', 'Reviews']","['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency', 'robust-evaluation-methods']"
SP:882f6b8aee08a259cec69cf67502fc2ba6b1aff0,Re-evaluating Evaluation in Text Summarization,EMNLP,2020,"['Manik Bhandari', 'Pranav Gour', 'Atabak Ashfaq', 'Pengfei Liu', 'Graham Neubig']","Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as text summarization. However, while the field has progressed, our standard metrics have not – for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for text summarization: assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both systemlevel and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive): https://github.com/neulab/REALSumm","

The paper discusses the importance of automated evaluation metrics in text summarization tasks and highlights the need to re-evaluate the current standard metric, ROUGE, which has been used for almost 20 years. The authors assess the reliability of automatic metrics using top-scoring system outputs on modern datasets and systems, both abstractive and extractive, for system-level and summary-level evaluation settings. They find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. The authors release a dataset of human judgments collected from 25 top-scoring neural summarization systems, which can be found on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of automatic summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of automatic summarization systems.', 'How will the summaries be used?': 'The summaries will be used to analyze the correspondence between various metrics and human evaluation, and to re-examine assumptions about the evaluation of automatic summarization systems. The authors call for future research to update and improve the evaluation process for summarization systems.'}",['analysis'],[],[],[],[],https://github.com/neulab/REALSumm,https://aclanthology.org/2020.emnlp-main.751,"{'Manual evaluation of text summarization is the gold standard but is time-consuming and costly, leading to the majority of research papers relying on automatic evaluation metrics such as ROUGE, JS-2, S3, BERTScore, and MoverScore. However, it is not clear how well these metrics correlate with human judgment and whether they are reliable for evaluating modern summarization systems.': 'Perform meta-evaluation using a dataset annotated with human judgments (e.g. TAC1 2008) to test the degree to which automatic metrics correlate with human judgment. Create a large benchmark for meta-evaluating summarization metrics, including outputs from 25 top-scoring extractive and abstractive summarization systems on the CNN/DailyMail dataset, automatic evaluations from several evaluation metrics, and manual evaluations using the lightweight pyramids method. Conduct four experiments analyzing the correspondence between various metrics and human evaluation to re-examine assumptions about the evaluation of automatic summarization systems. Highlight the need for future meta-evaluation to be across multiple datasets and evaluate metrics on different application scenarios, the need for more systematic metaevaluation of summarization metrics that updates with evolving systems and datasets, and the potential benefit of a shared task similar to the WMT Metrics Task in Machine Translation.'}",,['News'],['robust-evaluation-methods']
SP:f453ae98b466cb66df1bdba16acf981bd045e502,CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines,SIGIR,2022,"['Soham Poddar', 'Azlaan Mustafa Samad', 'Rajdeep Mukherjee', 'Niloy Ganguly', 'Saptarshi Ghosh']","Convincing people to get vaccinated against COVID-19 is a key societal challenge in the present times. As a first step towards this goal, many prior works have relied on social media analysis to understand the specific concerns that people have towards these vaccines, such as potential side-effects, ineffectiveness, political factors, and so on. Though there are datasets that broadly classify social media posts into Anti-vax and Pro-Vax labels, there is no dataset (to our knowledge) that labels social media posts according to the specific anti-vaccine concerns mentioned in the posts. In this paper, we have curated CAVES, the first large-scale dataset containing about 10k COVID-19 anti-vaccine tweets labelled into various specific anti-vaccine concerns in a multi-label setting. This is also the first multi-label classification dataset that provides explanations for each of the labels. Additionally, the dataset also provides class-wise summaries of all the tweets. We also perform preliminary experiments on the dataset and show that this is a very challenging dataset for multi-label explainable classification and tweet summarization, as is evident by the moderate scores achieved by some state-of-the-art models.","The paper discusses the societal challenge of convincing people to get vaccinated against COVID-19 and the use of social media analysis to understand specific concerns people have towards vaccines. The authors have curated CAVES, a large-scale dataset of about 10k COVID-19 anti-vaccine tweets labeled into various specific anti-vaccine concerns in a multi-label setting. This is the first multi-label classification dataset that provides explanations for each label and class-wise summaries of all tweets. Preliminary experiments show that this is a challenging dataset for multi-label explainable classification and tweet summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to help authorities quickly understand the concerns being raised by people about vaccines.', 'Who is the target audience?': 'The summaries are for social media researchers and authorities.', 'How will the summaries be used?': 'The summaries will be used to gain a fine-grained understanding of anti-vaccine concerns among the masses and to perform the task of multi-document or tweet-stream summarization.'}",['corpus'],[],[],[],[],https://github.com/sohampoddar26/caves-data,https://doi.org/10.1145/3477495.3531745,"{'A significant fraction of the population is skeptical about taking COVID-19 vaccines due to different reasons, and understanding their concerns is very important for convincing such people about the benefits of the vaccines.': 'The authors provide a large-scale dataset by annotating tweets into fine-grained concerns about vaccines, which can help social media researchers/authorities gain a fine-grained understanding of anti-vaccine concerns among the masses.', 'Researchers have only relied on human surveys/manual analysis at a small scale or unsupervised topic models which do not perform too well and require manual intervention to understand the reasons behind vaccine hesitancy.': 'The authors provide the first large-scale dataset of social media posts labeled with various reasons for vaccine hesitancy, which can aid the study of vaccine-related opinions on social media and help develop models for automated fine-grained retrieval and analysis of concerns people have towards vaccines.', 'Once the classes of anti-vaccine concerns are identified, it is important to summarize the tweets in a class so that authorities can quickly glance through the various concerns being raised by people and act accordingly to promote the use of vaccines.': 'The CAVES dataset contains human-compiled summaries of the tweets pertaining to each anti-vaccine concern (i.e., class-wise summaries), which can act as an excellent resource for performing the task of multi-document or tweet-stream summarization.', 'The performances in the multi-label classification and explanation generation tasks are not very high, indicating a need for better models for these tasks.': 'The authors provide the CAVES dataset along with benchmarking codes on Github, which can be used to develop better models for multi-label classification and explanation generation tasks.'}",,['Social Media'],['lack-of-suitable-training-data']
SP:8bd7bec1d32e3268c1b8a9aa311d71623e888045,ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining,ACL,2021,"['Alexander R. Fabbri', 'Faiaz Rahman', 'Imad Rizvi', 'Borui Wang', 'Haoran Li', 'Yashar Mehdad', 'Dragomir Radev']","While online conversations can cover a vast amount of information in many different formats, abstractive text summarization has primarily focused on modeling solely news articles. This research gap is due, in part, to the lack of standardized datasets for summarizing online discussions. To address this gap, we design annotation protocols motivated by an issues–viewpoints–assertions framework to crowdsource four new datasets on diverse online conversation forms of news comments, discussion forums, community question answering forums, and email threads. We benchmark state-of-the-art models on our datasets and analyze characteristics associated with the data. To create a comprehensive benchmark, we also evaluate these models on widely-used conversation summarization datasets to establish strong baselines in this domain. Furthermore, we incorporate argument mining through graph construction to directly model the issues, viewpoints, and assertions present in a conversation and filter noisy input, showing comparable or improved results according to automatic and human evaluations.","The paper discusses the lack of standardized datasets for summarizing online discussions, which has resulted in abstractive text summarization primarily focusing on news articles. To address this gap, the authors design annotation protocols to crowdsource four new datasets on diverse online conversation forms. They benchmark state-of-the-art models on these datasets and analyze characteristics associated with the data. They also evaluate these models on widely-used conversation summarization datasets to establish strong baselines in this domain. The authors incorporate argument mining through graph construction to directly model the issues, viewpoints, and assertions present in a conversation and filter noisy input, showing comparable or improved results according to automatic and human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of conversational data to address the research gap in summarizing online conversations and to test newly-developed models.', 'Who is the target audience?': 'The summaries are for researchers and developers working on conversation summarization models.', 'How will the summaries be used?': 'The summaries will be used to benchmark state-of-the-art models on several conversation datasets and to provide a clear baseline for future work. They will also be used to analyze the characteristics of the proposed datasets and to apply argument mining to reduce noise in long-text input.'}","['corpus', 'method']",[],[],[],[],,https://aclanthology.org/2021.acl-long.535,"{'Less work has focused on summarizing online conversations.': 'Crowdsourcing a suite of four datasets, called ConvoSumm, that can evaluate a model’s performance on a broad spectrum of conversation data. Identifying several key categories of data for which standard human-created development and testing datasets do not exist, namely (1) news article comments, (2) discussion forums and debate, (3) community question answering, and (4) email threads. Designing annotation protocols motivated by work in quantifying viewpoints present in news comment data to crowdsource 250 development and 250 test examples for each of the above domains.', 'The availability of benchmark datasets for comparing methods has limited work in other conversation summarization domains and thus likely inhibited progress.': 'Benchmarking a state-of-the-art abstractive model on several conversation datasets: dialogue summarization from SAMSum, heuristic-generated community question answering from CQASumm, meeting summarization data from AMI and ICSI, and smaller test sets in the news comments, discussion forum, and email domains.', 'Conversational text scatters main points across multiple utterances and between numerous writers, making the text summarization task in the conversational data domain challenging.': 'Using recent work in end-to-end argument mining to instantiate the theoretical graph framework which motivated the annotation protocol for conversation summarization. Employing the “issues–viewpoints–assertions” argument structure for summarizing news comments. Constructing this argument graph using entailment relations, linearizing the graph, training a graph-to-text model, and experimenting with argument mining as a way to reduce noise in long-text input.', 'Lack of uniformity in datasets used in recent conversation papers.': 'Introducing manually-curated datasets for conversation summarization, called ConvoSumm, for four domains of conversational data: news article comments, discussion forums and debate, community question answering, and email threads.'}",,['Forum Discussions'],['lack-of-suitable-training-data']
SP:7d33bd28b3a6401ea9f9737adaef50ea62c86206,ASPECTNEWS: Aspect-Oriented Summarization of News Documents,ACL,2022,"['Ojas Ahuja', 'Jiacheng Xu', 'Akshay Gupta', 'Kevin Horecka', 'Greg Durrett']","Generic summaries try to cover an entire document and query-based summaries try to answer document-specific questions. But real users’ needs often fall in between these extremes and correspond to aspects, high-level topics discussed among similar types of documents. In this paper, we collect a dataset of realistic aspect-oriented summaries, ASPECTNEWS, which covers different subtopics about articles in news sub-domains. We annotate data across two domains of articles, earthquakes and fraud investigations, where each article is annotated with two distinct summaries focusing on different aspects for each domain. A system producing a single generic summary cannot concisely satisfy both aspects. Our focus in evaluation is how well existing techniques can generalize to these domains without seeing in-domain training data, so we turn to techniques to construct synthetic training data that have been used in query-focused summarization work. We compare several training schemes that differ in how strongly keywords are used and how oracle summaries are extracted. Our evaluation shows that our final approach yields (a) focused summaries, better than those from a generic summarization system or from keyword matching; (b) a system sensitive to the choice of keywords.1","The paper discusses the limitations of generic and query-based summaries and proposes aspect-oriented summaries that focus on high-level topics discussed among similar types of documents. The authors collected a dataset of aspect-oriented summaries for articles in news sub-domains and evaluated existing techniques for generating such summaries without in-domain training data. They compared different training schemes and found that their final approach produced focused summaries that were better than those from a generic summarization system or keyword matching, and that the system was sensitive to the choice of keywords.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to produce aspect-oriented extractive summarization, which can provide tailored summaries to different users based on their information needs.', 'Who is the target audience?': 'The summaries are for users who require specific information from a document, such as political science researchers studying responses to earthquakes or fraud reports.', 'How will the summaries be used?': 'The summaries will be used to provide users with relevant information from a document, tailored to their specific needs, in realistic settings where a user is interested in vague aspects of the document.'}","['corpus', 'method']",[],[],[],[],https://github.com/oja/aosumm,https://aclanthology.org/2022.acl-long.449,"{'Current text summarization systems rely on large amounts of supervised data, which provide a single, generic, topic-agnostic summary, but fail to produce summaries tailored to the diverse information needs of different users.': 'The authors propose a new dataset for evaluating single-document aspect-oriented extractive summarization, called ASPECTNEWS, which includes subsets of examples from CNN/Daily Mail following certain topics. They ask annotators to select sentences relevant to specific information needs, which correspond to imagined use cases. They build a system that can summarize a document conditioned on certain aspect-level keywords without assuming annotated training data for those aspects.', 'There are no large-scale supervised training sets suitable for generating aspect-oriented training data from generic summaries.': 'The authors explore methods to generate aspect-oriented training data from generic summaries and compare these with past approaches on their ability to adapt to their aspect-oriented setting, which requires taking aspectual keyword inputs and being appropriately sensitive to these keywords.', 'Existing summarization models fail to produce aspect-oriented summaries that score high on agreement with human aspect-oriented annotations.': ""The authors' model produces summaries that score higher on agreement with human aspect-oriented annotations than generic summarization models, previous aspect-oriented models, and baselines such as keyword matching. They find that the summaries their model generates are sensitive to the choice of keywords."", 'Abstractive query-focused systems hallucinate significantly in the multi-document setting.': 'The authors justify their choice of an extractive framework for their aspect-oriented summarization system, as they find that abstractive query-focused systems hallucinate significantly in this setting.'}",,['News'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:620620792c12d134fb641a00351763427d319833,On the Summarization of Consumer Health Questions,ACL,2019,"['Asma Ben Abacha', 'Dina Demner-Fushman']","Question understanding is one of the main challenges in question answering. In real world applications, users often submit natural language questions that are longer than needed and include peripheral information that increases the complexity of the question, leading to substantially more false positives in answer retrieval. In this paper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000 summarized consumer health questions. We explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this new task. In particular, we show that semantic augmentation from question datasets improves the overall performance, and that pointer-generator networks outperform sequence-to-sequence attentional models on this task, with a ROUGE-1 score of 44.16%. We also present a detailed error analysis and discuss directions for improvement that are specific to question summarization.","The paper discusses the challenge of question understanding in question answering, particularly in the context of natural language questions that are longer than necessary and contain peripheral information. The authors study neural abstractive models for medical question summarization and introduce the MeQSum corpus of 1,000 summarized consumer health questions. They explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this task. The authors show that semantic augmentation from question datasets improves performance and that pointer-generator networks outperform sequence-to-sequence attentional models, achieving a ROUGE-1 score of 44.16%. The paper also includes a detailed error analysis and suggestions for improving question summarization.",{},['corpus'],[],[],[],[],,https://aclanthology.org/P19-1215,"{'Teaching machines how to automatically understand natural language questions to retrieve relevant answers is a challenging task due to different factors such as the question length, lexical heterogeneity, and lack of domain-specific training datasets.': 'Several efforts proposed interactive and non-interactive query relaxation techniques to translate the input questions into structured queries covering specific elements of the questions. Other efforts focused on identifying question similarity and question entailment in order to retrieve similar or entailed questions that have associated answers, or paraphrasing the questions and submitting the simplified versions to QA systems.', 'Question simplification or summarization was less studied than the summarization of news articles that has been the focus of neural abstractive methods in recent years.': 'The authors tackle the task of consumer health question summarization, defining it as generating a condensed question expressing the minimum information required to find correct answers to the original question. They create a new corpus of 1K consumer health questions and their summaries based on this definition.', 'Patients and their families tend to provide numerous peripheral details such as the patient history that are not always needed to find correct answers.': 'Question summarization plays a key role in improving the performance of QA systems, and the authors focus on consumer health questions as a natural candidate for this task. They explore data augmentation techniques, including semantic selection from open-domain datasets, and study the behavior of state-of-the-art neural abstractive models on the original and augmented datasets. They also present a detailed error analysis and discuss potential areas of improvements for consumer health question summarization.'}",,['CQA'],['lack-of-suitable-training-data']
SP:26856ce2d21634c5417a8bcdcd8a585aa3e8c5f7,WikiAsp: A Dataset for Multi-domain Aspect-based Summarization,TACL,2021,"['Hiroaki Hayashi', 'Prashant Budania', 'Peng Wang', 'Chris Ackerson', 'Raj Neervannan', 'Graham Neubig']","Aspect-based summarization is the task of generating focused summaries based on specific points of interest. Such summaries aid efficient analysis of text, such as quickly understanding reviews or opinions from different angles. However, due to large differences in the type of aspects for different domains (e.g., sentiment, product features), the development of previous models has tended to be domainspecific. In this paper, we propose WikiAsp,1 a large-scale dataset for multi-domain aspectbased summarization that attempts to spur research in the direction of open-domain aspect-based summarization. Specifically, we build the dataset using Wikipedia articles from 20 different domains, using the section titles and boundaries of each article as a proxy for aspect annotation. We propose several straightforward baseline models for this task and conduct experiments on the dataset. Results highlight key challenges that existing summarization models face in this setting, such as proper pronoun handling of quoted sources and consistent explanation of time-sensitive","information. The paper proposes a new dataset, WikiAsp, for multi-domain aspect-based summarization, which aims to encourage research in open-domain aspect-based summarization. The dataset is built using Wikipedia articles from 20 different domains, and several baseline models are proposed and tested. The results highlight challenges that existing summarization models face in this setting, such as handling pronouns and time-sensitive information.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide targeted summaries of a document from different perspectives, allowing readers to fulfill focused information needs more easily and quickly.', 'Who is the target audience?': 'The summaries are for humans consuming the information to browse specific aspects of interest more readily.', 'How will the summaries be used?': 'The summaries will be used to fulfill focused information needs more easily and quickly by providing targeted summaries of a document from different perspectives.'}",['corpus'],[],[],[],[],http://github.com/neulab/wikiasp,https://doi.org/10.1162/tacl_a_00362,"{'Existing aspect-based summarization work is narrowly focused on specific domains such as product or restaurant reviews, which limits its applicability to other genres.': 'The authors propose a dataset for multidomain aspect-based summarization that allows for training models on a wider variety of genres.', 'Existing datasets and analyses lack structure, broad domain coverage, or both.': 'The authors argue that generating structured summaries is of inherent interest and construct a dataset that allows for the extraction, curation, and filtering of section titles of Wikipedia articles to form natural annotations of aspects and corresponding text.', 'The unique challenges posed by a multi-domain and multi-document setting, such as the need to correctly order scattered and possibly duplicate pieces of information from different sources.': 'The authors devise a baseline two-stage method consisting of aspect identification and summarization using extractive and abstractive models, and conduct experiments on the proposed dataset to analyze the generated summaries and identify further challenges, such as correctly modifying pronouns based on the relationship to the topic of interest in certain domains involving interviews or quotes of people.'}",,['Wikipedia'],"['lack-of-suitable-training-data', 'controlled-and-tailored-summarization']"
SP:aee375f2bdf9a0d5ecdea9324093d1be09a69d09,CDEvalSumm: An Empirical Study of Cross-Dataset Evaluation for Neural Summarization Systems,EMNLP,2020,"['Yiran Chen', 'Pengfei Liu', 'Ming Zhong', 'Zi-Yi Dou', 'Danqing Wang', 'Xipeng Qiu', 'Xuanjing Huang']","Neural network-based models augmented with unsupervised pre-trained knowledge have achieved impressive performance on text summarization. However, most existing evaluation methods are limited to an in-domain setting, where summarizers are trained and evaluated on the same dataset. We argue that this approach can narrow our understanding of the generalization ability for different summarization systems. In this paper, we perform an indepth analysis of characteristics of different datasets and investigate the performance of different summarization models under a crossdataset setting, in which a summarizer trained on one corpus will be evaluated on a range of out-of-domain corpora. A comprehensive study of 11 representative summarization systems on 5 datasets from different domains reveals the effect of model architectures and generation ways (i.e. abstractive and extractive) on model generalization ability. Further, experimental results shed light on the limitations of existing summarizers. Brief introduction and supplementary code can be found in https://github.com/zide05/CDEvalSumm.","The paper discusses the limitations of existing evaluation methods for text summarization models, which are typically trained and evaluated on the same dataset. The authors argue that this approach can narrow our understanding of the generalization ability for different summarization systems. To address this, they perform an in-depth analysis of different datasets and investigate the performance of 11 representative summarization systems on 5 datasets from different domains under a cross-dataset setting. The study reveals the effect of model architectures and generation ways (i.e. abstractive and extractive) on model generalization ability and sheds light on the limitations of existing summarizers. Supplementary code can be found on their Github page.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of existing summarization systems under cross-dataset evaluation.', 'Who is the target audience?': 'The summaries are for evaluating the generalization ability of current top-scoring summarization systems.', 'How will the summaries be used?': 'The summaries will be used to identify the weaknesses of existing summarization systems and to design more robust summarization systems.'}",['analysis'],[],[],[],[],https://github.com/zide05/CDEvalSumm,https://arxiv.org/abs/2010.05139,"{'Existing summarization models tend to show defects when evaluated from other aspects beyond ROUGE, such as factual accuracy and abstractive summarization performance.': 'The authors propose cross-dataset evaluation as a new perspective to evaluate summarization models. They evaluate the performance of summarization systems trained on one corpus on a range of out-of-dataset corpora, which enables them to evaluate model performance from a different angle.', 'The generalization ability of current summarization systems when transferring to new datasets still remains unclear, which poses a significant challenge to design a reliable system in realistic scenarios.': 'The authors conduct a comprehensive experimental analysis involving eleven summarization systems, five benchmark datasets from different domains, and two evaluation aspects (semantic equivalency and factuality) to explore the effect of different architectures and generation ways on model generalization ability.', 'It is unclear whether different neural architectures and generation ways of summarizers influence the cross-dataset generalization performances.': 'The authors ask two questions to address this problem: Q1: How do different neural architectures of summarizers influence the cross-dataset generalization performances? Q2: Do different generation ways (extractive and abstractive) of summarizers influence the cross-dataset generalization ability? They conduct experiments to answer these questions and present two measures (Stiffness and Stableness) to characterize generalization ability in different views.', 'Dataset bias can affect the interpretation of system behaviors.': 'The authors conduct a dataset bias-aided analysis and suggest that a better understanding of datasets will be helpful for us to interpret systems’ behaviors.'}",,"['News', 'Scholarly Documents', 'Social Media', 'Patents']",['robust-evaluation-methods']
SP:d09dc0f375789a0b60cc48201fe62fa8c60cb690,End-to-End Segmentation-based News Summarization,ACL,2022,"['Yang Liu', 'Chenguang Zhu', 'Michael Zeng']","In this paper, we bring a new way of digesting news content by introducing the task of segmenting a news article into multiple sections and generating the corresponding summary to each section. We make two contributions towards this new task. First, we create and make available a dataset, SEGNEWS, consisting of 27k news articles with sections and aligned heading-style section summaries. Second, we propose a novel segmentation-based language generation model adapted from pretrained language models that can jointly segment a document and produce the summary for each section. Experimental results on SEGNEWS demonstrate that our model can outperform several state-of-the-art sequence-tosequence generation models for this new task.","System: The paper introduces a new way of digesting news content by segmenting a news article into multiple sections and generating corresponding summaries for each section. The authors create a dataset called SEGNEWS, consisting of 27k news articles with sections and aligned heading-style section summaries. They propose a novel segmentation-based language generation model adapted from pretrained language models that can jointly segment a document and produce the summary for each section. Experimental results on SEGNEWS show that their model outperforms several state-of-the-art sequence-to-sequence generation models for this task.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a more organized way of understanding long articles and to facilitate a more effective style of reading documents.', 'Who is the target audience?': 'The summaries are for users who want to quickly access information beyond the truncated portion of a news article.', 'How will the summaries be used?': 'The summaries will be used to reduce the cognitive burden of reading the article and to provide a structural organization of the content, which can benefit many important NLP tasks.'}","['corpus', 'method']",[],[],[],[],,https://aclanthology.org/2022.findings-acl.46,"{'Current news summarization systems only provide one generic summary of the whole article, making it difficult for users to quickly access information beyond the truncated portion.': 'The authors propose a new task of Segmentation-based News Summarization, which aims to identify potential sections of a news article and generate corresponding summaries for each section. This provides a more organized way of understanding long articles and facilitates a more effective style of reading documents.', 'Many expository texts, like news articles, consist of long sequences of paragraphs with very little structural demarcation, making it difficult to provide a structural organization of the content.': 'Segmenting a news article can provide a structural organization of the content, which is not only helpful to reading but also benefits many important NLP tasks. The authors propose a subtopical segmentation that can be useful for these documents.', 'Generating a concise text description of each section further reduces the cognitive burden of reading the article.': 'The authors propose generating concise text descriptions of each section, which is an effective alternative to traditional summarization tasks.', 'Current systems usually truncate the text and only generate a summary based on the partial article.': 'The authors propose an end-to-end approach for the Segmentation-based News Summarization task, which can jointly segment an article while generating the corresponding summaries. The model is equipped with a segmentation-aware attention mechanism, allowing it to capture segmentation information during summary generation. This approach does not alter the inner structure of Transformers and can integrate many pretrained language generation models, leading to a high degree of flexibility and better performance.', 'There is a lack of benchmark datasets for the Segmentation-based News Summarization task.': 'The authors create and publicize a large-scale benchmark, SEGNEWS, for the Segmentation-based News Summarization task.'}",,['News'],"['exploiting-the-structure-of-long-documents', 'controlled-and-tailored-summarization']"
SP:ecbf5959acf441a8d00607d3a6a3e85f6e970979,Automatically Discarding Straplines to Improve Data Quality for Abstractive News Summarization,ACL,2022,"['Amr Keleg', 'Matthias Lindemann', 'Danyang Liu', 'Wanqiu Long', 'Bonnie L. Webber']","Recent improvements in automatic news summarization fundamentally rely on large corpora of news articles and their summaries. These corpora are often constructed by scraping news websites, which results in including not only summaries but also other kinds of texts. Apart from more generic noise, we identify straplines as a form of text scraped from news websites that commonly turn out not to be summaries. The presence of these nonsummaries threatens the validity of scraped corpora as benchmarks for news summarization. We have annotated extracts from two news sources that form part of the Newsroom corpus (Grusky et al., 2018), labeling those which were straplines, those which were summaries, and those which were both. We present a rule-based strapline detection method that achieves good performance on a manually annotated test set1. Automatic evaluation indicates that removing straplines and noise from the training data of a news summarizer results in higher quality summaries, with improvements as high as 7 points ROUGE score.","The paper discusses the impact of non-summary texts, specifically straplines, on the quality of news article summarization. The authors identify straplines as a common form of non-summary text that is often included in scraped corpora used for news summarization. They present a rule-based strapline detection method that achieves good performance and show that removing straplines and noise from the training data of a news summarizer results in higher quality summaries, with improvements as high as 7 points ROUGE score.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the data quality in scraped news summarization corpora.', 'Who is the target audience?': 'The summaries are for models trained on benchmarks that were collected by scraping a large collection of web-pages.', 'How will the summaries be used?': 'The summaries will be used to improve the usefulness of models trained on these benchmarks and to evaluate the quality of the models.'}","['corpus', 'method']",[],[],[],[],https://github.com/namednil/straplines,https://aclanthology.org/2022.nlppower-1.5,"{'The datasets used for automatic text summarization contain a substantial portion of articles that are paired with texts that are not summaries, negatively impacting the usefulness of models trained on these benchmarks.': 'The authors propose methods for improving the data quality in scraped news summarization corpora, focusing on the Newsroom benchmark. They identify noise in the extraction process as a main issue and suggest removing straplines and noise from the training data to obtain high quality summaries.', 'Most straplines in the Newsroom corpus are not summaries of their associated articles, making it necessary to distinguish a strapline aimed at piquing a reader’s interest from an abstractive summary.': 'The authors designed a strapline annotation guideline and created heuristics for a rule-based classifier that distinguishes straplines from summaries. They empirically verify the usefulness of these heuristics for strapline detection and show that removing straplines and noise from the training data with their heuristics results in higher quality summaries.'}",,['News'],['controlled-and-tailored-summarization']
SP:54de1380754d8853fd26f233e5da069d1e53ef00,Falsesum: Generating Document-level NLI Examples for Recognizing Factual Inconsistency in Summarization,NAACL,2022,"['Prasetya Ajie Utama', 'Joshua Bambrick', 'Nafise Sadat Moosavi', 'Iryna Gurevych']","Neural abstractive summarization models are prone to generate summaries which are factually inconsistent with their source documents. Previous work has introduced the task of recognizing such factual inconsistency as a downstream application of natural language inference (NLI). However, state-of-the-art NLI models perform poorly in this context due to their inability to generalize to the target task. In this work, we show that NLI models can be effective for this task when the training data is augmented with high-quality task-oriented examples. We introduce Falsesum, a data generation pipeline leveraging a controllable text generation model to perturb human-annotated summaries, introducing varying types of factual inconsistencies. Unlike previously introduced document-level NLI datasets, our generated dataset contains examples that are diverse and inconsistent yet plausible. We show that models trained on a Falsesum-augmented NLI dataset improve the state-of-the-art performance across four benchmarks for detecting factual inconsistency in summarization.1","The paper discusses how neural abstractive summarization models can generate summaries that are factually inconsistent with their source documents. Previous attempts to recognize such inconsistencies using natural language inference (NLI) have been unsuccessful due to the models' inability to generalize to the task. The authors propose a data generation pipeline called Falsesum, which uses a text generation model to introduce varying types of factual inconsistencies into human-annotated summaries. The resulting dataset contains diverse yet plausible examples, and models trained on it improve performance on four benchmarks for detecting factual inconsistency in summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to address the problem of factual inconsistency in generated summaries.', 'Who is the target audience?': 'The generated summaries are for use in natural language inference (NLI) models to detect factual inconsistency in abstractive summarization.', 'How will the summaries be used?': 'The generated summaries will be used to augment existing NLI datasets and improve the performance of NLI models in recognizing factually inconsistent summaries.'}","['corpus', 'analysis']",[],[],[],[],https://github.com/joshbambrick/Falsesum,https://aclanthology.org/2022.naacl-main.199,"{'Models that generate highly fluent abstractive summaries are susceptible to generating factually inconsistent outputs.': 'The authors propose a new line of research for recognizing factual inconsistency in generated summaries by introducing Falsesum, a data generation pipeline that produces NLI examples consisting of documents paired with gold summaries as positive examples and automatically generated inconsistent summaries as negative examples. They train a text generation model to render false summaries of a given document using only supervision from an existing summarization dataset, and use this model to generate a large-scale NLI dataset for the task of recognizing factually inconsistent summaries.', 'Earlier solutions have adopted out-of-the-box NLI models to detect factual inconsistency, albeit with limited success.': 'The authors propose a novel training pipeline to create a text generation model which takes as input a pair of a document and a corresponding gold summary. It then perturbs the summary such that it is no longer factually consistent with the original document. This strategy obviates the need for explicit examples of inconsistent summaries, using only an existing summarization dataset.', 'Most NLI datasets are not designed to reflect the input characteristics of downstream tasks, and there is a discrepancy in terms of the input granularity.': 'The authors use Falsesum to generate a large-scale NLI dataset for the task of recognizing factually inconsistent summaries. The resultant dataset consists of pairs with documents as the premise and naturalistic summaries as the hypotheses, each labeled as either entailment or non-entailment. They demonstrate the utility of their generated data for augmenting existing NLI datasets, showing that NLI models trained on Falsesum-augmented data outperform those trained on previous document-level NLI datasets.', 'Previous solutions synthesize NLI examples using rule-based transformations or language model-based replacements, limiting their diversity and ability to reflect realistic factual errors in summarization.': 'The authors propose a generator that supports switchable input control codes to determine the type of factual error exhibited in the generated output. This design allows Falsesum to compose diverse and naturalistic outputs which more closely resemble the inconsistent summaries generated by summarization models. They show that the improvement over the benchmarks is largely attributable to the diversity of factual errors that Falsesum introduces.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:47aab60579dd11a764c70a633dece5c3299e024f,Joint Learning of Answer Selection and Answer Summary Generation in Community Question Answering,AAAI,2020,"['Yang Deng', 'Wai Lam', 'Yuexiang Xie', 'Daoyuan Chen', 'Yaliang Li', 'Min Yang', 'Ying Shen']","Community question answering (CQA) gains increasing popularity in both academy and industry recently. However, the redundancy and lengthiness issues of crowdsourced answers limit the performance of answer selection and lead to reading difficulties and misunderstandings for community users. To solve these problems, we tackle the tasks of answer selection and answer summary generation in CQA with a novel joint learning model. Specifically, we design a question-driven pointer-generator network, which exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. Meanwhile, we leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. In addition, we construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method can effectively address the answer redundancy issue in CQA and achieves state-ofthe-art results on both answer selection and text summarization tasks. Furthermore, the proposed model is shown to be of great transferring ability and applicability for resource-poor CQA tasks, which lack of reference answer summaries.","The paper discusses the issues of redundancy and lengthiness in crowdsourced answers in Community Question Answering (CQA), which limit the performance of answer selection and lead to difficulties for community users. To solve these problems, the authors propose a novel joint learning model that tackles the tasks of answer selection and answer summary generation in CQA. They design a question-driven pointer-generator network that exploits the correlation information between question-answer pairs to aid in attending the essential information when generating answer summaries. They also leverage the answer summaries to alleviate noise in original lengthy answers when ranking the relevancy degrees of question-answer pairs. The authors construct a new large-scale CQA corpus, WikiHowQA, which contains long answers for answer selection as well as reference summaries for answer summarization. The experimental results show that the joint learning method effectively addresses the answer redundancy issue in CQA and achieves state-of-the-art results on both answer selection and text summarization tasks. The proposed model is also shown to be of great transferring ability and applicability for resource-poor CQA tasks that lack reference answer summaries.",{},"['corpus', 'method']",[],[],[],[],https://github.com/dengyang17/wikihowQA,https://ojs.aaai.org/index.php/AAAI/article/view/6266,"{'The noise introduced by the redundancy of answers makes it difficult for answer selection model to pick out correct answers from a set of candidates.': 'The authors propose a joint learning framework of answer selection and abstractive summarization (ASAS) to employ the question information to guide the abstractive summarization, and leverage the summaries to reduce noise in answers for precisely measuring the correlation degrees of QA pairs.', 'Compared with other QA systems (e.g., factoid question answering), answers in CQA are often too long for community users to read and comprehend.': 'The authors propose to generate abstractive answer summaries in CQA by taking advantage of both the contextual information from the source text and the relationship between the question-answer pair.', 'Extractive summarization methods sometimes fall short of generalization of all the important information in the whole answer and consistency of the core idea.': 'The authors propose to use abstractive summarization methods to generate answer summaries in CQA, which can assemble or generate summaries from the source article or external vocabulary, based on the information from the source text.', 'Obtaining reference summaries is usually labor-intensive and time-consuming in a new domain.': 'The authors design a transfer learning strategy to improve resource-poor CQA tasks with large-scale supervision data.'}",,['CQA'],['information-loss-and-incoherence-in-extractive-summarization']
SP:115328822ddcaedbb64cf25f45b9224662e1ec18,SUMPUBMED: Summarization Dataset of PubMed Scientific Articles,ACL,2021,"['Vivek Gupta', 'Prerna Bharti', 'Pegah Nokhiz', 'Harish Karnick']","Most earlier work on text summarization is carried out on news article datasets. The summary in these datasets is naturally located at the beginning of the text. Hence, a model can spuriously utilize this correlation for summary generation instead of truly learning to summarize. To address this issue, we constructed a new dataset, SUMPUBMED, using scientific articles from the PubMed archive. We conducted a human analysis of summary coverage, redundancy, readability, coherence, and informativeness on SUMPUBMED. SUMPUBMED is challenging because (a) the summary is distributed throughout the text (not-localized on top), and (b) it contains rare domain-specific scientific terms. We observe that seq2seq models that adequately summarize news articles struggle to summarize SUMPUBMED. Thus, SUMPUBMED opens new avenues for the future improvement of models as well as the development of new evaluation metrics.","The paper discusses the limitations of text summarization models that are trained on news article datasets, where the summary is typically located at the beginning of the text. To address this issue, the authors created a new dataset called SUMPUBMED, which contains scientific articles from the PubMed archive. The summary in SUMPUBMED is distributed throughout the text and contains rare domain-specific scientific terms, making it challenging for seq2seq models that are trained on news articles to summarize effectively. The authors conclude that SUMPUBMED provides new opportunities for improving text summarization models and developing new evaluation metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific documents to create a new scientific summarization dataset, SUMPUBMED, which has longer text documents and summaries with non-localized information from documents.', 'Who is the target audience?': 'The summaries are for researchers and scientists who need to quickly understand the content of long and complex scientific documents such as essays, research papers, and books.', 'How will the summaries be used?': 'The summaries will be used to help researchers and scientists quickly identify relevant information in scientific documents, saving them time and effort in their research. The authors evaluated several extractive, abstractive (seq2seq), and hybrid summarization models on SUMPUBMED to determine the best approach for summarizing scientific documents.'}",['corpus'],[],[],[],[],https://github.com/vgupta123/sumpubmed,https://aclanthology.org/2021.acl-srw.30,{},,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'robust-evaluation-methods']"
SP:6228bef1bee63b2a95b2d88f1789c1993db1ad57,Unsupervised Opinion Summarization with Content Planning,AAAI,2021,"['Reinald Kim Amplayo', 'Stefanos Angelidis', 'Mirella Lapata']","The recent success of deep learning techniques for abstractive summarization is predicated on the availability of largescale datasets. When summarizing reviews (e.g., for products or movies), such training data is neither available nor can be easily sourced, motivating the development of methods which rely on synthetic datasets for supervised training. We show that explicitly incorporating content planning in a summarization model not only yields output of higher quality, but also allows the creation of synthetic datasets which are more natural, resembling real world document-summary pairs. Our content plans take the form of aspect and sentiment distributions which we induce from data without access to expensive annotations. Synthetic datasets are created by sampling pseudo-reviews from a Dirichlet distribution parametrized by our content planner, while our model generates summaries based on input reviews and induced content plans. Experimental results on three domains show that our approach outperforms competitive models in generating informative, coherent, and fluent summaries that capture opinion consensus.","The paper discusses the challenges of using deep learning techniques for summarizing reviews due to the lack of large-scale datasets. The authors propose a method that incorporates content planning into the summarization model, which improves the quality of the output and allows for the creation of more natural synthetic datasets. The content plans are generated from aspect and sentiment distributions induced from data without expensive annotations. The synthetic datasets are created by sampling pseudo-reviews from a Dirichlet distribution, and the model generates summaries based on input reviews and induced content plans. Experimental results show that their approach outperforms other models in generating informative, coherent, and fluent summaries that capture opinion consensus.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to facilitate decision making by condensing multiple reviews for a given product and identifying which weaknesses and features to pay attention to.', 'Who is the target audience?': 'The summaries are for users who want to make informed decisions about products based on online reviews.', 'How will the summaries be used?': 'The summaries will be used to provide a succinct conveyance of opinions to users, allowing them to quickly and easily understand the salient aspects of a product based on the reviews.'}","['corpus', 'method']",[],[],[],[],https://github.com/rktamplayo/PlanSum,https://ojs.aaai.org/index.php/AAAI/article/view/17481,"{'The large volume of online product reviews makes it difficult for users to make informed decisions.': 'Automatic methods for digesting review content, such as sentiment analysis and opinion mining, have been developed to facilitate decision making.', 'There is a lack of opinion summaries in review websites, and annotating them on a large scale is difficult.': 'Previous work has relied on extractive approaches, where parts of input reviews are copied and arranged onto a summary. More recent methods focus on generating abstractive summaries, and use synthetic summary-review pairs created by sampling a review from a corpus of product reviews.', 'Synthetic datasets cannot resemble real-world data, and previous methods for creating them have limitations.': 'The authors propose incorporating content planning in unsupervised opinion summarization, using aspect and sentiment probability distributions induced from data without expensive annotations. These distributions are used as parameters to a Dirichlet distribution to create a synthetic dataset of review-summary pairs, where the variation of aspect mentions among reviews can be controlled.', 'Real-world reviews discuss a variety of opinions covering different aspects of the entity under consideration, and some aspects are more salient than others.': 'Content plans can be usefully employed to reflect the natural variation of sampled reviews in creating a synthetic dataset. The authors propose an opinion summarization model that uses these distributions as a content plan to guide the generation of abstractive summaries.', 'Current methods for opinion summarization have limitations in terms of performance and capturing salient opinions.': 'Experiments on three datasets representing different domains and summarization requirements show that the proposed approach outperforms competitive systems in terms of ROUGE, achieving state of the art across the board. Human evaluation further confirms that the summaries produced by the model capture salient opinions as well as being coherent and fluent.'}",,['Reviews'],['lack-of-suitable-training-data']
SP:cbb10bb6551c58dc5e227126e719e86ebf3e2476,Automatic learner summary assessment for reading comprehension,NAACL,2019,"['Menglin Xia', 'Ekaterina Kochmar', 'Ted Briscoe']",Automating the assessment of learner summaries provides a useful tool for assessing learner reading comprehension. We present a summarization task for evaluating nonnative reading comprehension and propose three novel approaches to automatically assess the learner summaries. We evaluate our models on two datasets we created and show that our models outperform traditional approaches that rely on exact word match on this task. Our best model produces quality assessments close to professional examiners.,"

System: The paper discusses the development of a tool for assessing learner reading comprehension through automated assessment of their summaries. The authors propose three novel approaches to assess the summaries and evaluate them on two datasets they created. The results show that their models outperform traditional approaches and produce quality assessments close to those of professional examiners.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to evaluate non-native reading comprehension.', 'Who is the target audience?': 'The summaries are for learners of English as a second or other language (ESOL).', 'How will the summaries be used?': 'The summaries will be used to assess the quality of the learner summary and can lead to effective educational applications to enhance reading comprehension tasks.'}",['metric'],[],[],[],[],,https://aclanthology.org/N19-1261,"{'Manual summary assessment is time-consuming and costly, leading to modern English exams replacing the summarization task with easier-to-score multiple choice or short answer questions.': 'Automating the assessment of learner summarization skills provides an efficient evaluation method for the quality of the learner summary and can lead to effective educational applications to enhance reading comprehension tasks.', 'Non-native reading comprehension needs to be evaluated through a summarization task.': 'The authors present a summarization task for evaluating non-native reading comprehension.', 'Traditional approaches to summarization assessment rely on exact word match.': 'The authors propose three novel machine learning approaches to assessing learner summaries: extracting features to measure content similarity, calculating a similarity matrix based on sentence-to-sentence similarity and applying a Convolutional Neural Network (CNN) model, and building an end-to-end summarization assessment model using the Long Short Term Memory (LSTM) model.', 'The performance of the proposed models needs to be evaluated.': 'The authors compiled two datasets to evaluate their models and show that their models outperform traditional approaches and produce quality assessments close to professional examiners. They also release the data with the paper.', 'The proposed models need to be combined into a single system.': 'The authors combine the three approaches in a single system using a simple parallel ensemble modeling technique.'}",,['Student Responses'],['robust-evaluation-methods']
SP:f4946334953d03d6904280e423c794e176ac4c08,Investigating Metric Diversity for Evaluating Long Document Summarisation,COLING,2022,"['Cai Yang', 'Stephen Wan']","Long document summarisation, a challenging summarisation scenario, is the focus of the recently proposed LongSumm shared task. One of the limitations of this shared task has been its use of a single family of metrics for evaluation (the ROUGE metrics). In contrast, other fields, like text generation, employ multiple metrics. We replicated the LongSumm evaluation using multiple test set samples (vs. the single test set of the official shared task) and investigated how different metrics might complement each other in this evaluation framework. We show that under this more rigorous evaluation, (1) some of the key learnings from Longsumm 2020 and 2021 still hold, but the relative ranking of systems changes, and (2) the use of additional metrics reveals additional highquality summaries missed by ROUGE, and (3) we show that SPICE is a candidate metric for summarisation evaluation for LongSumm1.","The paper discusses the LongSumm shared task, which focuses on long document summarization and has been limited by its use of a single family of metrics for evaluation. The authors replicated the evaluation using multiple test set samples and found that the use of additional metrics revealed high-quality summaries missed by the original metrics. They also suggest that SPICE could be a candidate metric for summarization evaluation in LongSumm1. The relative ranking of systems changed under this more rigorous evaluation, but some key learnings from previous years still held.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long scientific articles to bridge the gap in text summarization research, where most work focuses on shorter documents or generating shorter summaries.', 'Who is the target audience?': 'The summaries are required by corporations and governments for productivity gains.', 'How will the summaries be used?': 'The summaries will be used to provide detailed and informative technical summaries of source articles, and the authors propose a diversity of metrics to evaluate the quality of the summaries.'}",['analysis'],[],[],[],[],https://github.com/caiyangcy/SDP-LongSumm-Metric-Diversity,https://aclanthology.org/2022.sdp-1.13,"{'Summarizing long documents into detailed summaries has not dominated the summarisation research field.': 'The authors propose the shared task of summarizing long scientific articles (LongSumm) to bridge this gap and produce a detailed and informative technical summary of a source article.', 'The LongSumm shared tasks were limited to the ROUGE family of metrics, which may not be the best metric for this new domain.': 'The authors take the approach that diversity of metrics is key and employ metrics from NLG E2E shared task and MS Coco evaluation scripts, such as SPICE and BERTScore, to cover a range of linguistic phenomena.', 'The informativeness of ROUGE might be affected by stopword matching.': 'The authors show this issue and suggest using a spectrum of different system approaches, including oracle methods, baselines, and state-of-the-art approaches, to consider the role of different metrics for the LongSumm evaluation.', 'There is a need for complementary views on summarisation quality.': 'The authors show that SPICE agrees somewhat with ROUGE and BERTScore, offering a complementary view on summarisation quality.'}",,['Scholarly Documents'],"['exploiting-the-structure-of-long-documents', 'robust-evaluation-methods']"
SP:43d129b2d152177c52e117d370b5dab06579413e,HaRiM: Evaluating Summary Quality with Hallucination Risk,AACL,2022,"['Seonil Son', 'Junsoo Park', 'Jeong-in Hwang', 'Junghwa Lee', 'Hyungjong Noh', 'Yeonsoo Lee']","One of the challenges of developing a summarization model arises from the difficulty in measuring the factual inconsistency of the generated text. In this study, we reinterpret the decoder overconfidence-regularizing objective suggested in (Miao et al., 2021) as a hallucination risk measurement to better estimate the quality of generated summaries. We propose a reference-free metric, HaRiM, which only requires an off-the-shelf summarization model to compute the hallucination risk based on token likelihoods. Deploying it requires no additional training of models or ad-hoc modules, which usually need alignment to human judgments. For summary-quality estimation, HaRiM records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits the use of summarization models, facilitates the progress of both automated evaluation and generation of summary.","The paper discusses the challenge of measuring the factual consistency of generated text in summarization models. The authors propose a reference-free metric called HaRiM, which measures hallucination risk based on token likelihoods and correlates well with human judgment on three summary-quality annotation sets. They reinterpret a previously suggested objective as a hallucination risk measurement to better estimate summary quality without requiring additional training or alignment to human judgments. The authors hope their work will facilitate progress in both automated evaluation and generation of summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to develop a summarization model.', 'Who is the target audience?': 'The intended audience for the generated summaries is not specified in the paper.', 'How will the summaries be used?': 'The generated summaries will be used for automated evaluation and generation of summary.'}",['metric'],[],[],[],[],,https://aclanthology.org/2022.aacl-main.66,"{'Difficulty in measuring the factual inconsistency of generated text in summarization models.': 'Reinterpret the decoder overconfidence-regularizing objective as a hallucination risk measurement to better estimate the quality of generated summaries.', 'Need for a reference-free metric to compute hallucination risk in summarization models.': 'Propose HaRiM, a reference-free metric that only requires an off-the-shelf summarization model to compute hallucination risk based on token likelihoods.', 'Additional training of models or ad-hoc modules needed for summary-quality estimation.': 'Deploy HaRiM, which requires no additional training of models or ad-hoc modules, and records state-of-the-art correlation to human judgment on three summary-quality annotation sets: FRANK, QAGS, and SummEval.', 'Lack of progress in automated evaluation and generation of summary.': 'Merit the use of summarization models and hope that the proposed work facilitates the progress of both automated evaluation and generation of summary.'}",,['News'],['robust-evaluation-methods']
SP:eb7b1459e695a0e3fdf8f5659aa348d78094c038,FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization,ACL,2020,"['Esin Durmus', 'Mona Diab']","Neural abstractive summarization models are prone to generate content inconsistent with the source document, i.e. unfaithful. Existing automatic metrics do not capture such mistakes effectively. We tackle the problem of evaluating faithfulness of a generated summary given its source document. We first collected human annotations of faithfulness for outputs from numerous models on two datasets. We find that current models exhibit a trade-off between abstractiveness and faithfulness: outputs with less word overlap with the source document are more likely to be unfaithful. Next, we propose an automatic question answering (QA) based metric for faithfulness, FEQA,1 which leverages recent advances in reading comprehension. Given questionanswer pairs generated from the summary, a QA model extracts answers from the document; non-matched answers indicate unfaithful information in the summary. Among metrics based on word overlap, embedding similarity, and learned language understanding models, our QA-based metric has significantly higher correlation with human faithfulness scores, especially on highly abstractive summaries.","The paper discusses the issue of neural abstractive summarization models generating content inconsistent with the source document, and the inadequacy of existing automatic metrics to capture such mistakes. The authors propose an automatic question answering (QA) based metric for evaluating the faithfulness of generated summaries, which has a higher correlation with human faithfulness scores, especially on highly abstractive summaries. The authors also find that current models exhibit a trade-off between abstractiveness and faithfulness, with outputs having less word overlap with the source document being more likely to be unfaithful.",{'Who is the target audience?': 'The paper does not specify who the summaries are generated for.'},['metric'],[],[],[],[],https://github.com/esdurmus/summary-faithfulness,https://aclanthology.org/2020.acl-main.454/,"{'Abstractive summarization models may not always contain faithful information, which is vital for real-world applications.': 'The authors propose to address the problem of evaluating faithfulness of generated summaries given their source documents. They show that current models are limited by a trade-off between abstractiveness and faithfulness and investigate a diverse set of existing automatic evaluation metrics.', 'The correlations between existing automatic evaluation metrics and human scores of faithfulness drop significantly on highly abstractive summaries, where deeper text understanding beyond surface similarity is needed.': 'The authors propose to use question answering (QA) based automatic metrics to evaluate content selection in summarization. They use automatically generated QA pairs to represent information in the summary and validate it against the source. They generate a set of “groundtruth” QA pairs from the summary, using a learned model that converts a declarative sentence and an answer span to a question. Then, off-the-shelf reading comprehension models are evaluated on this set by extracting answer spans from the source documents.', 'Prior approaches using cloze tests for QA-based evaluation have limitations in terms of the range of QA models and answer types.': 'The authors propose a question generation approach that enables evaluation with a broader range of QA models and answer types (e.g. extractive and generative), thus maximally taking advantage of progress in QA.', 'Existing automatic metrics based on n-gram overlap, word embeddings, and language understanding models (relation extraction and entailment) have limited correlation with human scores of faithfulness on highly abstractive summaries from XSum.': 'The authors propose a new automatic metric called FEQA, which has significantly higher correlation with human scores of faithfulness and is the only metric that correlates with human scores on highly abstractive summaries from XSum.'}",,['News'],['robust-evaluation-methods']
SP:39a54f75dca32794b846eb89ad849a043c481c86,At Which Level Should We Extract? An Empirical Study on Extractive Document Summarization,COLING,2020,"['Qingyu Zhou', 'Furu Wei', 'Ming Zhou']","Extractive methods have proven to be very effective in automatic document summarization. Previous works perform this task by identifying informative contents at sentence level. However, it is unclear whether performing extraction at sentence level is the best solution. In this work, we show that unnecessity and redundancy issues exist when extracting full sentences, and extracting sub-sentential units is a promising alternative. Specifically, we propose extracting sub-sentential units on the corresponding constituency parsing tree. A neural extractive model which leverages the sub-sentential information and extracts them is presented. Extensive experiments and analyses show that extracting sub-sentential units performs competitively comparing to full sentence extraction under the evaluation of both automatic and human evaluations. Hopefully, our work could provide some inspiration of the basic extraction units in extractive summarization for future research.","The paper discusses the effectiveness of extractive methods in automatic document summarization and proposes extracting sub-sentential units instead of full sentences. The authors show that extracting full sentences can lead to redundancy and unnecessity issues, and present a neural extractive model that leverages sub-sentential information. The experiments and analyses demonstrate that extracting sub-sentential units performs competitively compared to full sentence extraction. The paper provides inspiration for future research on the basic extraction units in extractive summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to produce a brief piece of text that preserves the most important information in it.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important contents of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and to quickly identify the most important information in them.'}",['analysis'],[],[],[],[],,https://arxiv.org/abs/2004.02664,"{'Extracting full sentences may introduce unnecessary or duplicate information.': 'Compressing or rewriting the extracted sentences, or using methods such as Maximal Marginal Relevance (MMR) and sentence fusion to avoid or merge duplicate contents.', 'Extracted sentences may contain duplicate contents.': 'Using methods such as Maximal Marginal Relevance (MMR) and sentence fusion to avoid or merge duplicate contents.', 'Extracting full sentences may not be the best solution for extractive document summarization.': 'Extracting sub-sentential units in a sentence, focusing on non-terminal nodes in a constituency parsing tree, and choosing nodes with the clause tag such as S and SBAR for creating extraction units.', 'Extracting sub-sentential units may cause other issues.': 'Conducting experiments and analyses to identify and address any potential issues.'}",,['News'],['information-loss-and-incoherence-in-extractive-summarization']
SP:81aaf96715a16f42814f41d76d3ca5addc7386b8,Dissecting Generation Modes for Abstractive Summarization Models via Ablation and Attribution,ACL,2021,['Jiacheng Xu'],"Despite the prominence of neural abstractive summarization models, we know little about how they actually form summaries and how to understand where their decisions come from. We propose a two-step method to interpret summarization model decisions. We first analyze the model’s behavior by ablating the full model to categorize each decoder decision into one of several generation modes: roughly, is the model behaving like a language model, is it relying heavily on the input, or is it somewhere in between? After isolating decisions that do depend on the input, we explore interpreting these decisions using several different attribution methods. We compare these techniques based on their ability to select content and reconstruct the model’s predicted token from perturbations of the input, thus revealing whether highlighted attributions are truly important for the generation of the next token. While this machinery can be broadly useful even beyond summarization, we specifically demonstrate its capability to identify phrases the summarization model has memorized and determine where in the training pipeline this memorization happened, as well as study complex generation phenomena like sentence fusion on a per-instance basis.","The paper proposes a two-step method to interpret the decisions made by neural abstractive summarization models. The first step involves analyzing the model's behavior to categorize each decoder decision into one of several generation modes. The second step involves interpreting the decisions using different attribution methods to determine their importance for the generation of the next token. The paper demonstrates the method's capability to identify phrases the summarization model has memorized and determine where in the training pipeline this memorization happened, as well as study complex generation phenomena like sentence fusion on a per-instance basis.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to interpret the stepwise prediction decisions of neural abstractive summarization models.', 'Who is the target audience?': 'The summaries are not for any specific audience mentioned in the paper.', 'How will the summaries be used?': 'The summaries will be used to identify and forestall problems in generation, such as toxicity or factual errors.'}",['analysis'],[],[],[],[],https://github.com/jiacheng-xu/sum-interpret,https://aclanthology.org/2021.acl-long.539,"{'Little is known about how transformer-based neural summarization models work, particularly in terms of whether token generation decisions leverage the source text or rely primarily on knowledge from the language model.': ""The authors propose a two-stage analysis framework to more fully interpret the stepwise prediction decisions of neural abstractive summarization models. They bucket generation decisions into different modes of generation and use model ablations to determine when decisions are context-independent or context-dependent. They also examine interpretations based on several prior techniques and propose a comprehensive evaluation based on presenting counterfactual, partial inputs to assess the models' performance with different subsets of input data."", 'Summarization models make sequential decisions from a very large state space, and encoder-decoder models have a complex interaction of decoder-side and encoder-side computation to select the next word.': 'The authors use their two-stage analysis framework to understand how each individual decision depends on context and prior knowledge, and to locate the source evidence for context-dependent generation.', 'Pre-trained LMs blur the distinction between relying on implicit prior knowledge or explicit instance-dependent input.': ""The authors propose a comprehensive evaluation based on presenting counterfactual, partial inputs to quantitatively assess these models' performance with different subsets of the input data."", 'Problems in generation, such as toxicity or factual errors, need to be identified and forestalled.': ""Having tools to analyze these models is crucial to identifying and forestalling problems in generation, such as toxicity or factual errors. The authors' two-stage analysis framework can be used to find suspicious cases of memorization and bias.""}",,['News'],['hallucinations-in-the-generated-summaries']
SP:102d373a497567806de13f5400dcff782f468b66,Evaluation of Abstractive Summarisation Models with Machine Translation in Deliberative Processes,EMNLP,2021,"['Miguel Arana-Catania', 'Rob Procter', 'Yulan He', 'Maria Liakata']","We present work on summarising deliberative processes for non-English languages. Unlike commonly studied datasets, such as news articles, this deliberation dataset reflects difficulties of combining multiple narratives, mostly of poor grammatical quality, in a single text. We report an extensive evaluation of a wide range of abstractive summarisation models in combination with an off-the-shelf machine translation model. Texts are translated into English, summarised, and translated back to the original language. We obtain promising results regarding the fluency, consistency and relevance of the summaries produced. Our approach is easy to implement for many languages for production purposes by simply changing the translation model.","The paper discusses the summarization of deliberative processes in non-English languages, which involves combining multiple narratives of poor grammatical quality in a single text. The authors evaluate various abstractive summarization models in combination with a machine translation model, and report promising results in terms of fluency, consistency, and relevance of the summaries produced. The approach is easy to implement for many languages by changing the translation model.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to address the problem of information overload that often results from large amounts of generated content in deliberations, which prevents their potential from being fully realized.', 'Who is the target audience?': 'It is not explicitly stated who the summaries are for, but it can be inferred that they are for individuals involved in the deliberation process.', 'How will the summaries be used?': 'It is not explicitly stated how the summaries will be used, but it can be inferred that they will be used to synthesize and filter information collected through the deliberation process.'}",['metric'],[],[],[],[],,https://aclanthology.org/2021.newsum-1.7,"{'Large amounts of generated content in digital deliberations cause information overload, preventing their potential from being fully realized.': 'The authors propose using abstractive summarization models in combination with a machine translation system to synthesize and filter information collected through such processes.', 'Current technology of language models is mostly limited to a few languages, creating a barrier to their more widespread use.': ""The authors' approach can be deployed for many languages just by changing the translation model without the need to generate new, ad-hoc corpora for the task or costly retraining for each new language."", 'Low quality translations in low resourced languages limit the effectiveness of machine translation systems.': 'The authors complete the cycle of translating from the original language to English, summarizing, and translating back to the original language, thus avoiding the need for retraining.', 'Extractive approaches to summarization may not effectively abstract the results.': 'The authors propose using abstractive summarization models in combination with a process of sentence compression to effectively abstract the results.', 'Limited resources in a target language may limit the effectiveness of a summarizer.': 'The authors propose exploiting the capability of a resource-rich language summarizer in a teacher-student framework that connects it to the target language summarizer.'}",,['Deliberations'],[]
SP:ce422ea7d479a785a1998f550c948a37dca9a580,Finding a Balanced Degree of Automation for Summary Evaluation,EMNLP,2021,"['Shiyue Zhang', 'Mohit Bansal']","Human evaluation for summarization tasks is reliable but brings in issues of reproducibility and high costs. Automatic metrics are cheap and reproducible but sometimes poorly correlated with human judgment. In this work, we propose flexible semiautomatic to automatic summary evaluation metrics, following the Pyramid human evaluation method. Semi-automatic LitePyramid retains the reusable human-labeled Summary Content Units (SCUs) for reference(s) but replaces the manual work of judging SCUs’ presence in system summaries with a natural language inference (NLI) model. Fully automatic LitePyramid further substitutes SCUs with automatically extracted Semantic Triplet Units (STUs) via a semantic role labeling (SRL) model. Finally, we propose in-between metrics, LitePyramid, where we use a simple regressor to predict how well the STUs can simulate SCUs and retain SCUs that are more difficult to simulate, which provides a smooth transition and balance between automation and manual evaluation. Comparing to 15 existing metrics, we evaluate human-metric correlations on 3 existing meta-evaluation datasets and our newlycollected PyrXSum (with 100/10 XSum examples/systems). It shows that LitePyramid consistently has the best summary-level correlations; LitePyramid works better than or comparable to other automatic metrics; LitePyramid trades off small correlation drops for larger manual effort reduction, which can reduce costs for future data collection.1","The paper discusses the challenges of evaluating summarization tasks using human evaluation and automatic metrics. The authors propose a flexible semiautomatic to automatic summary evaluation metrics called LitePyramid, which uses a natural language inference model and semantic role labeling model to replace manual work. LitePyramid is compared to 15 existing metrics and evaluated on three meta-evaluation datasets and a newly collected dataset. The results show that LitePyramid consistently has the best summary-level correlations and can reduce costs for future data collection.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the quality of summarization methods.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization methods.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different summarization methods and to guide model selection.'}",['metric'],[],[],[],[],https://github.com/ZhangShiyue/Lite2-3Pyramid,https://aclanthology.org/2021.emnlp-main.531,"{'Evaluating the quality of summaries is a challenging task, and human evaluation is usually regarded as the gold standard. However, manual evaluation is not reproducible and expensive, making it hard to apply extensively in model selection. Automatic metrics have been proposed, but most of them cannot reliably substitute human evaluation due to unstable performance, weak correlations with human judgment, or more indication of topic similarity than information overlap.': ""The authors propose to combine human and automatic evaluations and find a balance between reliability and reproducibility. They retain the reusable Summary Content Units (SCUs) but replace human effort in the second step with a neural model. They use a pretrained Natural Language Inference (NLI) model and finetune it on in-domain gold labels of SCUs' presence. They replace humans with the finetuned model, making the evaluation results reproducible as long as the same model is used. They also automate the presence annotation, leading to a fully automatic metric called Lite2Pyramid. They simulate SCUs via an automatic method for large-scale datasets using Semantic Role Labeling (SRL) and take each triplet as a pseudo-SCU, which they call Semantic Triplet Unit (STU), leading to a fully automatic metric called Lite3Pyramid. They investigate balanced trade-offs between SCUs and STUs and design an active learning inspired selection method to help decide which sub-parts of the dataset are more worthy of obtaining expensive SCUs for, leading to a smooth, flexible transition from Lite2Pyramid to Lite3Pyramid and balancing reliability with cost.""}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:5b88a60d1bcf6ba0c9ab00456d2a287c0d4b1440,Understanding Points of Correspondence between Sentences for Abstractive Summarization,ACL,2020,"['Logan Lebanoff', 'John Muchovej', 'Franck Dernoncourt', 'Doo Soon Kim', 'Lidan Wang', 'Walter Chang', 'Fei Liu']","Fusing sentences containing disparate content is a remarkable human ability that helps create informative and succinct summaries. Such a simple task for humans has remained challenging for modern abstractive summarizers, substantially restricting their applicability in realworld scenarios. In this paper, we present an investigation into fusing sentences drawn from a document by introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text. The types of points of correspondence are delineated by text cohesion theory, covering pronominal and nominal referencing, repetition and beyond. We create a dataset containing the documents, source and fusion sentences, and human annotations of points of correspondence between sentences. Our dataset bridges the gap between coreference resolution and summarization. It is publicly shared to serve as a basis for future work to measure the success of sentence fusion systems.1","The paper discusses the challenge of fusing sentences with disparate content to create informative and succinct summaries, which is a task that humans can easily perform but is difficult for modern abstractive summarizers. The authors propose introducing the notion of points of correspondence, which are cohesive devices that tie any two sentences together into a coherent text, and provide a dataset containing human annotations of points of correspondence between sentences. The dataset bridges the gap between coreference resolution and summarization and can serve as a basis for future work to measure the success of sentence fusion systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve automated summarization, specifically in the area of sentence fusion.', 'Who is the target audience?': 'The summaries are for use by automated summarization systems.', 'How will the summaries be used?': 'The summaries will be used to evaluate the ability of summarization models to perform sentence fusion and to broaden the understanding of points of correspondence used for sentence fusion. The dataset is publicly released for this purpose.'}",['analysis'],[],[],[],[],https://github.com/ucfnlp/points-of-correspondence,https://aclanthology.org/2020.acl-srw.26,"{'Establishing correspondence between disparate sentences is a major challenge in sentence fusion.': 'The authors seek to uncover hidden correspondences between sentences to improve content selection and deep sentence fusion. They describe the first effort at establishing points of correspondence between disparate sentences, inspired by Halliday and Hasan’s theory of text cohesion.', 'Modern abstractive summarizers struggle to reliably perform sentence fusion, and only a small percentage of summary sentences generated by these systems are fusion sentences.': 'The authors present a sizable dataset for sentence fusion containing human-annotated corresponding regions between pairs of sentences. This dataset can be used as a testbed for evaluating the ability of summarization models to perform sentence fusion.', 'Previous efforts at sentence fusion have focused on merging similar sentences, but humans are able to combine disparate sentences containing fundamentally different content.': 'The authors focus specifically on analyzing fusion of disparate sentences, which is a distinct problem from fusing a set of similar sentences. They aim to broaden the understanding of points of correspondence used for sentence fusion.', 'Fusion sentences generated by abstractive summarizers often contain incorrect facts.': ""The authors' dataset contains human-annotated corresponding regions between pairs of sentences, which can help improve the accuracy of fusion sentences generated by summarization models. They also report on insights gained from annotations to suggest important future directions for sentence fusion.""}",,['News'],[]
SP:a5bc07553f2e5379d07d80fd2fee5d8ed080af08,HOLMS: Alternative Summary Evaluation with Large Language Models,COLING,2020,"['Yassine Mrabet', 'Dina Demner-Fushman']","Efficient document summarization requires evaluation measures that can not only rank a set of systems based on an average score, but also highlight which individual summary is better than another. However, despite the very active research on summarization approaches, few works have proposed new evaluation measures in the recent years. The standard measures relied upon for the development of summarization systems are most often ROUGE and BLEU which, despite being efficient in overall system ranking, remain lexical in nature and have a limited potential when it comes to training neural networks. In this paper, we present a new hybrid evaluation measure for summarization, called HOLMS, that combines both language models pre-trained on large corpora and lexical similarity measures. Through several experiments, we show that HOLMS outperforms ROUGE and BLEU substantially in its correlation with human judgments on several extractive summarization datasets for both linguistic quality and pyramid scores.","The paper discusses the need for evaluation measures in document summarization that can rank systems based on individual summaries rather than just an average score. It highlights the limitations of current measures like ROUGE and BLEU, which are lexical in nature and not ideal for training neural networks. The authors propose a new hybrid evaluation measure called HOLMS, which combines language models and lexical similarity measures. They demonstrate through experiments that HOLMS outperforms ROUGE and BLEU in correlation with human judgments on several extractive summarization datasets for both linguistic quality and pyramid scores.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization systems.', 'How will the summaries be used?': 'The summaries will be used to rank summarization systems based on their performance and to highlight which individual summary is better than another.'}",['metric'],[],[],[],[],,https://aclanthology.org/2020.coling-main.498/,"{'Existing evaluation measures for document summarization only rank a set of systems based on an average score and do not highlight which individual summary is better than another.': 'The authors propose a new hybrid evaluation measure for summarization, called HOLMS, that can not only rank a set of systems based on an average score but also highlight which individual summary is better than another.', 'Few works have proposed new evaluation measures for document summarization in recent years.': 'The authors propose a new evaluation measure for summarization, called HOLMS, that combines both language models pre-trained on large corpora and lexical similarity measures.', 'The standard measures relied upon for the development of summarization systems, such as ROUGE and BLEU, remain lexical in nature and have a limited potential when it comes to training neural networks.': 'The authors propose a new hybrid evaluation measure for summarization, called HOLMS, that combines both language models pre-trained on large corpora and lexical similarity measures, which outperforms ROUGE and BLEU substantially in its correlation with human judgments on several extractive summarization datasets for both linguistic quality and pyramid scores.'}",,['News'],['robust-evaluation-methods']
SP:77fbc760de90c1f059340c01fccd49fb40dad188,"Evaluation of Summarization Systems across Gender, Age, and Race",EMNLP,2021,"['Anna Jørgensen', 'Anders Søgaard']","Summarization systems are ultimately evaluated by human annotators and raters. Usually, annotators and raters do not reflect the demographics of end users, but are recruited through student populations or crowdsourcing platforms with skewed demographics. For two different evaluation scenarios – evaluation against gold summaries and system output ratings – we show that summary evaluation is sensitive to protected attributes. This can severely bias system development and evaluation, leading us to build models that cater for some groups rather than others.","

System: The paper discusses how summarization systems are evaluated by human annotators and raters, who are often recruited through platforms with skewed demographics. The authors argue that this can lead to bias in system development and evaluation, as summary evaluation is sensitive to protected attributes. They suggest building models that cater to all groups rather than just some.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the progress of summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization systems.', 'How will the summaries be used?': 'The summaries will be used to analyze the preferences and judgments of different demographic groups in rater studies of summarization systems.'}",['analysis'],[],[],[],[],https://github.com/ajoer/summary_preferences,https://aclanthology.org/2021.newsum-1.6,"{'Summarization systems are evaluated by comparing machine-generated summaries to human summaries or by human rater studies, which involve human participants. However, the participants are typically recruited in some way, and this sampling bias may be a problem.': 'The authors ask whether different demographics exhibit different preferences in rater studies of summarization systems and present the first in-detail evaluations of summarization systems across demographic groups, focusing on gender, age, and race. They analyze what drives these differences and provide recommendations for future evaluations of summarization systems.', 'NLP models are only fair if they do not put certain demographics at a disadvantage, and it is crucial that benchmarks reflect preferences and judgments across those demographics.': 'The authors challenge the widely held position that lay people cannot be used for summary evaluation and believe that variance in summary quality is a product of social differences. They argue that it is something we need to worry about in NLP and recommend that future evaluations of summarization systems take into account demographic differences.'}",,['Wikipedia'],['robust-evaluation-methods']
SP:4876cc74ba509e63830aa6c793e741ad06ae39b8,A Graph-theoretic Summary Evaluation for ROUGE,EMNLP,2018,"['Elaheh ShafieiBavani', 'Mohammad Ebrahimi', 'Raymond Wong', 'Fang Chen']","ROUGE is one of the first and most widely used evaluation metrics for text summarization. However, its assessment merely relies on surface similarities between peer and model summaries. Consequently, ROUGE is unable to fairly evaluate summaries including lexical variations and paraphrasing. We propose a graph-based approach adopted into ROUGE to evaluate summaries based on both lexical and semantic similarities. Experiment results over TAC AESOP datasets show that exploiting the lexico-semantic similarity of the words used in summaries would significantly help ROUGE correlate better with human judgments.","System: The paper discusses the limitations of the ROUGE evaluation metric for text summarization, which only considers surface similarities between summaries and cannot accurately assess summaries with lexical variations and paraphrasing. The authors propose a graph-based approach to incorporate both lexical and semantic similarities into ROUGE. The results of experiments on TAC AESOP datasets show that this approach improves the correlation between ROUGE and human judgments.","{'What is the purpose of the summaries?': 'The authors are generating summaries to quantify the quality of automatic text summarization.', 'Who is the target audience?': 'The summaries are for evaluating the performance of automatic text summarization systems.', 'How will the summaries be used?': 'The summaries will be used to compare the concordance of system-generated summaries and human-generated reference summaries, and to identify the semantic similarities of linguistic items.'}",['metric'],[],[],[],[],,https://aclanthology.org/D18-1085/,"{'Relying only on lexical overlaps may underrate content quality scores in automatic text summarization.': 'The authors propose to help ROUGE with identifying the semantic similarities of linguistic items by considering senses instead of words. They use the Personalized PageRank (PPR) algorithm to leverage repetitive random walks on WordNet 3.0 as a semantic network. They disambiguate each word into its intended sense and obtain the probability distribution of each sense over all senses in the network. They measure the semantic similarity by looking at the path taken by the random walker and weighting the overlaps between a pair of ranked PPR vectors.', 'ROUGE or other surface-based evaluation metrics cannot capture the similarity between sentences that are semantically similar but lexically different.': 'The authors propose a graph-based approach called ROUGE-G that computes semantic similarity scores between n-grams, along with their match counts, to perform both semantic and lexical comparisons of peer and model summaries. ROUGE-G significantly outperforms its corresponding variants of ROUGE in the experiment results.', 'The bias towards lexical similarities in ROUGE limits its applicability to abstractive summarization.': 'The authors believe that ROUGE-G has the potential to expand the applicability of ROUGE to abstractive summarization due to its lexico-semantic analysis of summaries.'}",,['News'],['robust-evaluation-methods']
SP:7c1c936aec8c74ceb521dde1af37a6739188b921,Time-Limits and Summaries for Faster Relevance Assessing,SIGIR,2019,"['Shahin Rahbariasl', 'Mark D. Smucker']","Relevance assessing is a critical part of test collection construction as well as applications such as high-recall retrieval that require large amounts of relevance feedback. In these applications, tens of thousands of relevance assessments are required and assessing costs are directly related to the speed at which assessments are made. We conducted a user study with 60 participants where we investigated the impact of time limits (15, 30, and 60 seconds) and document size (full length vs. short summaries) on relevance assessing. Participants were shown either full documents or document summaries that they had to judge within a 15, 30, or 60 seconds time constraint per document. We found that using a time limit as short as 15 seconds or judging document summaries in place of full documents could significantly speed judging without significantly affecting judging quality. Participants found judging document summaries with a 60 second time limit to be the easiest and best experience of the six conditions. While time limits may speed judging, the same speed benefits can be had with high quality document summaries while providing an improved judging experience for assessors.",The paper discusses the importance of relevance assessing in applications such as high-recall retrieval and test collection construction. The authors conducted a user study with 60 participants to investigate the impact of time limits and document size on relevance assessing. They found that using a time limit as short as 15 seconds or judging document summaries in place of full documents could significantly speed judging without significantly affecting judging quality. Participants found judging document summaries with a 60 second time limit to be the easiest and best experience. The authors suggest that high quality document summaries can provide the same speed benefits as time limits while improving the judging experience for assessors.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to investigate the effect of time limits and document summaries on relevance assessing speed and accuracy.', 'Who is the target audience?': 'The summaries are for the assessors who are hired to collect relevance judgments for tasks such as test collection construction.', 'How will the summaries be used?': 'The summaries will be used to test the potential of summaries in improving the speed and accuracy of relevance assessing. The authors conducted a controlled laboratory study that used a factorial design and varied the time allowed and the document form to investigate the effect of time limits and document summaries on relevance assessing speed and accuracy.'}",['analysis'],[],[],[],[],,https://doi.org/10.1145/3331184.3331270,"{'Speed accuracy tradeoff is a well-known issue in relevance judging.': 'Investigate the effect of time limits and document summaries on relevance assessing speed and accuracy.', 'Speed and accuracy are chief concerns in relevance judging.': 'Conduct a controlled laboratory study that varies the time allowed and the document form.', 'Many factors influence the speed and accuracy of relevance judging.': 'Identify the chief factors, such as the assessors, the search topic or task, and the items being judged.', 'Time limits less than 60 seconds hurt the discrimination ability of assessors when judging full documents.': 'Use time limits with full documents to force the relevance assessor to make a judgment based on their limited examination of the document with little loss in accuracy.', 'Judging summaries with a time limit of 60 seconds was most favored by participants.': 'Use summaries to potentially increase the speed of relevance judging with little loss in quality.'}",,['News'],[]
SP:baf4b7ae39ee7e2b72898d0462d692b8bee2433d,Summarization Evaluation in the Absence of Human Model Summaries Using the Compositionality of Word Embeddings,COLING,2018,"['Elaheh ShafieiBavani', 'Mohammad Ebrahimi', 'Raymond Wong', 'Fang Chen']","We present a new summary evaluation approach that does not require human model summaries. Our approach exploits the compositional capabilities of corpus-based and lexical resource-based word embeddings to develop the features reflecting coverage, diversity, informativeness, and coherence of summaries. The features are then used to train a learning model for predicting the summary content quality in the absence of gold models. We evaluate the proposed metric in replicating the human assigned scores for summarization systems and summaries on data from query-focused and update summarization tasks in TAC 2008 and 2009. The results show that our feature combination provides reliable estimates of summary content quality when model summaries are not available.","The paper presents a new approach for evaluating the quality of summaries without the need for human model summaries. The approach uses word embeddings to develop features that reflect coverage, diversity, informativeness, and coherence of summaries. These features are then used to train a learning model for predicting summary content quality. The proposed metric was evaluated on data from query-focused and update summarization tasks in TAC 2008 and 2009, and the results show that the feature combination provides reliable estimates of summary content quality when model summaries are not available.","{'What is the purpose of the summaries?': 'The authors are generating summaries to evaluate the quality of automatic text summarization.', 'Who is the target audience?': 'The summaries are for evaluating the quality of system-generated summaries.', 'How will the summaries be used?': 'The summaries will be used to provide a means for model-free evaluation of summaries, particularly on non-standard test sets where model summaries are not available.'}",['metric'],[],[],[],[],,https://aclanthology.org/C18-1077,"{'Current summary evaluation methods heavily rely on multiple human-generated model summaries to assess the quality of system-generated summaries, which falls short on non-standard test sets where model summaries are not available.': 'Evaluating summaries by their comparison with the input obtains good correlations with manual evaluations. Identifying a suitable input-summary similarity metric will provide a means for model-free evaluation of summaries.', 'The need for a more accurate input-summary evaluation method.': 'Comparing semantic representations of the input and summary content will lead to more accurate input-summary evaluation. The authors explore the effectiveness of compositionality of word embeddings in developing a model-free automatic metric to evaluate summary content quality.', 'The need to demonstrate the effectiveness of the proposed approach.': 'The authors conducted a set of experiments on data from query-focused and update summarization tasks in TAC1 2008 and 2009. The reliability of the metric is also studied conducting an error analysis. The experiment results show that quantifying the indicators of content quality by taking advantage of compositional properties of the word and sense embeddings produces summary scores which accurately replicate human assessments.', 'The need to clarify that the proposed approach complements but is not intended to replace existing model-based evaluation approaches.': 'The authors clarify that their approach complements but is not intended to replace existing model-based evaluation approaches, since their reliability and strength are important for high confidence evaluations.'}",,['News'],['robust-evaluation-methods']
SP:3c90fbd572a82efcd5e1d4cce2d5aa216f30d61e,Earlier Isn’t Always Better: Sub-aspect Analysis on Corpus and System Biases in Summarization,EMNLP,2019,"['Taehee Jung', 'Dongyeop Kang', 'Lucas Mentch', 'Eduard Hovy']","Despite the recent developments on neural summarization systems, the underlying logic behind the improvements from the systems and its corpus-dependency remains largely unexplored. Position of sentences in the original text, for example, is a well known bias for news summarization. Following in the spirit of the claim that summarization is a combination of sub-functions, we define three sub-aspects of summarization: position, importance, and diversity and conduct an extensive analysis of the biases of each sub-aspect with respect to the domain of nine different summarization corpora (e.g., news, academic papers, meeting minutes, movie script, books, posts). We find that while position exhibits substantial bias in news articles, this is not the case, for example, with academic papers and meeting minutes. Furthermore, our empirical study shows that different types of summarization systems (e.g., neural-based) are composed of different degrees of the sub-aspects. Our study provides useful lessons regarding consideration of underlying sub-aspects when collecting a new summarization dataset or developing a new system.","The paper explores the biases and sub-aspects of summarization systems, specifically position, importance, and diversity, across nine different summarization corpora. The study finds that while position exhibits substantial bias in news articles, this is not the case for academic papers and meeting minutes. Additionally, different types of summarization systems are composed of different degrees of the sub-aspects. The study provides useful lessons for developing new summarization systems and collecting new summarization datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to explore the underlying rationales behind the improvements in neural summarization systems and their dependence on the training corpus.', 'Who is the target audience?': 'The summaries are for future summarization researches to provide actionable messages and to investigate biases in current summarization systems.', 'How will the summaries be used?': 'The summaries will be used to develop a notion of corpus bias and system bias, investigate which aspects are most important for different corpora, and explore the sub-aspect functions of summarization including position, importance, and diversity.'}",['analysis'],[],[],[],[],,https://doi.org/10.18653/v1/D19-1327,"{'The underlying rationales behind the improvements in neural summarization systems and their dependence on the training corpus remain largely unexplored.': 'The authors explore three important aspects of summarization - position, importance, and diversity - and conduct an in-depth analysis of these aspects over nine different domains of summarization corpora.', 'The position bias in news articles affects summarization tasks.': 'Narayan et al. collected a new dataset called XSum to create single sentence summaries that include material from multiple positions in the source document. Kedzie et al. showed that the position bias in news articles is not the same across other domains such as meeting minutes.', 'Many existing summarization systems are instances of mixtures of sub-aspect functions.': 'The authors follow the sub-aspect theory and explore the three important aspects of summarization - position, importance, and diversity - to investigate which aspects are most important for each corpus and develop a notion of corpus bias.', 'Summarizing long documents and conversations are extremely difficult tasks that require multiple aspects together.': 'The authors investigate which aspects are most important for each corpus and develop a notion of corpus bias to address the difficulty of summarizing long documents and conversations.', 'Biases exist in current summarization systems.': 'The authors conduct an in-depth analysis of the three important aspects of summarization and develop a notion of system bias to address the biases in current summarization systems. Simple ensembling of multiple aspects of systems show comparable performance with simple single-aspect systems.', 'Reference summaries in current corpora include less than 15% of new words that do not appear in the source document, except for abstract text of academic papers.': 'The authors provide this empirical result to inform future summarization researches.', 'Semantic volume overlap between the reference and model summaries is not correlated with the hard evaluation metrics such as ROUGE.': 'The authors provide this empirical result to inform future summarization researches.'}",,"['News', 'Scholarly Documents', 'Social Media', 'Books', 'Meeting Transcripts', 'Movie Scripts']","['exploiting-the-structure-of-long-documents', 'pretraining-and-sample-efficiency', 'robust-evaluation-methods']"
SP:d3d6a530f36fe2f11eff9f5082d32b6d34cb7073,Searching for Effective Neural Extractive Summarization: What Works and What’s Next,ACL,2019,"['Ming Zhong', 'Pengfei Liu', 'Danqing Wang', 'Xipeng Qiu', 'Xuanjing Huang']","The recent years have seen remarkable success in the use of deep neural networks on text summarization. However, there is no clear understanding of why they perform so well, or how they might be improved. In this paper, we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and learning schemas. Additionally, we find an effective way to improve current frameworks and achieve the state-ofthe-art result on CNN/DailyMail by a large margin based on our observations and analyses. Hopefully, our work could provide more clues for future research on extractive summarization. Source code will be available on Github1.","System: The paper discusses the success of deep neural networks in text summarization, but notes that there is still much to be understood about why they work so well and how they can be improved. The authors explore different model architectures, transferable knowledge, and learning schemas to improve neural extractive summarization systems. They also present a new framework that achieves state-of-the-art results on CNN/DailyMail. The paper aims to provide insights for future research on extractive summarization and the source code is available on Github.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to better understand how neural network-based approaches to extractive summarization could benefit from different types of model architectures, transferable knowledge, and learning schemas, and how they might be improved.', 'Who is the target audience?': 'The summaries are for researchers who want to design better architectures and explore new state-of-the-art results along a right direction.', 'How will the summaries be used?': 'The summaries will be used to provide more hints for follow-up researchers to design better architectures and explore new state-of-the-art results along a right direction.'}",['analysis'],[],[],[],[],https://github.com/fastnlp/fastNLP,https://aclanthology.org/P19-1100/,"{'It is poorly understood why deep neural networks perform well in text summarization and what their shortcomings are, limiting the ability to design better architectures.': 'Conduct a detailed empirical study to analyze and understand existing models, focusing on extractive summarization, and explore how neural network-based approaches can benefit from different types of model architectures, transferable knowledge, and learning schemas.', 'Little is known about the functionality of each neural component and the differences between them, raising questions about how the choice of different neural architectures (CNN, RNN, Transformer) influences the performance of the summarization system, which components matter for specific datasets, and whether current models suffer from the over-engineering problem.': 'Analyze the above questions to understand the system better, choose suitable architectures in different application scenarios, and motivate the development of more powerful frameworks.', 'The improvement in accuracy and performance is not only due to the shift from feature engineering to structure engineering but also the flexible ways to incorporate external knowledge and learning schemas to introduce extra instructive constraints.': 'Take the first steps toward answering questions about which type of pre-trained models (supervised or unsupervised pre-training) is more friendly to the summarization task and whether introducing external transferable knowledge or changing another learning schema can push the state-of-the-art results to a new level.', 'There is a need to peer into the internal working mechanism of different testing cases and provide sufficient evaluation scenarios to better understand the characteristics of different datasets.': 'Build a testbed for the summarization system, design different summarization models in the training environment, and provide evaluation scenarios in the testing environment, including a multi-domain test, sentence shuffling test, and analysis of models by different metrics (repetition, sentence length, and position bias).'}",,['News'],['controlled-and-tailored-summarization']
SP:b36904dfe6819b26c54c3fd46410e2f706863ea5,Is Human Scoring the Best Criteria for Summary Evaluation?,ACL,2021,"['Oleg Vasilyev', 'John Bohannon']","A summary quality measure is judged by how well it correlates with quality scores produced by human annotators. A higher correlation with human scores is considered to be a decisive indicator of a better measure. In this work we present observations that cast doubt on this view. We also show a possibility of an alternative indicator for selecting the best measure from a family of measures, a criterion that does not rely on human scores.",System: The paper challenges the commonly held belief that a summary quality measure is best judged by how closely it correlates with quality scores produced by human annotators. The authors present observations that question this view and propose an alternative criterion for selecting the best measure from a group of measures that does not rely on human scores.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to convey important and only important information of the text in a fluent, comprehensible and concise summary, preserving the factual consistency with the text.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but it discusses different families of automated measures of summary quality and provides examples of evaluation measures that correlate well with human evaluation scores.'}",['metric'],[],[],[],[],,https://aclanthology.org/2021.findings-acl.192,"{'The subjectivity of summary qualities makes it difficult to design and use human annotations for evaluating summary quality.': 'The authors suggest being careful in the design and usage of human annotations and argue that factual faithfulness can be annotated objectively with detailed classification of factual errors.', 'Annotators are biased in favor of anything that makes the scoring easier, such as extractiveness of the summary and focus on the top part of the document.': 'The authors suggest being aware of these biases and designing evaluation measures that are not influenced by them.', 'A dubious modification that imitates human annotator behavior can increase the correlation with human scores, leading to false improvements in automated evaluation measures.': 'The authors provide an example of a true improvement that increases correlation with human scores for a good reason and suggest using an alternative criterion for selecting an optimal evaluation measure from a family of measures that does not rely on human scores.', 'There are several families of automated measures of summary quality, and it can be difficult to choose a good evaluation measure.': 'The authors suggest using a high correlation with human evaluation scores as the crucial criterion for choosing a good evaluation measure and exploring alternative criteria that are robust across different kinds of texts and summaries.', 'The BLANC family of evaluation measures has two different setups, BLANC-help and BLANC-tune, which may differ by the parameters defining the setup.': 'The authors use the BLANC family of evaluation measures for their demonstration because it is easily interpretable as an analogy to a human reader that uses the summary to guess the content of the text and explore the differences between the BLANC-help and BLANC-tune setups.'}",,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:b4cfd4e5837e3415ad22594682bfe7c19cd5e20a,SUMMAC: Re-Visiting NLI-based Models for Inconsistency Detection in Summarization,TACL,2022,"['Philippe Laban', 'Tobias Schnabel', 'Paul N. Bennett', 'Marti A. Hearst']","In the summarization domain, a key requirement for summaries is to be factually consistent with the input document. Previous work has found that natural language inference (NLI) models do not perform competitively when applied to inconsistency detection. In this work, we revisit the use of NLI for inconsistency detection, finding that past work suffered from a mismatch in input granularity between NLI datasets (sentence-level), and inconsistency detection (document level). We provide a highly effective and light-weight method called SUMMACCONV that enables NLI models to be successfully used for this task by segmenting documents into sentence units and aggregating scores between pairs of sentences. We furthermore introduce a new benchmark called SUMMAC (Summary Consistency) which consists of six large inconsistency detection datasets. On this dataset, SUMMACConv obtains state-of-the-art results with a balanced accuracy of 74.4%, a 5% improvement compared with prior work.","The paper discusses the importance of factual consistency in summaries and the limitations of natural language inference (NLI) models for inconsistency detection. The authors propose a new method called SUMMACCONV, which segments documents into sentence units and aggregates scores between pairs of sentences, enabling NLI models to be successfully used for this task. They also introduce a new benchmark called SUMMAC, consisting of six large inconsistency detection datasets. On this dataset, SUMMACConv obtains state-of-the-art results with a balanced accuracy of 74.4%, a 5% improvement compared with prior work.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the factually consistency of the summaries.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick and accurate understanding of the content of a document, while ensuring that the summary remains factually consistent with the original document.'}","['corpus', 'metric']",[],[],[],[],https://github.com/tingofurro/summac/.,https://doi.org/10.1162/tacl_a_00453,"{'Current summarization models have a major limitation in their inability to remain factually consistent with the respective input document, leading to summary inconsistencies.': 'The authors propose a new approach for inconsistency detection based on the aggregation of sentence-level entailment scores for each pair of input document and summary sentences. They present two model variants that differ in the way they aggregate sentence-level scores into a single score.', 'Early attempts at using NLI to detect consistency errors in summaries were unsuccessful.': 'The authors revisit this approach and show that NLI models can be successfully used for inconsistency detection, as long as they are used at the appropriate granularity. They illustrate the importance of working with sentence pairs for making NLI models work for inconsistency detection.', 'Existing inconsistency detection models are outperformed by the proposed approach.': 'The SUMMAC models outperform existing inconsistency detection models on the benchmark, with the SUMMACCONV obtaining an overall balanced accuracy of 74.4%, 5% above prior work. The authors publicly release the models and datasets.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:489624042e8d3575aaa41d1d10b347a703244db6,What Have We Achieved on Text Summarization?,EMNLP,2020,"['Dandan Huang', 'Leyang Cui', 'Sen Yang', 'Guangsheng Bao', 'Kun Wang', 'Jun Xie', 'Yue Zhang']","Deep learning has led to significant improvement in text summarization with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by automatic summarizers and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric1 (MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency; 2) milestone techniques such as copy, coverage and hybrid extractive/abstractive methods do bring specific improvements but also demonstrate limitations; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results.","The paper discusses the current state of text summarization using deep learning and highlights the gaps that still exist between automatic summarizers and human professionals. The authors use the Multidimensional Quality Metric to identify 8 major sources of errors on 10 representative summarization models. They find that extractive summarizers are generally better than abstractive ones in terms of faithfulness and factual-consistency. They also note that pre-training techniques, particularly sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART being the most effective. The paper provides insights into the strengths and limitations of different summarization techniques and highlights areas for future research.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the practical importance of automatic text summarization, which has received constant research attention.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of automatic text summarization.', 'How will the summaries be used?': 'The summaries will be used to compare and evaluate different summarization methods, including extractive and abstractive approaches, and to identify the primary sources of errors in representative models. The authors also release a test set and evaluation toolkit to help future research on evaluation methods and automatic summarization systems.'}","['corpus', 'analysis']",[],[],[],[],https://github.com/hddbang/PolyTope,https://aclanthology.org/2020.emnlp-main.33,"{'The quality of machine-generated summaries still falls far behind human written ones.': 'Quantify the primary sources of errors over representative models using PolyTope, a set of 8 metrics on the Accuracy and Fluency aspects. Models are analyzed by the overall error counts on a test set according to each metric, and therefore our evaluation can be more informative and objective compared with existing manual evaluation reports.', 'ROUGE has been shown insufficient as a precise indicator on summarization quality evaluation.': 'Use human evaluation as a complement to ROUGE scores. We manually evaluate 10 text summarizers using PolyTope, which includes Lead-3, TextRank, Sequence-to-sequence with Attention, SummaRuNNer, PointGenerator, Point-Generator-withCoverage, BottomUp, BertSumExt, BertSumExtAbs, and BART.', 'It still remains uncertain what we have achieved overall and what fundamental changes each milestone technique has brought.': 'Analyze the effectiveness of frequently-used techniques in summarization systems, including traditional rule-based methods, neural architectures, extractive vs abstractive approaches, milestone techniques such as copy and coverage, and hybrid extractive/abstractive models.', 'The main shortcoming of abstractive models is omission and intrinsic hallucination.': 'Use pre-training, which is highly effective for summarization, and even achieves a better content selection capability without copy and coverage mechanisms. Particularly, joint pre-training combining text understanding and generation gives the most salient advantage, with the BART model achieving by far the state-of-the-art results on both automatic and our human evaluations.'}",,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:5ce7976ee1f04d0da56b084ea1f122e0e3cbdd56,Are Factuality Checkers Reliable? Adversarial Meta-evaluation of Factuality in Summarization,EMNLP,2021,"['Yiran Chen', 'Pengfei Liu', 'Xipeng Qiu']","With the continuous upgrading of the summarization systems driven by deep neural networks, researchers have higher requirements on the quality of the generated summaries, which should be not only fluent and informative but also factually correct. As a result, the field of factual evaluation has developed rapidly recently. Despite its initial progress in evaluating generated summaries, the meta-evaluation methodologies of factuality metrics are limited in their opacity, leading to the insufficient understanding of factuality metrics’ relative advantages and their applicability. In this paper, we present an adversarial meta-evaluation methodology that allows us to (i) diagnose the fine-grained strengths and weaknesses of 6 existing top-performing metrics over 24 diagnostic test datasets, (ii) search for directions for further improvement by data augmentation. Our observations from this work motivate us to propose several calls for future research. We make all codes, diagnostic test datasets, trained factuality models available: https://github.com/zide05/ AdvFact.","The paper discusses the importance of generating summaries that are not only fluent and informative but also factually correct, and the rapid development of the field of factual evaluation. However, the meta-evaluation methodologies of factuality metrics are limited in their opacity, leading to insufficient understanding of their relative advantages and applicability. The paper presents an adversarial meta-evaluation methodology that diagnoses the strengths and weaknesses of 6 existing top-performing metrics over 24 diagnostic test datasets and searches for directions for further improvement by data augmentation. The authors propose several calls for future research and make all codes, diagnostic test datasets, and trained factuality models available.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the factuality of the generated summaries.', 'Who is the target audience?': 'The summaries are for automated text summarization systems that use neural networks.', 'How will the summaries be used?': 'The summaries will be used to assess the factuality of generated summaries and to improve the performance of current checkers.'}",['analysis'],[],[],[],[],https://github.com/zide05/AdvFact,https://aclanthology.org/2021.findings-emnlp.179,"{'Existing automated metrics for text summarization, such as ROUGE and BERTScore, do not effectively assess the factuality of generated summaries.': 'The authors propose a search for new automated metrics that can assess the factuality of generated summaries. They also propose an adversarial meta-evaluation framework that can perform fine-grained evaluation of factuality metrics.', 'The evaluation methodologies of factuality metrics are limited in their opacity, making it difficult to interpret their results.': 'The authors propose a fine-grained meta-evaluation methodology for factuality metrics that can assess their relative strengths and weaknesses. They also call for a more fine-grained and interpretable meta-evaluation of factuality metrics for future research.', 'The lack of understanding of factuality metrics’ applicability reduces their reliability, and users may take the risk of over-estimating their generalization ability so as to apply them to inappropriate evaluation samples.': 'The authors propose effective adversarial transformations that can either be applied to test set for model diagnosis or applied to training set for data augmentation, by which they further improve the performance of current checkers. They also released their constructed diagnostic test sets with various characteristics, as well as augmented training data and more robust factuality metrics.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:dfd7e418ca39484e3fd090ead5eccf048e241f3c,QuestEval: Summarization Asks for Fact-based Evaluation,EMNLP,2021,"['Thomas Scialom', 'Paul-Alexis Dray', 'Patrick Gallinari', 'Sylvain Lamprier', 'Benjamin Piwowarski', 'Jacopo Staiano', 'Alex Wang']","Summarization evaluation remains an open research problem: current metrics such as ROUGE are known to be limited and to correlate poorly with human judgments. To alleviate this issue, recent work has proposed evaluation metrics which rely on question answering models to assess whether a summary contains all the relevant information in its source document. Though promising, the proposed approaches have so far failed to correlate better than ROUGE with human judgments. In this paper, we extend previous approaches and propose a unified framework, named QUESTEVAL. In contrast to established metrics such as ROUGE or BERTScore, QUESTEVAL does not require any groundtruth reference. Nonetheless, QUESTEVAL substantially improves the correlation with human judgments over four evaluation dimensions (consistency, coherence, fluency, and relevance), as shown in extensive experiments. We make code and models available.1","The paper discusses the limitations of current metrics for evaluating summarization, such as ROUGE, and proposes a new framework called QUESTEVAL. Unlike other metrics, QUESTEVAL does not require a groundtruth reference and relies on question answering models to assess whether a summary contains all the relevant information from its source document. The paper shows that QUESTEVAL significantly improves the correlation with human judgments over four evaluation dimensions: consistency, coherence, fluency, and relevance. The authors also provide code and models for the framework.","{'Who is the target audience?': 'The generated summaries are for evaluating the performance of NLG systems, and are intended for researchers and developers in the field of artificial intelligence.'}",['metric'],[],[],[],[],https://github.com/ThomasScialom/QuestEval,https://aclanthology.org/2021.emnlp-main.529,"{'The reliability of automatic evaluation metrics for NLG systems is low and there is a need for new evaluation metrics that correlate better with human judgments.': 'The authors propose a new reference-less metric called QUESTEVAL that improves the correlation with human judgments.', 'Summarization is one of the most difficult NLG tasks to evaluate automatically due to the large number of possible correct outputs and the need for information selection.': 'The authors propose using question generation and answering metrics to evaluate summarization systems, which measure the extent to which a summary provides sufficient information to answer questions posed on its corresponding source document.', 'N-gram based metrics like ROUGE poorly reflect human preference and do not measure factual consistency.': 'The authors propose using QUESTEVAL, which is effective at measuring factual consistency and obtains state-of-the-art results in terms of correlation with human judgments.', 'State-of-the-art generative models produce fluent summaries but frequently contain false or unsupported information.': 'The authors propose using QUESTEVAL to measure factual consistency and ensure that generated summaries are factually consistent with their source documents.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:575bde806434bb560ff992a878889d1b141f99ee,Supporting content evaluation of student summaries by Idea Unit embedding,ACL,2019,"['Marcello Gecchele', 'Hiroaki Yamada', 'Takenobu Tokunaga', 'Yasuyo Sawaki']","This paper discusses the computer-assisted content evaluation of summaries. We propose a method to make a correspondence between the segments of the source text and its summary. As a unit of the segment, we adopt “Idea Unit (IU)” which is proposed in Applied Linguistics. Introducing IUs enables us to make a correspondence even for the sentences that contain multiple ideas. The IU correspondence is made based on the similarity between vector representations of IU. An evaluation experiment with two source texts and 20 summaries showed that the proposed method is more robust against rephrased expressions than the conventional ROUGEbased baselines. Also, the proposed method outperformed the baselines in recall. We implemented the proposed method in a GUI tool “Segment Matcher” that aids teachers to establish a link between corresponding IUs across the summary and source text.","The paper proposes a method for computer-assisted content evaluation of summaries by establishing a correspondence between segments of the source text and its summary using ""Idea Units (IUs)."" The IU correspondence is based on the similarity between vector representations of IU. The proposed method is more robust against rephrased expressions than conventional ROUGE-based baselines and outperformed the baselines in recall. The proposed method has been implemented in a GUI tool called ""Segment Matcher"" to help teachers establish a link between corresponding IUs across the summary and source text.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to develop student linguistic proficiency, including text comprehension and composition.', 'Who is the target audience?': ""The summaries are for teachers to evaluate a student's proficiency in language."", 'How will the summaries be used?': 'The summaries will be used to assess if the summary conveys the important ideas of the source text, as well as the grammatical and lexical correctness.'}",['metric'],[],[],[],[],,https://aclanthology.org/W19-4436,"{'Finding the corresponding information between the summary and source text is not an easy task for humans.': 'The authors propose a support tool for evaluating student summaries in terms of their contents by suggesting the links between the ideas of a source text and its summary.', 'Rephrasing often obfuscates the bonds between the contents of the source and summary texts, making summary evaluation a complex activity.': 'The authors suggest dividing texts into Idea Units (IUs) to deal with complex sentences that convey multiple ideas. The IU is defined as a minimal fragment of a text that conveys an “idea” or “thought” coherently. They make correspondence between IUs instead of sentences across the source text and its summary. To circumvent inaccurate IU pairing due to rephrasing, they adopt word embedding for the calculation of IU similarity.'}",,['Student Responses'],['controlled-and-tailored-summarization']
SP:b361b18af674d85a719a79031cf7bcaf51e3eec3,Facet-Aware Evaluation for Extractive Summarization,ACL,2020,"['Yuning Mao', 'Liyuan Liu', 'Qi Zhu', 'Xiang Ren', 'Jiawei Han']","Commonly adopted metrics for extractive summarization focus on lexical overlap at the token level. In this paper, we present a facetaware evaluation setup for better assessment of the information coverage in extracted summaries. Specifically, we treat each sentence in the reference summary as a facet, identify the sentences in the document that express the semantics of each facet as support sentences of the facet, and automatically evaluate extractive summarization methods by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. To facilitate this new evaluation setup, we construct an extractive version of the CNN/Daily Mail dataset and perform a thorough quantitative investigation, through which we demonstrate that facet-aware evaluation manifests better correlation with human judgment than ROUGE, enables fine-grained evaluation as well as comparative analysis, and reveals valuable insights of state-of-the-art summarization methods.1","The paper proposes a new evaluation setup for extractive summarization that focuses on assessing the information coverage in extracted summaries. This setup involves treating each sentence in the reference summary as a facet and identifying the sentences in the document that express the semantics of each facet as support sentences. The evaluation is then performed by comparing the indices of extracted sentences and support sentences of all the facets in the reference summary. The authors construct an extractive version of the CNN/Daily Mail dataset to facilitate this new evaluation setup and demonstrate that it is more effective than commonly adopted metrics like ROUGE in manifesting better correlation with human judgment, enabling fine-grained evaluation and comparative analysis, and revealing valuable insights of state-of-the-art summarization methods.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the effectiveness of text summarization methods.', 'Who is the target audience?': 'The summaries are for the summarization community to better assess information coverage and gain deeper understandings of the current benchmark dataset and state-of-the-art methods.', 'How will the summaries be used?': 'The summaries will be used to compare different extractive methods in terms of their capability of extracting salient and non-redundant sentences, and to fine-grained evaluate both abstractive and extractive methods. They will also be used to explore the feasibility of automatic facet-aware mappings creation.'}",['metric'],[],[],[],[],https://github.com/morningmoni/FAR,https://aclanthology.org/2020.acl-main.445,"{'The evaluation of text summarization remains challenging and controversial, with the most commonly used evaluation metric of summarization, ROUGE, having limitations and failing to reach consensus with human judgment.': 'The authors propose a facet-aware evaluation setup that better assesses information coverage for extractive summarization by treating each reference sentence as a facet, identifying document sentences that express the semantics of each facet as support sentences of the facet, and measuring information coverage by Facet-Aware Recall (FAR).', 'Extractive methods are somewhat unfairly penalized for extracting long sentences that cover the facets, and conventional extractive labels correspond to the entire reference summary rather than individual facets.': 'The authors use Facet-Aware Mappings (FAMs) as labels indicating which sentences should be extracted but they are grouped with respect to each facet, allowing for a more accurate assessment on the summary quality.', 'The effectiveness of facet-aware evaluation has not been verified.': 'The authors construct an extractive version of the CNN/Daily Mail dataset by annotating its FAMs and revisit state-of-the-art extractive methods using this new extractive dataset, showing that FAR correlates better with human evaluation than ROUGE.', 'The feasibility of automatic FAM creation has not been explored.': 'The authors evaluate sentence regression approaches against the ground-truth annotations (i.e., FAMs) and generalize facet-aware evaluation to the entire CNN/Daily Mail dataset without any human annotation.', 'There has not been a thorough quantitative analysis regarding the characteristics of the CNN/Daily Mail dataset.': 'The authors provide the first thorough quantitative analysis regarding the characteristics of the CNN/Daily Mail dataset.'}",,['News'],['robust-evaluation-methods']
SP:f448239ae5a6749fd9ec4e560bcf88bdbaa01a61,Mapping the Design Space of Human-AI Interaction in Text Summarization,NAACL,2022,"['Ruijia Cheng', 'Alison Smith-Renner', 'Ke Zhang', 'Joel R. Tetreault', 'Alejandro Jaimes']","Automatic text summarization systems commonly involve humans for preparing data or evaluating model performance, yet, there lacks a systematic understanding of humans’ roles, experience, and needs when interacting with or being assisted by AI. From a human-centered perspective, we map the design opportunities and considerations for human-AI interaction in text summarization and broader text generation tasks. We first conducted a systematic literature review of 70 papers, developing a taxonomy of five interactions in AI-assisted text generation and relevant design dimensions. We designed text summarization prototypes for each interaction. We then interviewed 16 users, aided by the prototypes, to understand their expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization and propose design considerations accordingly.","The paper explores the role of humans in automatic text summarization systems and the design considerations for human-AI interaction in text generation tasks. The authors conducted a literature review and developed a taxonomy of five interactions in AI-assisted text generation. They designed text summarization prototypes for each interaction and interviewed 16 users to understand their expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization. The paper proposes design considerations for human-AI interaction in text summarization and broader text generation tasks.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to understand the roles, experience, and needs of humans when interacting with or being assisted by AI in text summarization and broader text generation tasks.', 'Who is the target audience?': 'The summaries are for users who interact with or are assisted by AI in text summarization and broader text generation tasks.', 'How will the summaries be used?': 'The summaries will be used to propose design considerations for human-AI interaction in text summarization and broader text generation tasks.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2022.naacl-main.33,"{""Lack of systematic understanding of humans' roles, experience, and needs when interacting with or being assisted by AI in text summarization and broader text generation tasks."": 'Conduct a systematic literature review of 70 papers to develop a taxonomy of five interactions in AI-assisted text generation and relevant design dimensions. Design text summarization prototypes for each interaction and interview 16 users, aided by the prototypes, to understand their expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization and propose design considerations accordingly.', 'Lack of design opportunities and considerations for human-AI interaction in text summarization and broader text generation tasks from a human-centered perspective.': 'Map the design opportunities and considerations for human-AI interaction in text summarization and broader text generation tasks from a human-centered perspective.', ""Lack of understanding of users' expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization."": 'Interview 16 users, aided by the prototypes, to understand their expectations, experience, and needs regarding efficiency, control, and trust with AI in text summarization and propose design considerations accordingly.'}",,['News'],['controlled-and-tailored-summarization']
SP:787031b30f31e048216216e4a2853615d51ccbf3,Fact-based Content Weighting for Evaluating Abstractive Summarisation,ACL,2020,"['Xinnuo Xu', 'Ondřej Dušek', 'Jingyi Li', 'Verena Rieser', 'Ioannis Konstas']","Abstractive summarisation is notoriously hard to evaluate since standard word-overlap-based metrics are biased towards specific words in the human reference. We introduce a new evaluation metric which abstracts away from the word-level and instead is based on factlevel content weighting, i.e. relating the facts of the document to the facts of the summary. We follow the assumption that a good summary will reflect all relevant facts, i.e. the ones present in the ground truth (human-generated reference summary). We confirm this hypothesis by showing that our weightings are highly correlated to human perception and compare favourably to the recent manual highlightbased metric of Hardy et al. (2019).ive summarisation is notoriously hard to evaluate since standard word-overlap-based metrics are biased towards specific words in the human reference. We introduce a new evaluation metric which abstracts away from the word-level and instead is based on factlevel content weighting, i.e. relating the facts of the document to the facts of the summary. We follow the assumption that a good summary will reflect all relevant facts, i.e. the ones present in the ground truth (human-generated reference summary). We confirm this hypothesis by showing that our weightings are highly correlated to human perception and compare favourably to the recent manual highlightbased metric of Hardy et al. (2019).","The paper discusses the difficulty of evaluating abstractive summarization using standard word-overlap-based metrics, and introduces a new evaluation metric based on fact-level content weighting. The metric relates the facts of the document to the facts of the summary, and assumes that a good summary will reflect all relevant facts present in the human-generated reference summary. The authors confirm this hypothesis by showing that their weightings are highly correlated to human perception and compare favorably to a recent manual highlight-based metric.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress long textual documents into short summaries while retaining the most important information from the source.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the given paper.', 'How will the summaries be used?': 'The potential uses of the summaries are not specified in the given paper.'}",['metric'],[],[],[],[],https://github.com/XinnuoXu/CorrFA_for_Summarizaion,https://aclanthology.org/2020.acl-main.455,"{'Decoders are amenable to pathogeniessuch as hallucination and/or omission of important information, which are hard to capture using existing evaluation metrics.': 'The authors propose a new evaluation metric based on content weighting, where they abstract away from the particular surface form of the target summary, but represent it as facts using Semantic Role Labelling (SRL). In this way, they aim to better capture the semantic correctness of a summary, i.e. be more sensitive to hallucinations and omissions.', 'Most datasets used for abstractive summarisation only contain a single reference summary, which most existing automatic metrics evaluate against, and thus tend to downvote paraphrases.': 'The authors propose to weight the facts present in the source document according to the facts selected by a human-written summary. This alignment is conducted using contextual, rather than token-level, embeddings, e.g., BERT. For evaluation, they measure whether an automatically generated summary is able to capture the same facts as the target.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:2c74c6c4d1ebba48b0afaa5c3350b52be6108ba7,A Semantic QA-Based Approach for Text Summarization Evaluation,AAAI,2018,"['Ping Chen', 'Fei Wu', 'Tong Wang', 'Wei Ding']","Many Natural Language Processing and Computational Linguistics applications involve the generation of new texts based on some existing texts, such as summarization, text simplification and machine translation. However, there has been a serious problem haunting these applications for decades, that is, how to automatically and accurately assess quality of these applications. In this paper, we will present some preliminary results on one especially useful and challenging problem in NLP system evaluation – how to pinpoint content differences of two text passages (especially for large passages such as articles and books). Our idea is intuitive and very different from existing approaches. We treat one text passage as a small knowledge base, and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, we will be able to compare their content precisely. The experiment using 2007 DUC summarization corpus clearly shows promising results.","The paper discusses the challenge of assessing the quality of Natural Language Processing and Computational Linguistics applications that generate new texts based on existing texts. Specifically, the paper focuses on the problem of pinpointing content differences between two text passages, especially for large passages such as articles and books. The authors propose a new approach that treats one text passage as a small knowledge base and asks it a large number of questions to identify all content points. By comparing the correctly answered questions from two text passages, the authors are able to compare their content precisely. The experiment using 2007 DUC summarization corpus shows promising results.",{'Who is the target audience?': 'The summaries of documents are for use in NLP system evaluation.'},['analysis'],[],[],[],[],,https://arxiv.org/abs/1704.06259,"{'The main problem tackled by the authors is how to automatically and accurately assess the quality of Natural Language Processing and Computational Linguistics applications that involve the generation of new texts based on existing texts.': 'The authors propose a solution to this problem by presenting a method to pinpoint content differences of two text passages, especially for large passages such as articles and books. They treat one text passage as a small knowledge base and ask it a large number of questions to exhaustively identify all content points in it. By comparing the correctly answered questions from two text passages, they are able to compare their content precisely.', 'The authors also address the challenge of identifying content differences in large text passages, which is a particularly difficult problem in NLP system evaluation.': 'The authors propose a solution to this problem by treating one text passage as a small knowledge base and asking it a large number of questions to exhaustively identify all content points in it. This approach allows for the identification of content differences in large text passages with greater accuracy and precision.', 'Existing approaches to content comparison in NLP system evaluation are not intuitive and may not accurately capture all content differences between two text passages.': 'The authors propose a new approach to content comparison that is intuitive and different from existing approaches. By treating one text passage as a small knowledge base and asking it a large number of questions, they are able to exhaustively identify all content points in it and compare it to another text passage with greater accuracy and precision.'}",,['News'],[]
SP:1a0e30f4fcbf8a7da4ba8ff4d741af4c82136093,Self-Repetition in Abstractive Neural Summarizers,AACL,2022,"['Nikita Salkar', 'Thomas Trikalinos', 'Byron C. Wallace', 'Ani Nenkova']","We provide a quantitative and qualitative analysis of self-repetition in the output of neural summarizers. We measure self-repetition as the number of n-grams of length four or longer that appear in multiple outputs of the same system. We analyze the behavior of three popular architectures (BART, T5 and Pegasus), fine-tuned on five datasets. In a regression analysis, we find that the three architectures have different propensities for repeating content across output summaries for inputs, with BART being particularly prone to self-repetition. Fine-tuning on more abstractive data, and on data featuring formulaic language, is associated with a higher rate of self-repetition. In qualitative analysis we find systems produce artefacts such as ads and disclaimers unrelated to the content being summarized, as well as formulaic phrases common in the fine-tuning domain. Our approach to corpus level analysis of self-repetition may help practitioners clean up training data for summarizers and ultimately support methods for minimizing the amount of self-repetition.","The paper analyzes self-repetition in the output of neural summarizers, measuring it as the number of repeated n-grams of length four or longer. Three popular architectures (BART, T5, and Pegasus) are analyzed, and it is found that BART is particularly prone to self-repetition. Fine-tuning on more abstractive data and data featuring formulaic language is associated with a higher rate of self-repetition. Qualitative analysis reveals that systems produce artefacts such as ads and disclaimers unrelated to the content being summarized, as well as formulaic phrases common in the fine-tuning domain. The paper suggests that their approach to corpus level analysis of self-repetition may help practitioners clean up training data for summarizers and ultimately support methods for minimizing the amount of self-repetition.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to study the novelty of models with respect to their own outputs, by measuring the extent to which the content a model generates is formulaic repetition produced across inputs.', 'Who is the target audience?': 'The summaries are for abstractive summarization tasks and are generated by sequence-to-sequence neural models such as BART, T5, and Pegasus.', 'How will the summaries be used?': 'The repetition metrics introduced by the authors may be broadly useful in characterizing the performance of new abstractive summarization systems, as they show that models differ markedly with respect to these measures.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2022.aacl-short.42,"{'Abstractive summarization systems often repeat text verbatim from inputs, which reduces the novelty of their outputs.': 'The authors study the novelty of models with respect to their own outputs by measuring the extent to which the content a model generates is formulaic repetition produced across inputs. They analyze how often long n-grams (length ≥4) appear in at least two summaries for different inputs.', 'It is unclear how much repetition is normal in a particular domain, and how much is too much.': 'The authors contextualize their measurements by contrasting repetition in summaries written by humans with what they observe in system outputs. They find that in three out of the five domains they study, long n-gram repetition is considerably higher in automatically produced summaries than in human-written summaries. In the fourth domain, scientific papers, self-repetition even in human summaries is so high that the measure they use may not be sensitive enough to distinguish differences in repetition at this range.', 'Undesirable repetition behavior in summarization systems is difficult to quantify.': 'The authors hypothesize that such behavior can be easier to quantify when systems are evaluated across domains, tasking a system trained in one domain to generate summaries in another. They perform a regression analysis in which they include as predictors system architecture, as well as training and test datasets. They find that BART is especially prone to self-repetition, more so than the other architectures they consider, and that the type of training data used to fine-tune the sequence-to-sequence model for summarization has a considerable impact on the propensity of models to repeat themselves.', 'The dimension of repetition and novelty in summarization has not been explored previously.': ""The authors' work highlights this dimension and introduces repetition metrics that may be broadly useful in characterizing the performance of new abstractive summarization systems, as they show that models differ markedly with respect to these measures.""}",,['News'],['efficient-encoding-of-long-documents']
SP:d34ac4e7f3f31adeb0bcff213df223525d62a1de,On Faithfulness and Factuality in Abstractive Summarization,ACL,2020,"['Joshua Maynez', 'Shashi Narayan', 'Bernd Bohnet', 'Ryan McDonald']","It is well known that the standard likelihood training and approximate decoding objectives in neural text generation models lead to less human-like responses for open-ended tasks such as language modeling and story generation. In this paper we have analyzed limitations of these models for abstractive document summarization and found that these models are highly prone to hallucinate content that is unfaithful to the input document. We conducted a large scale human evaluation of several neural abstractive summarization systems to better understand the types of hallucinations they produce. Our human annotators found substantial amounts of hallucinated content in all model generated summaries. However, our analysis does show that pretrained models are better summarizers not only in terms of raw metrics, i.e., ROUGE, but also in generating faithful and factual summaries as evaluated by humans. Furthermore, we show that textual entailment measures better correlate with faithfulness than standard metrics, potentially leading the way to automatic evaluation metrics as well as training and decoding criteria.1","The paper examines the limitations of neural text generation models for abstractive document summarization and finds that these models often generate content that is unfaithful to the input document. A large scale human evaluation of several neural abstractive summarization systems was conducted to better understand the types of hallucinations they produce. The analysis shows that pretrained models are better summarizers in terms of generating faithful and factual summaries as evaluated by humans. Textual entailment measures are found to better correlate with faithfulness than standard metrics, potentially leading to better automatic evaluation metrics and training and decoding criteria.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to accomplish the task of document summarization, which involves producing a shorter version of a document while preserving its information content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes, such as providing a quick overview of a document, helping readers decide whether to read the full text, or assisting in information retrieval tasks.'}",['analysis'],[],[],[],[],https://github.com/google-research-datasets/xsum_hallucination_annotations,https://aclanthology.org/2020.acl-main.173,"{'Conditional text generation models generate hallucinated text in extreme abstractive document summarization.': 'Investigate the frequency and nature of hallucinations in abstractive summarizers using a large-scale human evaluation.', 'Document summarization requires models to generate text that is not only human-like but also faithful and/or factual given the document.': 'Conduct a study to evaluate the faithfulness and factuality of summaries generated by abstractive summarizers.', 'Abstractive summarizers frequently generate both intrinsic and extrinsic hallucinations.': 'Report the frequency of intrinsic and extrinsic hallucinations in single-sentence summaries.', 'The majority of extrinsic hallucinations are erroneous.': 'Analyze the accuracy of extrinsic hallucinations and report the percentage of factual extrinsic hallucinations.', 'Automatic metrics such as ROUGE and BERTScore correlate less with faithfulness/factuality than metrics derived from automatic semantic inference systems.': 'Explore the use of automatic semantic inference systems as evaluation measures and model training and decoding objectives.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:eae823f79fb7299f98fad668fe4a26a3bc4dd7a6,Neural Text Summarization: A Critical Evaluation,EMNLP,2019,"['Wojciech Kryściński', 'Nitish Shirish Keskar', 'Bryan McCann', 'Caiming Xiong', 'Richard Socher']","Text summarization aims at compressing long documents into a shorter form that conveys the most important parts of the original document. Despite increased interest in the community and notable research effort, progress on benchmark datasets has stagnated. We critically evaluate key ingredients of the current research setup: datasets, evaluation metrics, and models, and highlight three primary shortcomings: 1) automatically collected datasets leave the task underconstrained and may contain noise detrimental to training and evaluation, 2) current evaluation protocol is weakly correlated with human judgment and does not account for important characteristics such as factual correctness, 3) models overfit to layout biases of current datasets and offer limited diversity in their outputs.","The paper discusses the current state of text summarization, which aims to condense long documents into shorter versions while retaining important information. Despite increased interest and research, progress on benchmark datasets has stalled. The authors identify three primary issues: 1) datasets may contain noise and are underconstrained, 2) evaluation metrics do not account for important factors such as factual correctness, and 3) models overfit to biases in current datasets and lack diversity in their outputs.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress long textual documents into a short, human-readable form that contains the most important information from the source.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and to quickly get an overview of the main points of a document.'}",['analysis'],[],[],[],[],,https://aclanthology.org/D19-1051,"{'Stagnation in progress on text summarization benchmarks despite substantial research effort.': 'The authors argue that this stagnation can be partially attributed to the current research setup, which involves uncurated, automatically collected datasets and non-informative evaluations protocols. They propose to shift the focus of the research community into developing a more robust research setup for text summarization.', 'Use of uncurated, automatically collected datasets in text summarization research.': 'The authors propose to curate datasets for text summarization research, ensuring that they are diverse, representative, and of high quality.', 'Non-informative evaluation metrics in text summarization research.': 'The authors propose to develop new evaluation metrics that better capture the quality of summaries, such as metrics that measure coherence, fluency, and informativeness.', 'Lack of diversity in model outputs in text summarization research.': 'The authors propose to encourage the development of models that generate diverse summaries, such as models that can generate multiple summaries for a single input document.'}",,['News'],[]
SP:c15e0ab3d8bb9138fdc0734beaa86e156a04b1e2,A Principled Framework for Evaluating Summarizers: Comparing Models of Summary Quality against Human Judgments,ACL,2017,"['Maxime Peyrard', 'Judith Eckle-Kohler']","We present a new framework for evaluating extractive summarizers, which is based on a principled representation as optimization problem. We prove that every extractive summarizer can be decomposed into an objective function and an optimization technique. We perform a comparative analysis and evaluation of several objective functions embedded in wellknown summarizers regarding their correlation with human judgments. Our comparison of these correlations across two datasets yields surprising insights into the role and performance of objective functions in the different summarizers.","

System: The paper introduces a new framework for evaluating extractive summarizers based on an optimization problem. It shows that every extractive summarizer can be broken down into an objective function and an optimization technique. The authors compare and evaluate several objective functions in well-known summarizers and analyze their correlation with human judgments. The comparison across two datasets provides surprising insights into the role and performance of objective functions in different summarizers.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the quality indicators of a summary and to understand the properties of ""good"" summaries.', 'Who is the target audience?': 'The summaries are for the research community to identify the best possible quality indicators of a summary and use it in optimization-based systems.', 'How will the summaries be used?': 'The summaries will be used to evaluate the objective function and the optimization technique separately and independently, and to compare well-known summarization systems regarding their implicit choices of quality indicators.'}",['analysis'],[],[],[],[],,https://aclanthology.org/P17-2005,"{'The traditional “intrinsic” evaluation comparing system summaries against human reference summaries is problematic because it is actually an end-to-end evaluation of summarization systems which is performed after θ has been optimized by O. This is highly problematic from an evaluation point of view, because first, θ is typically not optimized exactly, and second, there might be side-effects caused by the particular optimization technique O, e.g., a sentence extracted to maximize θ might be suitable because of other properties not included in θ.': 'The (θ,O) decomposition proposed by the authors enables a well-defined and principled evaluation of extractive summarizers on the level of their components θ and O. This allows for a more accurate evaluation of the objective function and the optimization technique separately and independently.', 'The commonly used evaluation metric ROUGE yields a noisy surrogate evaluation compared to the much more meaningful evaluation based on human judgments.': 'The authors propose to compare θ functions of different summarizers by measuring the correlation of their θ functions with human judgments.', 'Extractive summarization is not solved yet.': 'The authors provide a novel and principled evaluation framework for ES which allows for the identification of the best possible θ and use it in optimization-based systems. They believe that the identification of such a θ is the central question of summarization, because this optimal θ would represent an optimal definition of summary quality both from an algorithmic point of view and from the human perspective.'}",,['News'],['robust-evaluation-methods']
SP:3a99900cfdef0e0375160043b1c052a1123806fc,From COMET to COMES – Can Summary Evaluation Benefit from Translation Evaluation?,AACL,2022,"['Mateusz Krubiński', 'Pavel Pecina']","COMET is a recently proposed trainable neuralbased evaluation metric developed to assess the quality of Machine Translation systems. In this paper, we explore the usage of COMET for evaluating Text Summarization systems – despite being trained on multilingual MT outputs, it performs remarkably well in monolingual settings, when predicting summarization output quality. We introduce a variant of the model – COMES – trained on the annotated summarization outputs that uses MT data for pre-training. We examine its performance on several datasets with human judgments collected for different notions of summary quality, covering several domains and languages.","The paper discusses the use of COMET, a neural-based evaluation metric for Machine Translation systems, for evaluating Text Summarization systems. Despite being trained on multilingual MT outputs, COMET performs well in monolingual settings for predicting summarization output quality. The authors introduce a variant of the model, COMES, trained on annotated summarization outputs using MT data for pre-training. The performance of COMES is examined on several datasets with human judgments for different notions of summary quality, across various domains and languages.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the quality of generated output in text summarization.', 'Who is the target audience?': 'The summaries are for evaluating the progress during training and comparing outputs from independent systems in text summarization.', 'How will the summaries be used?': 'The summaries will be used to improve correlation with human judgment and to be robust to both domain shifts and changes in annotation style in text summarization.'}",['metric'],[],[],[],[],https://github.com/Unbabel/COMET/,https://aclanthology.org/2022.eval4nlp-1.3/,"{'Lack of standardized framework for collecting human judgments for text summarization evaluation.': 'The authors propose using different methods for collecting human judgments, such as Likert scale, Direct Assessment, or methods that output numerical score indirectly.', 'Limited availability of annotated data for text summarization evaluation.': 'The authors propose using the large amount of available annotated data for machine translation evaluation to improve text summarization evaluation.', 'Reliance on string-overlap metric (ROUGE) for text summarization evaluation.': 'The authors propose examining the applicability of the COMET metric, which is trained on annotated machine translation data and capable of directly regressing a quality score, for text summarization evaluation. They also propose a variant of the model, COMES2, that uses annotated machine translation data for pre-training and is capable of predicting several aspects of summary quality.'}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:1ae079a33f11e112823e2a1774ec95f2d4adf10b,Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary,TACL,2021,"['Daniel Deutsch', 'Tania Bedrax-Weiss', 'Dan Roth']","A desirable property of a reference-based evaluation metric that measures the content quality of a summary is that it should estimate how much information that summary has in common with a reference. Traditional text overlap based metrics such as ROUGE fail to achieve this because they are limited to matching tokens, either lexically or via embeddings. In this work, we propose a metric to evaluate the content quality of a summary using question-answering (QA). QA-based methods directly measure a summary’s information overlap with a reference, making them fundamentally different than text overlap metrics. We demonstrate the experimental benefits of QA-based metrics through an analysis of our proposed metric, QAEval. QAEval outperforms current state-of-the-art metrics on most evaluations using benchmark datasets, while being competitive on others due to limitations of state-of-the-art models. Through a careful analysis of each component of QAEval, we identify its performance bottlenecks and estimate that its potential upper-bound performance surpasses all other automatic metrics, approaching that of the gold-standard Pyramid Method.1","The paper proposes a new metric, QAEval, to evaluate the content quality of a summary using question-answering (QA) instead of traditional text overlap based metrics such as ROUGE. QA-based methods directly measure a summary's information overlap with a reference, making them fundamentally different than text overlap metrics. The authors demonstrate the experimental benefits of QA-based metrics through an analysis of QAEval, which outperforms current state-of-the-art metrics on most evaluations using benchmark datasets. The authors also identify the performance bottlenecks of QAEval and estimate that its potential upper-bound performance surpasses all other automatic metrics, approaching that of the gold-standard Pyramid Method.","{'Who is the target audience?': 'The summaries are for evaluating the content quality of a summary, and are used by researchers in the field of text summarization.', 'How will the summaries be used?': 'The summaries will be used to evaluate the performance of summarization systems, and to compare the performance of different automatic evaluation metrics.'}",['metric'],[],[],[],[],https://github.com/CogComp/qaeval-experiments,https://aclanthology.org/2021.tacl-1.47,"{'The current reference-based evaluation metrics compare two summaries based on matching their tokens, which do not express the same information and end up comparing the similarity of two summaries based on the topics they discuss.': 'The authors propose a metric to evaluate the content quality of a summary using question-answering (QA) within a QA evaluation framework that represents the information of a reference summary using QA pairs, then estimates how much of this information is contained in a candidate summary by calculating the proportion of questions it can answer. This QA-based metric directly measures the information overlap, providing a summary quality signal that is not effectively captured by text overlap based metrics.', 'The performance of current state-of-the-art models in QA-based evaluation metrics is limited by the QA model and the task of verifying if the predicted answer is correct.': 'The authors identify the QA model and answer verification as the performance bottlenecks through a careful analysis of each component of QAEval. They show that with human-level QA and answer verification performance, the summary-level upper-bound correlations of QAEval are better than all other automatic metrics and approach the gold-standard Pyramid Method.', 'The current automatic evaluation metrics for summarization systems do not provide accurate and reliable results.': 'The authors propose QAEval, a more general QA-based metric for evaluating the content of summaries, which achieves state-of-the-art correlations to human judgments on benchmark datasets when used to evaluate summarization systems. They experimentally show the benefit of QAEval, both with current state-of-the-art methods and by estimating its potential upper-bound performance.'}",,['News'],[]
SP:4d6f6eb09af54a2accbf6715f1330af70f6dd540,Crowdsourcing Lightweight Pyramids for Manual Summary Evaluation,NAACL,2019,"['Ori Shapira', 'David Gabay', 'Yang Gao', 'Hadar Ronen', 'Ramakanth Pasunuru', 'Mohit Bansal', 'Yael Amsterdamer', 'Ido Dagan']","Conducting a manual evaluation is considered an essential part of summary evaluation methodology. Traditionally, the Pyramid protocol, which exhaustively compares system summaries to references, has been perceived as very reliable, providing objective scores. Yet, due to the high cost of the Pyramid method and the required expertise, researchers resorted to cheaper and less thorough manual evaluation methods, such as Responsiveness and pairwise comparison, attainable via crowdsourcing. We revisit the Pyramid approach, proposing a lightweight samplingbased version that is crowdsourcable. We analyze the performance of our method in comparison to original expert-based Pyramid evaluations, showing higher correlation relative to the common Responsiveness method. We release our crowdsourced Summary-ContentUnits, along with all crowdsourcing scripts, for future evaluations.","The paper discusses the importance of manual evaluation in summary evaluation methodology and the traditional Pyramid protocol, which is reliable but expensive and requires expertise. Cheaper and less thorough manual evaluation methods have been used instead, but the authors propose a lightweight sampling-based version of the Pyramid approach that can be crowdsourced. They analyze the performance of their method and release their crowdsourced Summary-ContentUnits and crowdsourcing scripts for future evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the content quality of summaries, which is an integral part of summarization research.', 'Who is the target audience?': 'The summaries are for evaluating the performance of a summarization system, both for system comparisons and for quick development cycle testing.', 'How will the summaries be used?': 'The summaries will be used for either automatic or manual evaluation of the summarization system. Automatic evaluation provides an inexpensive means of measuring the validity of a system, while manual evaluation employs human-in-the-loop protocols for assessment.'}",['analysis'],[],[],[],[],https://github.com/OriShapira/LitePyramids,https://aclanthology.org/N19-1072,"{'The reliability of automatic evaluation approaches for measuring the performance of summarization systems is often perceived as insufficient.': 'Manual evaluation, which employs human-in-the-loop protocols for assessment, is a more expensive but reliable alternative.', 'The Pyramid method, a prominent manual evaluation methodology, requires laborious manual work performed by annotators who must browse through non-trivial guidelines.': 'The authors propose a simplified crowdsourcable and reproducible version of the Pyramid method that leverages the strong signal of the reference summaries and similarly bases its score on less subjective SCU judgments. This method relies on statistical sampling rather than exhaustive SCU extraction and testing, lowering overall cost.', 'Simple manual evaluation approaches, such as Responsiveness and pairwise comparison, do not rely on reference summaries and can be attained via crowdsourcing, but are quite subjective and not reliable enough to produce consistent scores across experiments.': ""The authors' proposed simplified crowdsourcable version of the Pyramid method suggests appealing advantages over prior crowdsourcable evaluation methods. It correlates with the original Pyramid scores better than the common Responsiveness method and shows better stability.""}",,['News'],['robust-evaluation-methods']
SP:c30b436caf33ac11a47aabf24d7f0cfd52b91147,Understanding the Behaviour of Neural Abstractive Summarizers using Contrastive Examples,NAACL,2019,"['Krtin Kumar', 'Jackie Chi Kit Cheung']","Neural abstractive summarizers generate summary texts using a language model conditioned on the input source text, and have recently achieved high ROUGE scores on benchmark summarization datasets. We investigate how they achieve this performance with respect to human-written gold-standard abstracts, and whether the systems are able to understand deeper syntactic and semantic structures. We generate a set of contrastive summaries which are perturbed, deficient versions of human-written summaries, and test whether existing neural summarizers score them more highly than the human-written summaries. We analyze their performance on different datasets and find that these systems fail to understand the source text, in a majority of the cases.",The paper examines the performance of neural abstractive summarizers in generating summary texts and their ability to understand deeper syntactic and semantic structures. The authors generate a set of contrastive summaries and test whether existing neural summarizers score them more highly than human-written summaries. They find that these systems fail to understand the source text in a majority of cases.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to investigate how abstractive summarization systems achieve good results and whether they represent progress towards language understanding and generation.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any particular audience, but the authors are testing the abstractive summarizers in terms of how they score potential candidate summaries.', 'How will the summaries be used?': 'The summaries will be used to test whether the summarizers favour output summaries with specific desired qualities, such as generating a summary that is semantically consistent and entailed by the source text. The authors also hope to develop a comprehensive evaluation scheme that captures all relevant aspects of summary quality.'}",['analysis'],[],[],[],[],https://github.com/krtin/ContrastiveSummaries,https://aclanthology.org/N19-1396/,"{'ROUGE provides a limited view of the performance of abstractive summarization systems.': 'The authors propose a novel method to directly test the abstractive summarizers in terms of how they score potential candidate summaries, viewing them as conditional language models.', 'The authors want to investigate how abstractive summarization systems achieve good results and whether they represent progress towards language understanding and generation.': 'The authors propose to test whether the summarizers favour output summaries with specific desired qualities, such as generating a summary that is semantically consistent and entailed by the source text.', 'The authors want to demonstrate the difficulty of controlling expressive neural abstractive systems to produce correct and fluent output.': 'The authors test how well the neural abstractive summarizers distinguish human-written abstracts from contrastive distractors, which are clearly incorrect summaries that are generated using a rule-based procedure.', 'The authors want to revisit fundamental issues in summarization evaluation for neural abstractive models.': 'The authors propose a comprehensive evaluation scheme that captures all relevant aspects of summary quality can be developed.', 'The authors want to make their code for generating contrastive summaries available online.': 'The authors make their code for generating contrastive summaries available online.'}",,['News'],['robust-evaluation-methods']
SP:d29edc0882dd68fb8229be48eb7727a53eff6371,SSAS: Semantic Similarity for Abstractive Summarization,IJCNLP,2017,"['Raghuram Vadapalli', 'Litton J Kurisinkel', 'Manish Gupta', 'Vasudeva Varma']","Ideally a metric evaluating an abstract system summary should represent the extent to which the system-generated summary approximates the semantic inference conceived by the reader using a humanwritten reference summary. Most of the previous approaches relied upon word or syntactic sub-sequence overlap to evaluate system-generated summaries. Such metrics cannot evaluate the summary at semantic inference level. Through this work we introduce the metric of Semantic Similarity for Abstractive Summarization (SSAS)1, which leverages natural language inference and paraphrasing techniques to frame a novel approach to evaluate system summaries at semantic inference level. SSAS is based upon a weighted composition of quantities representing the level of agreement, contradiction, topical neutrality, paraphrasing, and optionally ROUGE score between a systemgenerated and a human-written summary.","The paper introduces a new metric called Semantic Similarity for Abstractive Summarization (SSAS) that evaluates system-generated summaries at a semantic inference level. Previous approaches relied on word or syntactic sub-sequence overlap, which cannot evaluate summaries at this level. SSAS uses natural language inference and paraphrasing techniques to weigh quantities representing agreement, contradiction, topical neutrality, paraphrasing, and optionally ROUGE score between a system-generated and human-written summary.","{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to mimic human expert's capabilities of inference making and producing a summary in her own writing style."", 'Who is the target audience?': 'The summaries are for anyone who needs to generate summaries from varying information sources such as social media, databases, web articles etc.', 'How will the summaries be used?': 'The summaries will be used for a constructive evolution of research on abstractive summarization, to establish a metric which can judge the quality of a system-generated abstractive summary.'}",['metric'],[],[],[],[],,https://aclanthology.org/I17-2034/,{},,['News'],['robust-evaluation-methods']
SP:1f1ce3e25619d8d5a46a67363430dbe5775ee58c,HIGHRES: Highlight-based Reference-less Evaluation of Summarization,ACL,2019,"['Hardy Shashi Narayan', 'Andreas Vlachos']","There has been substantial progress in summarization research enabled by the availability of novel, often large-scale, datasets and recent advances on neural network-based approaches. However, manual evaluation of the system generated summaries is inconsistent due to the difficulty the task poses to human non-expert readers. To address this issue, we propose a novel approach for manual evaluation, HIGHlight-based Reference-less Evaluation of Summarization (HIGHRES), in which summaries are assessed by multiple annotators against the source document via manually highlighted salient content in the latter. Thus summary assessment on the source document by human judges is facilitated, while the highlights can be used for evaluating multiple systems. To validate our approach we employ crowd-workers to augment with highlights a recently proposed dataset and compare two state-of-the-art systems. We demonstrate that HIGHRES improves inter-annotator agreement in comparison to using the source document directly, while they help emphasize differences among systems that would be ignored under other evaluation approaches.1",The paper discusses the challenges of manual evaluation of system-generated summaries and proposes a novel approach called HIGHlight-based Reference-less Evaluation of Summarization (HIGHRES). This approach involves assessing summaries against the source document using manually highlighted salient content. The authors validate their approach by employing crowd-workers to augment a dataset and compare two state-of-the-art systems. They demonstrate that HIGHRES improves inter-annotator agreement and helps emphasize differences among systems that would be ignored under other evaluation approaches.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to measure progress in summarization and evaluate the performance of different methods.', 'Who is the target audience?': 'The summaries are for researchers and developers working on automatic summarization methods.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different summarization methods and measure progress in the field.'}",['metric'],[],[],[],[],https://github.com/sheffieldnlp/highres,https://aclanthology.org/P19-1330/,"{""Measuring progress in summarization is difficult due to the task's input and the potential for multiple equally good summaries."": 'The authors propose a novel approach for manual evaluation, HIGHlight-based Referenceless Evaluation of document Summarization (HIGHRES), in which a summary is assessed against the source document via manually highlighted salient content in the latter. This approach avoids reference bias, as the multiple highlights obtained help consider more content than what is contained in a single reference.', 'Automatic measures such as ROUGE are unlikely to be sufficient to measure performance in summarization and evaluation against single reference summaries can exhibit reference bias.': 'The authors propose manual evaluation as necessary for measuring progress in summarization. They also propose to evaluate the clarity of a summary separately from its fluency, as they are different dimensions. Finally, HIGHRES provides absolute instead of ranked evaluation, thus the assessment of a system can be conducted and interpreted without reference to other systems.', 'The intrinsic difficulty of the task has led to research without manual evaluation or only fluency being assessed manually.': 'The authors propose HIGHRES as a novel approach for manual evaluation that assesses the content of a summary separately from its fluency. They also demonstrate that HIGHRES improves interannotator agreement and emphasizes differences among systems that would be ignored under other evaluation approaches, including reference-based evaluation.'}",,['News'],['robust-evaluation-methods']
SP:6dadd581a9f95b1f9735469eb65bf0b8a9f2a799,A Simple Theoretical Model of Importance for Summarization,ACL,2019,['Maxime Peyrard'],"Research on summarization has mainly been driven by empirical approaches, crafting systems to perform well on standard datasets with the notion of information Importance remaining latent. We argue that establishing theoretical models of Importance will advance our understanding of the task and help to further improve summarization systems. To this end, we propose simple but rigorous definitions of several concepts that were previously used only intuitively in summarization: Redundancy, Relevance, and Informativeness. Importance arises as a single quantity naturally unifying these concepts. Additionally, we provide intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.","System: The paper argues that establishing theoretical models of Importance will advance our understanding of summarization and improve summarization systems. The authors propose definitions of Redundancy, Relevance, and Informativeness, and show how Importance arises as a single quantity that unifies these concepts. The paper also provides intuitions to interpret the proposed quantities and experiments to demonstrate the potential of the framework to inform and guide subsequent works.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to identify the most important information and produce a comprehensive output for a particular user and task.', 'Who is the target audience?': 'The summaries are for a particular user and task.', 'How will the summaries be used?': 'The summaries will be used to guide future empirical works and facilitate the development of practical solutions.'}",['theory'],[],[],[],[],,https://aclanthology.org/P19-1101,"{'The core challenge of summarization is the identification and selection of important information, which involves vague and undefined terms such as Importance and Information.': 'The authors propose a simple definition of information importance within an abstract theoretical framework, using information theory to rigorously discuss the abstract concept of information.', 'Automatic text summarization research has focused on empirical developments, leaving the formal definitions of Importance latent.': 'The authors postulate that theoretical models of Importance are beneficial to organize research and guide future empirical works.', 'Empirical approaches to summarization may lack guidance and only identify signals correlating with the vague human intuition of Importance.': 'The authors propose a framework that unifies the concepts of Redundancy, Relevance, and Informativeness, and formulate properties required from a useful notion of Importance.', 'Structural features like centrality and repetitions are still among the most used proxies for Importance, but they just correlate with Importance in standard datasets and reveal weaknesses under simple adversarial attacks.': 'The authors provide a theoretical framework that correlates well with human judgments, making it promising to guide future empirical works.'}",,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:4ac9c83f774342facfe975b7edc51ef1e91e8a62,Pruning Basic Elements for Better Automatic Evaluation of Summaries,NAACL,2018,"['Ukyo Honda', 'Tsutomu Hirao', 'Masaaki Nagata']","We propose a simple but highly effective automatic evaluation measure of summarization, pruned Basic Elements (pBE). Although the BE concept is widely used for the automated evaluation of summaries, its weakness is that it redundantly matches basic elements. To avoid this redundancy, pBE prunes basic elements by (1) disregarding frequency count of basic elements and (2) reducing semantically overlapped basic elements based on word similarity. Even though it is simple, pBE outperforms ROUGE in DUC datasets in most cases and achieves the highest rank correlation coefficient in TAC 2011 AESOP task.","The paper introduces a new automatic evaluation measure for summarization called pruned Basic Elements (pBE). It addresses the weakness of the widely used BE concept, which redundantly matches basic elements. pBE prunes basic elements by disregarding frequency count and reducing semantically overlapped elements based on word similarity. The study shows that pBE outperforms ROUGE in DUC datasets and achieves the highest rank correlation coefficient in TAC 2011 AESOP task.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the quality of system summaries.', 'Who is the target audience?': 'The summaries are for automatic evaluation measures in summarization studies.', 'How will the summaries be used?': 'The summaries will be used to raise the scores given by automatic evaluation measures and to compare the performance of different summarization systems.'}",['metric'],[],[],[],[],https://github.com/ukyh/prunedBE,https://aclanthology.org/N18-2104,"{'Automatic evaluation measures score low-information units higher, which are less informative than units connected with verbs.': 'The authors propose to disregard the frequency count of basic elements to cut back redundant units.', 'Automatic evaluation measures ignore the semantic overlap of units, which yields inaccurate scoring of paraphrased units.': 'The authors propose to reduce semantically overlapped basic elements using word embeddings to cut back redundant units.'}",,['News'],['robust-evaluation-methods']
SP:26efcfd5d33e28ffaf809d95ad8b07dd27c49c43,Factual Consistency Evaluation for Text Summarization via Counterfactual Estimation,EMNLP,2021,"['Yuexiang Xie', 'Fei Sun', 'Yang Deng', 'Yaliang Li', 'Bolin Ding']","Despite significant progress has been achieved in text summarization, factual inconsistency in generated summaries still severely limits its practical applications. Among the key factors to ensure factual consistency, a reliable automatic evaluation metric is the first and the most crucial one. However, existing metrics either neglect the intrinsic cause of the factual inconsistency or rely on auxiliary tasks, leading to an unsatisfied correlation with human judgments or increasing the inconvenience of usage in practice. In light of these challenges, we propose a novel metric to evaluate the factual consistency in text summarization via counterfactual estimation, which formulates the causal relationship among the source document, the generated summary, and the language prior. We remove the effect of language prior, which can cause factual inconsistency, from the total causal effect on the generated summary, and provides a simple yet effective way to evaluate consistency without relying on other auxiliary tasks. We conduct a series of experiments on three public abstractive text summarization datasets, and demonstrate the advantages of the proposed metric in both improving the correlation with human judgments and the convenience of usage. The source code is available at https://github.com/xieyxclack/factual_coco.","The paper discusses the issue of factual inconsistency in generated summaries despite significant progress in text summarization. The authors propose a novel metric to evaluate factual consistency in text summarization via counterfactual estimation, which removes the effect of language prior from the total causal effect on the generated summary. This provides a simple yet effective way to evaluate consistency without relying on other auxiliary tasks. The authors conduct experiments on three public abstractive text summarization datasets and demonstrate the advantages of the proposed metric in improving the correlation with human judgments and the convenience of usage. The source code is available at https://github.com/xieyxclack/factual_coco.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide informative, relevant, and fluent texts using deep neural networks.', 'Who is the target audience?': 'The summaries are for practical applications of text summarization techniques.', 'How will the summaries be used?': 'The summaries will be used to ensure factual consistency in text summarization, and a reliable automatic evaluation metric is crucial for this purpose.'}",['metric'],[],[],[],[],https://github.com/xieyxclack/factual_coco,https://aclanthology.org/2021.findings-emnlp.10,"{'The authors highlight the challenge of ensuring factual consistency in text summarization, which limits practical applications of text summarization techniques. Existing automatic metrics, such as ROUGE and METEOR, are poorly correlated with human judgments on factual consistency.': 'The authors propose a new evaluation metric, named Counterfactual Consistency (CoCo), which evaluates the factual consistency of summarized texts via counterfactual estimation. CoCo does not rely on auxiliary tasks and is designed to address the intrinsic cause of factual inconsistency. The authors use causal inference to formulate the causal relationship among the source document, the generated summary, and the language prior to build up the causal graph for text summarization. They propose counterfactual abstractive summarization to estimate the causal effect of language prior on the generated summary and remove it from the total causal effect. The estimated effect, which is the causal effect of the source document on the generated summary, serves as a factual consistency score of the generated summary.', 'The authors note that the language prior learned by the decoder in sequence-to-sequence (Seq2Seq) summarization models can lead to hallucination of inconsistency tokens due to spurious linguistic correlations learned from the training corpus.': 'The authors propose counterfactual abstractive summarization to estimate the causal effect of language prior on the generated summary and remove it from the total causal effect. This helps to ensure that the generated summary relies more on the source document than the language prior, which should lead to greater factual consistency with respect to the source document.', 'The authors highlight the need for a reliable automatic evaluation metric for factual consistency in text summarization that does not rely on auxiliary tasks.': 'The authors propose CoCo, which does not rely on auxiliary tasks and achieves a significant improvement against existing automatic metrics for text summarization in terms of the correlation with human annotations.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:9e0e59bc67e9941f6ae56c030a27dfda1a04ff51,SueNes: A Weakly Supervised Approach to Evaluating Single-Document Summarization via Negative Sampling,NAACL,2022,"['Forrest Sheng Bao', 'Minghui Qiu', 'Yinfei Yang', 'Cen Chen']","Canonical automatic summary evaluation metrics, such as ROUGE, focus on lexical similarity which cannot well capture semantics nor linguistic quality and require a reference summary which is costly to obtain. Recently, there have been a growing number of efforts to alleviate either or both of the two drawbacks. In this paper, we present a proof-of-concept study to a weakly supervised summary evaluation approach without the presence of reference summaries. Massive data in existing summarization datasets are transformed for training by pairing documents with corrupted reference summaries. In cross-domain tests, our strategy outperforms baselines with promising improvements, and show a great advantage in gauging linguistic qualities over all metrics.","The paper discusses the limitations of current automatic summary evaluation metrics, which focus on lexical similarity and require a reference summary. The authors propose a weakly supervised approach that does not require a reference summary, using existing summarization datasets and pairing documents with corrupted reference summaries for training. In cross-domain tests, their approach outperforms baselines and shows advantages in gauging linguistic qualities over all metrics.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to solve the problem of summarization in natural language processing, which involves generating a summary from a source document that is longer than the summary.', 'Who is the target audience?': 'The summaries are for machine-generated summaries in various applications such as customer support, team conversation, and bug reporting.', 'How will the summaries be used?': 'The summaries will be used to evaluate the quality of machine-generated summaries using a hybrid approach that combines the best of both reference-based and reference-free metrics. The approach uses human-written summaries in training but does not require them in summary evaluation.'}",['metric'],[],[],[],[],https://github.com/forrestbao/SueNes/,https://aclanthology.org/2022.naacl-main.175,"{'Existing metrics for summarization evaluation favor lexical similarity and require a reference summary, which can be expensive to obtain.': 'The authors propose a hybrid approach that combines reference-based and reference-free methods. They use human-written summaries to train a model, but do not require them for summary evaluation. They call their approach SueNes, which stands for ""Summary evaluation by Negative sampling.""', 'Reference-based metrics have better performance, but are impractical for industrial use where it is too costly to manually craft reference summaries.': 'The authors use a weakly supervised approach that mutates reference summaries and pairs them with documents to form training data. This allows them to use human-written summaries in training, but not in summary evaluation.', 'Reference-free approaches generally perform poorer than reference-based ones, and often rely on non-summarization tasks that introduce noise.': 'The authors use a hybrid approach that combines the strengths of both reference-based and reference-free methods. They show that their approach outperforms reference-free baselines and all existing metrics in gauging linguistic qualities.', 'The quality of a summary is usually evaluated on two facets: content/fact aspects and linguistic qualities.': 'The authors show that their approach can be used to build models that excel on different tasks by feeding training data from the same source but mutated in different strategies. For example, deleting words is the best for linguistic qualities while deleting sentences is the best for content/fact coverage.', 'There is a need for more research into hybridizing reference-free and reference-based summary evaluation.': 'The authors hope that their study can inspire more research into this area. They provide their code at https://github.com/forrestbao/SueNes/ for others to use and build upon.'}",,"['Legislative Bills', 'Scholarly Documents', 'Patents']","['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:bd2ad9c2f8474888a6cc0abd4092bc30031450b0,FACTGRAPH: Evaluating Factuality in Summarization with Semantic Graph Representations,NAACL,2022,"['Leonardo F. R. Ribeiro', 'Mengwen Liu', 'Iryna Gurevych', 'Markus Dreyer', 'Mohit Bansal']","Despite recent improvements in abstractive summarization, most current approaches generate summaries that are not factually consistent with the source document, severely restricting their trust and usage in real-world applications. Recent works have shown promising improvements in factuality error identification using text or dependency arc entailments; however, they do not consider the entire semantic graph simultaneously. To this end, we propose FACTGRAPH, a method that decomposes the document and the summary into structured meaning representations (MR), which are more suitable for factuality evaluation. MRs describe core semantic concepts and their relations, aggregating the main content in both document and summary in a canonical form, and reducing data sparsity. FACTGRAPH encodes such graphs using a graph encoder augmented with structure-aware adapters to capture interactions among the concepts based on the graph connectivity, along with text representations using an adapter-based text encoder. Experiments on different benchmarks for evaluating factuality show that FACTGRAPH outperforms previous approaches by up to 15%. Furthermore, FACTGRAPH improves performance on identifying content verifiability errors and better captures subsentence-level factual inconsistencies.1","The paper discusses the limitations of current abstractive summarization approaches, which often generate summaries that are not factually consistent with the source document. The authors propose a new method called FACTGRAPH, which decomposes the document and summary into structured meaning representations (MR) to better evaluate factuality. FACTGRAPH encodes these MRs using a graph encoder and text encoder, and experiments show that it outperforms previous approaches by up to 15% in identifying factual errors and inconsistencies.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to establish a new level of performance in terms of grammatical fluency and combining salient parts of the source document.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any particular audience, but they are being generated to improve factuality evaluation in natural language processing.', 'How will the summaries be used?': 'The summaries will be used to assess factuality in natural language processing, with the goal of improving the accuracy and consistency of generated summaries.'}",['metric'],[],[],[],[],https://github.com/amazon-research/fact-graph,https://aclanthology.org/2022.naacl-main.236,"{'Current summarization models generate summaries that are not factually consistent, resulting in hallucinations.': 'The authors propose FACTGRAPH, a graph-enhanced approach that incorporates core information from the document and the summary into the factuality model using graph-based meaning representations (MRs) that capture semantic relations between entities.', 'Previous factuality evaluation methods have a reduced correlation with human judgments and may not capture semantic errors well.': 'FACTGRAPH is a dual approach that encodes both text and graph modalities, better integrating linguistic knowledge and structured semantic knowledge. The authors use Abstract Meaning Representation (AMR), a semantic formalism that encodes core concepts and explicitly models relations in the text, to improve factuality evaluation.', 'It is challenging to properly encode core semantic content from the document and summary and reason over salient pieces of information to assess summary factuality.': 'FACTGRAPH uses parameterefficient text and graph encoders that share the same pretrained model and differ by their adapter weights. The representations of the two modalities are combined to generate the factuality score.', 'Previous work treats semantic relations as isolated units, not simultaneously considering the entire semantic structure of both document and summary texts.': 'FACTGRAPH uses graph-based MRs that capture the entire semantic structure of both document and summary texts, improving factuality evaluation by reducing data sparsity and localizing generation errors in abstractive scenarios.', 'The lack of good quality factuality training data is a reason for poor performance in factuality evaluation.': 'The authors consolidate a factuality dataset with human annotations derived from previous works to improve factuality evaluation.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:dbe00968c8f130ddebbec2d09a70a666d3206e83,Automated Pyramid Summarization Evaluation,CONLL,2019,"['Yanjun Gao', 'Chen Sun', 'Rebecca J. Passonneau']","Pyramid evaluation was developed to assess the content of paragraph length summaries of source texts. A pyramid lists the distinct units of content found in several reference summaries, weights content units by how many reference summaries they occur in, and produces three scores based on the weighted content of new summaries. We present an automated method that is more efficient, more transparent, and more complete than previous automated pyramid methods. It is tested on a new dataset of student summaries, and historical NIST data from extractive summarizers.","System: The paper discusses the development of a method called Pyramid evaluation, which assesses the content of paragraph-length summaries of source texts. This method involves creating a pyramid that lists distinct units of content found in several reference summaries, weights them based on how many reference summaries they occur in, and produces three scores based on the weighted content of new summaries. The paper presents an automated version of this method that is more efficient, transparent, and complete than previous automated pyramid methods. The new method is tested on a dataset of student summaries and historical NIST data from extractive summarizers.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the importance of summary content, independent of wording.', 'Who is the target audience?': 'The summaries are for educational psychologists studying human summarization skills and their development throughout secondary school and beyond.', 'How will the summaries be used?': 'The summaries will be used to assess the importance of summary content and provide feedback for educational applications.'}",['metric'],[],[],[],[],https://github.com/serenayj/PyrEval,https://aclanthology.org/K19-1038,"{'Summarization evaluation relies almost exclusively on ROUGE, an automated tool that cannot directly assess importance of summary content, or novel wording for the same information.': 'The authors present an automated method to assess the importance of summary content, independent of wording, based on a widely used manual evaluation called pyramid.', 'The manual pyramid method requires human annotators to identify Summary Content Units (SCUs) by grouping phrases from different reference summaries into the same SCU if they express the same propositional content.': 'The authors present PyrEval, which outperforms previous work on automated pyramid in accuracy and efficiency. It produces human-readable pyramids, and prints matches between SCUs and evaluation summaries, which can support feedback for educational applications.', 'ROUGE does not consider the relative importance of content, or account for synonyms of words that appear in the reference summaries.': 'The authors propose using the pyramid method to assess the importance of summary content, which takes into account the number of reference summaries that express an SCU and increases the score of an evaluation summary if it expresses the same content as an SCU.'}",,['Student Responses'],['robust-evaluation-methods']
SP:80cb24b9fab78cfb103ec12e6685cd49d7317537,Training Dynamics for Text Summarization Models,ACL,2022,"['Tanya Goyal', 'Jiacheng Xu', 'Junyi Jessy Li', 'Greg Durrett']","Pre-trained language models (e.g. BART) have shown impressive results when fine-tuned on large summarization datasets. However, little is understood about this fine-tuning process, including what knowledge is retained from pre-training time or how content selection and generation strategies are learnt across iterations. In this work, we analyze the training dynamics for generation models, focusing on summarization. Across different datasets (CNNDM, XSUM, MEDIASUM) and summary properties, such as abstractiveness and hallucination, we study what the model learns at different stages of its fine-tuning process. We find that a propensity to copy the input is learned early in the training process consistently across all datasets studied. On the other hand, factual errors, such as hallucination of unsupported facts, are learnt in the later stages, though this behavior is more varied across domains. Based on these observations, we explore complementary approaches for modifying training: first, disregarding high-loss tokens that are challenging to learn and second, disregarding low-loss tokens that are learnt very quickly in the latter stages of the training process. We show that these simple training modifications allow us to configure our model to achieve different goals, such as improving factuality or improving abstractiveness.1","The paper discusses the fine-tuning process of pre-trained language models for summarization tasks and analyzes the training dynamics for generation models. The study focuses on different datasets and summary properties, such as abstractiveness and hallucination, to understand what the model learns at different stages of its fine-tuning process. The authors find that the model learns to copy the input early in the training process consistently across all datasets studied, while factual errors are learned in the later stages, though this behavior is more varied across domains. Based on these observations, the authors explore complementary approaches for modifying training to achieve different goals, such as improving factuality or improving abstractiveness.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to study the fine-tuning process of large pre-trained language models for abstractive summarization.', 'Who is the target audience?': 'The summaries are for studying the essential components of abstractive summarization models, abstractiveness and factual consistency, and investigating when each of these is learned during fine-tuning.', 'How will the summaries be used?': 'The insights from the training dynamics can be leveraged to optimize along target summarization goals like factuality or abstractiveness.'}",['analysis'],[],[],[],[],https://github.com/tagoyal/training-dynamics-generation,https://aclanthology.org/2022.findings-acl.163,"{'Little insight into what ""skill"" or behavior is learned at which stage of the training process for abstractive summarization models.': 'The authors make the first attempt at understanding the fine-tuning process of large pre-trained language models for summarization. They study two essential components of abstractive summarization models, abstractiveness and factual consistency, and investigate when each of these is learned during fine-tuning.', 'Summarization models tend to overfit to easier examples in datasets with a high fraction of extractive summaries, effectively ignoring harder examples in the dataset.': 'The authors find that easy-to-learn skills such as copy behavior are acquired very early in the fine-tuning process. They also show that insights from these training dynamics can be leveraged to optimize along target summarization goals like factuality or abstractiveness.', 'Longer training on noisy datasets can significantly hurt factuality.': 'The authors investigate how factual correctness of summaries evolves with the fine-tuning process, juxtaposing it against other factors such as abstractiveness and dataset quality. They show that they can substantially improve the factuality of summarization models trained on noisy datasets (e.g. XSUM) by downweighting high-loss tokens while preserving the high level of abstractiveness.', 'The nature of the training process and potential interventions to modify what gets learned are poorly understood for text generation tasks like abstractive summarization.': 'The authors extend prior work on loss truncation, using token sub-sampling to dynamically modify the loss computation during training to alter the learned behavior of summarization models. They show that downweighting low-loss tokens under the same framework allows them to significantly improve the abstractiveness of generated summaries compared to the baseline models for relatively extractive datasets (e.g. CNNDM and MEDIASUM).'}",,['News'],"['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:ac138fdd007cf64c92aff89b3b8447d43d84448c,Estimating Summary Quality with Pairwise Preferences,NAACL,2018,['Markus Zopf'],"Automatic evaluation systems in the field of automatic summarization have been relying on the availability of gold standard summaries for over ten years. Gold standard summaries are expensive to obtain and often require the availability of domain experts to achieve high quality. In this paper, we propose an alternative evaluation approach based on pairwise preferences of sentences. In comparison to gold standard summaries, they are simpler and cheaper to obtain. In our experiments, we show that humans are able to provide useful feedback in the form of pairwise preferences. The new framework performs better than the three most popular versions of ROUGE with less expensive human input. We also show that our framework can reuse already available evaluation data and achieve even better results.","The paper proposes a new evaluation approach for automatic summarization systems based on pairwise preferences of sentences, which is simpler and cheaper to obtain than gold standard summaries. The authors show that humans can provide useful feedback using this approach, and that it outperforms the three most popular versions of ROUGE with less expensive human input. Additionally, the framework can reuse already available evaluation data to achieve even better results.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to address the challenge of automatic text summarization, which is a pressing challenge due to the huge amount of information contained in texts.', 'Who is the target audience?': 'The summaries are generated for humans.', 'How will the summaries be used?': 'The summaries will be used for evaluation of automatically generated summaries, which is an active field of research.'}",['metric'],[],[],[],[],,https://aclanthology.org/N18-1152,"{'Manual evaluation of automatically generated summaries is time-consuming and not scalable.': 'The authors propose an alternative evaluation framework that uses simple and inexpensive pairwise preferences of sentences instead of gold standard summaries. They provide pairs of sentences from the input document of a summarization task to human annotators and ask which of the two sentences contains more important information.', 'Gold standard summaries are expensive and time-consuming to create, limiting research in automatic summarization.': ""The authors' proposed evaluation framework does not rely on gold standard summaries. Instead, the model uses the collected pairwise preferences to generate a ranking of all sentences according to information importance. Summaries which contain sentences similar to the upper part of the ranking are then considered to be better than summaries which contain unimportant sentences from the lower part of the ranking."", 'Currently available automatic evaluation methods for text summarization are viewed with skepticism.': ""The authors' proposed evaluation framework is an alternative to existing methods and has been shown to be as good as or better than existing methods, at a much lower annotation cost.""}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:ecc88a0e16b7351cbbd0e1e599141fb0ac5d9fea,Studying Summarization Evaluation Metrics in the Appropriate Scoring Range,ACL,2019,['Maxime Peyrard'],"In summarization, automatic evaluation metrics are usually compared based on their ability to correlate with human judgments. Unfortunately, the few existing human judgment datasets have been created as by-products of the manual evaluations performed during the DUC/TAC shared tasks. However, modern systems are typically better than the best systems submitted at the time of these shared tasks. We show that, surprisingly, evaluation metrics which behave similarly on these datasets (average-scoring range) strongly disagree in the higher-scoring range in which current systems now operate. It is problematic because metrics disagree yet we can’t decide which one to trust. This is a call for collecting human judgments for high-scoring summaries as this would resolve the debate over which metrics to trust. This would also be greatly beneficial to further improve summarization systems and metrics alike.","The paper discusses the issue of evaluating automatic summarization systems using human judgments. The current human judgment datasets were created during the DUC/TAC shared tasks, but modern systems are better than the best systems submitted at that time. The paper shows that evaluation metrics which behave similarly on these datasets strongly disagree in the higher-scoring range where current systems operate. This creates a problem as we cannot decide which metric to trust. The paper calls for collecting human judgments for high-scoring summaries to resolve this debate and improve summarization systems and metrics.","{'What is the purpose of the summaries?': 'The authors are studying the behavior of evaluation metrics in the high-scoring range for summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization systems.', 'How will the summaries be used?': 'The summaries will be used to guide progress in summarization research and provide supervision for training summarization systems. The authors also call for the gathering of human judgments in the high-scoring range to improve the evaluation metrics.'}",['analysis'],[],[],[],[],https://github.com/PeyrardM/acl-2019-Compare_Evaluation_Metrics,https://aclanthology.org/P19-1502,"{'The progress in summarization is tightly intertwined with the capability to quickly measure improvements, but automatic metrics development remains an open problem.': 'The authors propose dedicating significant research to the development of automatic metrics.', 'Few human judgment datasets have been created, and the existing ones are mostly average compared to nowadays standards.': 'The authors suggest creating more human judgment datasets, especially in the high-scoring range.', 'The score distribution on which evaluation metrics are tested differs from the one in which they now operate, and there is no guarantee that evaluation metrics behave according to human judgments in the high-scoring range.': 'The authors propose studying several evaluation metrics in the high-scoring range based on an automatically generated dataset to observe their behavior.', 'Current metrics cannot be distinguished based solely on an analysis of available human judgments, and they will promote very different summaries and systems.': 'The authors call for the gathering of human judgments in the high-scoring range to improve the evaluation metrics.'}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:f96eb9f8d671e8a32355120962c3c701afa2eda7,Unsupervised Reference-Free Summary Quality Evaluation via Contrastive Learning,EMNLP,2020,"['Hanlu Wu', 'Tengfei Ma', 'Lingfei Wu', 'Tariro Manyumwa', 'Shouling Ji']","Evaluation of a document summarization system has been a critical factor to impact the success of the summarization task. Previous approaches, such as ROUGE, mainly consider the informativeness of the assessed summary and require human-generated references for each test summary. In this work, we propose to evaluate the summary qualities without reference summaries by unsupervised contrastive learning. Specifically, we design a new metric which covers both linguistic qualities and semantic informativeness based on BERT. To learn the metric, for each summary, we construct different types of negative samples with respect to different aspects of the summary qualities, and train our model with a ranking loss. Experiments on Newsroom and CNN/Daily Mail demonstrate that our new evaluation method outperforms other metrics even without reference summaries. Furthermore, we show that our method is general and transferable across datasets.",The paper proposes a new method for evaluating the quality of document summarization systems without requiring human-generated reference summaries. The method uses unsupervised contrastive learning and a new metric based on BERT that covers both linguistic qualities and semantic informativeness. The model is trained with a ranking loss using different types of negative samples for each summary. The experiments on Newsroom and CNN/Daily Mail datasets show that the proposed method outperforms other metrics and is generalizable across datasets.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the performance of automatic text summarization and generation models.', 'Who is the target audience?': 'The summaries are for evaluating the quality of the generated summaries.', 'How will the summaries be used?': 'The summaries will be used to compare and improve the performance of automatic text summarization and generation models.'}",['metric'],[],[],[],[],https://github.com/whl97/LS-Score,https://aclanthology.org/2020.emnlp-main.294,"{'The authors identify the problem of evaluating the quality of automatic text summarization and generation systems, which greatly affects the assessment of summarization models. Human evaluation is the most ideal metric, but it is time-consuming and labor-intensive.': 'The authors propose an automatic evaluation metric that can simulate the ability of human judgement and save human resources. They develop a new unsupervised contrastive learning framework for automatically evaluating the summary qualities without comparing with reference summaries or training with human ratings.', 'Most of the existing automatic evaluation methods assess a summary by comparing it with reference texts written by humans, which are costly to obtain. In addition, most of them only consider the semantic similarities with references, which ignores the linguistic qualities and other important aspects.': 'The authors design an evaluator to consider both linguistic and semantic aspects of a summary. They create a set of negative samples by perturbing the training samples for each aspect and compare the scores of original training samples and the negative samples to obtain the contrastive loss function and learn the evaluator.', 'The existing methods for automatic evaluation of text summarization and generation systems have intrinsic drawbacks and correlate poorly with human evaluation.': 'The authors propose a new unsupervised method for summary quality evaluation that achieves the best performance on single-document summarization datasets and can be easily used across different datasets.'}",,['News'],['robust-evaluation-methods']
SP:7f9ea0c13fa0d21851effe56fd29a24ee38b30d6,To Point or Not to Point: Understanding How Abstractive Summarizers Paraphrase Text,ACL,2021,"['Matt Wilber', 'William Timkey', 'Marten van Schijndel']","Abstractive neural summarization models have seen great improvements in recent years, as shown by ROUGE scores of the generated summaries. But despite these improved metrics, there is limited understanding of the strategies different models employ, and how those strategies relate their understanding of language. To understand this better, we run several experiments to characterize how one popular abstractive model, the pointer-generator model of See et al. (2017), uses its explicit copy/generation switch to control its level of abstraction (generation) vs extraction (copying). On an extractive-biased dataset, the model utilizes syntactic boundaries to truncate sentences that are otherwise often copied verbatim. When we modify the copy/generation switch and force the model to generate, only simple paraphrasing abilities are revealed alongside factual inaccuracies and hallucinations. On an abstractivebiased dataset, the model copies infrequently but shows similarly limited abstractive abilities. In line with previous research, these results suggest that abstractive summarization models lack the semantic understanding necessary to generate paraphrases that are both abstractive and faithful to the source document.ive neural summarization models have seen great improvements in recent years, as shown by ROUGE scores of the generated summaries. But despite these improved metrics, there is limited understanding of the strategies different models employ, and how those strategies relate their understanding of language. To understand this better, we run several experiments to characterize how one popular abstractive model, the pointer-generator model of See et al. (2017), uses its explicit copy/generation switch to control its level of abstraction (generation) vs extraction (copying). On an extractive-biased dataset, the model utilizes syntactic boundaries to truncate sentences that are otherwise often copied verbatim. When we modify the copy/generation switch and force the model to generate, only simple paraphrasing abilities are revealed alongside factual inaccuracies and hallucinations. On an abstractivebiased dataset, the model copies infrequently but shows similarly limited abstractive abilities. In line with previous research, these results suggest that abstractive summarization models lack the semantic understanding necessary to generate paraphrases that are both abstractive and faithful to the source document.","The paper discusses the limitations of abstractive neural summarization models despite their improved ROUGE scores. The authors conducted experiments on the pointer-generator model to understand how it controls its level of abstraction and extraction. The model utilizes syntactic boundaries to truncate sentences on an extractive-biased dataset, but when forced to generate, it only shows simple paraphrasing abilities with factual inaccuracies and hallucinations. On an abstractive-biased dataset, the model copies infrequently and shows limited abstractive abilities. The results suggest that abstractive summarization models lack the semantic understanding necessary to generate faithful and abstractive paraphrases.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization models.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2021.findings-acl.298,"{'Abstractive models often generate summaries that are ungrammatical or unfaithful to the source document, and are prone to repetition in their outputs.': 'The authors propose studying a model with an explicit abstraction/extraction switch, the pointer-generator model of See et al. (2017), to understand how abstraction manifests in neural summarization models and determine the environments where abstractive summarization is an effective summarization strategy.', 'Paraphrasing ability is not directly measured by popular metrics, leading to a lack of understanding of the generative process.': 'Previous research has aimed to alleviate these issues in evaluation: Zhang et al. (2018a) propose evaluating summaries with human evaluations of informativeness and coherence, and Ganesan (2018) implements a metric to reward models that paraphrase via simple synonym substitutions according to WordNet. However, truly abstractive models should be capable of more complex paraphrasing strategies.', ""The model's abstractive capabilities are limited; it understands how to identify and combine constituents from the source text in a grammatical fashion, but lacks the semantic understanding required to produce grammatical, faithful and meaningful paraphrases."": ""The authors modify the switch value, forcing more frequent paraphrase generation during decoding, revealing the limits of the model's paraphrasing capabilities.""}",,['News'],[]
SP:5488e49d69d92367d2645983b48721f31ada60da,Content Selection in Deep Learning Models of Summarization,EMNLP,2018,"['Chris Kedzie', 'Kathleen McKeown']","We carry out experiments with deep learning models of summarization across the domains of news, personal stories, meetings, and medical articles in order to understand how content selection is performed. We find that many sophisticated features of state of the art extractive summarizers do not improve performance over simpler models. These results suggest that it is easier to create a summarizer for a new domain than previous work suggests and bring into question the benefit of deep learning models for summarization for those domains that do have massive datasets (i.e., news). At the same time, they suggest important questions for new research in summarization; namely, new forms of sentence representations or external knowledge sources are needed that are better suited to the sumarization task.","The paper discusses experiments with deep learning models of summarization in various domains, finding that many sophisticated features do not improve performance over simpler models. This suggests that creating a summarizer for a new domain may be easier than previously thought, and questions the benefit of deep learning models for summarization in domains with massive datasets. The paper suggests that new forms of sentence representations or external knowledge sources are needed for better summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries to better understand how deep learning models of summarization perform content selection across multiple domains.', 'Who is the target audience?': 'The summaries are not explicitly stated to be for any particular audience.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but the results suggest that deep learning models may not be as effective at learning robust and meaningful content features for summarization as previously thought.'}",['analysis'],[],[],[],[],https://github.com/kedz/nnsum/,https://aclanthology.org/D18-1208,"{'It is not well understood how deep learning models perform content selection with only word and sentence embedding based features as input.': 'The authors seek to better understand how deep learning models of summarization perform content selection across multiple domains by analyzing several recent sentence extractive neural network architectures and comparing them to the simpler approach of word embedding averaging.', 'Nonneural network approaches often use frequency and information theoretic measures as proxies for content salience, but these are not explicitly used in most neural network summarization systems.': 'The authors propose to analyze several recent sentence extractive neural network architectures to better understand how deep learning models perform content selection.', 'It is not clear whether auto-regressive sentence extraction is necessary for summarization.': 'The authors question the necessity of auto-regressive sentence extraction and propose two alternative models that extract sentences independently.', 'It is not clear whether pre-trained word embeddings or learned embeddings are better for summarization.': 'The authors compare pre-trained word embeddings to learned embeddings in five of six datasets to determine which is better.', 'It is not clear whether sentence position bias dominates the learning signal for all domains.': 'The authors analyze sentence position bias across multiple domains and find that it dominates the learning signal for news summarization, but not for other domains.', 'It is not clear whether more sophisticated architectures are necessary for sentence embedding.': 'The authors compare Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN) based sentence representations to the simpler approach of word embedding averaging to understand the gains derived from more sophisticated architectures.', 'It is not clear whether auto-regressive sentence extraction or non auto-regressive sentence extraction is better for summarization.': 'The authors compare auto-regressive sentence extraction to non auto-regressive sentence extraction in all domains to determine which is better.'}",,"['News', 'Scholarly Documents', 'Social Media', 'Meeting Transcripts']",[]
SP:405ef000520645de9a2ea1e861ec2efec8dd9f58,Analyzing Sentence Fusion in Abstractive Summarization,EMNLP,2019,"['Logan Lebanoff', 'John Muchovej', 'Franck Dernoncourt', 'Doo Soon Kim', 'Seokhwan Kim', 'Walter Chang', 'Fei Liu']","While recent work in abstractive summarization has resulted in higher scores in automatic metrics, there is little understanding on how these systems combine information taken from multiple document sentences. In this paper, we analyze the outputs of five state-of-the-art abstractive summarizers, focusing on summary sentences that are formed by sentence fusion. We ask assessors to judge the grammaticality, faithfulness, and method of fusion for summary sentences. Our analysis reveals that system sentences are mostly grammatical, but often fail to remain faithful to the original article.","System: The paper examines how abstractive summarization systems combine information from multiple sentences to form summary sentences. The researchers analyzed the outputs of five state-of-the-art summarizers and found that while the summary sentences were mostly grammatical, they often failed to remain faithful to the original article. The study highlights the need for further research in this area to improve the accuracy of abstractive summarization systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to examine the truthfulness of the summaries and to improve the consolidation of information from multiple source texts.', 'Who is the target audience?': 'The summaries are for real-world applications where summarization is widely accepted.', 'How will the summaries be used?': 'The summaries will be used to provide condensed and accurate information from multiple source texts.'}",['analysis'],[],[],[],[],,https://aclanthology.org/D19-5413,"{'Abstractive summarization systems struggle to combine content from multiple source texts, resulting in output summaries that contain poor grammar and even incorrect facts.': 'The authors perform an extensive analysis of summary outputs generated by state-of-the-art systems, examining features such as truthfulness to the original document, grammaticality, and method of how sentences are merged together.', 'Sentence fusion, which reduces two or more sentences to one by taking content from each sentence and merging them together, is a difficult task that requires improvement.': 'The authors focus on sentence fusion in this work and analyze several dimensions of the outputs, including faithfulness to the original article, grammaticality, and method of fusion.', 'Abstractive summarization systems often introduce incorrect facts and are ungrammatical.': 'The authors present three main findings: 38.3% of the system outputs introduce incorrect facts, while 21.6% are ungrammatical; systems often simply concatenate chunks of text when performing sentence fusion, while largely avoiding other methods of fusion like entity replacement; systems struggle to reliably perform complex fusion, as entity replacement and other methods result in incorrect facts 47–75% of the time.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:97ed87e4a0af5e7b22a1fe0c339178dd8c30a0ad,Phrase-Level Localization of Inconsistency Errors in Summarization by Weak Supervision,COLING,2022,"['Masato Takatsuka', 'Tetsunori Kobayashi', 'Yoshihiko Hayashi']","Although the fluency of automatically generated abstractive summaries has improved significantly with advanced methods, the inconsistency that remains in summarization is recognized as an issue to be addressed. In this study, we propose a methodology for localizing inconsistency errors in summarization. A synthetic dataset that contains a variety of factual errors likely to be produced by a common summarizer is created by applying sentence fusion, compression, and paraphrasing operations. In creating the dataset, we automatically label erroneous phrases and the dependency relations between them as “inconsistent,” which can contribute to detecting errors more adequately than existing models that rely only on dependency arc-level labels. Subsequently, this synthetic dataset is employed as weak supervision to train a model called SumPhrase, which jointly localizes errors in a summary and their corresponding sentences in the source document. The empirical results demonstrate that our SumPhrase model can detect factual errors in summarization more effectively than existing weakly supervised methods owing to the phrase-level labeling. Moreover, the joint identification of error-corresponding original sentences is proven to be effective in improving error detection accuracy.","The paper proposes a methodology for identifying inconsistency errors in summarization. A synthetic dataset is created to train a model called SumPhrase, which can detect factual errors in summarization more effectively than existing weakly supervised methods. The joint identification of error-corresponding original sentences is proven to be effective in improving error detection accuracy.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the quality of automatically generated abstractive summaries.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries will be used to improve the reliability and usability of summarization systems.'}",['metric'],[],[],[],[],https://github.com/taka2946/sumphrase,https://aclanthology.org/2022.coling-1.537,"{'More than 30% of automatically generated abstractive summaries are inconsistent with the source documents due to unintentionally introduced factual errors, affecting the reliability and usability of summarization systems.': 'The authors propose a weakly supervised approach that employs a synthetic dataset containing automatically generated errors to train an error localization model called SumPhrase.', 'Existing approaches for evaluating inconsistency in summarization are either unsupervised and rely on external NLU systems or weakly supervised but produce error distributions that are considerably different from those produced by actual summarization models.': 'The authors propose a new approach that incorporates sentence fusion and compression operations in addition to paraphrasing to create a synthetic dataset that reproduces recurring summarization errors.', 'The detection of factual errors in a summary is not always combined with the identification of their corresponding sentences in the source document, which can limit the usability and performance of the error detection system.': 'The authors propose a joint approach that combines the detection of errors in a summary with the identification of their corresponding sentences in the source document, improving both the usability and performance of the error detection system.', 'The quality and quantity of the synthetic dataset used for weakly supervised training is crucial for the success of the approach.': 'The authors present an improved method for generating a synthetic dataset that incorporates common means of summary generation and empirically investigate the effectiveness of these types of operations.', 'The effectiveness of the proposed method for localizing inconsistencies between a source document and the summary is not demonstrated.': 'The authors empirically demonstrate that the proposed method can localize inconsistencies more effectively than existing weakly supervised methods.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'pretraining-and-sample-efficiency']"
SP:a1b03476825159d8eac6ef1a01617f1febf34697,Investigating Crowdsourcing Protocols for Evaluating the Factual Consistency of Summaries,NAACL,2022,"['Xiangru Tang', 'Alexander R. Fabbri', 'Ziming Mao', 'Griffin Adams', 'Borui Wang', 'Haoran Li', 'Yashar Mehdad', 'Dragomir Radev']","Current pre-trained models applied for summarization are prone to factual inconsistencies that misrepresent the source text. Evaluating the factual consistency of summaries is thus necessary to develop better models. However, the human evaluation setup for evaluating factual consistency has not been standardized. To determine the factors that affect the reliability of the human evaluation, we crowdsource evaluations for factual consistency across stateof-the-art models on two news summarization datasets using the rating-based Likert Scale and ranking-based Best-Worst Scaling. Our analysis reveals that the ranking-based Best-Worst Scaling offers a more reliable measure of summary quality across datasets and that the reliability of Likert ratings highly depends on the target dataset and the evaluation design. To improve crowdsourcing reliability, we extend the scale of the Likert rating and present a scoring algorithm for Best-Worst Scaling that we call value learning. Our crowdsourcing guidelines will be publicly available to facilitate future work on factual consistency in summarization.","The paper discusses the issue of factual inconsistencies in current pre-trained models used for summarization and the need to evaluate the factual consistency of summaries to develop better models. The authors conducted crowdsourced evaluations using two different methods to determine the factors that affect the reliability of human evaluation. They found that the ranking-based Best-Worst Scaling method is more reliable than the rating-based Likert Scale method, which highly depends on the target dataset and evaluation design. To improve crowdsourcing reliability, they extended the Likert rating scale and presented a scoring algorithm for Best-Worst Scaling called value learning. The authors also made their crowdsourcing guidelines publicly available to facilitate future work on factual consistency in summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the factual consistency of the generated summaries with respect to the source.', 'Who is the target audience?': 'The summaries are for researchers who are interested in evaluating the factual consistency of pre-trained language models in abstractive text summarization.', 'How will the summaries be used?': 'The summaries will be used to determine the reliability of human evaluation for summarization factual consistency and to present a novel ranking-based protocol with the highest reliability. The authors will also release their evaluation guidelines and annotations to promote future work on factual consistency evaluation.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2022.naacl-main.417,"{'Pre-trained language models tend to produce text that is factually inconsistent with the input in abstractive text summarization.': 'Evaluating the factual consistency of the generated summaries with respect to the source is an important task. Metrics have been proposed for evaluating factual consistency, including applying natural language inference and question-answering models. However, current metrics still do not correlate highly with human judgments on factual consistency.', 'Differences in the evaluation task design affect the quality of the resulting human judgments and system comparisons in crowdsourced evaluations.': 'Researchers typically crowdsource human evaluations using platforms such as Amazon’s Mechanical Turk. Two of the primary paradigms of crowdsourced evaluations are ranking-based and rating-based. Best-Worst Scaling is a ranking-based method that produces higher-quality evaluations than rating scales such as the Likert Scale for tasks such as sentiment analysis.', 'Previous studies have not analyzed annotation reliability in the context of factual consistency for summarization.': 'The authors are the first to study the reliability of human evaluation for summarization factual consistency. They study rating and ranking-based protocols across two summarization datasets and four state-of-the-art abstractive models. They determine the factors affecting human evaluation reliability and present a novel ranking-based protocol with the highest reliability.', 'There is a lack of evaluation guidelines and annotations for factual consistency evaluation in summarization.': 'The authors will release their evaluation guidelines and annotations to promote future work on factual consistency evaluation.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:bbad29f515ef21974161ab6e5d3fb62fa60f879b,Automatic Pyramid Evaluation Exploiting EDU-based Extractive Reference Summaries,EMNLP,2018,"['Tsutomu Hirao', 'Hidetaka Kamigaito', 'Masaaki Nagata']","This paper tackles automation of the pyramid method, a reliable manual evaluation framework. To construct a pyramid, we transform human-made reference summaries into extractive reference summaries that consist of Elementary Discourse Units (EDUs) obtained from source documents and then weight every EDU by counting the number of extractive reference summaries that contain the EDU. A summary is scored by the correspondences between EDUs in the summary and those in the pyramid. Experiments on DUC and TAC data sets show that our methods strongly correlate with various manual evaluations.","

System: The paper discusses the automation of the pyramid method, a manual evaluation framework. The authors transform human-made reference summaries into extractive reference summaries consisting of Elementary Discourse Units (EDUs) from source documents. They then weight each EDU by counting the number of extractive reference summaries that contain it. The summary is scored based on the correspondences between EDUs in the summary and those in the pyramid. The authors conducted experiments on DUC and TAC data sets and found that their methods strongly correlate with various manual evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to develop high quality summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization systems.', 'How will the summaries be used?': 'The summaries will be used to improve the performance of summarization systems by identifying important content and evaluating semantic correctness.'}",['metric'],[],[],[],[],,https://aclanthology.org/D18-1450/,"{'The evaluation scores computed by automatic measures like ROUGE-N and Basic Elements are not useful for improving system performance because they do not address semantic correctness.': 'The pyramid method was proposed as a manual evaluation that identifies conceptual contents, Summary Content Units (SCUs), in reference summaries and constructs a pyramid by collecting semantically equivalent SCUs. However, it requires considerable cost and effort.', 'The automatic pyramid evaluation method, Pyramid Evaluation via Automated Knowledge Extraction (PEAK), which regards subject-predicate-object triples as alternatives to SCUs, is unreliable because the performance of subject-predicate-object triples extraction is not satisfying for practical demands and semantic similarity utilized for clustering the triples does not correlate well with human judgment.': 'The authors propose another automatic pyramid evaluation method that constructs a pyramid consisting of Elementary Discourse Units (EDUs), clause-like text units introduced in Rhetorical Structure Theory. EDUs are regarded as alternatives to SCUs, and the authors transform human-made reference summaries into EDU-based extractive reference summaries and weight every EDU by counting the number of the extractive reference summaries that contain the EDU. The authors conducted experiments on the Document Understanding Conference (DUC) 2003 to 2007 data sets and Text Analysis Conference (TAC) 2008 to 2011 data sets, and the results showed that their methods exhibit strong correlation with manual evaluations.'}",,['News'],['robust-evaluation-methods']
SP:d4ed4b305392f0ee40ba548bea5e4b21773e8e3e,Re-Examining System-Level Correlations of Automatic Summarization Evaluation Metrics,NAACL,2022,"['Daniel Deutsch', 'Rotem Dror', 'Dan Roth']","How reliably an automatic summarization evaluation metric replicates human judgments of summary quality is quantified by systemlevel correlations. We identify two ways in which the definition of the system-level correlation is inconsistent with how metrics are used to evaluate systems in practice and propose changes to rectify this disconnect. First, we calculate the system score for an automatic metric using the full test set instead of the subset of summaries judged by humans, which is currently standard practice. We demonstrate how this small change leads to more precise estimates of system-level correlations. Second, we propose to calculate correlations only on pairs of systems that are separated by small differences in automatic scores which are commonly observed in practice. This allows us to demonstrate that our best estimate of the correlation of ROUGE to human judgments is near 0 in realistic scenarios. The results from the analyses point to the need to collect more high-quality human judgments and to improve automatic metrics when differences in system scores are small.1","The paper discusses the reliability of automatic summarization evaluation metrics in replicating human judgments of summary quality. The authors identify two inconsistencies in the definition of system-level correlation and propose changes to address them. First, they suggest using the full test set instead of a subset judged by humans to calculate the system score for an automatic metric, leading to more precise estimates of system-level correlations. Second, they propose calculating correlations only on pairs of systems with small differences in automatic scores, which are commonly observed in practice. The authors demonstrate that the best estimate of the correlation of ROUGE to human judgments is near 0 in realistic scenarios, highlighting the need for more high-quality human judgments and improved automatic metrics when differences in system scores are small.","{'What is the purpose of the summaries?': 'The authors are not generating the summaries of the documents.', 'Who is the target audience?': 'The paper is for summarization researchers and the community who use automatic metrics to evaluate summarization systems.', 'How will the summaries be used?': 'The paper proposes changes to the evaluation of automatic metrics to better align with how they are used to evaluate summarization systems. The proposed changes aim to improve the accuracy of metric correlations and the ability of automatic metrics to discriminate between similarly performing systems.'}",['analysis'],[],[],[],[],http://cogcomp.org/page/publication_view/973,https://aclanthology.org/2022.naacl-main.442,"{'There are disconnects between how automatic metrics are evaluated and how they are used to evaluate systems.': 'Modify the system-level correlation definition to use the entire test set to calculate the system scores for automatic metrics instead of only the subset of summaries judged by humans.', 'Metrics are evaluated in a setting that is much easier than how they are actually used.': 'Redefine a high quality metric to be one for which a small difference in score reliably indicates a difference in quality. Then, instead of calculating the correlation with all available system pairs, only evaluate with pairs of systems whose automatic metric scores differ by some threshold.'}",,['News'],['robust-evaluation-methods']
SP:26bb013c4bd3f6cc1487eb9a3b06812593784fce,Asking and Answering Questions to Evaluate the Factual Consistency of Summaries,ACL,2020,"['Alex Wang', 'Kyunghyun Cho', 'Mike Lewis']","Practical applications of abstractive summarization models are limited by frequent factual inconsistencies with respect to their input. Existing automatic evaluation metrics for summarization are largely insensitive to such errors. We propose QAGS,1 an automatic evaluation protocol that is designed to identify factual inconsistencies in a generated summary. QAGS is based on the intuition that if we ask questions about a summary and its source, we will receive similar answers if the summary is factually consistent with the source. To evaluate QAGS, we collect human judgments of factual consistency on model-generated summaries for the CNN/DailyMail (Hermann et al., 2015) and XSUM (Narayan et al., 2018) summarization datasets. QAGS has substantially higher correlations with these judgments than other automatic evaluation metrics. Also, QAGS offers a natural form of interpretability: The answers and questions generated while computing QAGS indicate which tokens of a summary are inconsistent and why. We believe QAGS is a promising tool in automatically generating usable and factually consistent text. Code for QAGS will be available at https://github. com/W4ngatang/qags.","The paper discusses the limitations of abstractive summarization models due to frequent factual inconsistencies in their output. Existing automatic evaluation metrics are not sensitive to such errors. The authors propose QAGS, an automatic evaluation protocol that identifies factual inconsistencies in generated summaries by asking questions about the summary and its source. QAGS has higher correlations with human judgments of factual consistency than other automatic evaluation metrics and provides interpretability by indicating which tokens of a summary are inconsistent and why. The authors believe QAGS is a promising tool for automatically generating usable and factually consistent text. Code for QAGS is available on GitHub.",{'Who is the target audience?': 'The target audience for the generated document summaries is not specified in the given paper.'},"['corpus', 'metric']",[],[],[],[],https://github.com/W4ngatang/qags,https://aclanthology.org/2020.acl-main.450,"{'The lack of automatic evaluation metrics that can detect factual inconsistencies in model-generated summaries.': 'Introduce a general framework for evaluating conditional text generation that is designed to detect factual inconsistencies in generated text with respect to some input. The framework consists of three steps: (1) Given a generated text, a question generation (QG) model generates a set of questions about the text. (2) Use question answering (QA) models to answer these questions given both the input and the generated text. (3) Compute a quality score based on the similarity of corresponding answers.', 'The inadequacy of standard metrics for evaluating generated text, which are predominantly based on counting n-grams and are insensitive to semantic errors.': 'Use recent progress in QA and QG to ask and answer human readable, on-topic questions. This approach leverages recent progress in QA and QG to ask and answer human readable, on-topic questions (Devlin et al., 2019; Song et al., 2019).', 'The challenge of evaluating factual consistencies, which has been noted to be challenging even for humans, in addition to being slow and costly.': 'Introduce QAGS (Question Answering and Generation for Summarization), a metric for evaluating the factual consistency of abstractive document summaries. QAGS shows dramatically higher correlations with human judgments of factuality compared to commonly used automatic metrics such as ROUGE.', 'The need for evaluation metrics that are able to capture subtle semantic errors to build better models.': 'Develop QAGS, an automatic model-based evaluation metric for measuring the factual consistency of model-generated text.', 'The lack of robustness of evaluation metrics to a number of factors including underlying model quality and domain mismatch.': 'Analyze the robustness of QAGS through an ablation study. QAGS shows robustness to the quality of the underlying QG and QA models, the domain of the models, and the number of questions asked. Even under the worst ablation settings, QAGS still has stronger correlation with human judgments than other automatic metrics.', 'The lack of access to a question answering dataset to train the QG and QA models.': 'QAGS only assumes access to a question answering dataset to train the QG and QA models, and is applicable to any modality where a QA model is available, e.g. text, images, or knowledge graphs.', 'The lack of understanding of which parts of summaries are inconsistent.': 'Analyze the questions and answers produced in computing QAGS to illustrate which parts of summaries are inconsistent.', 'The lack of availability of models and code to compute QAGS.': 'Release models and code to compute QAGS.'}",,['News'],['robust-evaluation-methods']
SP:1694d7285bfc7de62fe4641dd4f7646cfdf0ee8c,What Makes a Good Podcast Summary?,SIGIR,2022,"['Rezvaneh Rezapour', 'Rosie Jones', 'Sravana Reddy', 'Ian Soboroff']","Abstractive summarization of podcasts is motivated by the growing popularity of podcasts and the needs of their listeners. Podcasting is a markedly different domain from news and other media that are commonly studied in the context of automatic summarization. As such, the qualities of a good podcast summary are yet unknown. Using a collection of podcast summaries produced by different algorithms alongside human judgments of summary quality obtained from the TREC 2020 Podcasts Track, we study the correlations between various automatic evaluation metrics and human judgments, as well as the linguistic aspects of summaries that result in strong evaluations.ive summarization of podcasts is motivated by the growing popularity of podcasts and the needs of their listeners. Podcasting is a markedly different domain from news and other media that are commonly studied in the context of automatic summarization. As such, the qualities of a good podcast summary are yet unknown. Using a collection of podcast summaries produced by different algorithms alongside human judgments of summary quality obtained from the TREC 2020 Podcasts Track, we study the correlations between various automatic evaluation metrics and human judgments, as well as the linguistic aspects of summaries that result in strong evaluations.","

System: This paper discusses the motivation behind abstractive summarization of podcasts, which is driven by the increasing popularity of podcasts and the needs of their listeners. The authors note that podcasting is a unique domain that differs from news and other media commonly studied in automatic summarization research. The study uses a collection of podcast summaries generated by different algorithms and human judgments of summary quality from the TREC 2020 Podcasts Track to explore the correlations between various automatic evaluation metrics and human judgments, as well as the linguistic aspects of summaries that lead to strong evaluations. The qualities of a good podcast summary are still unknown, and this study aims to shed light on this topic.","{'What is the purpose of the summaries?': 'The authors are generating summaries of podcasts to aid listeners in deciding whether to listen to the full episode and to assist podcast creators in writing descriptions and constructing audio trailers.', 'Who is the target audience?': 'The summaries are for podcast listeners who rely on written text descriptions to decide whether to listen to an episode, and for podcast creators to aid in writing descriptions and constructing audio trailers.', 'How will the summaries be used?': 'The summaries will be used to aid listeners in deciding whether to listen to the full episode and to assist podcast creators in writing descriptions and constructing audio trailers.'}",['analysis'],[],[],[],[],,https://doi.org/10.1145/3477495.3531802,"{'Podcast episodes are typically long, requiring a significant investment of listening time.': 'Podcast summaries could serve as a basis for decision-making, or even stand in as a synopsis for the full episode when a listener does not have time for the complete listening experience.', 'Podcast creators may need assistance in writing descriptions or constructing audio trailers.': 'Automatic summarization could aid podcast creators in writing descriptions, serve to augment manually written descriptions in podcast streaming platforms, or assist in the construction of audio trailers.', 'There are questions about how to evaluate the quality of podcast summaries.': 'The authors study different automatic evaluation metrics and linguistic features, and explore how they correlate with human judgments, in order to quantify what makes a good podcast summary.'}",,['Podcast Transcripts'],"['controlled-and-tailored-summarization', 'robust-evaluation-methods']"
SP:74801824acb5a6519c629e71127215263a45c85f,Evaluation of Cross Domain Text Summarization,SIGIR,2020,"['Liam Scanlon', 'Shiwei Zhang', 'Xiuzhen Zhang', 'Mark Sanderson']","Extractive-abstractive hybrid summarization can generate readable, concise summaries for long documents. Extraction-then-abstraction and extraction-with-abstraction are two representative approaches to hybrid summarization. But their general performance is yet to be evaluated by large scale experiments.We examined two state-of-theart hybrid summarization algorithms from three novel perspectives: we applied them to a form of headline generation not previously tried, we evaluated the generalization of the algorithms by testing them both within and across news domains; and we compared the automatic assessment of the algorithms to human comparative judgments. It is found that an extraction-then-abstraction hybrid approach outperforms an extraction-with-abstraction approach, particularly for cross-domain headline generation.","The paper discusses the effectiveness of extractive-abstractive hybrid summarization in generating concise summaries for long documents. Two approaches to hybrid summarization, extraction-then-abstraction and extraction-with-abstraction, are compared and evaluated through large-scale experiments. The study examines the generalization of the algorithms by testing them within and across news domains and comparing automatic assessments to human judgments. The results show that the extraction-then-abstraction approach outperforms the extraction-with-abstraction approach, especially for cross-domain headline generation.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the general performance of hybrid summarization approaches.', 'Who is the target audience?': 'The summaries are for evaluating the performance of hybrid summarization approaches, specifically the RL and IL models, on the task of headline generation.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of the RL and IL models for headline generation and to evaluate their generalization across different news domains. Human evaluation will also be used to rank the relative performance of the models.'}",['analysis'],[],[],[],[],https://github.com/scanlia/Evaluation-of-Cross-Domain-Text-Summarization,https://doi.org/10.1145/3397271.3401285,"{'Traditional extractive summarization methods are not as effective as hybrid approaches in generating readable and concise summaries.': 'The authors propose two hybrid summarization models, one using Reinforcement Learning (RL) and the other using inconsistency loss (IL), which outperform traditional extractive summarizers for multi-sentence summarization tasks.', 'The effectiveness of hybrid summarization approaches needs to be evaluated for headline generation tasks.': 'The authors test the RL and IL models on the task of headline generation and evaluate their generalization across different news domains.', 'Summarization evaluation metrics such as ROUGE, BLEU, and METEOR reward summaries with high word overlap with a reference summary, but human evaluation is not widely adopted.': 'The authors gather human comparisons to rank the relative performance of the two models and find that the METEOR and ROUGE-2 metrics correlate best with human judgments.'}",,['News'],['robust-evaluation-methods']
SP:029b2596e3df27c2dc0f96e4bff13b08f42f1092,Understanding the Extent to which Content Quality Metrics Measure the Information Quality of Summaries,CONLL,2021,"['Daniel Deutsch', 'Dan Roth']","Reference-based metrics such as ROUGE or BERTScore evaluate the content quality of a summary by comparing the summary to a reference. Ideally, this comparison should measure the summary’s information quality by calculating how much information the summaries have in common. In this work, we analyze the token alignments used by ROUGE and BERTScore to compare summaries and argue that their scores largely cannot be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. Further, we provide evidence that this result holds true for many other summarization evaluation metrics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community’s research goal, to generate summaries with high-quality information. However, we conclude by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research.1","The paper analyzes the token alignments used by reference-based metrics such as ROUGE and BERTScore to compare summaries and argues that their scores largely cannot be interpreted as measuring information overlap. Rather, they are better estimates of the extent to which the summaries discuss the same topics. The consequence of this result is that the most frequently used summarization evaluation metrics do not align with the community’s research goal, to generate summaries with high-quality information. However, the paper concludes by demonstrating that a recently proposed metric, QAEval, which scores summaries using question-answering, appears to better capture information quality than current evaluations, highlighting a direction for future research.","{'What is the purpose of the summaries?': 'The authors are discussing the development of a reliable metric that can automatically evaluate the content of a summary.', 'Who is the target audience?': 'The paper does not explicitly state who the summaries are for.', 'How will the summaries be used?': 'The summaries are used to evaluate the quality of information in a summary, and the paper discusses the shortcomings of current evaluation metrics in measuring information overlap.'}",['analysis'],[],[],[],[],https://github.com/CogComp/content-analysis-experiments,https://aclanthology.org/2021.conll-1.24,"{'The current evaluation metrics for summarization largely fail to evaluate the quality of information in a summary.': 'The authors demonstrate that ROUGE and BERTScore largely do not measure how much information two summaries have in common. They provide evidence that suggests this result holds true for many other evaluation metrics as well.', 'It is not clear whether metrics such as ROUGE and BERTScore evaluate summaries based on how much information they have in common with the reference or some less desirable dimension of similarity, such as whether the two summaries discuss the same topics.': 'The authors cast ROUGE and BERTScore into a unified framework in which the similarity of two summaries is calculated based on an alignment between the summaries’ tokens. This alignment-based view of the metrics enables performing two different analyses of how well they measure information overlap.', 'The authors expand their analysis to consider if 10 other evaluation metrics successfully measure information quality or not.': 'By demonstrating that nearly all of the metrics correlate much more strongly to ROUGE than to the gold-standard method of manually comparing two summaries’ information, the authors argue that the metrics are likely to measure information overlap no better than ROUGE does.', 'The authors propose a promising direction for future research in summarization evaluation metrics.': 'The authors demonstrate that one recently proposed metric that evaluates summaries using question-answering (QA), QAEval, correlates equally well to ROUGE and gold-standard annotations of information overlap. They provide evidence that it measures information overlap much more strongly than either ROUGE or BERTScore does, supporting that QA-based metrics are a promising direction for future research.'}",,['News'],['robust-evaluation-methods']
SP:6c0f94f1034cc90fc825e44b6c69084508f4ae3d,Using Analytic Scoring Rubrics in the Automatic Assessment of College-Level Summary Writing Tasks in L2,IJCNLP,2017,"['Tamara Sladoljev-Agejev', 'Jan Šnajder']","Assessing summaries is a demanding, yet useful task which provides valuable information on language competence, especially for second language learners. We consider automated scoring of college-level summary writing task in English as a second language (EL2). We adopt the Reading-forUnderstanding (RU) cognitive framework, extended with the Reading-to-Write (RW) element, and use analytic scoring with six rubrics covering content and writing quality. We show that regression models with reference-based and linguistic features considerably outperform the baselines across all the rubrics. Moreover, we find interesting correlations between summary features and analytic rubrics, revealing the links between the RU and RW constructs.","The paper discusses the automated scoring of college-level summary writing tasks in English as a second language (EL2) using the Reading-for-Understanding (RU) cognitive framework, extended with the Reading-to-Write (RW) element, and analytic scoring with six rubrics covering content and writing quality. The authors show that regression models with reference-based and linguistic features perform better than baselines across all rubrics and reveal interesting correlations between summary features and analytic rubrics, highlighting the links between the RU and RW constructs.","{'What is the purpose of the summaries?': 'The authors are generating summaries to assess summary writing skills, which are important for academic or professional purposes, particularly for L2 writers who may struggle with language competence.', 'Who is the target audience?': 'The summaries are for college-level students in English as a second language (EL2).', 'How will the summaries be used?': 'The summaries will be used to enhance assessment of summaries, especially in the context of higher education or professional environments, by experimenting with regression models to predict expert-rated analytic scores and carrying out a correlation analysis between text features and analytic scores. Additionally, the authors compile and make available a dataset of expert-rated college-level summaries in EL2.'}",['metric'],[],[],[],[],,https://aclanthology.org/I17-2031/,"{'Assessing L2 summaries is highly demanding, especially if analytic rubrics are involved, as they require raters’ expertise and much concentration when assessing language proficiency at various levels (e.g., lexis, syntax, discourse).': 'Automated scoring is of considerable importance to enhance assessment of summaries, especially in the context of higher education or professional environments.', 'In summaries, raters are expected to put additional effort into checking for accuracy, relevance, completeness, and coherence of the summary against the source text.': 'The authors investigate automated scoring of summaries based on six analytic rubrics used in the assessment of college-level writing in English as a second language (EL2).', 'Summary writing skills may be particularly challenging for L2 writers who may still be struggling with lower levels of language competence such as grammar or vocabulary.': 'Summary writing is sometimes used together with essays to assess university-level abilities in L2. The authors build upon the Reading-for-Understanding (RU) cognitive framework to analyze automated scoring both in terms of reading comprehension and writing quality. They also carry out a correlation analysis between the text features and analytic scores, discovering patterns that link the RW and RU constructs, including signals of inadequate L2 competence. Lastly, they compile and make available a dataset of expert-rated college-level summaries in EL2.'}",,['Student Responses'],['hallucinations-in-the-generated-summaries']
SP:88024fc41a56cd84a351f754b51f35cbfff5c459,How to Find Strong Summary Coherence Measures? A Toolbox and a Comparative Study for Summary Coherence Measure Evaluation,COLING,2022,"['Julius Steen', 'Katja Markert']","Automatically evaluating the coherence of summaries is of great significance both to enable cost-efficient summarizer evaluation and as a tool for improving coherence by selecting highscoring candidate summaries. While many different approaches have been suggested to model summary coherence, they are often evaluated using disparate datasets and metrics. This makes it difficult to understand their relative performance and identify ways forward towards better summary coherence modelling. In this work, we conduct a large-scale investigation of various methods for summary coherence modelling on an even playing field. Additionally, we introduce two novel analysis measures, intra-system correlation and bias matrices, that help identify biases in coherence measures and provide robustness against system-level confounders. While none of the currently available automatic coherence measures are able to assign reliable coherence scores to system summaries across all evaluation metrics, large-scale language models fine-tuned on self-supervised tasks show promising results, as long as finetuning takes into account that they need to generalize across different summary lengths.","The paper discusses the importance of automatically evaluating the coherence of summaries and the challenges of doing so due to the use of disparate datasets and metrics. The authors conduct a large-scale investigation of various methods for summary coherence modeling and introduce two novel analysis measures to identify biases in coherence measures. They find that currently available automatic coherence measures are not reliable across all evaluation metrics, but large-scale language models fine-tuned on self-supervised tasks show promising results if they are trained to generalize across different summary lengths.","{'What is the purpose of the summaries?': 'The authors are generating the summaries to improve the quality of automatically generated summaries by ensuring that they are not only informative but also well-written and coherent.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used as a tool for improving summarizer output, such as a reranker, and to reduce evaluation costs by automatically evaluating the coherence of the summaries.'}",['analysis'],[],[],[],[],https://github.com/julmaxi/summary_coherence_evaluation,https://aclanthology.org/2022.coling-1.527,"{'There is no agreement on how to evaluate summary coherence automatically, which makes it hard to ascertain the state of summary coherence modelling and to identify promising directions for future research.': 'The authors introduce a new evaluation metric, intra-system correlation, that measures performance within the summaries generated by a single summarizer and is more challenging and resilient against system-level confounders. They also introduce bias matrices as a novel analysis tool that allows detecting when coherence measures are biased towards specific summarizers.', 'Current evaluation metrics provide an incomplete picture of coherence measure performance as they focus on comparing summaries generated by different summarizers, which includes many easy decisions due to the large performance gaps between them. Additionally, they are vulnerable to coherence measures exploiting confounding system properties to correctly rank systems without modelling coherence.': 'The authors propose using intra-system correlation as a more challenging and resilient evaluation metric that measures performance within the summaries generated by a single summarizer.', 'Evaluation is often conducted on disparate datasets and uses system outputs from DUC conferences, which do not necessarily represent recent advances in text summarizers. In addition, there is no agreement on how the coherence measure scores should be compared to human scores.': 'The authors conduct a large-scale comparison of coherence measures on the recent SummEval dataset and propose using intra-system correlation as a new evaluation metric. They also highlight the weaknesses of current evaluation regimes other than system-level correlation.', 'Even relatively strong coherence measures are biased towards outputs of certain summarizers, which raises concern about their generalizability.': 'The authors introduce bias matrices as a novel analysis tool that allows detecting when coherence measures are biased towards specific summarizers.', 'SummEval is not conducive to entity-based modelling, which has been successful on many other coherence tasks.': 'The authors highlight this limitation of SummEval and suggest exploring other datasets and tasks for entity-based modelling.', 'Most shuffle-based models transfer poorly to summaries.': 'The authors present evidence that fine-tuning a masked language model (MLM) on the shuffle task as a classifier achieves the most promising performance and allows the model to adapt more easily to comparing documents of different content and lengths, highlighting a possible avenue for future work.'}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:67e49b0313b8518a6563f8011302225c3790bb32,PrefScore: Pairwise Preference Learning for Reference-free Summarization Quality Assessment,COLING,2022,"['Ge Luo', 'Forrest Sheng Bao']","Evaluating machine-generated summaries without a human-written reference summary has been a need for a long time. Inspired by preference labeling in existing work of summarization evaluation, we propose to judge summary quality by learning the preference rank of summaries using the Bradley-Terry power ranking model from inferior summaries generated by corrupting base summaries. Extensive experiments on several datasets show that our weakly supervised scheme can produce scores highly correlated with human ratings.","

System: The paper proposes a method for evaluating machine-generated summaries without a human-written reference summary. The method involves learning the preference rank of summaries using the Bradley-Terry power ranking model from inferior summaries generated by corrupting base summaries. The experiments conducted on several datasets show that the proposed method can produce scores highly correlated with human ratings.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for the task of natural language processing, specifically for summarization.', 'Who is the target audience?': 'The summaries are for automatic systems to generate, and for human evaluation to judge the quality of the system-generated summaries.', 'How will the summaries be used?': 'The summaries will be used to evaluate the quality of system-generated summaries using automatic metrics, which can be reference-based or reference-free. The authors propose a new approach for reference-free summary quality assessment via pairwise preference learning using negative sampling.'}",['metric'],[],[],[],[],https://github.com/NKWBTB/PrefScore,https://aclanthology.org/2022.coling-1.515,"{'Human evaluation of system-generated summaries is non-trivial and laborious.': 'Automatic metrics have been developed to judge the quality of system-generated summaries. These metrics can be categorized as reference-based or reference-free, depending on whether reference summaries are needed in the evaluation stage.', 'Creating human-written reference summaries is laborious and expensive.': 'Recent works are shifting to reference-free metrics. These metrics leverage pretrained language models to carry out text understanding tasks to evaluate the helpfulness of a summary for understanding its source document.', 'Reference-free metrics may show a lower correlation with human evaluation scores than some of the reference-based metrics.': 'To trade off between the human effort needed and the quality of the evaluation, some work pursues a pairwise preference approach which collects preference labels over sentences in documents or over summaries from a human assessor as it requires less cognitive effort than writing a reference summary or manually scoring a machine-generated summary.', 'Existing pairwise preference approaches do not examine the learned preference model as a metric for summarization evaluation.': 'The authors propose a reference-free summary quality assessment via pairwise preference learning using negative sampling. A pre-trained text embedding model is used in a siamese network to learn the preference utility in an end-to-end, weakly supervised fashion.', 'Existing pairwise preference approaches have limitations in cross-domain and multi-document settings.': 'The authors promote their work to cross-domain and multi-document settings and show that the learned models are competitive compared to the state-of-the-art reference-free metrics.'}",,['News'],['robust-evaluation-methods']
SP:9cf412a4eafb2a84828b37f1b17044a5f2f13042,A Training-free and Reference-free Summarization Evaluation Metric via Centrality-weighted Relevance and Self-referenced Redundancy,ACL,2021,"['Wang Chen', 'Piji Li', 'Irwin King']","In recent years, reference-based and supervised summarization evaluation metrics have been widely explored. However, collecting human-annotated references and ratings are costly and time-consuming. To avoid these limitations, we propose a training-free and reference-free summarization evaluation metric. Our metric consists of a centralityweighted relevance score and a self-referenced redundancy score. The relevance score is computed between the pseudo reference built from the source document and the given summary, where the pseudo reference content is weighted by the sentence centrality to provide importance guidance. Besides an F1-based relevance score, we also design an Fβ-based variant that pays more attention to the recall score. As for the redundancy score of the summary, we compute a self-masked similarity score with the summary itself to evaluate the redundant information in the summary. Finally, we combine the relevance and redundancy scores to produce the final evaluation score of the given summary. Extensive experiments show that our methods can significantly outperform existing methods on both multi-document and single-document summarization evaluation. The source code is released at https://github.com/Chen-WangCUHK/Training-Free-and-Ref-Free-SummEvaluation.","The paper proposes a training-free and reference-free summarization evaluation metric to avoid the costly and time-consuming process of collecting human-annotated references and ratings. The metric consists of a centrality-weighted relevance score and a self-referenced redundancy score. The relevance score is computed between the pseudo reference built from the source document and the given summary, and the redundancy score evaluates the redundant information in the summary. The final evaluation score is produced by combining the relevance and redundancy scores. The proposed method outperforms existing methods on both multi-document and single-document summarization evaluation. The source code is available at the given link.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the performance of text summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of text summarization systems.', 'How will the summaries be used?': 'The summaries will be used to develop automatic evaluation metrics for text summarization systems.'}",['metric'],[],[],[],[],https://github.com/Chen-Wang-CUHK/Training-Free-and-Ref-Free-Summ-Evaluation,https://aclanthology.org/2021.acl-long.34,"{'Human evaluation is expensive, time-consuming, and nonreproducible. Thus, it is necessary to develop automatic evaluation metrics for text summarization systems.': 'The authors propose a novel training-free and reference-free summarization evaluation metric which considers both relevance and redundancy.', 'Existing automatic summarization evaluation metrics can be roughly categorized into two groups: reference-based metrics and reference-free metrics. In this work, the authors focus on reference-free metrics.': 'The authors propose a reference-free metric for both multiple and single document summarization evaluation.', 'The SOTA reference-free method for multi-document summarization evaluation, SUPERT, only considers the relevance score between the document and the summary while ignoring the other aspects such as how much redundant information is contained in the summary. Besides, SUPERT assumes that all pseudo reference sentences are equally-important.': 'The authors propose a centrality-weighted relevance score that effectively utilizes the sentence centrality of the documents to provide importance guidance for the pseudo reference tokens and sentences. Based on the weights, they compute a weighted relevance score that is more precise by considering the relative importance.', 'Although SUPERT may employ sentence centrality to select document sentences as a pseudo reference, they ignore the sentence centrality after the selection and still treat the selected sentences equally-important.': 'The authors propose a centrality-weighted relevance score that effectively utilizes the sentence centrality of the documents to provide importance guidance for the pseudo reference tokens and sentences.', 'LS Score, although it does not require a reference during the evaluation of a summary, it requires a large-scale training dataset with reference summaries to train the linguistic scorer.': 'The authors propose a novel training-free and reference-free metric for both multiple and single document summarization evaluation.', ""To the best of the authors' knowledge, there is no reference-free evaluation metric showing that it can achieve the SOTA performance on both multi-document and single-document summarization."": 'The authors propose a novel training-free and reference-free metric that can achieve SOTA performance on both multiple and single document summarization under the reference-free setting.'}",,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'robust-evaluation-methods']"
SP:a6a9d554f28dbcc17e2b639a5fa8368aff7cc7e9,How to Evaluate a Summarizer: Study Design and Statistical Analysis for Manual Linguistic Quality Evaluation,EACL,2021,"['Julius Steen', 'Katja Markert']","Manual evaluation is essential to judge progress on automatic text summarization. However, we conduct a survey on recent summarization system papers that reveals little agreement on how to perform such evaluation studies. We conduct two evaluation experiments on two aspects of summaries’ linguistic quality (coherence and repetitiveness) to compare Likert-type and ranking annotations and show that best choice of evaluation method can vary from one aspect to another. In our survey, we also find that study parameters such as the overall number of annotators and distribution of annotators to annotation items are often not fully reported and that subsequent statistical analysis ignores grouping factors arising from one annotator judging multiple summaries. Using our evaluation experiments, we show that the total number of annotators can have a strong impact on study power and that current statistical analysis methods can inflate type I error rates up to eight-fold. In addition, we highlight that for the purpose of system comparison the current practice of eliciting multiple judgements per summary leads to less powerful and reliable annotations given a fixed study budget.",The paper discusses the importance of manual evaluation in assessing progress in automatic text summarization. The authors conducted a survey on recent summarization system papers and found little agreement on how to perform evaluation studies. They conducted two evaluation experiments on coherence and repetitiveness and compared Likert-type and ranking annotations. They found that the best choice of evaluation method can vary depending on the aspect being evaluated. The authors also found that study parameters are often not fully reported and subsequent statistical analysis ignores grouping factors. They showed that the total number of annotators can have a strong impact on study power and that current statistical analysis methods can inflate type I error rates up to eight-fold. They highlight that eliciting multiple judgments per summary leads to less powerful and reliable annotations for system comparison given a fixed study budget.,"{'What is the purpose of the summaries?': 'The authors are not generating the summaries of the documents. They are conducting a comprehensive survey of recent works in text summarization to investigate the optimal annotation methods, design, and statistical analysis of summary evaluation studies.', 'Who is the target audience?': 'The paper does not mention who the summaries are for. However, the authors are conducting a study on manual summary evaluation in text summarization.', 'How will the summaries be used?': 'The study on manual summary evaluation will be used to investigate the optimal annotation methods, design, and statistical analysis of summary evaluation studies. The authors propose alternative methods for statistical analysis and suggest that repeated judgements for the same summary lead to less reliable and powerful studies for system-level comparison.'}",['analysis'],[],[],[],[],https://github.com/julmaxi/summary_lq_analysis,https://aclanthology.org/2021.eacl-main.160,"{'Current automatic metrics for summary evaluation have low correlation with human judgements on summary quality, especially for linguistic quality evaluation.': 'Conduct a comprehensive survey on the current practices in manual summary evaluation to investigate the optimal annotation methods, design and statistical analysis of summary evaluation studies. Report important study parameters, such as the total number of annotators, and use appropriate statistical tests that do not lead to inflated type I error in the presence of grouping factors.', 'The design of the manual annotation, specifically the overall number of annotators as well as the distribution of annotators to annotation items, has substantial impact on power, reliability and type I errors of subsequent statistical analysis.': 'Carry out annotation experiments for coherence and repetition using both Likert and ranking-style questions on the output of four recent summarizers and reference summaries. Show that ranking-style evaluations are more reliable and cost-efficient for coherence, while on repetition, where many documents do not exhibit any problems, Likert outperforms ranking.', 'Most current papers do not consider the interaction of annotation design and statistical analysis, leading to up to eight-fold increases in type I errors when using standard significance tests.': 'Perform Monte-Carlo simulations based on annotation data to show the risk posed by ignoring grouping factors in statistical analysis. Propose to either use mixed effect models for analysis or to design studies in such a manner that results can be aggregated into independent samples, amenable to simpler analysis tools.', 'The common practice of eliciting repeated judgements for the same summary leads to less reliable and powerful studies for system-level comparison when compared to studies with the same budget but only one judgement per summary.': 'Show that studies with only one judgement per summary are more reliable and powerful for system-level comparison.'}",,['News'],['robust-evaluation-methods']
SP:c42c539a0137b6f7f0c5fb613c4e75b4c1b4ccc0,Evaluating the Factual Consistency of Abstractive Text Summarization,EMNLP,2020,"['Wojciech Kryściński', 'Bryan McCann', 'Caiming Xiong', 'Richard Socher']","The most common metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. We propose a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. Training data is generated by applying a series of rule-based transformations to the sentences of source documents. The factual consistency model is then trained jointly for three tasks: 1) predict whether each summary sentence is factually consistent or not, 2) in either case, extract a span in the source document to support this consistency prediction, 3) for each summary sentence that is deemed inconsistent, extract the inconsistent span from it. Transferring this model to summaries generated by several neural models reveals that this highly scalable approach outperforms previous models, including those trained with strong supervision using datasets from related domains, such as natural language inference and fact checking. Additionally, human evaluation shows that the auxiliary span extraction tasks provide useful assistance in the process of verifying factual consistency. We also release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.","

The paper proposes a model-based approach for verifying factual consistency and identifying conflicts between source documents and generated summaries. The model is trained jointly for three tasks: predicting whether each summary sentence is factually consistent or not, extracting a span in the source document to support this consistency prediction, and extracting the inconsistent span from each summary sentence that is deemed inconsistent. The approach outperforms previous models and provides useful assistance in verifying factual consistency. The authors also release a dataset, code, and trained model weights for factual consistency verification.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to transduce long documents into a shorter form that retains the most important aspects from the source document.', 'Who is the target audience?': 'The target audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but it does address the problem of verifying factual consistency between source documents and generated summaries. The authors propose a novel, weakly-supervised BERT-based model for verifying factual consistency, and they add specialized modules that explain which portions of both the source document and generated summary are pertinent to the model’s decision. The proposed model and dataset will be released to the public.'}","['corpus', 'metric']",[],[],[],[],https://github.com/salesforce/factCC,https://aclanthology.org/2020.emnlp-main.750,"{'Insufficient evaluation protocols that omit important dimensions, such as factual consistency, noisy datasets that leave the task underconstrained, and strong, domain-specific layout biases in the data that dominate training signal.': 'The authors propose a weakly-supervised BERT-based model for verifying factual consistency, and they add specialized modules that explain which portions of both the source document and generated summary are pertinent to the model’s decision. They also generate training data from source documents by applying a series of rule-based transformations that were inspired by error-analysis of neural summarization model outputs.', 'Up to 30% of summaries generated by abstractive models contain factual inconsistencies.': 'The authors propose a novel, weakly-supervised BERT-based model for verifying factual consistency between source documents and generated summaries.', 'Verifying factual consistency requires the entire source document, while current NLI datasets focus on classifying logical entailment between short, single sentence pairs.': 'The authors propose a weakly-supervised BERT-based model for verifying factual consistency that is trained on source documents and summaries.', 'Factual consistency checking focuses on adherence of facts to information provided by a source document without guarantee that the information is true.': 'The authors propose a weakly-supervised BERT-based model for verifying factual consistency that checks whether a summary contains only statements that are entailed by the source document.', 'Lack of explanatory modules that augment factual consistency models and provide useful assistance to humans as they verify the factual consistency between a source document and generated summaries.': 'The authors add specialized modules to their factual consistency model that explain which portions of both the source document and generated summary are pertinent to the model’s decision. Through human evaluation, they show that these explanatory modules provide useful assistance to humans.', 'Lack of a manually annotated dataset for factual consistency verification.': 'The authors release a manually annotated dataset for factual consistency verification, code for training data generation, and trained model weights at https://github.com/salesforce/factCC.'}",,['News'],[]
SP:0efdfd6fd0927c22fae0c62ea550fe6552115dcd,ESTIME: Estimation of Summary-to-Text Inconsistency by Mismatched Embeddings,EMNLP,2021,"['Oleg Vasilyev', 'John Bohannon']","We propose a new reference-free summary quality evaluation measure, with emphasis on the faithfulness. The measure is based on finding and counting all probable potential inconsistencies of the summary with respect to the source document. The proposed ESTIME, Estimator of Summary-to-Text Inconsistency by Mismatched Embeddings, correlates with expert scores in summary-level SummEval dataset stronger than other common evaluation measures not only in Consistency but also in Fluency. We also introduce a method of generating subtle factual errors in human summaries. We show that ESTIME is more sensitive to subtle errors than other common evaluation measures.","The paper introduces a new reference-free summary quality evaluation measure called ESTIME, which focuses on the faithfulness of the summary. The measure counts potential inconsistencies between the summary and the source document and correlates strongly with expert scores in the SummEval dataset. The paper also presents a method of generating subtle factual errors in human summaries and shows that ESTIME is more sensitive to these errors than other common evaluation measures.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the factual consistency of the summaries with the text.', 'Who is the target audience?': 'The summaries are for evaluation purposes, to assess the performance of summarization models and evaluation measures.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different evaluation measures, with a focus on factual consistency. The authors propose a new evaluation measure called ESTIME, which uses mismatched embeddings to estimate summary-to-text inconsistency.'}",['metric'],[],[],[],[],https://github.com/PrimerAI/blanc/tree/master/estime,https://aclanthology.org/2021.eval4nlp-1.10.pdf,"{'Summarization models create summaries that lack factual consistency with the source text, suffering from errors such as hallucinations and entity swaps.': 'Human annotation of factual consistency can be used to classify factual errors and improve the objectivity of annotation scores.', 'Existing summary evaluation measures may be sensitive to certain qualities over others, making it difficult to assess factual consistency.': 'Different approaches to evaluation, such as question-answering based evaluation, text reconstruction, and text similarity, can be used to estimate how well a summary preserves factual consistency.', 'To assess the effectiveness of an evaluation measure for factual consistency, a dataset of human-annotated imperfect machine-generated summaries or artificially introduced factual errors is necessary.': 'The authors introduce ESTIME, a new evaluation measure that emphasizes factual consistency and uses mismatched embeddings. They also introduce a natural method of generating subtle factual errors to compare the performance of ESTIME with other measures on human-written summaries.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:5ae80953ec5c27b094a03fd2953a5e90ad592ec6,Question Answering as an Automatic Evaluation Metric for News Article Summarization,NAACL,2019,"['Matan Eyal', 'Tal Baumel', 'Michael Elhadad']","Recent work in the field of automatic summarization and headline generation focuses on maximizing ROUGE scores for various news datasets. We present an alternative, extrinsic, evaluation metric for this task, Answering Performance for Evaluation of Summaries. APES utilizes recent progress in the field of reading-comprehension to quantify the ability of a summary to answer a set of manually created questions regarding central entities in the source article. We first analyze the strength of this metric by comparing it to known manual evaluation metrics. We then present an end-to-end neural abstractive model that maximizes APES, while increasing ROUGE scores to competitive results.","The paper discusses recent developments in automatic summarization and headline generation, which have focused on maximizing ROUGE scores. The authors propose an alternative evaluation metric called Answering Performance for Evaluation of Summaries (APES), which uses reading comprehension to assess a summary's ability to answer questions about the source article. They compare APES to other manual evaluation metrics and present a neural abstractive model that maximizes APES and increases ROUGE scores.",{},['metric'],[],[],[],[],,https://aclanthology.org/N19-1395,"{'Current summarization models are divided into two approaches, extractive and abstractive, and the most common method for summaries evaluation, ROUGE, has shown a decrease in summary level correlation when only a single reference is given.': 'The authors introduce a new automatic evaluation metric, APES, more suitable for single reference news article datasets.', 'The reduction of the task of summaries evaluation to an extrinsic task such as question answering is effective only under specific settings, including the availability of questions focusing on central information and a reliable question answering (QA) model.': 'The authors propose using salient entities as questions and a relatively easy type of questions, fill-in-the-blank, to train a QA system.', 'The authors aim to maximize APES by increasing attention scores of salient entities while increasing ROUGE to a competitive level.': 'The authors present a new abstractive model that achieves this goal.'}",,['News'],['robust-evaluation-methods']
SP:5fc087e65022d696090724e7d53028571c55068b,QAFactEval: Improved QA-Based Factual Consistency Evaluation for Summarization,NAACL,2022,"['Alexander R. Fabbri', 'Chien-Sheng Wu', 'Wenhao Liu', 'Caiming Xiong']","Factual consistency is an essential quality of text summarization models in practical settings. Existing work in evaluating this dimension can be broadly categorized into two lines of research, entailment-based and question answering (QA)-based metrics, and different experimental setups often lead to contrasting conclusions as to which paradigm performs the best. In this work, we conduct an extensive comparison of entailment and QA-based metrics, demonstrating that carefully choosing the components of a QA-based metric, especially question generation and answerability classification, is critical to performance. Building on those insights, we propose an optimized metric, which we call QAFACTEVAL, that leads to a 14% average improvement over previous QA-based metrics on the SummaC factual consistency benchmark, and also outperforms the best-performing entailment-based metric. Moreover, we find that QA-based and entailment-based metrics can offer complementary signals and be combined into a single metric for a further performance boost.","The paper discusses the importance of factual consistency in text summarization models and evaluates two types of metrics, entailment-based and question answering (QA)-based, for measuring this quality. The authors find that carefully selecting the components of a QA-based metric is critical to performance and propose an optimized metric called QAFACTEVAL, which outperforms previous QA-based and entailment-based metrics. Additionally, the authors suggest that combining both types of metrics can further improve performance.",{},['metric'],[],[],[],[],https://github.com/salesforce/QAFactEval,https://aclanthology.org/2022.naacl-main.187,"{'State-of-the-art text summarization models are not always factually consistent with the source documents they are conditioned on.': 'Determine the factual consistency of a summary using either entailment-based metrics or QA-based metrics.', 'Quantitative comparisons among entailment-based and QA-based metrics often differ in their choices of baseline model and input granularity, evaluating on single datasets and drawing differing conclusions as to the best paradigm.': 'Propose a benchmark called SummaC to compare metrics across six factual consistency datasets for the task of binary factual consistency classification, whether a summary is entirely factually consistent or not.', 'QA-based metrics are not as interpretable as entailment-based metrics due to their inherent decomposability.': 'Conduct an extensive hyperparameter analysis of current QA-based metrics and break them down into four constituent components: 1) the selection of answers to ask questions about, 2) question generation (QG) conditioned upon these answers, 3) question answering (QA) based on the source document, and 4) answer overlap evaluation between QA model output and selected answers.', 'There is no optimized metric that outperforms both entailment-based and QA-based metrics.': 'Propose an optimized metric called QAFACTEVAL that combines QA-based metrics and NLI-based metrics via a simple learned network, achieving state-of-the-art results on a factual consistency benchmark consisting of 6 individual datasets.', 'There is a lack of comprehensive benchmark results for factual consistency metrics and areas for future work in QA-based metrics.': 'Report results for 10 additional metrics across classification and correlation analysis, providing the most comprehensive benchmark results for factual consistency metrics and highlighting areas for future work in QA-based metrics.'}",,['News'],[]
SP:e0a5687369753bf112ca4719c62dcfe5fbbd2d48,SUM-QE: a BERT-based Summary Quality Estimation Model,EMNLP,2019,"['Stratos Xenouleas', 'Prodromos Malakasiotis', 'Marianna Apidianaki', 'Ion Androutsopoulos']","We propose SUM-QE, a novel Quality Estimation model for summarization based on BERT. The model addresses linguistic quality aspects that are only indirectly captured by content-based approaches to summary evaluation, without involving comparison with human references. SUM-QE achieves very high correlations with human ratings, outperforming simpler models addressing these linguistic aspects. Predictions of the SUM-QE model can be used for system development, and to inform users of the quality of automatically produced summaries and other types of generated text.","System: The paper introduces a new model called SUM-QE, which uses BERT to evaluate the quality of summarizations. Unlike other models, SUM-QE focuses on linguistic quality aspects that are not captured by content-based approaches. The model achieves high correlations with human ratings and outperforms simpler models. The predictions of SUM-QE can be used for system development and to inform users about the quality of automatically generated summaries and other types of text.","{'What is the purpose of the summaries?': 'The authors are generating summaries to address Quality Estimation (QE) for summarization.', 'Who is the target audience?': 'The summaries are for informing users of the quality of automatically produced summaries and other types of generated text, and to select the best among summaries output by multiple systems.', 'How will the summaries be used?': 'The predictions made by SUM-QE can be used for system development and to inform users of the quality of automatically produced summaries and other types of generated text.'}",['metric'],[],[],[],[],https://github.com/nlpaueb/SumQE,https://doi.org/10.18653/v1/D19-1618,"{'Traditional evaluation metrics fail to capture linguistic qualities of summaries.': 'The authors propose a model called SUM-QE that successfully predicts linguistic qualities of summaries using the BERT language representation model.', 'Difficulty in measuring the quality of automatically produced summaries.': 'SUM-QE can be used to inform users of the quality of automatically produced summaries and select the best among summaries output by multiple systems.', 'Lack of a comprehensive evaluation of the proposed model.': 'The authors provide a thorough evaluation of SUM-QE on three publicly available summarization datasets from NIST shared tasks and compare its performance to a wide variety of baseline methods capturing different aspects of linguistic quality.', 'Difficulty in modeling linguistic qualities that relate to both text content and form.': 'The authors show the ability of BERT to model linguistic qualities that relate to both text content and form, achieving very high correlations with human ratings.'}",,['News'],['robust-evaluation-methods']
SP:d10b469f162e2343ceeb042185a32dfcff5169e4,InfoLM: A New Metric to Evaluate Summarization & Data2Text Generation,AAAI,2022,"['Pierre Jean A. Colombo', 'Chloé Clavel', 'Pablo']","Assessing the quality of natural language generation systems through human annotation is very expensive. Additionally, human annotation campaigns are time-consuming and include non-reusable human labour. In practice, researchers rely on automatic metrics as a proxy of quality. In the last decade, many string-based metrics (e.g., BLEU) have been introduced. However, such metrics usually rely on exact matches and thus, do not robustly handle synonyms. In this paper, we introduce InfoLM a family of untrained metrics that can be viewed as a string-based metric that addresses the aforementioned flaws thanks to a pre-trained masked language model. This family of metrics also makes use of information measures allowing the adaptation of InfoLM to various evaluation criteria. Using direct assessment, we demonstrate that InfoLM achieves statistically significant improvement and over 10 points of correlation gains in many configurations on both summarization and data2text generation.","The paper discusses the challenges of assessing the quality of natural language generation systems through human annotation, which is expensive and time-consuming. Researchers often rely on automatic metrics, but existing string-based metrics like BLEU do not handle synonyms well. The authors introduce InfoLM, a family of untrained metrics that uses a pre-trained masked language model and information measures to address these flaws. They demonstrate that InfoLM achieves significant improvement and correlation gains in many configurations on both summarization and data2text generation through direct assessment.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of natural language processing (NLP) systems that perform text-to-text transformation.', 'Who is the target audience?': 'The summaries are for researchers who want to compare the outputs of NLP systems and evaluate their performance.', 'How will the summaries be used?': 'The summaries will be used to automatically evaluate the performance of NLP systems using untrained metrics that rely on a continuous representation and do not require human annotation. The proposed approach, InfoLM, is a family of new untrained metrics to evaluate text summarization and data2text generation.'}",['metric'],[],[],[],[],,https://ojs.aaai.org/index.php/AAAI/article/view/21299,"{'Automatic evaluation of natural language generation (NLG) systems is a challenge due to the task-specific definition of success criteria and the high annotation costs and time required for human evaluation.': 'Researchers tend to rely on automatic evaluation metrics, which fall into two categories: trained metrics and untrained metrics. In this paper, the authors focus on untrained metrics as they may generalize better to new data. They introduce InfoLM, a family of new untrained metrics to evaluate text summarization and data2text generation. InfoLM overcomes the common pitfall of string matching metrics and does not require selecting a layer or relying on an arbitrary aggregation function. It combines a pre-trained model and a contrast function between two discrete probability distributions.', 'String-based metrics often fail to robustly match paraphrases and focus mainly on the surface form, while embedding-based metrics rely on continuous representations.': 'InfoLM relies on statistics on tokens and can be seen as a string-based metric, but it does not suffer from common pitfalls of string-based metrics as the pre-trained masked language model (PMLM) also allows assigning a high score to paraphrases and capturing distant dependencies.', 'Existing BERT-based metrics require selecting specific layers or using arbitrary aggregation techniques.': 'InfoLM differs from existing BERT-based metrics as it directly relies on the PMLM, which outputs discrete probability distributions. Thus, it does not require selecting specific layers or using arbitrary aggregation techniques.', 'The authors aim to demonstrate that InfoLM is better suited than concurrent metrics for evaluating summarization and data2text generation.': 'The authors conduct a comparison using multiple correlation measures with human judgment both at the text and system level. They also dissect InfoLM to better understand the relative importance of each component, such as calibration and sensibility to the change of information measures.'}",,['News'],"['lack-of-suitable-training-data', 'robust-evaluation-methods']"
SP:dee2e7053b9dac7fe0e8e352c32d4e85805711ce,The Feasibility of Embedding Based Automatic Evaluation for Single Document Summarization,EMNLP,2019,"['Simeng Sun', 'Ani Nenkova']","ROUGE is widely used to automatically evaluate summarization systems. However, ROUGE measures semantic overlap between a system summary and a human reference on word-string level, much at odds with the contemporary treatment of semantic meaning. Here we present a suite of experiments on using distributed representations for evaluating summarizers, both in reference-based and in reference-free setting. Our experimental results show that the max value over each dimension of the summary ELMo word embeddings is a good representation that results in high correlation with human ratings. Averaging the cosine similarity of all encoders we tested yields high correlation with manual scores in reference-free setting. The distributed representations outperform ROUGE in recent corpora for abstractive news summarization but are less good on older test data and systems.",The paper discusses the limitations of using ROUGE to evaluate summarization systems and presents experiments on using distributed representations for evaluation. The results show that the max value over each dimension of the summary ELMo word embeddings and averaging the cosine similarity of all encoders yield high correlation with human ratings in both reference-based and reference-free settings. The distributed representations outperform ROUGE in recent corpora for abstractive news summarization but are less effective on older test data and systems.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of single document summarization systems.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different summarization systems and to evaluate the quality of the summaries generated by these systems.'}",['metric'],[],[],[],[],,https://aclanthology.org/D19-1116,"{'The widely used ROUGE automatic evaluation for summarization relies on token overlap between reference and system summary, which provides a limited view of meaning.': 'The authors propose exploring more compelling semantic matching techniques, such as cosine similarity between the reference and summary embedding, which works better than ROUGE on recent datasets for comparing single document summarization systems.', 'Prior work has incorporated word embeddings in ROUGE pairwise comparison of n-grams, but still relies on ROUGE and n-gram co-occurrences in the computation of semantic similarity.': 'The authors thoroughly abandon ROUGE and n-gram co-occurrences in the computation of semantic similarity, and instead focus on embedding similarity between the reference and summary.', 'Evaluating single document summaries without reference summaries is challenging and has been explored using a variety of word-string similarity techniques.': 'The authors propose studying reference-free evaluations via embedding similarity between the full document to be summarized and the system summaries, and compare several popular representations including sentence embedding, un-contextualized word embedding, and contextualized word embedding. They validate their method on three different test sets with human evaluation to give a sense of the generalizability of their findings.'}",,['News'],['robust-evaluation-methods']
SP:a86e62638e97efdb7fdef327eb96790e53c446bb,An Anchor-Based Automatic Evaluation Metric for Document Summarization,COLING,2020,"['Kexiang Wang', 'Tianyu Liu', 'Baobao Chang', 'Zhifang Sui']","The widespread adoption of reference-based automatic evaluation metrics such as ROUGE has promoted the development of document summarization. In this paper, we consider a new protocol for designing reference-based metrics that require the endorsement of source document(s). Following protocol, we propose an anchored ROUGE metric fixing each summary particle on source document, which bases the computation on more solid ground. Empirical results on benchmark datasets validate that source document helps to induce a higher correlation with human judgments for ROUGE metric. Being self-explanatory and easy-to-implement, the protocol can naturally foster various effective designs of reference-based metrics besides the anchored ROUGE introduced here.","The paper discusses a new protocol for designing reference-based metrics for document summarization that requires the endorsement of source documents. The proposed anchored ROUGE metric fixes each summary particle on the source document, resulting in a more solid computation. Empirical results on benchmark datasets show that using the source document induces a higher correlation with human judgments for the ROUGE metric. The protocol is self-explanatory and easy to implement, and can foster various effective designs of reference-based metrics besides the anchored ROUGE.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to evaluate system performance for the task of document summarization.', 'Who is the target audience?': 'The summaries are for evaluating the performance of document summarization systems.', 'How will the summaries be used?': 'The summaries will be used as an automatic evaluation metric to assess the performance of document summarization systems.'}",['metric'],[],[],[],[],,https://aclanthology.org/2020.coling-main.500,"{'The current off-the-shelf metrics for evaluating document summarization have their own drawbacks and are not ideal for real-world settings, especially for multi-document summarization.': 'The authors propose a new protocol of reference-based summarization metrics that considers the impact of the source document on the computation. This new protocol makes the source document endorse a certain metric and allows for fact-checking of the information in the peer summary based on the information pool of the source document.', 'Existing reference-based metrics for document summarization do not consider the impact of the source document on the computation.': 'The authors advance a new protocol of reference-based metrics that requires the direct participation of the source document in the computation of any reference-based metric for document summarization. This new protocol introduces a key dimension that can nurture reference-based summarization metrics.', 'The current anchored version of ROUGE metric does not utilize the source document in the computation.': 'The authors propose an anchored version of ROUGE metric under the new protocol that utilizes a set of lexical items (called particles) in the source document corresponding to a certain particle in the summary. This introduces a weighted scheme that focuses more on the link to the source document.'}",,['News'],['robust-evaluation-methods']
SP:072fa07524327a2bbcbb00c09f97031ed2cdf546,"How to Compare Summarizers without Target Length? Pitfalls, Solutions and Re-Examination of the Neural Summarization Literature",NAACL,2019,"['Simeng Sun', 'Ori Shapira', 'Ido Dagan', 'Ani Nenkova']","Until recently, summarization evaluations compared systems that produce summaries of the same target length. Neural approaches to summarization however have done away with length requirements. Here we present detailed experiments demonstrating that summaries of different length produced by the same system have a clear non-linear pattern of quality as measured by ROUGE F1 scores: initially steeply improving with summary length, then starting to gradually decline. Neural models produce summaries of different length, possibly confounding improvements of summarization techniques with potentially spurious learning of optimal summary length. We propose a new evaluation method where ROUGE scores are normalized by those of a random system producing summaries of the same length. We reanalyze a number of recently reported results and show that some negative results are in fact reports of system improvement once differences in length are taken into account. Finally, we present a small-scale human evaluation showing a similar trend of perceived quality increase with summary length, calling for the need of similar normalization in reporting human scores.","The paper discusses how traditional summarization evaluations compared systems that produced summaries of the same length, but neural approaches have done away with this requirement. The paper presents experiments showing that summaries of different lengths produced by the same system have a clear non-linear pattern of quality as measured by ROUGE F1 scores. The paper proposes a new evaluation method where ROUGE scores are normalized by those of a random system producing summaries of the same length. The paper reanalyzes recently reported results and shows that some negative results are actually reports of system improvement once differences in length are taken into account. Finally, the paper presents a small-scale human evaluation showing a similar trend of perceived quality increase with summary length, calling for the need of similar normalization in reporting human scores.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate algorithms for text summarization of news.', 'Who is the target audience?': 'The summaries are not intended for any specific audience, but rather for the purpose of evaluating the effectiveness of different summarization algorithms.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different summarization algorithms, and to determine which algorithms are most effective at producing summaries of a pre-specified length.'}",['analysis'],[],[],[],[],,https://aclanthology.org/W19-2303,"{'The practice of fixing required summary length was abandoned with the advent of neural methods, but the confounding effect of output length has been widely acknowledged.': 'A meaningful evaluation should explicitly take output length into account.', 'Prior to 2015, researchers reported ROUGE recall as standard evaluation, but best practices for using ROUGE call for truncating the summaries to the desired length.': '(Nallapati et al., 2016) suggested using ROUGE F1 instead of recall, which can penalize longer summaries.', 'The rest of the neural summarization literature adopted F1 evaluation without further discussion, but it may not penalize longer summaries as intended.': 'The authors propose an alternative evaluation that appropriately normalizes ROUGE scores and reinterpret several recent results to show that not taking into account differences in length may have favored misleading conclusions.', 'The established practice was to require human references of different lengths in order to evaluate system outputs of the respective length, which has recently been shown unnecessary.': 'The authors present a pilot analysis of summary length in human evaluation.'}",,['News'],['robust-evaluation-methods']
SP:141cc85133e9416d54b82d660bb4acc005e2b927,Metrics also Disagree in the Low Scoring Range: Revisiting Summarization Evaluation Metrics,COLING,2020,"['Manik Bhandari', 'Pranav Gour', 'Atabak Ashfaq', 'Pengfei Liu']","In text summarization, evaluating the efficacy of automatic metrics without human judgments has become recently popular. One exemplar work (Peyrard, 2019) concludes that automatic metrics strongly disagree when ranking high-scoring summaries. In this paper, we revisit their experiments and find that their observations stem from the fact that metrics disagree in ranking summaries from any narrow scoring range. We hypothesize that this may be because summaries are similar to each other in a narrow scoring range and are thus, difficult to rank. Apart from the width of the scoring range of summaries, we analyze three other properties that impact inter-metric agreement Ease of Summarization, Abstractiveness, and Coverage. To encourage reproducible research, we make all our analysis code and data publicly available.1","The paper discusses the evaluation of automatic metrics in text summarization, specifically focusing on the disagreement between metrics when ranking high-scoring summaries. The authors revisit previous experiments and suggest that the narrow scoring range of summaries may be the reason for the disagreement. They also analyze three other properties that impact inter-metric agreement: Ease of Summarization, Abstractiveness, and Coverage. The authors make their analysis code and data publicly available to encourage reproducible research.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the quality of evaluation metrics, also known as meta-evaluation, which is a crucial step in summarization evaluation.', 'Who is the target audience?': 'The summaries are for evaluating the quality of evaluation metrics, and are not intended for any specific audience.', 'How will the summaries be used?': 'The summaries will be used to analyze the correlation between different automated metrics for summarization evaluation, and to identify factors that affect the correlations of these metrics.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2020.coling-main.501,"{'Automated metrics strongly disagree for ranking high-scoring summaries.': 'The authors revisit the experiments of Peyrard (2019) and find that not only do metrics disagree in the high scoring range, they also disagree in the low and medium scoring range. They observe that metrics agree in ranking summaries from the full scoring range but disagree in ranking summaries from low, average, and high scoring ranges when taken separately.', 'Manual annotations for meta-evaluation are expensive and time-consuming.': 'The authors focus on measuring the correlation between different metrics, which is a human judgment-free method.', 'It is unclear which factors affect the correlations of metrics.': 'The authors analyze three properties of a reference summary on inter-metric correlation - Ease of Summarization, Abstractiveness and Coverage. They find that for highly extractive document-reference summary pairs, inter-metric correlation is high whereas metrics disagree when ranking summaries of abstractive document-reference summary pairs.', 'It is unclear whether the scoring range or the width of the scoring range affects inter-metric correlation.': 'The authors find that the scoring range has little effect on the correlation of metrics. It is rather the width of the scoring range which affects inter-metric correlation.'}",,['News'],['robust-evaluation-methods']
SP:084f4313c45f3f56a7b432e6ea327d968fce1734,What Makes a Good and Useful Summary? Incorporating Users in Automatic Summarization Research,NAACL,2022,"['Maartje ter Hoeve', 'Julia Kiseleva', 'Maarten de Rijke']","Automatic text summarization has enjoyed great progress over the years and is used in numerous applications, impacting the lives of many. Despite this development, there is little research that meaningfully investigates how the current research focus in automatic summarization aligns with users’ needs. To bridge this gap, we propose a survey methodology that can be used to investigate the needs of users of automatically generated summaries. Importantly, these needs are dependent on the target group. Hence, we design our survey in such a way that it can be easily adjusted to investigate different user groups. In this work we focus on university students, who make extensive use of summaries during their studies. We find that the current research directions of the automatic summarization community do not fully align with students’ needs. Motivated by our findings, we present ways to mitigate this mismatch in future research on automatic summarization: we propose research directions that impact the design, the development and the evaluation of automatically generated summaries.","The paper discusses the gap between the current research focus in automatic summarization and users' needs, particularly university students who heavily rely on summaries. To address this, the authors propose a survey methodology that can be adjusted to investigate different user groups. They find that the current research directions do not fully align with students' needs and suggest ways to mitigate this mismatch in future research.","{'What is the purpose of the summaries?': 'The authors are generating summaries to investigate how the current research focus in automatic summarization aligns with users’ needs.', 'Who is the target audience?': 'The summaries are for university students who make extensive use of summaries during their studies.', 'How will the summaries be used?': 'The summaries will be used to identify ways to mitigate the mismatch between the current research directions of the automatic summarization community and students’ needs.'}",['analysis'],[],[],[],[],https://github.com/maartjeth/survey_useful_summarization,https://aclanthology.org/2022.naacl-main.4,"{'There is little research that investigates how the current research focus in automatic summarization aligns with users’ needs.': 'The authors propose a survey methodology that can be used to investigate the needs of users of automatically generated summaries.', 'The needs of users of automatically generated summaries are dependent on the target group.': 'The authors design their survey in such a way that it can be easily adjusted to investigate different user groups.', 'The current research directions of the automatic summarization community do not fully align with university students’ needs.': 'The authors propose research directions that impact the design, the development and the evaluation of automatically generated summaries to mitigate this mismatch in future research on automatic summarization.'}",,['Course Material'],['controlled-and-tailored-summarization']
SP:3171332d672efd28b32477806b5208ef02a04d1e,Evaluating Multiple System Summary Lengths: A Case Study,EMNLP,2018,"['Ori Shapira', 'David Gabay', 'Hadar Ronen', 'Judit Bar-Ilan', 'Yael Amsterdamer', 'Ani Nenkova', 'Ido Dagan']","Practical summarization systems are expected to produce summaries of varying lengths, per user needs. While a couple of early summarization benchmarks tested systems across multiple summary lengths, this practice was mostly abandoned due to the assumed cost of producing reference summaries of multiple lengths. In this paper, we raise the research question of whether reference summaries of a single length can be used to reliably evaluate system summaries of multiple lengths. For that, we have analyzed a couple of datasets as a case study, using several variants of the ROUGE metric that are standard in summarization evaluation. Our findings indicate that the evaluation protocol in question is indeed competitive. This result paves the way to practically evaluating varying-length summaries with simple, possibly existing, summarization benchmarks.",The paper explores whether reference summaries of a single length can be used to evaluate system summaries of varying lengths. The authors conducted a case study using several variants of the ROUGE metric and found that the evaluation protocol is competitive. This paves the way for practical evaluation of varying-length summaries using existing summarization benchmarks.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate summarization systems.', 'Who is the target audience?': 'The summaries are for the summarization community.', 'How will the summaries be used?': 'The summaries will be used to assess the performance of summarization systems across multiple summary lengths.'}",['analysis'],[],[],[],[],,https://aclanthology.org/D18-1087,"{'Summarization systems are typically evaluated based on a single summary length, which may not accurately reflect their performance across different summary lengths.': 'The authors propose that the summarization community should consider evaluating summarization systems over multiple length outputs to allow better assessment of length-related performance within and across systems.', 'The high cost of creating multiple-length reference summaries has led to the use of a single reference summary length in subsequent benchmarks and datasets.': 'The authors raise the research question of whether reference summaries of a single length can be used to evaluate system summaries of multiple lengths, as reliably as when using references of multiple lengths, with respect to different standard evaluation metrics.', 'The evaluation methodology used by Kikuchi et al. (2016) to evaluate system summaries of multiple lengths against a single reference summary length was not assessed through correlation to human judgment.': 'The authors provide a closer look into this methodology, given its potential value, and test their research question over the DUC 2001 and 2002 data, which are the only datasets that include multiple length reference and submitted system summaries, as well as manual assessment of the latter.', 'The authors suggest that their promising results from the DUC 2001 and 2002 data should be repeated in future work to test their question over more recent and broader summarization datasets and human evaluation schemes.': 'Repeating the assessment methodology presented in this paper would allow the community to feasibly resume proper evaluation and deliberate development of systems that target effective summaries across a range of lengths.'}",,['News'],['robust-evaluation-methods']
SP:2370a00e548d9883979bb7112e8abaf4610a6ce4,Ranking Generated Summaries by Correctness: An Interesting but Challenging Application for Natural Language Inference,ACL,2019,"['Tobias Falke', 'Leonardo F. R. Ribeiro', 'Prasetya Ajie Utama', 'Ido Dagan', 'Iryna Gurevych']","While recent progress on abstractive summarization has led to remarkably fluent summaries, factual errors in generated summaries still severely limit their use in practice. In this paper, we evaluate summaries produced by state-of-the-art models via crowdsourcing and show that such errors occur frequently, in particular with more abstractive models. We study whether textual entailment predictions can be used to detect such errors and if they can be reduced by reranking alternative predicted summaries. That leads to an interesting downstream application for entailment models. In our experiments, we find that outof-the-box entailment models trained on NLI datasets do not yet offer the desired performance for the downstream task and we therefore release our annotations as additional test data for future extrinsic evaluations of NLI.","The paper discusses the limitations of abstractive summarization due to factual errors in generated summaries. The authors evaluate summaries produced by state-of-the-art models and find that errors occur frequently, especially with more abstractive models. They explore the use of textual entailment predictions to detect and reduce such errors by reranking alternative predicted summaries. The authors find that current entailment models do not offer the desired performance for this task and release their annotations as additional test data for future evaluations of natural language inference.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a condensed version of the content.', 'Who is the target audience?': 'The summaries are for users who want to quickly understand the main points of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and provide a quick overview of the content of a document.'}",['analysis'],[],[],[],[],,https://aclanthology.org/P19-1213,"{'Abstractive summarization models introduce factual errors in their generated summaries.': 'The authors propose to use natural language inference (NLI) to detect factual errors in generated summaries and rerank them based on their correctness.', 'The effectiveness of using NLI for reranking generated summaries is unclear.': 'The authors compare different NLI models and find that models trained on NLI datasets transfer poorly to their downstream task. They release their collected annotations to improve NLI models for this setup.', 'The correctness of generated summaries needs to be verified efficiently.': 'The authors describe a crowdsourcing approach to efficiently verify the correctness of generated summaries.', 'State-of-the-art abstractive summarization models still have errors in their generated summaries.': 'The authors report correctness estimates for summaries generated by three recent abstractive summarization systems and show that even state-of-the-art models have errors in 25% of their summaries.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:5c372171c6f08753d8af911870afe35e0a1607d8,Understanding Neural Abstractive Summarization Models via Uncertainty,EMNLP,2020,"['Jiacheng Xu', 'Shrey Desai', 'Greg Durrett']","An advantage of seq2seq abstractive summarization models is that they generate text in a free-form manner, but this flexibility makes it difficult to interpret model behavior. In this work, we analyze summarization decoders in both blackbox and whitebox ways by studying on the entropy, or uncertainty, of the model’s token-level predictions. For two strong pretrained models, PEGASUS (Zhang et al., 2020) and BART (Lewis et al., 2020) on two summarization datasets, we find a strong correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder’s uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving a sense of what factors make a context particularly selective for the model’s next output token. Finally, we study the relationship of decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. We show that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly.1","The paper discusses the difficulty in interpreting the behavior of seq2seq abstractive summarization models, which generate text in a free-form manner. The authors analyze summarization decoders by studying the entropy of the model's token-level predictions, finding a correlation between low prediction entropy and where the model copies tokens rather than generating novel text. The decoder's uncertainty also connects to factors like sentence position and syntactic distance between adjacent pairs of tokens, giving insight into what factors make a context particularly selective for the model's next output token. Finally, the authors study the relationship between decoder uncertainty and attention behavior to understand how attention gives rise to these observed effects in the model. The paper concludes that uncertainty is a useful perspective for analyzing summarization and text generation models more broadly.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization models and understand their behavior.', 'Who is the target audience?': 'The summaries are not intended for any specific audience, but rather for analysis and inspection of generation systems.', 'How will the summaries be used?': 'The summaries will be used to understand the behavior of abstractive summarization models and improve their performance.'}",['analysis'],[],[],[],[],https://github.com/jiacheng-xu/text-sum-uncertainty,https://aclanthology.org/2020.emnlp-main.508,"{'Abstractive summarization models are not as straightforward and interpretable as their extractive counterparts, leading to downstream errors such as factual inconsistencies with the input document.': 'The authors propose to interpret and understand abstractive summarization models through the lens of decoder uncertainty, or the entropy of decisions during generation.', 'Summarization models specifically have not received similar attention in terms of interpretability compared to other NLU models.': 'The authors focus on analyzing and inspecting generation systems using uncertainty as a technique for analysis.', 'Uncertainty in generation has been studied from various perspectives, but it is underutilized as a technique for analysis and inspection of generation systems.': 'The authors use uncertainty as a tool to characterize decoder behavior in text generation.', 'The abstractiveness of reference summaries fundamentally changes model behavior, but this has not been extensively studied.': 'The authors study two prominent summarization models, PEGASUS and BART, fine-tuned on two English summarization datasets, CNN/Daily Mail and XSum, to understand model behavior in each setting.', 'The interaction of content selection and lexical choice in certain contexts is not well understood.': 'The authors establish two coarse types for decoded tokens, copy and generate, and find that the entropy of the generation decision correlates with whether the model is copying or generating, as well as where in the sentence the token is.', 'The relationship between uncertainty and syntax in generated sentences is not well understood.': 'The authors extend their analysis by looking at how uncertainty relates to the syntax of the generated sentence, whether uncertainty connects to syntactic notions of surprisal, and how the entropy varies across certain syntactic productions.', 'The correlation between attention entropy and prediction entropy is not well understood.': 'The authors derive a way to quantify decoder attention by aggregating distinct self-attention heads, revealing the correlation between the attention entropy and prediction entropy, and investigating the correspondence between the prediction entropy and the fraction of the past and future decoded tokens.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:02aae9f0540ace1df34547b544ed80cec4467e8f,What Makes a Good Summary? Reconsidering the Focus of Automatic Summarization,NAACL,2022,"['Maartje ter Hoeve', 'Julia Kiseleva', 'Maarten de Rijke']","Automatic text summarization has enjoyed great progress over the last years. Now is the time to re-assess its focus and objectives. Does the current focus fully adhere to users’ desires or should we expand or change our focus? We investigate this question empirically by conducting a survey amongst heavy users of pre-made summaries. We find that the current focus of the field does not fully align with participants’ wishes. In response, we identify three groups of implications. First, we argue that it is important to adopt a broader perspective on automatic summarization. Based on our findings, we illustrate how we can expand our view when it comes to the types of input material that is to be summarized, the purpose of the summaries and their potential formats. Second, we define requirements for datasets that can facilitate these research directions. Third, usefulness is an important aspect of summarization that should be included in our evaluation methodology; we propose a methodology to evaluate the usefulness of a summary. With this work we unlock important research directions for future work on automatic summarization and we hope to initiate the development of methods in these directions.","The paper discusses the need to re-assess the focus and objectives of automatic text summarization and whether they align with users' desires. The authors conducted a survey among heavy users of pre-made summaries and found that the current focus of the field does not fully align with participants' wishes. They propose adopting a broader perspective on automatic summarization, expanding the types of input material that can be summarized, and defining requirements for datasets that can facilitate these research directions. They also propose including usefulness as an important aspect of summarization in the evaluation methodology and propose a methodology to evaluate the usefulness of a summary. The authors hope to unlock important research directions for future work on automatic summarization.","{'What is the purpose of the summaries?': ""The authors are investigating whether the current focus of automatic text summarization aligns with users' desires."", 'Who is the target audience?': 'The summaries are for heavy users of pre-made summaries.', 'How will the summaries be used?': ""The authors propose expanding the focus of automatic summarization to better align with users' desires, and suggest a methodology for evaluating the usefulness of a summary.""}",['analysis'],[],[],[],[],,https://arxiv.org/abs/2012.07619,"{""The current focus of automatic text summarization does not fully align with users' desires."": 'Adopt a broader perspective on automatic summarization by expanding the view on the types of input material that is to be summarized, the purpose of the summaries, and their potential formats.', 'Lack of datasets that can facilitate research directions.': 'Define requirements for datasets that can facilitate research directions.', 'Usefulness is an important aspect of summarization that should be included in the evaluation methodology.': 'Propose a methodology to evaluate the usefulness of a summary.'}",,['Course Material'],['controlled-and-tailored-summarization']
SP:d8813f27be055ea9e193173aa4227a6e5f3b5bd6,Benchmarking Answer Verification Methods for Question Answering-Based Summarization Evaluation Metrics,ACL,2022,"['Daniel Deutsch', 'Dan Roth']","Question answering-based summarization evaluation metrics must automatically determine whether the QA model’s prediction is correct or not, a task known as answer verification. In this work, we benchmark the lexical answer verification methods which have been used by current QA-based metrics as well as two more sophisticated text comparison methods, BERTScore and LERC. We find that LERC out-performs the other methods in some settings while remaining statistically indistinguishable from lexical overlap in others. However, our experiments reveal that improved verification performance does not necessarily translate to overall QA-based metric quality: In some scenarios, using a worse verification method — or using none at all — has comparable performance to using the best verification method, a result that we attribute to properties of the datasets.1","The paper discusses the importance of answer verification in question answering-based summarization evaluation metrics. The authors benchmark various answer verification methods, including lexical overlap and more sophisticated text comparison methods like BERTScore and LERC. They find that LERC performs well in some settings, but overall, improved verification performance does not necessarily lead to better QA-based metric quality. The authors attribute this to dataset properties.",{'Who is the target audience?': 'The intended audience for the generated summaries is not specified in the given paper.'},['analysis'],[],[],[],[],http://cogcomp.org/page/publication_view/966,https://aclanthology.org/2022.findings-acl.296,"{'Answer verification is a critical step in QA-based evaluation metrics to suppress noisy output from the QA model and identify inconsistent information across texts.': 'The authors benchmark various answer verification strategies for QA-based summarization evaluation metrics to understand whether methods that are more advanced than lexical overlap are better able to classify phrases as having the same or different meaning.', 'It is unknown whether more sophisticated text comparison methods provide a benefit in the answer verification task.': 'The authors analyze four answer verification methods, including exact match, token F1, BERTScore, and LERC, in combination with two QA-based metrics, QAEval and FEQA.', 'It is unclear whether any improvements in verification performance translate to a better QA-based evaluation metric.': 'The authors find that LERC performs the best at the actual task of answer verification in general, although in some settings it is statistically indistinguishable from token F1. However, their results also show that any such improvement in verification performance does not always translate to a better QA-based evaluation metric.', 'It is unclear whether a sophisticated verification method is necessary or even useful when the QA model performance is high or the verification task is easy.': 'The authors recommend using both token F1 and LERC for answer verification since F1 may suffice in some situations and they suspect LERC provides additional benefits, although they are difficult to measure.'}",,['News'],['robust-evaluation-methods']
SP:bc314b7d212f86b0c45bae055e1998cedbf66aac,Gradient-based Adversarial Factual Consistency Evaluation for Abstractive Summarization,EMNLP,2021,"['Zhiyuan Zeng', 'Jiaze Chen', 'Weiran Xu', 'Lei Li']","Neural abstractive summarization systems have gained significant progress in recent years. However, abstractive summarization often produce inconsisitent statements or false facts. How to automatically generate highly abstract yet factually correct summaries? In this paper, we proposed an efficient weaksupervised adversarial data augmentation approach to form the factual consistency dataset. Based on the artificial dataset, we train an evaluation model that can not only make accurate and robust factual consistency discrimination but is also capable of making interpretable factual errors tracing by backpropagated gradient distribution on token embeddings. Experiments and analysis conduct on public annotated summarization and factual consistency datasets demonstrate our approach effective and reasonable. Our codes can be found at https://github.com/ parZival27/GrAdualCC",The paper proposes a method for generating highly abstract yet factually correct summaries using an efficient weak-supervised adversarial data augmentation approach. The approach forms a factual consistency dataset and trains an evaluation model that can accurately and robustly discriminate factual consistency and trace factual errors. Experiments and analysis on public annotated summarization and factual consistency datasets demonstrate the effectiveness and reasonableness of the approach. The codes for the approach can be found at https://github.com/parZival27/GrAdualCC.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to produce a simplified version of the source document while retaining salient information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of the source document.', 'How will the summaries be used?': 'The summaries can be used to verify the credibility and usability of models, and to make it easier for people to understand the content of the source document.'}","['corpus', 'metric']",[],[],[],[],https://github.com/parZival27/GrAdualCC,https://aclanthology.org/2021.emnlp-main.337,"{'Abstractive summarization methods often trade off abstractiveness with factual consistency, leading to factual errors in generated summaries.': 'The authors propose a weakly supervised factual consistency evaluation model and a gradient-based factual errors tracing strategy to address this problem.', 'Previous approaches for detecting or boosting factual consistency in abstractive summarization focus mainly on factual consistency evaluation.': 'The authors propose a strategy to trace factual errors by explicitly marking out the latent inconsistent tokens in the generated summaries, providing more reliable and interpretable information.', 'Artificial datasets generated by rule-based transformations may oversimplify negative samples, leading to lower model performance and robustness.': ""The authors propose an adversarial data augmentation approach to obtain hard factual inconsistent examples, improving the model's performance and robustness."", 'Fact correction through text generation may increase uncertainty.': 'The authors propose a strategy to trace factual errors based on gradients distribution without adding any parameters, providing stronger interpretability for the factual consistency evaluation results.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:b6121c9d09327c6be34f7ff16389c321d8ac64e0,Fine-grained Factual Consistency Assessment for Abstractive Summarization Models,EMNLP,2021,"['Sen Zhang', 'Jianwei Niu', 'Chuyuan Wei']","Factual inconsistencies existed in the output of abstractive summarization models with original documents are frequently presented. Fact consistency assessment requires the reasoning capability to find subtle clues to identify whether a model-generated summary is consistent with the original document. This paper proposes a fine-grained two-stage Fact Consistency assessment framework for Summarization models (SumFC). Given a document and a summary sentence, in the first stage, SumFC selects the top-K most relevant sentences with the summary sentence from the document. In the second stage, the model performs fine-grained consistency reasoning at the sentence level, and then aggregates all sentences’ consistency scores to obtain the final assessment result. We get the training data pairs by data synthesis and adopt contrastive loss of data pairs to help the model identify subtle cues. Experiment results show that SumFC has made a significant improvement over the previous state-of-the-art methods. Our experiments also indicate that SumFC distinguishes detailed differences better.",System: This paper proposes a framework called SumFC for assessing the factual consistency of abstractive summarization models. SumFC uses a two-stage approach to select relevant sentences and perform fine-grained consistency reasoning at the sentence level. The model is trained using data synthesis and contrastive loss to identify subtle cues. Experimental results show that SumFC outperforms previous methods and can distinguish detailed differences better.,"{'What is the purpose of the summaries?': ""The authors are generating summaries of the documents to obtain a short and fluent text containing the original text's main idea."", 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main idea of a long text.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long texts, but they need to be factually consistent to be useful.'}",['metric'],[],[],[],[],,https://aclanthology.org/2021.emnlp-main.9,"{'Abstractive summarization models generate summaries with frequent factual errors, limiting their practicability.': 'The authors propose a fact consistency assessment framework for summarization models that splits the assessment process into two stages: sentence selection and consistency checking. Top-K pieces of evidence are selected from the original document, and each piece of evidence is reasoned with the summary sentence in detail. SumFC aggregates the results of top-K pieces of evidence to improve factual consistency.', 'Commonly used automatic evaluation metrics in text generation tasks are not capable of evaluating factual errors.': 'The authors propose a fact consistency assessment framework that can detect subtle factual inconsistency automatically for abstractive summarization models.', 'Existing methods for assessing factual consistency can only deal with some obvious factual errors and ignore textual details.': 'The authors propose a fact consistency assessment framework that reasons with each piece of evidence in detail to better distinguish differences between positive and synthesized negative sample pairs.', 'Manual evaluation of factual consistency is time-consuming and costly.': 'The authors propose a fact consistency assessment framework that can automatically assess factual consistency.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:7871a4a6a792c880ae5b6c335b1eca4a0303ada9,A Thorough Evaluation of Task-Specific Pretraining for Summarization,EMNLP,2021,"['Sascha Rothe', 'Joshua Maynez', 'Shashi Narayan']","Task-agnostic pretraining objectives like masked language models or corrupted span prediction are applicable to a wide range of NLP downstream tasks (Raffel et al., 2019), but are outperformed by task-specific pretraining objectives like predicting extracted gap sentences on summarization (Zhang et al., 2020). We compare three summarization specific pretraining objectives with the task agnostic corrupted span prediction pretraining in a controlled study. We also extend our study to a low resource and zero shot setup, to understand how many training examples are needed in order to ablate the task-specific pretraining without quality loss. Our results show that task-agnostic pretraining is sufficient for most cases which hopefully reduces the need for costly task-specific pretraining. We also report new state-of-the-art number for two summarization tasks using a T5 model with 11 billion parameters and an optimal beam search length penalty.","The paper compares task-agnostic pretraining objectives with task-specific pretraining objectives for summarization tasks in a controlled study. The results show that task-agnostic pretraining is sufficient for most cases, reducing the need for costly task-specific pretraining. The study also reports new state-of-the-art numbers for two summarization tasks using a T5 model with 11 billion parameters and an optimal beam search length penalty.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve content selection and achieve better performance on downstream tasks.', 'Who is the target audience?': 'The summaries are for text generation tasks, such as summarization and grammatical error correction.', 'How will the summaries be used?': 'The summaries will be used to refine pretraining methods and improve performance on low-resource and zero-shot setups.'}",['analysis'],[],[],[],[],,https://aclanthology.org/2021.emnlp-main.12,"{'Previous work mostly used task-agnostic pretraining methods, which may not be optimal for downstream tasks.': 'Refine pretraining to a setup that closer resembles the downstream task, such as task-specific priors into BERT language model pretraining, or removing/masking important sentences from an input document to teach summarization models to do better content selection.', 'Raffel et al. (2019) could not match the state of the art results achieved by PEGASUS, even with a much larger model.': 'Set the beam alpha parameter to the optimal value and report new state of the art results on XSum and SAMSum.', 'It is unclear if task-specific pretraining objectives are still at an advantage.': 'Reimplement all experiments in the same framework to avoid any influence of hyperparameters, pretraining datasets, tokenization or evaluation scripts. In a controlled comparison, the authors found that task-agnostic pretraining methods perform as good as task-specific pretraining methods for large finetuning setups.', 'It is unclear how many training examples are needed to ablate the task-specific pretraining without quality loss.': 'Extend the study to a low resource and zero-shot setup to understand this.', 'It is unclear if the findings also translate to other text generation tasks.': 'Pretrain a model with corrupted text and evaluate it on grammatical error correction to see if the findings generalize to other tasks.'}",,['News'],"['controlled-and-tailored-summarization', 'pretraining-and-sample-efficiency']"
SP:1615c6e659703d2eefc42e685963910947de2b4d,On the Abstractiveness of Neural Document Summarization,EMNLP,2018,"['Fangfang Zhang', 'Jin-ge Yao', 'Rui Yan']","Many modern neural document summarization systems based on encoder-decoder networks are designed to produce abstractive summaries. We attempted to verify the degree of abstractiveness of modern neural abstractive summarization systems by calculating overlaps in terms of various types of units. Upon the observation that many abstractive systems tend to be near-extractive in practice, we also implemented a pure copy system, which achieved comparable results as abstractive summarizers while being far more computationally efficient. These findings suggest the possibility for future efforts towards more efficient systems that could better utilize the vocabulary in the original document.","

System: The paper discusses modern neural document summarization systems that aim to produce abstractive summaries. The authors conducted a study to verify the degree of abstractiveness of these systems and found that many tend to be near-extractive in practice. They also implemented a pure copy system that achieved comparable results while being more computationally efficient. The authors suggest that future efforts should focus on developing more efficient systems that can better utilize the vocabulary in the original document.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to succinctly capture the meaning of the document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding lengthy documents.'}",['analysis'],[],[],[],[],,https://aclanthology.org/D18-1089,"{'Automated summarization generally produces extractive summaries by selecting complete sentences from the source document, which may not capture the essence of the document.': 'The authors propose to use modern neural summarization systems based on encoder-decoder networks that aim at producing abstractive summaries. These systems highly rely on the attention mechanism that focuses on different parts of input during the decoding stage.', 'It is unclear to what extent current neural document summarizers are abstractive.': 'The authors conduct a study on the popularly-used CNN / DailyMail news corpora to calculate various types of overlaps between summaries generated by neural abstractive summarizers and the original document. They find that many systems are in fact heavily extracting text spans from input.', 'Automated methods may not generate a wider range of summaries by extracting over sub-sentential units of meaning, such as elementary discourse units (EDUs), from the source documents rather than whole sentences.': 'The authors built on a rather standard pointer-generator system to produce a summarizer that purely copies from input. Limited vocabulary size makes the new summarizer more computationally efficient, without loss of performance.'}",,['News'],[]
SP:eaca92b6013666d4634971f8868a235f0d19d774,Re-evaluating Automatic Summarization with BLEU and 192 Shades of ROUGE,EMNLP,2015,['Yvette Graham'],"We provide an analysis of current evaluation methodologies applied to summarization metrics and identify the following areas of concern: (1) movement away from evaluation by correlation with human assessment; (2) omission of important components of human assessment from evaluations, in addition to large numbers of metric variants; (3) absence of methods of significance testing improvements over a baseline. We outline an evaluation methodology that overcomes all such challenges, providing the first method of significance testing suitable for evaluation of summarization metrics. Our evaluation reveals for the first time which metric variants significantly outperform others, optimal metric variants distinct from current recommended best variants, as well as machine translation metric BLEU to have performance on-par with ROUGE for the purpose of evaluation of summarization systems. We subsequently replicate a recent large-scale evaluation that relied on, what we now know to be, suboptimal ROUGE variants revealing distinct conclusions about the relative performance of state-of-the-art summarization systems.",The paper analyzes current evaluation methodologies for summarization metrics and identifies concerns such as the absence of methods for testing improvements over a baseline and the omission of important components of human assessment. The authors propose an evaluation methodology that overcomes these challenges and reveals which metric variants outperform others. They also find that the machine translation metric BLEU performs similarly to ROUGE for evaluating summarization systems. The authors replicate a recent evaluation that relied on suboptimal ROUGE variants and find different conclusions about the relative performance of state-of-the-art summarization systems.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific papers to evaluate the performance of summarization metrics.', 'Who is the target audience?': 'The summaries are for evaluating the performance of automatic summarization metrics.', 'How will the summaries be used?': 'The summaries will be used to draw conclusions about the relative performance of state-of-the-art summarization systems.'}",['analysis'],[],[],[],[],https://github.com/ygraham/nlp-williams,https://aclanthology.org/D15-1013/,"{'Summarization evaluation has diverged considerably from methodologies applied to evaluation of metrics in machine translation (MT).': 'The authors review past and current methodologies applied to the evaluation of summarization metrics and revisit evaluation methodologies applied to one particular area of summarization, evaluation of metrics.', 'Previous summarization metric evaluations have been limited by inclusion of only a small proportion of possible metrics and variants.': 'The authors highlight the disadvantage of omitting superior variants and evaluate all variants of ROUGE to identify the optimal choice of ROUGE variant in system evaluations.', 'Attempts to identify significant differences in performance of metrics in summarization evaluation are extremely rare and have not used an appropriate test.': 'The authors use appropriate statistical significance testing to identify significant differences in performance of metrics in summarization evaluation.', 'It is assumed that recommended ROUGE variants are optimal and conclusions about the relative performance of systems are drawn based on this assumption.': 'The authors show that distinct variants of ROUGE achieve significantly stronger correlation with human assessment than previous recommended best variants and replicate a recent evaluation of state-of-the-art summarization systems revealing distinct conclusions about the relative performance of systems.', 'There is a common belief that recall-based ROUGE is superior to precision-based BLEU for evaluation of summarization systems.': 'The authors include an evaluation of BLEU for the purpose of summarization evaluation and show that precision-based BLEU is on-par with recall-based ROUGE for evaluation of summarization systems.'}",,['News'],['robust-evaluation-methods']
SP:1706429c801f1591cad7f9045b35c38c0cd72376,The limits of automatic summarisation according to ROUGE,EACL,2017,['Natalie Schluter'],"This paper discusses some central caveats of summarisation, incurred in the use of the ROUGE metric for evaluation, with respect to optimal solutions. The task is NPhard, of which we give the first proof. Still, as we show empirically for three central benchmark datasets for the task, greedy algorithms empirically seem to perform optimally according to the metric. Additionally, overall quality assurance is problematic: there is no natural upper bound on the quality of summarisation systems, and even humans are excluded from performing optimal summarisation.","

System: This paper highlights the limitations of using the ROUGE metric for evaluating summarization systems, particularly in terms of optimal solutions. The authors provide the first proof that the task of summarization is NPhard. However, they also demonstrate that greedy algorithms perform well on three benchmark datasets. The paper also points out the difficulty in ensuring overall quality assurance, as there is no natural upper bound on the quality of summarization systems and even humans cannot achieve optimal summarization.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to evaluate the performance of automatic summarization algorithms.', 'Who is the target audience?': 'The summaries are for researchers and developers working on automatic summarization algorithms.', 'How will the summaries be used?': 'The summaries will be used to assess the effectiveness of different summarization algorithms and to compare their performance against each other.'}",['analysis'],[],[],[],[],,https://aclanthology.org/E17-2007/,"{'Perfect scores for extractive summarisation are theoretically computationally hard to achieve.': 'The authors provide the first proof of NP-hardness for optimization of extractive summarization with respect to ROUGE. Yet empirically the metric shows that greedy and exact global decoding method performances are similar.', '100% perfect scores are impossible for higher quality datasets.': 'The metric returns an average of ROUGE scores over multiple reference summaries in order to avoid bias. This means that it is impossible to obtain 100% ROUGE-n scores unless the reference summaries contain precisely the same n-grams.', 'Relative perfect scores are highly diverse and unattainable by humans.': 'The authors demonstrate that there is no possible relative perfect score, even if one has access to the sentences of the reference summaries. So, for example, even humans are doomed to perform sub-optimally.', 'State-of-the-art automatic summarization is unsupervised.': 'The authors observe that ICSISum is the only global summarizer using an exact algorithm and obtaining the best ROUGE-2 score without supervision. All the other approaches use greedy strategies/approximations, even if they intend to model global optimization. The authors raise the question of whether supervision gives substantial system performance improvement if one shifts from a greedy strategy to an exact global one.'}",,['News'],['robust-evaluation-methods']
SP:b237d50a499e282e5b0cb72c53288a4d705efaaf,Reference-free Summarization Evaluation via Semantic Correlation and Compression Ratio,NAACL,2022,"['Yizhu Liu', 'Qi Jia', 'Kenny Q. Zhu']","A document can be summarized in a number of ways. Reference-based evaluation of summarization has been criticized for its inflexibility. In this paper, we propose a new automatic reference-free evaluation metric that compares semantic distribution between source document and summary by pretrained language models and considers summary compression ratio. The experiments show that this metric is more consistent with human evaluation in terms of coherence, consistency, relevance, fluency.","

System: The paper proposes a new automatic reference-free evaluation metric for summarization that compares semantic distribution between source document and summary by pretrained language models and considers summary compression ratio. The experiments show that this metric is more consistent with human evaluation in terms of coherence, consistency, relevance, and fluency.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to evaluate the quality of summarization systems.', 'Who is the target audience?': 'The summaries are for evaluating the performance of summarization systems.', 'How will the summaries be used?': 'The summaries will be used to develop and improve summarization systems.'}",['metric'],[],[],[],[],https://github.com/YizhuLiu/summeval,https://aclanthology.org/2022.naacl-main.153,"{'Previous summarization evaluation metrics require human-annotated summaries as reference and cannot accurately evaluate the summary due to the variety of correct summaries and the difficulty and expense of writing many reference summaries.': 'The authors propose a reference-free evaluation metric (SDC*) that considers semantic distribution correlation and compression ratio between source document and summary.', 'Some reference-free evaluation metrics unsupervisedly construct a pseudo-reference summary by selecting salient sentences from the source document, which also ignore the variety of summaries.': 'The authors propose a new evaluation metric (SDC*) that takes into account the position and importance of tokens in the document by computing the correlation between the probability distribution of tokens in predicted documents with and without a prepended summary.', 'QA-based evaluation metrics achieve the possibility of evaluating summary quality by measuring how much information from the document is represented in the summary, but their performance depends on the quality of question generation and question-answering systems.': 'The authors propose a new evaluation metric (SDC*) that does not rely on question generation and question-answering systems.', 'Shannon score, the state-of-the-art summarization evaluation metric, cannot reflect the position and importance of each token in the document, which impacts coherence and salient information.': 'The authors propose a new evaluation metric (SDC*) that takes into account the position and importance of tokens in the document by computing the correlation between the probability distribution of tokens in predicted documents with and without a prepended summary. They also introduce compression ratio into SDC (SDC*) and penalize the long summary.'}",,['News'],['robust-evaluation-methods']
SP:ff891a71d59f5732e013808f946977754a2c4204,Rank-Aware Gain-Based Evaluation of Extractive Summarization,CIKM,2022,['Mousumi Akter'],"ROUGE has long been a popular metric for evaluating text summarization tasks as it eliminates time-consuming and costly human evaluations. However, ROUGE is not a fair evaluation metric for extractive summarization task as it is entirely based on lexical overlap. Additionally, ROUGE ignores the quality of the ranker for extractive summarization which performs the actual sentence/phrase extraction job. The main focus of the thesis is to design a nCG (normalized cumulative gain)-based evaluation metric for extractive summarization that is both rank-aware and semantic-aware (called Sem-nCG). One fundamental contribution of the work is that it demonstrates how we can generate more reliable semantic-aware ground truths for evaluating extractive summarization tasks without any additional human intervention. To the best of our knowledge, this work is the first of its kind. Preliminary experimental results demonstrate that the new Sem-nCG metric is indeed semantic-aware and also exhibits higher correlation with human judgement for single document summarization when single reference is considered.","The paper discusses the limitations of the ROUGE metric for evaluating extractive summarization tasks and proposes a new evaluation metric called Sem-nCG, which is both rank-aware and semantic-aware. The paper also demonstrates how to generate more reliable semantic-aware ground truths for evaluating extractive summarization tasks without additional human intervention. Preliminary experimental results show that the Sem-nCG metric is semantic-aware and has a higher correlation with human judgement for single document summarization when a single reference is considered.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for extractive summarization tasks.', 'Who is the target audience?': 'The summaries are for evaluating the performance of extractive summarization models.', 'How will the summaries be used?': 'The summaries will be used to compare the performance of different extractive summarization models using the proposed Sem-nCG evaluation metric.'}",['metric'],[],[],[],[],,https://doi.org/10.1145/3511808.3557821,"{'ROUGE does not take semantics into consideration and instead relies solely on the direct lexical overlap between the model summary and the reference summary (typically written by humans).': 'The authors propose an alternative gain-based evaluation metric called Sem-nCG for evaluating extractive summarization tasks, which is both semantic-aware and rewards a system summary based on some groundtruth ranking of sentences from the original document.', 'Evaluation of extractive summaries using ROUGE is problematic because, whereas extractive summaries contain words directly taken from the source document, a human reference may contain different words.': 'The authors propose using Sem-nCG, which creates semantic-aware groundtruth rankings of sentences within a source document without further human involvement, to address this limitation.', 'ROUGE has no way to evaluate the quality of a ranker, while at its core, extractive summarization is essentially a ranking task.': 'The authors propose using Sem-nCG, which rewards a system summary based on some groundtruth ranking of sentences from the original document, to evaluate the quality of a ranker.', 'There is a lack of reliable semantic-aware groundtruth rankings of sentences within a source document without further human assistance.': 'The authors propose using several state-of-the-art sentence embedding techniques to prepare groundtruth rankings of sentences from the original document by computing the semantic similarity between each individual sentence of the original document and the entire human written summary, to automatically create a reliable semantic-aware groundtruth rankings of sentences within a source document without further human assistance.', 'ROUGE often provides inaccurate conclusions.': 'The authors propose using Sem-nCG, which yields a significant number of conflicts with the original ROUGE metric, indicating that Sem-nCG is more accurate than ROUGE when cross-examined by humans.'}",,['News'],['robust-evaluation-methods']
SP:e2b33353950597b546d403c837508eb5bb73108f,GO FIGURE: A Meta Evaluation of Factuality in Summarization,ACL,2021,"['Saadia Gabriel', 'Asli Celikyilmaz', 'Rahul Jha', 'Yejin Choi', 'Jianfeng Gao', '♣ ♠Paul', 'G. Allen']","While neural language models can generate text with remarkable fluency and coherence, controlling for factual correctness in generation remains an open research question. This major discrepancy between the surface-level fluency and the content-level correctness of neural generation has motivated a new line of research that seeks automatic metrics for evaluating the factuality of machine text. In this paper, we introduce GO FIGURE, a metaevaluation framework for evaluating factuality evaluation metrics. We propose five necessary conditions to evaluate factuality metrics on diagnostic factuality data across three different summarization tasks. Our benchmark analysis on ten factuality metrics reveals that our metaevaluation framework provides a robust and efficient evaluation that is extensible to multiple types of factual consistency and standard generation metrics, including QA metrics. It also reveals that while QA metrics generally improve over standard metrics that measure factuality across domains, performance is highly dependent on the way in which questions are generated.","The paper discusses the challenge of ensuring factual correctness in machine-generated text and introduces a metaevaluation framework called GO FIGURE for evaluating factuality evaluation metrics. The framework proposes five necessary conditions for evaluating factuality metrics on diagnostic factuality data across three different summarization tasks. The benchmark analysis on ten factuality metrics shows that the framework provides a robust and efficient evaluation that is extensible to multiple types of factual consistency and standard generation metrics, including QA metrics. However, the performance of QA metrics is highly dependent on the way in which questions are generated.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the quality of text generation systems by reducing factual inconsistencies.', 'Who is the target audience?': 'The summaries are for text generation systems that aim to produce fluent, coherent, relevant, and factually correct text.', 'How will the summaries be used?': 'The summaries will be used to evaluate the effectiveness of factuality metrics across multiple domains, including extreme summarization, multi-sentence news summarization, and dialogue summarization.'}",['metric'],[],[],[],[],,https://aclanthology.org/2021.findings-acl.42,"{'Text generation systems can yield factually inconsistent text, caused by distorted or fabricated facts about the source text.': 'The authors propose a metaevaluation framework called GO FIGURE to assess the effectiveness of factuality metrics across multiple domains, including extreme summarization, multi-sentence news summarization, and dialogue summarization.', 'Commonly used metrics for measuring quality of generated text fail to capture structural aspects of language like negation and poorly correlate with human judgements.': 'The authors propose a set of diagnostics for measuring sensitivity of metrics to factual inconsistency and a diagnostic evaluation dataset of context/summary pairs for measuring the effectiveness of new factuality metrics in a controlled setting.', 'Models that abstract away salient aspects in document summarization tasks have been shown to generate text with up to 30% factual inconsistencies.': 'The authors provide an evaluation dataset of summaries generated by transformer-based models annotated with types of factual errors.'}",,"['News', 'Dialog']","['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:ad1b076c6e7ac214a8c7c7a5e54b14e0dc18f109,Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics,NAACL,2021,"['Artidoro Pagnoni', 'Vidhisha Balachandran', 'Yulia Tsvetkov']","Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights on the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations we identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgement as well as their specific strengths and weaknesses.1","The paper discusses the issue of factually unreliable outputs generated by modern summarization models and the lack of common benchmarks to measure their factuality. To address this, the authors devise a typology of factual errors and collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. They identify the proportion of different categories of factual errors in various summarization models and benchmark factuality metrics, showing their correlation with human judgement and specific strengths and weaknesses.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to ensure that summarization systems are factually consistent and to develop methods for evaluating them.', 'Who is the target audience?': 'The summaries are for information consumption.', 'How will the summaries be used?': ""The summaries will be used to assess the factuality of summarization systems and benchmark recently proposed factuality metrics. They will also be used to evaluate multiple summarization metrics against the authors' benchmark and show their strengths and weaknesses in detecting specific types of factual errors.""}","['corpus', 'metric']",[],[],[],[],https://github.com/artidoro/frank,https://aclanthology.org/2021.naacl-main.383/,"{'Common evaluation metrics for summarization based on n-gram overlap – BLEU, ROUGE, and METEOR – are insufficient to measure the factual correctness of summaries and fail to correlate with the human judgements of factuality.': 'The authors propose developing methods for evaluating summarization systems that are factually consistent and benchmarking recently proposed factuality metrics.', 'Approaches that model factuality as a binary concept do not provide any fine-grained understanding of the factual errors made by different systems that could serve as an actionable feedback on a system’s limitations.': 'The authors propose a linguistically motivated typology of factual errors for fine-grained analysis of factuality in summarization systems that provides some measure of the degree of non-factuality both in terms of the quantity and the category of factual violations that appear in the text.', 'The binary factuality of a text can be difficult to determine, and not all factual errors are equally important.': 'The authors propose modeling non-factuality as a multidimensional construct and not a label, and decomposing the concept of factuality into well-defined and grounded categories to make the final binary decision more objective.', 'There is a lack of common benchmarks for evaluating recently proposed factuality metrics.': 'The authors propose collecting a dataset of human judgements over a diverse set of model generated summaries on the CNN/DM and XSum datasets to assess the factuality of summarization systems and benchmark recently proposed factuality metrics.', 'There is a need to gain deeper insights into the types of errors made by summarization systems.': 'The authors propose using their typology of factual errors to categorize the types of errors made by summarization systems and gain deeper insights than simply categorizing content as factual or hallucinated.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:131d53a4f6e124dac3af371c35b1f7107efa01b8,Does Pretraining for Summarization Require Knowledge Transfer?,EMNLP,2021,"['Kundan Krishna', 'Jeffrey Bigham', 'Zachary C. Lipton']","Pretraining techniques leveraging enormous datasets have driven recent advances in text summarization. While folk explanations suggest that knowledge transfer accounts for pretraining’s benefits, little is known about why it works or what makes a pretraining task or dataset suitable. In this paper, we challenge the knowledge transfer story, showing that pretraining on documents consisting of character n-grams selected at random, we can nearly match the performance of models pretrained on real corpora. This work holds the promise of eliminating upstream corpora, which may alleviate some concerns over offensive language, bias, and copyright issues. To see whether the small residual benefit of using real data could be accounted for by the structure of the pretraining task, we design several tasks motivated by a qualitative study of summarization corpora. However, these tasks confer no appreciable benefit, leaving open the possibility of a small role for knowledge transfer.1","The paper discusses pretraining techniques in text summarization and challenges the idea that knowledge transfer is the reason for its success. The authors show that pretraining on randomly selected character n-grams can achieve similar performance to models pretrained on real corpora, which could eliminate concerns over offensive language, bias, and copyright issues. The authors also design several tasks to test the structure of pretraining tasks, but find no significant benefit, leaving the possibility of a small role for knowledge transfer.","{'What is the purpose of the summaries?': 'The authors are investigating the benefits of pretraining models for summarization tasks.', 'Who is the target audience?': 'The summaries are not intended for any specific audience.', 'How will the summaries be used?': 'The summaries are used to evaluate the performance of pretraining models on downstream summarization benchmarks.'}",['analysis'],[],[],[],[],https://github.com/acmi-lab/pretraining-with-nonsense,https://aclanthology.org/2021.findings-emnlp.273,"{'The scientific explanations for the benefits of pretrained models in downstream NLP tasks remain unknown.': 'The authors challenge the popular hypothesis that credits knowledge transfer for the improvements seen on downstream tasks by showing that pretraining objectives previously demonstrated to be helpful for summarization continue to deliver significant benefits even when applied on text consisting of randomly sampled nonsense words.', 'The benefits of pretraining have been observed even when the upstream text has no syntactic structure or is from a different domain entirely, making it difficult to argue that the synthetic corpus encodes linguistic knowledge in any relevant sense.': 'The authors investigate whether a pretraining task better aligned with the demands of summarization might close this residual gap by designing a collection of pretraining tasks inspired by some of the basic primitive operations that appear to be common routines required in order to create real-world summaries.', 'Using real data offers no benefit over the nonsense data when pretraining with synthetic tasks on multiple summarization benchmarks.': 'The authors propose that a large portion of the benefits seen may not be due to any knowledge transfer, but simply better initialization from an optimization perspective.', 'Using webscale pretraining corpora of unknown provenance raises concerns regarding bias, offensive speech, and intellectual property.': 'The ability to realize the benefits of pretraining without using real-world data could alleviate these concerns.'}",,"['News', 'Reviews']","['lack-of-suitable-training-data', 'pretraining-and-sample-efficiency']"
SP:d05327de6678763e917645a86eb51d4a7a670207,Play the Shannon Game With Language Models: A Human-Free Approach to Summary Evaluation,AAAI,2022,"['Nicholas Egan', 'Oleg Vasilyev', 'John Bohannon']","The goal of a summary is to concisely state the most important information in a document. With this principle in mind, we introduce new reference-free summary evaluation metrics that use a pretrained language model to estimate the information content shared between a document and its summary. These metrics are a modern take on the Shannon Game, a method for summary quality scoring proposed decades ago, where we replace human annotators with language models. We also view these metrics as an extension of BLANC, a recently proposed approach to summary quality measurement based on the performance of a language model with and without the help of a summary. Using transformer based language models, we empirically verify that our metrics achieve stateof-the-art correlation with human judgement of the summary quality dimensions of both coherence and relevance, as well as competitive correlation with human judgement of consistency and fluency.","The paper introduces new reference-free summary evaluation metrics that use a pretrained language model to estimate the information content shared between a document and its summary. These metrics are a modern take on the Shannon Game and an extension of BLANC. The authors empirically verify that their metrics achieve state-of-the-art correlation with human judgement of the summary quality dimensions of coherence and relevance, as well as competitive correlation with human judgement of consistency and fluency.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to measure summary quality and evaluate the performance of summarization algorithms.', 'Who is the target audience?': 'The summaries are for evaluating the quality of summarization algorithms in the NLP community.', 'How will the summaries be used?': 'The summaries will be used to determine the most reliable metrics for measuring summary quality and to evaluate the empirical performance of the proposed summarization evaluation metric, the Shannon Score.'}",['metric'],[],[],[],[],,https://ojs.aaai.org/index.php/AAAI/article/view/21304,"{'The most popular method for summary quality estimation, ROUGE, requires human written reference summaries for comparison and measures summary quality through simple token overlap, ignoring the syntax and semantics governing the way humans use language.': 'The authors propose a new summarization evaluation metric, the Shannon Score, that performs the Shannon Game with a language model such as GPT-2. By using a language model to autoregressively generate a document both with and without a summary as a prompt, they measure the information provided by the summary.', 'There is a need to determine summary quality by measuring how much information from the document is represented in the summary.': 'The authors propose measuring the difference in information content between the document and the summary, which was originally proposed as the Shannon Game by Hovy and Lin.', 'There is a lack of theoretically driven extension to the recently proposed BLANC metric, which measures the accuracy of unmasking document tokens with and without a summary.': 'The authors propose the Shannon Score as a more theoretically driven extension to the BLANC metric.', 'There is a need to understand the empirical performance of the proposed method as a summary evaluation technique.': 'The authors performed experiments to correlate their metrics against human judgement and found that their metrics perform strongly on the SummEval benchmark, achieving state-of-the-art correlation with human judgement of summary coherence and relevance, and competitive correlation with human judgement of summary consistency and fluency.'}",,['News'],['robust-evaluation-methods']
SP:ca3306bd7df84bce92501882258ed91974111101,Revisiting Automatic Evaluation of Extractive Summarization Task: Can We Do Better than ROUGE?,ACL,2022,"['Mousumi Akter', 'Naman Bansal', 'Shubhra Kanti Karmaker']","It has been the norm for a long time to evaluate automated summarization tasks using the popular ROUGE metric. Although several studies in the past have highlighted the limitations of ROUGE, researchers have struggled to reach a consensus on a better alternative until today. One major limitation of the traditional ROUGE metric is the lack of semantic understanding (relies on direct overlap of n-grams). In this paper, we exclusively focus on the extractive summarization task and propose a semantic-aware nCG (normalized cumulative gain)-based evaluation metric (called Sem-nCG) for evaluating this task. One fundamental contribution of the paper is that it demonstrates how we can generate more reliable semantic-aware ground truths for evaluating extractive summarization tasks without any additional human intervention. To the best of our knowledge, this work is the first of its kind. We have conducted extensive experiments with this new metric using the widely used CNN/DailyMail dataset. Experimental results show that the new Sem-nCG metric is indeed semantic-aware, shows higher correlation with human judgement (more reliable) and yields a large number of disagreements with the original ROUGE metric (suggesting that ROUGE often leads to inaccurate conclusions also verified by humans).",The paper discusses the limitations of the traditional ROUGE metric for evaluating automated summarization tasks and proposes a semantic-aware nCG-based evaluation metric called Sem-nCG. The paper demonstrates how to generate more reliable semantic-aware ground truths for evaluating extractive summarization tasks without additional human intervention. The authors conducted extensive experiments using the CNN/DailyMail dataset and found that Sem-nCG is more reliable and shows higher correlation with human judgement than ROUGE. The paper suggests that ROUGE often leads to inaccurate conclusions and Sem-nCG is a better alternative for evaluating extractive summarization tasks.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the performance of extractive summarization models.', 'Who is the target audience?': 'The summaries are for large-scale experiments as a replacement for time-consuming and pricey human evaluation.', 'How will the summaries be used?': 'The summaries will be used to evaluate the reliability and robustness of automatic evaluation metrics for extractive summarization tasks.'}",['metric'],[],[],[],[],,https://aclanthology.org/2022.findings-acl.122,"{'The most commonly used metric for evaluating text summarization is ROUGE, which has been criticized for not being semantic-aware.': 'The authors propose an alternative gain-based evaluation metric called Sem-nCG, which is semantic-aware and rewards a system-generated summary based on some groundtruth ranking of sentences from the original document.', 'The ROUGE metric was not originally proposed for evaluating the quality of a ranker, which is a crucial aspect of extractive summarization.': 'The Sem-nCG metric considers the quality of the sentence ranker by comparing the groundtruth ranking of sentences within a source document to the model-inferred ranking.', 'A human-written summary that is highly abstractive in nature may still suffer from low ROUGE scores due to fewer direct lexical overlaps between the system summary and human-written summary.': 'The Sem-nCG metric addresses this limitation by using several state-of-the-art sentence embedding techniques to compute semantic similarity between each individual sentence of the original document and the entire human-written summary.', 'Automatic evaluation of text summarization is challenging and often unreliable, which is a problem for large-scale experiments.': 'The Sem-nCG metric enables automatic evaluation without additional human intervention by automatically generating a reliable semantic-aware groundtruth ranking of sentences within a source document.'}",,['News'],['robust-evaluation-methods']
SP:acc2915b8eb5178e8d60041781d03a0cb4a9427d,Learning to Score System Summaries for Better Content Selection Evaluation,EMNLP,2017,"['Maxime Peyrard', 'Teresa Botschen', 'Iryna Gurevych']","The evaluation of summaries is a challenging but crucial task of the summarization field. In this work, we propose to learn an automatic scoring metric based on the human judgements available as part of classical summarization datasets like TAC-2008 and TAC-2009. Any existing automatic scoring metrics can be included as features, the model learns the combination exhibiting the best correlation with human judgments. The reliability of the new metric is tested in a further manual evaluation where we ask humans to evaluate summaries covering the whole scoring spectrum of the metric. We release the trained metric as an open-source tool.","System: The paper proposes a new automatic scoring metric for evaluating summaries, based on human judgments from classical summarization datasets. The model learns the best combination of existing automatic scoring metrics that correlates with human judgments. The reliability of the new metric is tested through a manual evaluation, and the trained metric is released as an open-source tool.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to convert source documents into a condensed text containing the most important information.', 'Who is the target audience?': 'The summaries are for automatic multi-document summarization systems.', 'How will the summaries be used?': 'The summaries will be used to evaluate the performance of automatic multi-document summarization systems.'}",['metric'],[],[],[],[],https://github.com/UKPLab/emnlp-ws-2017-s3,https://aclanthology.org/W17-4510/,"{'The lack of a gold standard for evaluating automatic multi-document summarization.': 'Manual evaluation by involving humans in the process of scoring a given system summary using metrics such as Responsiveness and Pyramid scheme. However, manual evaluations are expensive and not reproducible, so there is a need for cheap and reproducible metrics.', 'The need for cheap and reproducible metrics for evaluating automatic multi-document summarization.': 'The study of automatic evaluation metrics that aim to produce a semantic similarity score between the candidate summary and a pool of reference summaries previously written by human annotators. Some variants rely only on the source documents and the candidate summary ignoring the reference summaries.', 'The difficulty in selecting the best automatic metric for evaluating automatic multi-document summarization.': 'Consider manual evaluation metrics as the gold standard and select an automatic metric that reliably predicts how well a summarizer would perform if human evaluation was conducted. Use human judgment datasets like the ones constructed during the manual evaluation of the Text Analysis Conference (TAC) to evaluate the performance of automatic metrics.', 'The need for more consistent metrics correlating well with humans on every topic and capable of estimating the quality of individual summaries (not just systems).': 'Rely on human judgment datasets to learn an automatic scoring metric that exhibits high correlation with human judgments at the summary level. Incorporate any already existing automatic metric as a feature and learn the best combination of features matching human judgments.', 'The reliability of the learned metric.': 'Conduct a manual evaluation specifically designed to test the metric across its whole scoring spectrum.'}",,['News'],['robust-evaluation-methods']
SP:9d95d80871ee44ce821ef6dc965217925cc89a9f,Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports,ACL,2020,"['Yuhao Zhang', 'Derek Merck', 'Emily Bao Tsai', 'Christopher D. Manning', 'Curtis P. Langlotz']","Neural abstractive summarization models are able to generate summaries which have high overlap with human references. However, existing models are not optimized for factual correctness, a critical metric in real-world applications. In this work, we develop a general framework where we evaluate the factual correctness of a generated summary by factchecking it automatically against its reference using an information extraction module. We further propose a training strategy which optimizes a neural summarization model with a factual correctness reward via reinforcement learning. We apply the proposed method to the summarization of radiology reports, where factual correctness is a key requirement. On two separate datasets collected from hospitals, we show via both automatic and human evaluation that the proposed approach substantially improves the factual correctness and overall quality of outputs over a competitive neural summarization system, producing radiology summaries that approach the quality of humanauthored ones.","The paper discusses the limitations of existing neural abstractive summarization models in terms of factual correctness and proposes a framework to evaluate and optimize the factual correctness of generated summaries using an information extraction module and reinforcement learning. The proposed method is applied to the summarization of radiology reports, where factual correctness is crucial, and is shown to substantially improve the quality of outputs over a competitive neural summarization system, approaching the quality of human-authored summaries.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress the information while preserving the key facts in it.', 'Who is the target audience?': 'The summaries are potentially useful in many real-world applications, such as in the medical field, where they can accelerate the workflow, reduce repetitive human labor, and improve clinical communications.', 'How will the summaries be used?': ""The summaries will be used to provide a quick and concise overview of the document's content, with a focus on summarizing radiology reports. The authors aim to optimize the factual correctness of the summaries to prevent medical errors and improve clinical validity.""}",['metric'],[],[],[],[],https://github.com/yuhaozhang/summarize-radiology-findings,https://aclanthology.org/2020.acl-main.458,"{'Existing abstractive summarization models are optimized to generate summaries that highly overlap with human references, but this does not guarantee factually correct summaries.': 'The authors aim to optimize the factual correctness of existing neural summarization systems by designing a framework where an external information extraction system is used to extract information in the generated summary and produce a factual accuracy score by comparing it against the human reference summary.', 'Despite existing attempts at improving the factual correctness of abstractive summarization models, none of the existing work has focused explicitly on optimizing an abstractive summarization system with a correctness objective.': 'The authors develop a training strategy where they combine a factual correctness objective, a textual overlap objective, and a language model objective, and jointly optimize them via reinforcement learning (RL).', 'State-of-the-art systems trained with ample data still produce summaries with a substantial number of factual errors.': 'The authors apply their proposed training strategy to radiology reports and show that it substantially improves the factual correctness of the summaries generated by a competitive neural summarization system. They also observe that optimizing a textual overlap-based metric substantially improves the factual correctness of the resulting system compared to maximum likelihood training.', 'Factual correctness is a crucial metric in the radiology domain, and improving factual correctness will directly lead to an ability to use the system.': 'The authors demonstrate via human evaluation and analysis that their training strategy leads to summaries with higher overall quality and correctness and which are closer to the human-written ones. They also show that their system is able to generate summaries with clinical validity close to human-written ones.'}",,['Medical Reports'],['hallucinations-in-the-generated-summaries']
SP:01e3fad81bc7fd2529b6c7b76bf2b971ec7fb759,Masked Summarization to Generate Factually Inconsistent Summaries for Improved Factual Consistency Checking,NAACL,2022,"['Hwanhee Lee', 'Kang Min Yoo', 'Joonsuk Park', 'Hwaran Lee', 'Kyomin Jung']","Despite the recent advances in abstractive summarization systems, it is still difficult to determine whether a generated summary is factual consistent with the source text. To this end, the latest approach is to train a factual consistency classifier on factually consistent and inconsistent summaries. Luckily, the former is readily available as reference summaries in existing summarization datasets. However, generating the latter remains a challenge, as they need to be factually inconsistent, yet closely relevant to the source text to be effective. In this paper, we propose to generate factually inconsistent summaries using source texts and reference summaries with key information masked. Experiments on seven benchmark datasets demonstrate that factual consistency classifiers trained on summaries generated using our method generally outperform existing models and show a competitive correlation with human judgments. We also analyze the characteristics of the summaries generated using our method. We will release the pre-trained model and the code at https:// github.com/hwanheelee1993/MFMA.","The paper discusses the challenge of determining whether a generated summary is factually consistent with the source text, despite recent advances in abstractive summarization systems. The latest approach is to train a factual consistency classifier on factually consistent and inconsistent summaries, with the former readily available as reference summaries in existing summarization datasets. However, generating factually inconsistent summaries that are closely relevant to the source text remains a challenge. The paper proposes a method of generating such summaries using source texts and reference summaries with key information masked. Experiments on seven benchmark datasets demonstrate that factual consistency classifiers trained on summaries generated using this method generally outperform existing models and show a competitive correlation with human judgments. The characteristics of the summaries generated using this method are also analyzed, and a pre-trained model and code will be released.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents because as textual content available on- and offline explodes, automated text summarization is becoming increasingly crucial.', 'Who is the target audience?': 'The summaries are for automated text summarization systems that generate paraphrases.', 'How will the summaries be used?': 'The summaries will be used to train factual consistency classifiers for abstractive summaries.'}",['metric'],[],[],[],[],https://github.com/hwanheelee1993/MFMA,https://aclanthology.org/2022.findings-naacl.76,"{'Existing approaches to identify factual inconsistency in abstractive summaries have not been satisfactory.': 'Train a factual consistency classifier with a dataset specifically constructed for this purpose, using positive summaries that are assumed to be factually consistent and negative summaries that are factually inconsistent.', 'Generating effective negative summaries that are factually inconsistent with the source text is challenging.': 'Propose a novel method called Masked-and-Fill with Masked Article (MFMA), where parts of the source text and reference summary are masked and later inferred to generate a plausible but factually inconsistent summary.', 'Existing methods for generating negative summaries result in summaries that significantly diverge from the source texts and positive summaries, which is not ideal for training factual consistency classifiers.': 'Use the MFMA method to generate negative summaries that are more plausible and closer to the source text.', 'The characteristics of the negative summaries generated using the MFMA method are unknown.': 'Analyze the characteristics, such as affinity and diversity, of the negative summaries generated using the MFMA method.', 'The proposed method needs to be evaluated on benchmark datasets.': 'Conduct experiments on seven benchmark datasets to demonstrate the efficacy of the proposed method in terms of classification performance and correlation with human judgment.'}",,['News'],"['hallucinations-in-the-generated-summaries', 'robust-evaluation-methods']"
SP:b802dec282b3a9c9e6919c0c580c0af5eb491957,Readability Controllable Biomedical Document Summarization,EMNLP,2022,"['Zheheng Luo', 'Qianqian Xie', 'Sophia Ananiadou']","Different from general documents, it is recognised that the ease with which people can understand a biomedical text is eminently varied, owing to the highly technical nature of biomedical documents and the variance of readers’ domain knowledge. However, existing biomedical document summarization systems have paid little attention to readability control, leaving users with summaries that are incompatible with their levels of expertise. In recognition of this urgent demand, we introduce a new task of readability controllable summarization for biomedical documents, which aims to recognise users’ readability demands and generate summaries that better suit their needs: technical summaries for experts and plain language summaries (PLS) for laypeople. To establish this task, we construct a corpus consisting of biomedical papers with technical summaries and PLSs written by the authors, and benchmark multiple advanced controllable abstractive and extractive summarization models based on pre-trained language models (PLMs) with prevalent controlling and generation techniques. Moreover, we propose a novel masked language model (MLM) based metric and its variant to effectively evaluate the readability discrepancy between lay and technical summaries. Experimental results from automated and human evaluations show that though current control techniques allow for a certain degree of readability adjustment during generation, the performance of existing controllable summarization methods is far from desirable in this task.","The paper discusses the need for readability controllable summarization for biomedical documents, as existing summarization systems do not consider the varying levels of expertise of readers. The authors introduce a new task of generating technical summaries for experts and plain language summaries for laypeople, and construct a corpus of biomedical papers with both types of summaries. They benchmark multiple advanced summarization models and propose a novel metric to evaluate the readability discrepancy between the two types of summaries. The results show that current control techniques are not effective in generating suitable summaries for different levels of expertise.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide an efficient way for readers to acquire desirable biomedical information quickly.', 'Who is the target audience?': 'The summaries are for both non-experts and professionals who seek textual information on different readability levels, since the variance of their biomedical knowledge affects their ease of understanding biomedical papers.', 'How will the summaries be used?': 'The summaries will be used to improve the dissemination of scientific information by generating compatible summaries for various users according to their levels of expertise and needs.'}","['corpus', 'method']",['Controlled Generation'],['PLOS PLS'],['ROUGE'],"['Readability', 'Relevance', 'Coherence', 'Grammaticality']",http://www.nactem.ac.uk/readability/,https://aclanthology.org/2022.findings-emnlp.343/,"{'Current biomedical summarization systems fail to generate compatible summaries for various users according to their levels of expertise without considering the readability as an aspect to be controlled during summary generation.': 'The authors propose a novel task of readability controllable biomedical document summarization, which is to automatically recognize users’ readability demands and generate summaries that are compatible with their expertise level and needs.', 'The task of readability controllable biomedical document summarization is challenging since it requires the model to accurately recognize different readability demands from limited guiding signals.': 'The authors build the first corpus consisting of 28,124 biomedical literature with technical and plain language summaries written by the authors, then conduct a thorough analysis of the collected data including statistics, readability metrics, and textual features.', 'The task of readability controllable biomedical document summarization requires a suitable selection of content from long biomedical documents for various readers guided by their readability demands.': 'The authors examine several controlling techniques on prevalent pre-trained language models (PLMs) and evaluate their performance on their dataset.', 'The task of readability controllable biomedical document summarization requires the model to learn not only lexical and syntactic adjustment but also paraphrasing according to users’ needs.': 'The authors propose a novel masked noun phrase-based text complexity metric and its variant based on the masked language model (MLM) to better characterize readability differences between technical summary and PLS.', 'The performance of controlling techniques including prompts and multi-heads on both extractive and abstractive methods to adjust readability during summarization is far from satisfying.': 'The authors bring in human evaluation due to the inefficacy of current metrics for readability and text generation.'}",supervised,['Medical Reports'],['controlled-and-tailored-summarization']
SP:8d6ae05b260ea6fe155007feb645a1a53c83f027,Scientific Paper Extractive Summarization Enhanced by Citation Graphs,EMNLP,2022,"['Xiuying Chen', 'Mingzhe Li', 'Shen Gao', 'Rui Yan', 'Xin Gao', 'Xiangliang Zhang']","In a citation graph, adjacent paper nodes share related scientific terms and topics. The graph thus conveys unique structure information of document-level relatedness that can be utilized in the paper summarization task, for exploring beyond the intra-document information. In this work, we focus on leveraging citation graphs to improve scientific paper extractive summarization under different settings. We first propose a Multi-granularity Unsupervised Summarization model (MUS) as a simple and low-cost solution to the task. MUS finetunes a pre-trained encoder model on the citation graph by link prediction tasks. Then, the abstract sentences are extracted from the corresponding paper considering multi-granularity information. Preliminary results demonstrate that citation graph is helpful even in a simple unsupervised framework. Motivated by this, we next propose a Graph-based Supervised Summarization model (GSS) to achieve more accurate results on the task when large-scale labeled data are available. Apart from employing the link prediction as an auxiliary task, GSS introduces a gated sentence encoder and a graph information fusion module to take advantage of the graph information to polish the sentence representation. Experiments on a public benchmark dataset show that MUS and GSS bring substantial improvements over the prior state-of-the-art model.","The paper discusses the use of citation graphs to improve scientific paper extractive summarization. The authors propose two models: a Multi-granularity Unsupervised Summarization model (MUS) and a Graph-based Supervised Summarization model (GSS). MUS finetunes a pre-trained encoder model on the citation graph by link prediction tasks, while GSS introduces a gated sentence encoder and a graph information fusion module to polish the sentence representation. Experiments on a public benchmark dataset show that both models bring substantial improvements over the prior state-of-the-art model.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automatically extract the most important concepts from an article, removing secondary or redundant concepts.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main ideas of a scientific paper, such as researchers, students, or professionals in a specific field.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding scientific papers, as well as to identify relevant papers for further research or analysis.'}",['method'],"['Auxiliary Tasks', 'Input Encoding']",['SSN'],"['ROUGE', 'BERTScore', 'QuestEval']","['QA', 'Informativeness', 'Coherence', 'Succintness']",,https://aclanthology.org/2022.emnlp-main.270/,"{'Extractive scientific paper summarization is a challenging task due to the length and complexity of scientific papers, as well as the presence of domain-specific items in specific fields.': 'The authors propose using citation graph modeling to capture the structural information of scientific papers. They propose an unsupervised summarization model called Multi-granularity Unsupervised Summarization (MUS) that finetunes a pre-trained encoder model on the citation graph to obtain better sentence and document representations. They also propose a supervised model called Graph-based Supervised Summarization (GSS) that employs a graph neural network encoder based on a pre-trained language model to obtain sentence and document representations, and a gated sentence encoder to polish the sentence representations based on their relatedness to the document gist.', 'Existing works on extractive scientific paper summarization mainly focus on utilizing intradocument relationships, and the effectiveness of the citation graph in extractive summarization tasks is left to be explored.': 'The authors propose using citation graph modeling to capture the structural information of scientific papers. They demonstrate the effectiveness of citation graph modeling in scientific paper extractive summarization and propose two models, MUS and GSS, that learn from the citation graph structure to achieve better summarization.', 'The authors aim to achieve more accurate results for the scenario where large-scale labeled data is feasible.': 'The authors propose a supervised model called Graph-based Supervised Summarization (GSS) that employs a graph neural network encoder based on a pre-trained language model to obtain sentence and document representations, and a gated sentence encoder to polish the sentence representations based on their relatedness to the document gist. They also utilize a graph information fusion module to incorporate the information from reference papers to the polished sentence representations. Finally, a multi-task framework is applied to the model, which jointly assigns selection weights to extract abstracts and predicts whether there exists an edge between two nodes.'}",unsupervised,['Scholarly Documents'],['exploiting-the-structure-of-long-documents']
SP:82e249eb8c04f923bc08ac9ec3dbdafdeef6a34b,Improving abstractive summarization with energy-based re-ranking,EMNLP,2022,"['Diogo PernesÁç', 'Afonso MendesÁ', 'André F. T. MartinsÈÉÆ', 'ÁPriberam çUniversidade']","Current abstractive summarization systems present important weaknesses which prevent their deployment in real-world applications, such as the omission of relevant information and the generation of factual inconsistencies (also known as hallucinations). At the same time, automatic evaluation metrics such as CTC scores (Deng et al., 2021) have been recently proposed that exhibit a higher correlation with human judgments than traditional lexicaloverlap metrics such as ROUGE. In this work, we intend to close the loop by leveraging the recent advances in summarization metrics to create quality-aware abstractive summarizers. Namely, we propose an energy-based model that learns to re-rank summaries according to one or a combination of these metrics. We experiment using several metrics to train our energy-based re-ranker and show that it consistently improves the scores achieved by the predicted summaries. Nonetheless, human evaluation results show that the re-ranking approach should be used with care for highly abstractive summaries, as the available metrics are not yet sufficiently reliable for this purpose.","The paper discusses the weaknesses of current abstractive summarization systems, such as the omission of relevant information and the generation of factual inconsistencies. It proposes an energy-based model that learns to re-rank summaries according to recent advances in summarization metrics, which consistently improves the scores achieved by the predicted summaries. However, the paper also notes that the re-ranking approach should be used with care for highly abstractive summaries, as the available metrics are not yet sufficiently reliable for this purpose.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization systems, which currently suffer from problems such as omitting relevant information and factual inconsistencies.', 'Who is the target audience?': 'The summaries are for use in real-world applications, but the authors are also developing more reliable evaluation metrics with a stronger correlation with human judgment.', 'How will the summaries be used?': 'The summaries will be used to assess the quality of the generated summaries on the fly without the need for reference summaries. The re-ranking model can leverage the advantages of recently proposed evaluation metrics over traditional ones to improve the quality of the generated summaries.'}",['method'],['Objective Function'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'QuestEval', 'FactCC', 'CTC']","['Factual Consistency', 'Relevance', 'Fluency']",https://github.com/Priberam/SummEBR,https://aclanthology.org/2022.gem-1.1/,"{'Abstractive summarization systems suffer from omitting the most relevant information from the source document.': 'The authors propose a new approach to abstractive summarization via an energy-based model that is trained to re-rank the candidate summaries the same way that the chosen metric would rank them, which is computationally much more efficient. This way, they are distilling the metric, which presents as a by-product an additional advantage: a quality estimation system that can be used to assess the quality of the summaries on the fly without the need of reference summaries.', 'Factual inconsistencies (hallucinations) are estimated to be present in around 30% of the summaries produced by abstractive systems on the CNN/DailyMail dataset.': 'The authors propose using recently proposed evaluation metrics that better capture high-level semantic concepts and take into account the information present on the source document, which is crucial to detect hallucinations. They demonstrate the effectiveness of their approach on standard benchmark datasets for abstractive summarization and use a variety of summarization metrics as the target to train their model on, showing the versatility of the method.', 'The difficulty of evaluating the quality of summaries automatically, leading to the adoption of metrics that are often insufficient or even inappropriate.': 'The authors propose the development of more reliable evaluation metrics with a stronger correlation with human judgment, which is also an active area of research. They also conduct a human evaluation experiment, in which they compare their re-ranking model trained to maximize recent transformer-based metrics that aim to measure factual consistency and relevance.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:76fb3cc448731e55d5b4378166b7db5d0b6866d4,Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts,EMNLP,2022,"['Hongli Zhan', 'Tiberiu Sosea', 'Cornelia Caragea', 'Junyi Jessy Li']","Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people’s emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce COVIDET (Emotions and their Triggers during Covid-19), a dataset of ~1, 900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that COVIDET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts.","The paper discusses the importance of understanding the triggers that lead to people's emotions during crises such as the COVID-19 pandemic. It proposes a novel approach of emotion detection and trigger summarization using social media posts, which tend to be charged with multiple emotions and scattered triggers. The authors introduce COVIDET, a dataset of ~1,900 English Reddit posts related to COVID-19, with manual annotations of perceived emotions and abstractive summaries of their triggers. The paper also presents strong baselines for jointly detecting emotions and summarizing emotion triggers. The authors conclude that COVIDET presents new challenges in emotion-specific summarization and multi-emotion detection in long social media posts.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to identify the triggers of different emotions in the context of the COVID-19 pandemic.', 'Who is the target audience?': 'The summaries are for first responders, counselors, and scientific researchers who need insights into the emotional impact of large-scale crises like the COVID-19 pandemic.', 'How will the summaries be used?': 'The summaries will be used to train reliable emotion detection and trigger summarization approaches in a COVID-19 context. They will also provide valuable insights into the emotional impact of the pandemic and help identify areas where support is needed.'}",['corpus'],[],['COVIDET'],"['ROUGE', 'BERTScore']","['Coherence', 'Consistency', 'Fluency', 'Relevance']",https://github.com/honglizhan/CovidET,https://aclanthology.org/2022.emnlp-main.642/,"{'Fewer studies have focused on what leads to emotions in the scope of the text concerned in a data-driven manner.': 'The authors take a novel view and formulate emotion-trigger detection as an abstractive summarization task that synthesizes a natural language description of the events and their appraisals that trigger a particular emotion.', 'Different individuals may have distinct appraisals towards the same event, highlighting the challenging nature of understanding what triggers an emotion.': 'The authors address this challenge by annotating each post in their COVIDET dataset with 7 fine-grained emotion labels and a concise, abstractive summary describing the triggers of the emotion.', 'Prior emotion studies have considered only sentence-level texts or short tweets, making COVIDET challenging as it contains significantly longer texts.': 'The authors showcase examples of COVIDET in Appendix §A and benchmark models for emotion detection and emotion-trigger summarization using COVIDET.', ""General emotion detection or summarization models lag behind in performance compared to the authors' methods due to COVIDET's unique characteristics."": 'The authors emphasize the importance of COVIDET in training reliable emotion detection and trigger summarization approaches in a Covid-19 context. They also release COVIDET and their code for others to use.'}",supervised,['Social Media'],[]
SP:fdf2c8b9b238492bb832db230ca70b4ae15d1367,Extractive Summarization of Legal Decisions using Multi-task Learning and Maximal Marginal Relevance,EMNLP,2022,"['Abhishek Agarwal', 'Shanshan Xu', 'Matthias Grabmair']","Summarizing legal decisions requires the expertise of law practitioners, which is both timeand cost-intensive. This paper presents techniques for extractive summarization of legal decisions in a low-resource setting using limited expert annotated data. We test a set of models that locate relevant content using a sequential model and tackle redundancy by leveraging maximal marginal relevance to compose summaries. We also demonstrate an implicit approach to help train our proposed models generate more informative summaries. Our multi-task learning model variant leverages rhetorical role identification as an auxiliary task to further improve the summarizer. We perform extensive experiments on datasets containing legal decisions from the US Board of Veterans’ Appeals and conduct quantitative and expert-ranked evaluations of our models. Our results show that the proposed approaches can achieve ROUGE scores vis-à-vis expert extracted summaries that match those achieved by inter-annotator comparison.",The paper presents techniques for extractive summarization of legal decisions in a low-resource setting using limited expert annotated data. The models locate relevant content using a sequential model and tackle redundancy by leveraging maximal marginal relevance to compose summaries. The proposed approaches can achieve ROUGE scores vis-à-vis expert extracted summaries that match those achieved by inter-annotator comparison. The multi-task learning model variant leverages rhetorical role identification as an auxiliary task to further improve the summarizer.,"{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to help expedite the process of researching legal decisions and to provide cost-effective assistance to paralegals, lawyers, and other law practitioners.', 'Who is the target audience?': 'The summaries are for paralegals, lawyers, and other law practitioners who need to research large numbers of legal decisions from past cases to find similar precedents that justify their arguments and lead to favorable outcomes.', 'How will the summaries be used?': 'The summaries will be used to identify and extract essential sentences from the source document to compose the corresponding summary. They will help generate informative summaries with maximum information and minimum redundancy in a low-resource setting. The summaries will also be evaluated qualitatively with the help of a legal expert.'}","['corpus', 'method']",['Objective Function'],['BVA PTSD'],['ROUGE'],['Adequacy'],https://github.com/TUMLegalTech/summarization_emnlp22,https://aclanthology.org/2022.findings-emnlp.134/,"{'Extractive summarization of legal documents is challenging due to the redundancy in legal documents, as legal decisions can often contain several semantically similar sentences.': 'The authors propose to generate summaries that provide maximum information while minimizing redundancy by using Maximal Marginal Relevance (MMR) and adding a redundancy loss term to neural models.', 'The low availability of expert annotated summarization datasets in the legal domain makes it challenging to design automated systems to assist paralegals, lawyers, and other law practitioners.': 'The authors leverage large amounts of unlabeled data along with the small annotated datasets to gain maximum performance and use domain-specific variants of BERT pre-trained on large corpora of legal texts to better embed the legal terms and achieve robust performance.', 'To maximize the summarization performance, the authors need to leverage Multi-task Learning (MTL) by aggregating training samples from several smaller datasets of multiple related tasks.': 'The authors use rhetorical role identification as an auxiliary task to augment their annotated dataset and help generate better summaries. They combine extractive summarization and rhetorical role labeling in a multi-task setting to improve performance.'}",supervised,['Legal Proceedings'],['identifying-important-contents-from-the-document']
SP:99495c167f7f246158ac9c1c71826201bba3edb6,Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling,EMNLP,2022,"['Vidhisha Balachandran', 'Hannaneh Hajishirzi', 'William W. Cohen', 'Yulia Tsvetkov']","Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial nonfactual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of nonfactual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets— CNN/DM and XSum—we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model—FACTEDIT— improves factuality scores by over ∼11 points on CNN/DM and over ∼31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality.1ive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial nonfactual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of nonfactual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets— CNN/DM and XSum—we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model—FACTEDIT— improves factuality scores by over ∼11 points on CNN/DM and over ∼31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality.1","The paper proposes a new approach to correcting factual errors in abstractive summarization models. Instead of using heuristics to generate non-factual summaries, the authors generate hard, representative synthetic examples of non-factual summaries through infilling language models. With this data, they train a more robust fact-correction model to post-edit the summaries to improve factual consistency. The approach is shown to vastly outperform prior methods in correcting erroneous summaries on two popular summarization datasets, improving factuality scores by over ∼11 points on CNN/DM and over ∼31 points on XSum on average across multiple summarization models, while maintaining competitive summarization quality. The proposed model is called FACTEDIT.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the factuality of the generated summaries produced by modern summarization models.', 'Who is the target audience?': 'The summaries are for user-facing products that use language generation tools.', 'How will the summaries be used?': 'The summaries will be used to control for content factuality in generated summaries and to audit summarization systems to facilitate their reliability.'}","['method', 'analysis']",['Post Processing'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'FactCC', 'Ent-DAE']","['Fluency', 'Factuality']",https://github.com/vidhishanair/FactEdit,https://aclanthology.org/2022.emnlp-main.667/,"{'Modern summarization models generate non-factual and sometimes entirely fabricated content, posing severe risks including the spread of misinformation, panic, and other potentially harmful effects.': 'The authors propose post-editing generated summaries to fix factual inconsistencies while allowing summarization models to focus on fluency and content-relevance. They propose FACTEDIT, a novel approach to post-editing text, to control for content factuality in generated summaries.', 'There is no suitable data for training post-editing models to directly ""translate"" an incorrect summary to a correct one, and prior work constructed synthetic training data using simple heuristic errors that may not accurately represent the types and distribution of actual errors made by language models.': 'The authors propose using a new algorithm to generate adversarial (non-factual) examples using infilling language models, leveraging the capabilities of large language models to produce multiple candidates of alternative, erroneous summaries. These examples, along with factually correct references, are then used to train a sequence-to-sequence fact-correction model that aims at generating a factually consistent version of the candidate summary.', 'With increasing language generation capabilities, models make more complex factual errors involving discourse structures and paraphrasing which cannot be easily captured with heuristics.': 'The authors propose using their FACTEDIT approach to generalize over a wider range of factual errors in generated summaries from diverse summarization model types.', 'There is a need to evaluate the generalizability of the FACTEDIT model across different datasets and summarization models.': 'The authors evaluate FACTEDIT on two datasets - CNN/DailyMail and XSum - and across nine summarization models with the FRANK benchmark for evaluating various categories of factual errors in generated summaries.', 'There is a need to show that FACTEDIT effectively corrects diverse error categories without the need for special heuristics or annotations.': 'The authors show through their analysis that FACTEDIT effectively corrects diverse error categories without the need for special heuristics or annotations.', 'There is a need to audit summarization systems and facilitate their reliability.': 'An important application of FACTEDIT is to audit summarization systems and facilitate their reliability.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:dbdc31873eb27d544a137d864873e50cf32af9a5,Leveraging Locality in Abstractive Text Summarization,EMNLP,2022,"['Yixin Liu', 'Ansong Ni', 'Linyong Nan', 'Budhaditya Deb', 'Chenguang Zhu', 'Ahmed H. Awadallah', 'Dragomir Radev']","Neural attention models have achieved significant improvements on many natural language processing tasks. However, the quadratic memory complexity of the self-attention module with respect to the input length hinders their applications in long text summarization. Instead of designing more efficient attention modules, we approach this problem by investigating if models with a restricted context can have competitive performance compared with the memory-efficient attention models that maintain a global context by treating the input as a single sequence. Our model is applied to individual pages, which contain parts of inputs grouped by the principle of locality, during both the encoding and decoding stages. We empirically investigated three kinds of locality in text summarization at different levels of granularity, ranging from sentences to documents. Our experimental results show that our model has a better performance compared with strong baseline models with efficient attention modules, and our analysis provides further insights into our locality-aware modeling strategy.1","The paper discusses the challenges of using neural attention models for long text summarization due to the quadratic memory complexity of the self-attention module. Instead of designing more efficient attention modules, the authors investigate if models with a restricted context can have competitive performance. They propose a locality-aware modeling strategy where the model is applied to individual pages grouped by the principle of locality during both the encoding and decoding stages. The authors empirically investigate three kinds of locality in text summarization at different levels of granularity and show that their model outperforms strong baseline models with efficient attention modules.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for text summarization.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the given paper.', 'How will the summaries be used?': 'The potential uses of the generated summaries are not specified in the given paper.'}",['method'],['Input Encoding'],"['arXiv', 'PubMed', 'GovReport', 'MultiNews']",['ROUGE'],['Coherence'],https://github.com/yixinL7/PageSum,https://aclanthology.org/2022.emnlp-main.408/,"{'The self-attention module in neural attention models introduces a quadratic memory growth with respect to the input sequence length, making it difficult to handle long-text summarization datasets.': 'The authors propose a framework of leveraging locality for text summarization, which reduces the memory complexity of full-attention models while still maintaining competitive performance. Instead of viewing the input document as an entire sequence, they represent it as a number of pages which are constructed according to the principle of locality. Each of these pages is encoded independently by the encoder of their abstractive model, and the decoder makes local predictions over each page along with local confidence scores of its predictions, which are used to combine the local predictions into final outputs.', 'Efficient attention is just an approximation of full attention and can show lower performance compared with its counterpart.': 'The authors argue that models with a restricted context, where each token only receives a subset of tokens as its context during the entire computation, can be competitive with efficient attention models if they can effectively leverage locality in text summarization.', 'One of the key assumptions of efficient attention models is that all tokens in the input text should interact with each other.': 'The proposed framework highlights the role of locality in text summarization, where tokens in different pages never directly interact with each other during encoding and decoding.', 'Different types of locality exist in text summarization, such as spatial locality, discourse locality, and document locality.': 'The proposed framework allows for investigating several types of locality in text summarization, such as spatial locality or sequential locality, discourse locality, and document locality.', 'Most efficient attention models cannot take full advantage of pre-trained full-attention models.': 'The proposed framework can take the most advantage of pre-trained full-attention models because it preserves the same attention mechanism as the full-attention models, unlike most of the efficient attention models.', 'The overall complexity of encoder self-attention is high in full-attention models.': 'The proposed framework reduces the overall complexity of encoder self-attention to a linear relationship with the input document length.'}",supervised,"['Scholarly Documents', 'News', 'Govt. Reports']",['efficient-encoding-of-long-documents']
SP:e278331abb55cf13a92a48da3aae6502f436adca,Learning to Generate Overlap Summaries through Noisy Synthetic Data,EMNLP,2022,"['Naman Bansal', 'Mousumi Akter', 'Shubhra Kanti Karmaker']","Semantic Overlap Summarization (SOS) is a novel and relatively under-explored seq-to-seq task which entails summarizing common information from multiple alternate narratives. One of the major challenges for solving this task is the lack of existing datasets for supervised training. To address this challenge, we propose a novel data augmentation technique, which allows us to create large amount of synthetic data for training a seq-to-seq model that can perform the SOS task. Through extensive experiments using narratives from the news domain, we show that the models finetuned using the synthetic dataset provide significant performance improvements over the pre-trained vanilla summarization techniques and are close to the models fine-tuned on the golden training data; which essentially demonstrates the effectiveness of out proposed data augmentation technique for training seq-to-seq models on the SOS task.","The paper discusses the Semantic Overlap Summarization (SOS) task, which involves summarizing common information from multiple alternate narratives. The lack of existing datasets for supervised training is a major challenge for this task. To address this, the authors propose a novel data augmentation technique to create synthetic data for training a seq-to-seq model. Through experiments using news narratives, they show that models trained using the synthetic dataset provide significant performance improvements over pre-trained summarization techniques and are close to models trained on golden training data. The proposed data augmentation technique is effective for training seq-to-seq models on the SOS task.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to extract common information from multiple alternative narratives originating from various sources.', 'Who is the target audience?': 'The summaries are for anyone who needs to digest multi-narratives at scale and speed, such as those in the domains of education, health, and privacy.', 'How will the summaries be used?': 'The summaries will be used to train seq-to-seq models for the Semantic Overlap Summarization (SOS) task, which can generate a summary of common information from multiple alternative narratives. The generated summaries can be used to fine-tune existing pre-trained seq-to-seq summarization models and improve their accuracy.'}",['method'],['Data Augmentation'],['AllSides'],['ROUGE'],[],,https://aclanthology.org/2022.emnlp-main.807/,"{'Lack of readily available training data for supervised learning in the Semantic Overlap Summarization (SOS) task.': 'The authors propose a new unsupervised data generation technique which can generate an arbitrarily large number of synthetic training examples for the SOS task. Given an arbitrary text corpus from a particular domain, their data generation algorithm can produce an infinite number of SOS examples of the form {{DA, DB}, (DA ∩O DB)}, where, DA and DB are two narratives (in text) and DA ∩O DB is the desired reference summary of semantic overlap.', 'Difficulty in finding the best model to solve the SOS task.': 'The authors propose to leverage existing pre-trained seq-to-seq summarization models as an approximation of the overlap summary generator and create artificial examples to further fine-tune such seq-to-seq models. They validate whether fine-tuning with artificial examples is indeed useful for improving the accuracy of the seq-to-seq models using the human annotated and verified dataset (Bansal et al., 2022).', 'Lack of studies on the effectiveness of synthetic data generation approach in learning to generate Overlap Summaries.': 'The authors conduct experiments using 3 single document summarizers and 1 multi-document summarizer to show that their synthetic data generation approach can indeed help in learning to generate Overlap Summaries. They show that the models fine-tuned using their synthetic dataset provide significant performance improvements over the pretrained-only baselines and are close to the models fine-tuned on the golden training data.'}",supervised,['News'],['lack-of-suitable-training-data']
SP:4995f29709559c86eae6f2b4a56f85f002fd56eb,SentBS: Sentence-level Beam Search for Controllable Summarization,EMNLP,2022,"['Chenhui Shen', 'Liying Cheng', 'Lidong Bing', 'Yang You', 'Luo Si']","A wide range of control perspectives have been explored in controllable text generation. Structure-controlled summarization is recently proposed as a useful and interesting research direction. However, current structure-controlling methods have limited effectiveness in enforcing the desired structure. To address this limitation, we propose a sentence-level beam search generation method (SentBS), where evaluation is conducted throughout the generation process to select suitable sentences for subsequent generations. We experiment with different combinations of decoding methods to be used as subcomponents by SentBS and evaluate results on the structure-controlled dataset MReD. Experiments show that all explored combinations for SentBS can improve the agreement between the generated text and the desired structure, with the best method significantly reducing the structural discrepancies suffered by the existing model, by approximately 68%. 1","The paper discusses the limitations of current structure-controlling methods in controllable text generation and proposes a new method called sentence-level beam search generation (SentBS) to address these limitations. SentBS evaluates sentences throughout the generation process to select suitable ones for subsequent generations. The paper experiments with different decoding methods as subcomponents for SentBS and evaluates the results on the structure-controlled dataset MReD. The experiments show that all explored combinations for SentBS can improve the agreement between the generated text and the desired structure, with the best method reducing structural discrepancies by approximately 68%.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents for controllable text generation, which has a wide range of applications.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the contents of a research paper.', 'How will the summaries be used?': 'The summaries can be used to quickly identify the main points of a research paper and to determine whether it is relevant to a particular topic or research question.'}",['method'],['Controlled Generation'],['MReD'],"['ROUGE', 'BERTScore', 'Structure Similarity', 'Edit Distance']","['Fluency', 'Relevance', 'Decision Correctness', 'Structure Similarity']",https://github.com/Shen-Chenhui/SentBS,https://aclanthology.org/2022.emnlp-main.699/,"{""Existing controllable summarization models focus on improving the summary's similarity with the gold reference, leaving room for further improvement on the controllability."": 'The authors propose to enhance the structure-controllability in summarization by addressing the identified issues in existing models.', 'Existing models treat generation as a standalone process, which continuously generates the tokens solely based on the logits predictions, without stopping to reconsider whether the generated sequences satisfy the control signals.': 'The authors propose the Sentence-level Beam Search (SentBS) method to address this issue. SentBS conducts text generation with continuous evaluation on the sentence level with respect to the control requirements.', 'Autoregressive models can suffer from error propagation in generation due to self-attention, which can cause subsequent generations to deviate further from the desired output if the previous sequences are not well-controlled.': ""The authors propose SentBS to address this issue by producing multiple sentence options, evaluating and selecting the best sentence according to both the control structure as well as the model's log-likelihood, then continuing the generation for the next sentence."", 'The best-performing model on the recently released MReD dataset still generates around 29% of the sentences that do not follow the control structure, which is far from satisfactory.': ""The authors show that SentBS can significantly improve the model's structure-controllability. In particular, their best setting removes up to 68% of control mistakes produced by the existing model on MReD without compromising the summarization quality."", 'Existing models do not focus on sentence-by-sentence controlled generation for structure-controllable summarization.': 'The authors propose to conduct sentence-by-sentence controlled generation for structure-controllable summarization, which is a novel contribution to the field.'}",supervised,['Peer Reviews'],['controlled-and-tailored-summarization']
SP:dccdd8faa12b7032bdd5a91696ced9c364b0ffce,SEM-F1: an Automatic Way for Semantic Evaluation of Multi-Narrative Overlap Summaries at Scale,EMNLP,2022,"['Naman Bansal', 'Mousumi Akter', 'Shubhra Kanti Karmaker']","Recent work has introduced an important yet relatively under-explored NLP task called Semantic Overlap Summarization (SOS) that entails generating a summary from multiple alternative narratives which conveys the common information provided by those narratives. Previous work also published a benchmark dataset for this task by collecting 2, 925 alternative narrative pairs from the web and manually annotating 411 different reference summaries by engaging human annotators. In this paper, we exclusively focus on the automated evaluation of the SOS task using the benchmark dataset. More specifically, we first use the popular ROUGE metric from text-summarization literature and conduct a systematic study to evaluate the SOS task. Our experiments discover that ROUGE is not suitable for this novel task and therefore, we propose a new sentencelevel precision-recall style automated evaluation metric, called SEM-F1 (Semantic F1). It is inspired by the benefits of the sentence-wise annotation technique using overlap labels reported by the previous work. Our experiments show that the proposed SEM-F1 metric yields a higher correlation with human judgment and higher inter-rater agreement compared to the ROUGE metric.","The paper discusses the Semantic Overlap Summarization (SOS) task, which involves generating a summary from multiple alternative narratives that convey common information. The authors focus on the automated evaluation of the SOS task using a benchmark dataset and find that the popular ROUGE metric is not suitable for this task. They propose a new evaluation metric called SEM-F1, which yields higher correlation with human judgment and inter-rater agreement compared to ROUGE. The metric is inspired by the sentence-wise annotation technique using overlap labels reported in previous work.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a way to comprehend the complete picture of an event being reported and verify corresponding facts and opinions from different perspectives.', 'Who is the target audience?': 'The summaries are for anyone who needs to digest multi-narratives at scale and speed, including those in education, the health sector, military intelligence, content analysis, and privacy.', 'How will the summaries be used?': 'The summaries will be used to provide a concise summary of the common information provided by multiple alternative narratives, which can be highly useful for understanding events from different perspectives.'}",['analysis'],[],['AllSides'],['ROUGE'],[],,https://aclanthology.org/2022.emnlp-main.49/,"{'Computers are still far from being able to accurately interpret multiple alternative narratives, which remains an open problem.': 'The authors study the challenging area of automatic summarization of multiple alternative narratives from different perspectives, focusing exclusively on the automated evaluation of a new NLP task called Semantic Overlap Summarization (SOS) from multiple alternative narratives.', 'It is unclear how to properly evaluate the SOS task in an automated fashion.': 'The authors experiment with ROUGE, a widely popular metric for evaluating text summarization tasks, and demonstrate that ROUGE is NOT suitable for the automatic evaluation of SOS task. They propose a new precision-recall style evaluation metric, SEM-F1 (Semantic F1), for evaluating the SOS task based on the findings of their previous work.', 'There is no current baseline method that exactly matches the SOS task.': 'The authors frame the SOS task as a constrained seq-to-seq problem where the goal is to generate a summary from two input documents that convey the overlapping information present in both input text documents.'}",,['News'],[]
SP:b92dc5d02dcfe135e8614551510f0bb9d5613d69,Factual Error Correction for Abstractive Summaries Using Entity Retrieval,EMNLP,2022,"['Hwanhee Lee', 'Cheoneum Park', 'Seunghyun Yoon', 'Trung Bui', 'Franck Dernoncourt', 'Juae Kim', 'Kyomin Jung']","Despite the recent advancements in abstractive summarization systems leveraged from largescale datasets and pre-trained language models, the factual correctness of the summary is still insufficient. One line of trials to mitigate this problem is to include a post-editing process that can detect and correct factual errors in the summary. In building such a system, it is strongly required that 1) the process has a high success rate and interpretability and 2) it has a fast running time. Previous approaches focus on the regeneration of the summary, resulting in low interpretability and high computing resources. In this paper, we propose an efficient factual error correction system RFEC based on entity retrieval. RFEC first retrieves the evidence sentences from the original document by comparing the sentences with the target summary to reduce the length of the text to analyze. Next, RFEC detects entity-level errors in the summaries using the evidence sentences and substitutes the wrong entities with the accurate entities from the evidence sentences. Experimental results show that our proposed error correction system shows more competitive performance than baseline methods in correcting factual errors with a much faster speed.1",The paper discusses the problem of factual errors in abstractive summarization systems and proposes a solution in the form of an efficient factual error correction system called RFEC. The system is based on entity retrieval and retrieves evidence sentences from the original document to reduce the length of the text to analyze. It then detects entity-level errors in the summaries and substitutes the wrong entities with accurate ones from the evidence sentences. The experimental results show that RFEC outperforms baseline methods in correcting factual errors with a faster speed.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to provide a shorter version of the text that contains important information from the source article.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a document without reading the entire text.', 'How will the summaries be used?': ""The summaries can be used to save time and provide a quick overview of a document's content. They can also be used for information retrieval and to help people make informed decisions based on the main points of a document.""}","['method', 'analysis']",['Data Augmentation'],"['CNN/DailyMail', 'FactCC']",['Accuracy'],[],https://github.com/hwanheelee1993/RFEC,https://aclanthology.org/2022.gem-1.41/,"{'Factual inconsistency between the original text and the summary is frequently observed in abstractive summarization systems.': 'The authors propose RFEC, a retrieval-based factual error corrector that efficiently corrects factual errors with a much faster running time compared to seq2seq models. RFEC first retrieves evidence sentences for the given summary for correcting and detecting errors. Then, RFEC examines all of the entities to determine whether each entity has a factual error. If any entities have a factual error, RFEC substitutes these wrong entities with the correct entity by choosing them among the entities in the source article.', 'Previous works have introduced post-editing systems to alleviate factual errors in the summary, but all of those works adopt the seq2seq model, which requires a similar cost to the original abstractive summarization systems, resulting in significant inefficiency.': 'The authors propose RFEC as an alternative approach to post-editing that is more efficient than seq2seq models. RFEC decides whether to fix and correct factual errors through retrieval, resulting in higher computational efficiency.', ""Seq2seq based post-editing models can be affected by the model's own bias to the input summary."": ""RFEC is a retrieval-based model that is not affected by the model's own bias to the input summary.""}",,['News'],['hallucinations-in-the-generated-summaries']
SP:762732625b02e202e886f205ca6f89e65013a7ec,ECTSum: A New Benchmark Dataset For Bullet Point Summarization of Long Earnings Call Transcripts,EMNLP,2022,"['Rajdeep Mukherjee', 'Abhinav Bohra', 'Akash Banerjee', 'Soumya Sharma', 'Manjunath Hegde', 'Afreen Shaikh', 'Shivani Shrivastava', 'Koustuv Dasgupta', 'Niloy Ganguly', 'Saptarshi Ghosh', 'Pawan Goyal']","Despite tremendous progress in automatic summarization, state-of-the-art methods are predominantly trained to excel in summarizing short newswire articles, or documents with strong layout biases such as scientific articles or government reports. Efficient techniques to summarize financial documents, discussing facts and figures, have largely been unexplored, majorly due to the unavailability of suitable datasets. In this work, we present ECTSum, a new dataset with transcripts of earnings calls (ECTs), hosted by publicly traded companies, as documents, and experts-written short telegram-style bullet point summaries derived from corresponding Reuters articles. ECTs are long unstructured documents without any prescribed length limit or format. We benchmark our dataset with state-of-the-art summarization methods across various metrics evaluating the content quality and factual consistency of the generated summaries. Finally, we present a simple yet effective approach, ECT-BPS, to generate a set of bullet points that precisely capture the important facts discussed in the calls.","The paper discusses the lack of efficient techniques to summarize financial documents and introduces a new dataset called ECTSum, which consists of transcripts of earnings calls and expert-written bullet point summaries. The authors benchmark their dataset with state-of-the-art summarization methods and present a simple yet effective approach called ECT-BPS to generate bullet points that capture important facts discussed in the calls.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to automate the task of summarizing long unstructured earning call transcripts, which are typically in the form of thousands of words, and require a great deal of time and effort to quickly summarize the key facts covered in these transcripts.', 'Who is the target audience?': 'The summaries are for financial analysts and investors to review their price targets and trade decisions.', 'How will the summaries be used?': 'The summaries will be used to automate the task of summarizing long unstructured earning call transcripts, and to benchmark the performance of several representative summarization approaches from both supervised and unsupervised paradigms on the newly proposed dataset. The summaries will also be evaluated on several metrics that assess the content quality and factual consistency of the model-generated summaries.'}",['corpus'],[],['ECTSum'],"['ROUGE', 'BERTScore']","['Correctness', 'Relevance', 'Coverage']",https://github.com/rajdeep345/ECTSum,https://aclanthology.org/2022.emnlp-main.748/,"{'Earnings calls are long unstructured documents consisting of thousands of words, making it difficult and time-consuming for trained analysts to quickly summarize the key facts covered in these transcripts.': 'The authors present ECTSum, a new benchmark dataset for bullet-point summarization of long ECTs, which requires models to process long unstructured earning call transcripts and summarize them in a few words while capturing crucial metrics and maintaining factual consistency.', 'The document-to-summary compression ratio of ECTSum is the highest among existing long document summarization datasets with comparable document lengths, making it challenging for trained models to capture the most relevant facts discussed in the ECTs in as few words as possible.': 'The authors propose ECT-BPS, a simple approach to effectively summarize ECTs while ensuring factual correctness of the generated content. It consists of an extractive summarization module followed by a paraphrasing module, which is trained to paraphrase ECT sentences to short abstractive telegram-style bullet-points that precisely capture the numerical values and facts discussed in the calls.', 'Existing long document summarization datasets have fixed document layouts, while ECTs are free-form documents with salient information spread throughout the text, making it difficult for models to learn any stylistic signals.': 'The authors propose ECTSum, which is a free-form dataset that requires models to capture salient information spread throughout the text, and ECT-BPS, which uses an extractive summarization module to identify salient sentences from the source ECT and a paraphrasing module to paraphrase ECT sentences to short abstractive telegram-style bullet-points.', 'Neural models employing BERT, T5, or BART as document encoders cannot process documents longer than 512/1024 tokens, while the average length of ECTs is around 2.9K words (before tokenization).': 'The authors propose ECT-BPS, which uses an extractive summarization module to identify salient sentences from the source ECT and a paraphrasing module to paraphrase ECT sentences to short abstractive telegram-style bullet-points, allowing for effective summarization of ECTs despite the limitations of neural models.'}",supervised,['Meeting Transcripts'],[]
SP:62e5bc0a38fb2364294988a77f91975fea7ae405,FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness,EMNLP,2022,"['Wenhao Wu', 'Wei Li', 'Jiachen Liu', 'Xinyan Xiao', 'Ziqiang Cao', 'Sujian Li', 'Hua Wu']","Despite being able to generate fluent and grammatical text, current Seq2Seq summarization models still suffering from the unfaithful generation problem. In this paper, we study the faithfulness of existing systems from a new perspective of factual robustness which is the ability to correctly generate factual information over adversarial unfaithful information. We first measure a model’s factual robustness by its success rate to defend against adversarial attacks when generating factual information. The factual robustness analysis on a wide range of current systems shows its good consistency with human judgments on faithfulness. Inspired by these findings, we propose to improve the faithfulness of a model by enhancing its factual robustness. Specifically, we propose a novel training strategy, namely FRSUM, which teaches the model to defend against both explicit adversarial samples and implicit factual adversarial perturbations. Extensive automatic and human evaluation results show that FRSUM consistently improves the faithfulness of various Seq2Seq models, such as T5, BART.","The paper discusses the unfaithful generation problem in current Seq2Seq summarization models, despite their ability to generate fluent and grammatical text. The authors propose a new perspective of factual robustness to measure the faithfulness of existing systems, which is the ability to correctly generate factual information over adversarial unfaithful information. They propose a novel training strategy called FRSUM, which enhances the model's factual robustness by teaching it to defend against both explicit adversarial samples and implicit factual adversarial perturbations. The evaluation results show that FRSUM consistently improves the faithfulness of various Seq2Seq models, such as T5 and BART.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the faithfulness or factual consistency of abstractive summarization systems.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a given document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick and accurate understanding of the content of a given document, without having to read the entire document.'}","['method', 'analysis']",['Objective Function'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'FactCC', 'SummaC']","['Faithfulness', 'Informativeness']",,https://aclanthology.org/2022.findings-emnlp.267/,"{'The paper addresses the problem of improving the faithfulness or factual consistency of abstractive summarization models, which generate summaries that are not only fluent and informative but also faithful to the given document.': 'The authors propose a new training method called FRSUM, which improves the factual robustness and faithfulness of a model by defending against both explicit and implicit adversarial attacks. FRSUM teaches the model to generate correct information over unfaithful adversarial samples by using a novel factual adversarial loss. The training process also includes factual adversarial perturbation to induce the model to generate unfaithful information, making it more robust in generating factual spans and generating fewer errors during inference.', 'The authors analyze the factual robustness of a wide range of Seq2Seq models and find that current models are vulnerable to generating different types of unfaithful information, such as weak robustness in generating numbers in the XSum dataset.': ""The authors propose FRSUM as a novel faithful improvement training strategy that enhances a model's factual robustness and improves its faithfulness. FRSUM is adaptive to all Seq2Seq models and improves the faithfulness of various models while maintaining their informativeness."", 'The authors conduct fine-grained human evaluation to analyze different types of factual errors and find that FRSUM greatly reduces different types of factual errors, especially when applied to T5.': 'The authors validate the effectiveness of FRSUM through extensive automatic and human evaluations, which demonstrate that FRSUM greatly reduces different types of factual errors and improves the faithfulness of summarization models.'}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:dc785e6b5b6e50027dd73bea56df56180f312444,Learning From the Source Document: Unsupervised Abstractive Summarization,EMNLP,2022,"['Haojie Zhuang', 'Wei Emma Zhang', 'Jian Yang', 'Congbo Ma', 'Yutong Qu', 'Quan Z. Sheng']","Most of the state-of-the-art methods for abstractive text summarization are under supervised learning settings, while heavily relying on highquality and large-scale parallel corpora. In this paper, we remove the need for reference summaries and present an unsupervised learning method SCR (Summarize, Contrast and Review) for abstractive summarization, which leverages contrastive learning and is the first work to apply contrastive learning for unsupervised abstractive summarization. Particularly, we use the true source documents as positive source document examples, and strategically generated fake source documents as negative source document examples to train the model to generate good summaries. Furthermore, we consider and improve the writing quality of the generated summaries by guiding them to be similar to human-written texts. The promising results on extensive experiments show that SCR outperforms other unsupervised abstractive summarization baselines, which demonstrates its effectiveness.","The paper introduces an unsupervised learning method called SCR (Summarize, Contrast and Review) for abstractive text summarization. Unlike most state-of-the-art methods that heavily rely on high-quality and large-scale parallel corpora, SCR removes the need for reference summaries. It leverages contrastive learning and is the first work to apply it for unsupervised abstractive summarization. The model is trained using true source documents as positive examples and strategically generated fake source documents as negative examples. The generated summaries are also guided to be similar to human-written texts. The extensive experiments show that SCR outperforms other unsupervised abstractive summarization baselines, demonstrating its effectiveness.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to create a shorter text version that retains the most important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding longer documents, and can be particularly useful for people who need to quickly review a large number of documents.'}",['method'],['Data Augmentation'],"['CNN/DailyMail', 'Gigaword']",['ROUGE'],"['Informativeness', 'Readability', 'Copying']",,https://aclanthology.org/2022.findings-emnlp.309/,"{'Obtaining high-quality and large-scale datasets for supervised training in abstractive summarization is laborious and expensive, and human-written summaries may not always be the finest.': 'The authors propose unsupervised abstractive summarization methods, such as SCR, that do not require paired data and instead leverage self-supervised learning techniques.', 'The reconstruction objective in generative self-supervised methods is an over-restriction, as it is difficult for even humans to reconstruct the source document given the summary.': 'The authors propose to apply contrastive self-supervised learning to relax this restriction and leverage the learning signal of ""selecting the true source documents"" to guide summary generation.', 'Negative source document examples for contrastive learning are difficult to obtain and may miss important contents or have incorrect or irrelevant information.': 'The authors design different strategies to generate negative source document examples and consider writing quality to lead the generated summaries to be similar to human-written texts.'}",unsupervised,['News'],['lack-of-suitable-training-data']
SP:6444d444abbf185dacaca8af317c6a6319b3b520,CiteSum: Citation Text-guided Scientific Extreme Summarization and Domain Adaptation with Limited Supervision,EMNLP,2022,"['Yuning Mao', 'Ming Zhong', 'Jiawei Han']","Scientific extreme summarization (TLDR) aims to form ultra-short summaries of scientific papers. Previous efforts on curating scientific TLDR datasets failed to scale up due to the heavy human annotation and domain expertise required. In this paper, we propose a simple yet effective approach to automatically extracting TLDR summaries for scientific papers from their citation texts. Based on the proposed approach, we create a new benchmark CiteSum without human annotation, which is around 30 times larger than the previous human-curated dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its data characteristics and establishing strong baselines. We further demonstrate the usefulness of CiteSum by adapting models pre-trained on CiteSum (named CITES) to new tasks and domains with limited supervision. For scientific extreme summarization, CITES outperforms most fully-supervised methods on SciTLDR without any fine-tuning and obtains state-of-theart results with only 128 examples. For news extreme summarization, CITES achieves significant gains on XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE1 zero-shot performance and state-of-the-art few-shot performance. For news headline generation, CITES performs the best among unsupervised and zero-shot methods on Gigaword.1","The paper proposes a new approach to automatically extract ultra-short summaries of scientific papers from their citation texts, creating a new benchmark dataset called CiteSum without human annotation. The authors conduct a comprehensive analysis of CiteSum and demonstrate the usefulness of the dataset by adapting models pre-trained on CiteSum to new tasks and domains with limited supervision. The results show that CITES outperforms most fully-supervised methods on SciTLDR for scientific extreme summarization and achieves significant gains on XSum for news extreme summarization and news headline generation.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to provide ultra-short summaries of scientific papers that are more concise and accurate than paper abstracts.', 'Who is the target audience?': 'The summaries are for researchers and scientists who need to quickly understand the main contributions and methods of a cited paper.', 'How will the summaries be used?': 'The summaries will be used as ground-truth summaries of the cited papers and as a benchmark for scientific extreme summarization. They will also be used to pre-train models for low-resource adaptation to new tasks and domains such as news extreme summarization and headline generation.'}",['corpus'],[],['CiteSum'],['ROUGE'],[],https://github.com/morningmoni/CiteSum,https://aclanthology.org/2022.emnlp-main.750/,"{'Paper abstracts may not always be the ideal summary because they often involve certain details such as task description, background information, and experiment results.': 'The authors propose scientific extreme summarization, which aims at forming ultra-short summaries (usually one sentence) of the papers, namely the TLDR2 summaries.', 'Ultra-short paper summaries are far from being universally available.': 'The authors argue that citation texts can often serve as high-quality short summaries of the cited papers. They propose a simple yet effective approach to locating, extracting, and filtering citation texts from scientific papers. They then treat the processed citation texts as ground-truth summaries of the cited papers.', 'Human-annotated summaries of scientific documents are rather costly and require domain expertise.': 'The authors create a large-scale scientific extreme summarization benchmark, CiteSum, which is automatically derived from citation texts and around 30 times larger than the previous human-annotated dataset SciTLDR.', 'Models pre-trained on existing datasets may not perform well on new tasks and domains.': 'The authors demonstrate that models pre-trained on CiteSum, which they name as CITES (Citation Text-guided Summarizer), exhibit superior generalizability during low-resource adaptation to new tasks and domains such as news extreme summarization and headline generation with limited training.'}",supervised,['Scholarly Documents'],[]
SP:c7b4881819aeebf4bc236a01d1627b0e980b2076,Mutual Information Alleviates Hallucinations in Abstractive Summarization,EMNLP,2022,"['Liam van der Poel', 'Ryan Cotterell', 'Clara Meister']","Despite significant progress in the quality of language generated from abstractive summarization models, these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document. A number of works have tried to fix—or at least uncover the source of—the problem with limited success. In this paper, we identify a simple criterion under which models are significantly more likely to assign more probability to hallucinated content during generation: high model uncertainty. This finding offers a potential explanation for hallucinations: models default to favoring text with high marginal probability, i.e., high-frequency occurrences in the training set, when uncertain about a continuation. It also motivates possible routes for real-time intervention during decoding to prevent such hallucinations. We propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token—rather than purely the probability of the target token—when the model exhibits uncertainty. Experiments on the XSUM dataset show that our method decreases the probability of hallucinated tokens while maintaining the ROUGE and BERTS scores of top-performing decoding strategies. https://github.com/VanderpoelLiam/","The paper discusses the issue of abstractive summarization models exhibiting the tendency to output content not supported by the source document, known as hallucinations. The authors identify high model uncertainty as a criterion that leads to more probability of hallucinated content during generation. They propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token when the model exhibits uncertainty, which decreases the probability of hallucinated tokens while maintaining the ROUGE and BERTS scores of top-performing decoding strategies. The experiments on the XSUM dataset support the effectiveness of their proposed method.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for abstractive summarization, which condenses long documents into short summaries for various applications such as providing overviews of news articles or highlighting main points in technical documents.', 'Who is the target audience?': 'The summaries are for users who need a quick and concise understanding of the original document without having to read the entire text.', 'How will the summaries be used?': 'The summaries can be used for various purposes such as providing overviews of news articles or highlighting main points in technical documents.'}",['analysis'],[],['XSum'],"['ROUGE', 'BERTScore', 'FactScore', 'FactCC']",[],https://github.com/VanderpoelLiam/CPMI,https://aclanthology.org/2022.emnlp-main.399/,"{'Abstractive summarization models have been observed to hallucinate facts, i.e., add information to the output that was not present in the original text, which can lead to the spread of misinformation.': 'The authors propose a simple criterion to identify when a model is more likely to assign higher probability to content not necessarily derived from the source document. They link the start of a hallucination during generation to high model uncertainty about the next token, which they quantify by conditional entropy.', 'Hallucinations may be due to a tendency of models to default to placing probability mass on tokens that appeared frequently in the training corpus, a behavior previously observed in several NLP tasks.': 'The authors propose an alternative decoding strategy to combat this behavior. When a model exhibits high uncertainty, they change their decoding objective to pointwise mutual information between the source document and target token (PMI), encouraging the model to prioritize tokens relevant to the source document.', 'Changing completely to the PMI objective causes a drop in ROUGE-L scores.': 'The authors propose a conditional and temporary change to the decoding objective, which leads to only a small drop in ROUGE-L while increasing factuality according to the FACTScore metric.', 'There does not exist an efficient and robust set of techniques for identifying and preventing hallucinations during the generation process.': 'The authors propose their criterion and decoding strategy as a potential solution to this problem.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:7744ff0423909f4203e273c623840759e8ac19cc,REFEREE: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation,EMNLP,2022,"['Melanie Sclar', 'Peter West', 'Sachin Kumar', 'Yulia Tsvetkov', 'Yejin Choi']","We present REFEREE, a novel framework for sentence summarization that can be trained reference-free (i.e., requiring no gold summaries for supervision), while allowing direct control for compression ratio. Our work is the first to demonstrate that reference-free, controlled sentence summarization is feasible via the conceptual framework of Symbolic Knowledge Distillation (West et al., 2022), where latent knowledge in pre-trained language models is distilled via explicit examples sampled from the teacher models, further purified with three types of filters: length, fidelity, and Information Bottleneck. Moreover, we uniquely propose iterative distillation of knowledge, where student models from the previous iteration of distillation serve as teacher models in the next iteration. Starting off from a relatively modest set of GPT3-generated summaries, we demonstrate how iterative knowledge distillation can lead to considerably smaller, but better summarizers with sharper controllability. A useful by-product of this iterative distillation process is a high-quality dataset of sentence-summary pairs with varying degrees of compression ratios. Empirical results demonstrate that the final student models vastly outperform the much larger GPT3-Instruct model in terms of the controllability of compression ratios, without compromising the quality of resulting summarization.1","REFEREE is a new framework for sentence summarization that can be trained without the need for gold summaries. It allows for direct control of compression ratio and uses Symbolic Knowledge Distillation to distill latent knowledge from pre-trained language models. The framework proposes iterative distillation of knowledge, where student models from previous iterations serve as teacher models in the next iteration. The results show that the final student models outperform the much larger GPT3-Instruct model in terms of controllability of compression ratios without compromising the quality of summarization. The iterative distillation process also produces a high-quality dataset of sentence-summary pairs with varying degrees of compression ratios.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to create a more efficient, compact, and controllable summarization model.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but suggests that the promising empirical results of REFEREE encourage further future investigation to extend the framework of symbolic knowledge distillation for reference-free, controlled text summarization.'}",['method'],"['Data Augmentation', 'External Knowledge']",['RealNews'],"['ROUGE', 'BERTScore']","['Faithfulness', 'Relevance', 'Fluency']",https://github.com/msclar/referee,https://aclanthology.org/2022.emnlp-main.655/,"{'Generating high-quality and compact sentence summarizers without using supervised data.': 'The REFEREE framework uses Symbolic Knowledge Distillation to transfer implicit knowledge from a large language model to a smaller student model by explicitly generating knowledge in textual form. This allows REFEREE to be reference-free and begin by distilling from a large language model rather than with supervised data.', 'Improving multiple model aspects in each round such as length, fidelity, and information bottleneck, and allowing explicit length control at generation time.': 'REFEREE controls for more than just overall quality, improving multiple model aspects in each round such as length, fidelity, and information bottleneck, then allowing explicit length control at generation time.', 'Formulating reference-free, controlled sentence summarization as symbolic knowledge distillation.': 'REFEREE is the first to show that reference-free, controlled sentence summarization can be formulated as symbolic knowledge distillation.', 'Generating high-quality summaries at specified lengths with significantly higher accuracy than GPT-3.': 'REFEREE-CONTROL uses iteratively distilled summaries to train a model with explicit length control, which demonstrates a sharp degree of control in length and succeeds at generating high-quality summaries at specified lengths with significantly higher accuracy than GPT-3.'}",unsupervised,['News'],[]
SP:2d28b461955aa91596d4c703f686e438fbd5d166,Unsupervised Opinion Summarisation in the Wasserstein Space,EMNLP,2022,"['Jiayu Song', 'Iman Munire Bilal', 'Adam Tsakalidis', 'Rob Procter', 'Maria Liakata']","Opinion summarisation synthesises opinions expressed in a group of documents discussing the same topic to produce a single summary. Recent work has looked at opinion summarisation of clusters of social media posts. Such posts are noisy and have unpredictable structure, posing additional challenges for the construction of the summary distribution and the preservation of meaning compared to online reviews, which has been so far the focus of opinion summarisation. To address these challenges we present WassOS, an unsupervised abstractive summarization model which makes use of the Wasserstein distance. A Variational Autoencoder is used to get the distribution of documents/posts, and the distributions are disentangled into separate semantic and syntactic spaces. The summary distribution is obtained using the Wasserstein barycenter of the semantic and syntactic distributions. A latent variable sampled from the summary distribution is fed into a GRU decoder with a transformer layer to produce the final summary. Our experiments on multiple datasets including Twitter clusters, Reddit threads, and reviews show that WassOS almost always outperforms the state-of-the-art on ROUGE metrics and consistently produces the best summaries with respect to meaning preservation according to human evaluations.","The paper discusses the challenges of opinion summarization of social media posts and presents WassOS, an unsupervised abstractive summarization model that uses the Wasserstein distance. The model disentangles the distributions of documents/posts into separate semantic and syntactic spaces and obtains the summary distribution using the Wasserstein barycenter. A latent variable is then fed into a GRU decoder with a transformer layer to produce the final summary. The experiments on multiple datasets show that WassOS outperforms the state-of-the-art on ROUGE metrics and consistently produces the best summaries with respect to meaning preservation according to human evaluations.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to help with decision-making and to assist online users in finding relevant information of interest.', 'Who is the target audience?': 'The summaries are for online users who want to quickly understand the opinions of others on a particular topic.', 'How will the summaries be used?': 'The summaries will be used to help with decision-making and to provide relevant information to online users.'}",['method'],['Objective Function'],"['Twitter-COVID19', 'Reddit-COVID19', 'Amazon Product Reviews']",['ROUGE'],"['Non-redundancy', 'Referential Clarity', 'Fluency', 'Meaning Preservation']",https://github.com/Maria-Liakata-NLP-Group/WassOS,https://aclanthology.org/2022.emnlp-main.589/,"{'Most work on unsupervised abstractive opinion summarisation focuses on reviews, but it is also important to capture user opinions in online discussions over specific events or topics on popular social media platforms such as Twitter and Reddit, where the text structure and content is very different and often much noisier compared to review-based corpora.': 'The authors address multi-document unsupervised opinion summarisation from noisy social media data.', 'The main focus of unsupervised abstractive summarisation is the creation of a meaningful summary representation. However, previous work has not considered syntactic and semantic information separately, especially in documents with unpredictable structure.': 'The authors mitigate the potential effect of syntactic information on the acquisition of semantic information through a disentangled method. They combine the disentanglement into separate syntactic spaces from (Bao et al., 2019) with the Wasserstein distance and Wasserstein loss to obtain the summary distribution.', 'Another important consideration is the relative weights of documents within a summary vs obtaining an average.': 'The authors introduce a novel opinion summarisation method (“WassOS”) based on VAE and the Wasserstein barycenter. They disentangle the document distributions into separate semantic and syntactic spaces and introduce these distributions into the Wasserstein space to construct the summary distribution using the Wasserstein barycenter. This strategy can reduce the mutual interference of semantic and syntactic information and identify the representative summary distribution from multiple noisy documents.', 'There is a need for a comparison of the proposed method’s performance with established state-of-the-art (SOTA) unsupervised abstractive summarisation methods on clusters of posts on Twitter, Reddit threads and online reviews.': 'The authors compare their method’s performance with established SOTA unsupervised abstractive summarisation methods on clusters of posts on Twitter, Reddit threads and online reviews.', 'There is a need for both quantitative evaluation through standard summarisation metrics as well as qualitative evaluation of generated summaries.': 'The authors provide both quantitative evaluation through standard summarisation metrics as well as qualitative evaluation of generated summaries. Their results show that their approach outperforms the SOTA on most metrics and datasets while also showing the best performance on meaning preservation during human evaluation.'}",unsupervised,"['Opinions', 'Reviews', 'Social Media']",[]
SP:1a6079d40831cfcbd7a3ae08c333842f2b04484c,Faithful to the Document or to the World? Mitigating Hallucinations via Entity-Linked Knowledge in Abstractive Summarization,EMNLP,2022,"['Yue Dong', 'John Wieting', 'Pat Verga']","Existing abstractive summarization systems are hampered by content hallucinations in which models generate text that is not directly inferable from the source alone. Annotations from prior work have shown that some of these hallucinations, while being ‘unfaithful’ to the source, are nonetheless factual. Our analysis in this paper suggests that these factual hallucinations occur as a result of the prevalence of factual yet unfaithful entities in summarization datasets. We find that these entities are not aberrations, but instead examples of additional world knowledge being readily used to latently connect entities and concepts – in this case connecting entities in the source document to those in the target summary. In our analysis and experiments, we demonstrate that connecting entities to an external knowledge base can lend provenance to many of these unfaithful yet factual entities, and further, this knowledge can be used to improve the factuality of summaries without simply making them more extractive.","The paper discusses how existing abstractive summarization systems generate text that is not directly inferable from the source alone, resulting in content hallucinations. These hallucinations are sometimes factual but unfaithful to the source. The paper suggests that these factual hallucinations occur due to the prevalence of factual yet unfaithful entities in summarization datasets. The authors find that these entities are examples of additional world knowledge being used to connect entities and concepts. They demonstrate that connecting entities to an external knowledge base can improve the factuality of summaries without making them more extractive.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the factuality of abstractive summarization methods, which currently produce content that is not directly supported by the source text.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document, such as researchers, journalists, or the general public.', 'How will the summaries be used?': 'The summaries will be used to provide additional information that is important to understand the content of the source text. They may also be used to evaluate the factuality of generated summaries by linking entity mentions to canonical IDs in a knowledge base.'}","['method', 'analysis']",['External Knowledge'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'FactCC', 'Consistency']",['Factuality'],,https://aclanthology.org/2022.findings-emnlp.76/,"{'Abstractive summarization methods routinely produce content that is not directly supported by the source text, resulting in factual errors.': 'The authors investigate how external knowledge/facts in open-domain KBs can both lend provenance to extrinsic hallucinations and improve the factuality of generated summaries. They propose methods to improve the factuality of summaries by incorporating KB facts, such as a two-stage revision model to edit entities in the generation and a method that incorporates facts from an open-domain KB.', 'Most prior work considers extrinsic hallucinations as undesired, as they are not directly faithfully consistent with the source.': 'The authors suggest that many of these unfaithful hallucinations are actually factual and can provide additional information that is important to understand the content. They focus on improving the factuality of generated abstractive entities by providing additional facts that are relevant to the source.', 'Hallucinations occur as a result of ineffective learning.': 'The authors show that the training data frequently relies on facts that are not explicitly expressed in the text but instead require external knowledge to infer correctly, contradicting the widely held belief that hallucinations occur as a result of ineffective learning.', 'Entities (e.g., person, event, location, organization) in summaries are commonly hallucinated and often contain the most salient information.': 'The authors focus on improving the factuality of generated abstractive entities by providing additional facts that are relevant to the source. They propose entity-based metrics that evaluate the factuality of generations by linking entity mentions to canonical IDs in a KB, and comparing those to linked entities in the gold reference targets. This allows them to account for variations in the surface forms of entities in their evaluation.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:f209dc30a1e87fc639a0e79b1e2347486c144902,Summarizing Community-based Question-Answer Pairs,EMNLP,2022,"['Ting-Yao Hsu', 'Yoshi Suhara', 'Xiaolan Wang']","Community-based Question Answering (CQA), which allows users to acquire their desired information, has increasingly become an essential component of online services in various domains such as E-commerce, travel, and dining. However, an overwhelming number of CQA pairs makes it difficult for users without particular intent to find useful information spread over CQA pairs. To help users quickly digest the key information, we propose the novel CQA summarization task that aims to create a concise summary from CQA pairs. To this end, we first design a multi-stage data annotation process and create a benchmark dataset, COQASUM, based on the Amazon QA corpus. We then compare a collection of extractive and abstractive summarization methods and establish a strong baseline approach DedupLED for the CQA summarization task. Our experiment further confirms two key challenges, sentencetype transfer and deduplication removal, towards the CQA summarization task. Our data and code are publicly available.1","The paper proposes a new task of summarizing Community-based Question Answering (CQA) pairs to help users quickly digest key information. The authors design a multi-stage data annotation process and create a benchmark dataset, COQASUM, based on the Amazon QA corpus. They compare extractive and abstractive summarization methods and establish a strong baseline approach called DedupLED. The experiment confirms two key challenges, sentencetype transfer and deduplication removal, towards the CQA summarization task. The data and code are publicly available.",{},['corpus'],[],['CO-QASUM'],"['ROUGE', 'BERTScore']","['Informativeness', 'Coherence', 'Conciseness']",https://github.com/megagonlabs/qa-summarization,https://aclanthology.org/2022.emnlp-main.250/,"{'CQA contains heavily repetitive QA pairs, making it difficult for users to find and digest key information.': 'The authors propose a novel task of CQA summarization, which aims to summarize a collection of QA pairs about a single entity into a concise summary in declarative sentences.', 'CQA summarization needs to solve sentence-type transfer as questions in interrogative sentences have to be converted into declarative sentences to make a concise summary.': 'The authors develop a multi-stage annotation framework to enable reference summary annotation for CQA summarization. Sampled seed QA pairs are given to the annotator to convert into declarative sentences, which are then rewritten into gold-standard summaries by expert writers.', 'CQA contains duplicated questions and answers, making existing summarization solutions unsuitable for CQA summarization.': 'The authors establish a strong baseline approach, DedupLED, for the CQA summarization task. DedupLED finetunes the entire LED model for summary generation while additional classifier attached to the encoder is optimized to extract representative QA pairs. Leveraging the strengths of both abstractive and extractive summarization objectives, as well as the pre-trained language model checkpoints, DedupLED significantly outperforms the other alternative methods.'}",supervised,['CQA'],[]
SP:16c859f3d6c9dcfa7281dc0e419c988941a7e5ce,BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization,EMNLP,2022,"['Wojciech Kryściński', 'Nazneen Rajani', 'Divyansh Agarwal', 'Caiming Xiong', 'Dragomir Radev']","The majority of existing text summarization datasets include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases. While relevant, such datasets will offer limited challenges for future text summarization systems. We address these issues by introducing BOOKSUM, a collection of datasets for long-form narrative summarization. Our dataset covers documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and booklevel. The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures. To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset.","The paper discusses the limitations of existing text summarization datasets and introduces BOOKSUM, a collection of datasets for long-form narrative summarization. The dataset covers literature documents and includes highly abstractive, human-written summaries on three levels of granularity. The unique challenges posed by the domain and structure of the dataset include processing long documents, non-trivial causal and temporal dependencies, and rich discourse structures. The paper also evaluates multiple extractive and abstractive summarization models as baselines for the dataset.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to condense long documents into a short, human-readable form which contains only the salient parts of the source.', 'Who is the target audience?': 'The summaries are for text summarization systems.', 'How will the summaries be used?': 'The summaries will be used to address the shortcomings of existing datasets and introduce a collection of data resources for long-form narrative summarization. They will also introduce a set of new challenges for summarization systems and will be a viable target for single- and multi-document summarization approaches.'}",['corpus'],[],['BOOKSUM'],"['ROUGE', 'BERTScore', 'SummQA']","['Fluency', 'Coherence', 'Relevance', 'Factuality']",https://github.com/salesforce/booksum,https://aclanthology.org/2022.findings-emnlp.488/,"{'The existing datasets for text summarization focus on short-form documents, which limits the practical value of automatic summarization systems.': 'The authors introduce BOOKSUM, a collection of data resources for long-form narrative summarization, which includes documents from the literature domain ranging up to hundreds of pages.', ""The domains of existing datasets impose strict requirements regarding the document's layout and stylistic features, which can introduce layout biases into the datasets and limit the space for interpretation and reasoning."": 'The authors leverage the characteristics of fiction writing in BOOKSUM, which introduces a set of new challenges for summarization systems, including handling documents with rich discourse structure and generating highly abstractive and compressive summaries.', 'Documents in the existing datasets lack long-range causal and temporal dependencies and rich discourse structures.': 'BOOKSUM includes examples on three levels of granularity with increasing difficulty, including documents with non-trivial causal and temporal dependencies spread out through the entirety of the source and documents with parallel plots or changes between narration and dialogue.'}",,['Books'],[]
SP:0da9ec7997dc902b9614169ee5b9d723a96630f2,NARRASUM: A Large-Scale Dataset for Abstractive Narrative Summarization,EMNLP,2022,"['Chao Zhao', 'Faeze Brahman', 'Kaiqiang Song', 'Wenlin Yao', 'Dian Yu', 'Snigdha Chaturvedi']","Narrative summarization aims to produce a distilled version of a narrative to describe its most salient events and characters. Summarizing a narrative is challenging as it requires an understanding of event causality and character behaviors. To encourage research in this direction, we propose NARRASUM, a largescale narrative summarization dataset. It contains 122K narrative documents, which are collected from plot descriptions of movies and TV episodes with diverse genres, and their corresponding abstractive summaries. Experiments show that there is a large performance gap between humans and the state-of-the-art summarization models on NARRASUM. We hope that this dataset will promote future research in summarization, as well as broader studies of natural language understanding and generation. The dataset is available at https: //github.com/zhaochaocs/narrasum.","The paper proposes NARRASUM, a large-scale narrative summarization dataset containing 122K narrative documents and their corresponding abstractive summaries. The dataset is collected from plot descriptions of movies and TV episodes with diverse genres. The paper highlights the challenges of summarizing a narrative, which requires an understanding of event causality and character behaviors. The experiments show a large performance gap between humans and state-of-the-art summarization models on NARRASUM. The authors hope that this dataset will promote future research in summarization and broader studies of natural language understanding and generation. The dataset is available at https://github.com/zhaochaocs/narrasum.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to produce a distilled version of a narrative, either extractively or abstractively, to contain its most salient events and major characters. This ability is especially crucial for the understanding of narratives, and in general, the understanding of human behaviors and beliefs.', 'Who is the target audience?': 'The summaries are for readers who want to quickly discern the key points of a narrative. They are useful in real-world scenarios such as content recommendations and advertisements.', 'How will the summaries be used?': 'The summaries will be used to enable readers to quickly understand the salient events and major characters of a narrative. They can be used in various real-world scenarios such as content recommendations and advertisements.'}",['corpus'],[],['NARRASUM'],"['ROUGE', 'SummaC']","['Fluency', 'Faithfulness', 'Coherence', 'Informativeness']",https://github.com/zhaochaocs/narrasum,https://aclanthology.org/2022.findings-emnlp.14/,"{'Most existing studies on text summarization focus on news or structured documents, which have specific writing styles and structural cues. However, a typical narrative does not contain such structural cues, making it challenging for a model to identify the salient events and characters.': 'The authors propose an automatic data construction framework to build a large-scale, high-quality narrative summarization dataset. They collect narratives from plot descriptions of movies or TV episodes through online resources, align and verify plot descriptions of the same movie or TV episodes from different sources, and construct document-summary pairs by treating the long plot description as the document to be summarized and the shorter one (of the same movie or TV episode) as the corresponding summary. They filter out low-quality document-summary pairs and build NARRASUM, a large-scale dataset that contains around'}",,['Narratives'],[]
SP:462a01d9b6eaae533ce97cb02c807bc695db21a9,Toward Unifying Text Segmentation and Long Document Summarization,EMNLP,2022,"['Sangwoo Cho', 'Kaiqiang Song', 'Xiaoyang Wang', 'Fei Liu', 'Dong Yu']","Text segmentation is important for signaling a document’s structure. Without segmenting a long document into topically coherent sections, it is difficult for readers to comprehend the text, let alone find important information. The problem is only exacerbated by a lack of segmentation in transcripts of audio/video recordings. In this paper, we explore the role that section segmentation plays in extractive summarization of written and spoken documents. Our approach learns robust sentence representations by performing summarization and segmentation simultaneously, which is further enhanced by an optimization-based regularizer to promote selection of diverse summary sentences. We conduct experiments on multiple datasets ranging from scientific articles to spoken transcripts to evaluate the model’s performance. Our findings suggest that the model can not only achieve state-of-the-art performance on publicly available benchmarks, but demonstrate better crossgenre transferability when equipped with text segmentation. We perform a series of analyses to quantify the impact of section segmentation on summarizing written and spoken documents of substantial length and complexity.","The paper discusses the importance of text segmentation in understanding and summarizing long documents, particularly in transcripts of audio/video recordings. The authors propose an approach that simultaneously performs summarization and segmentation to learn robust sentence representations, which is further enhanced by an optimization-based regularizer to promote selection of diverse summary sentences. The approach was evaluated on multiple datasets and found to achieve state-of-the-art performance on publicly available benchmarks, with better crossgenre transferability when equipped with text segmentation. The paper also includes analyses to quantify the impact of section segmentation on summarizing written and spoken documents of substantial length and complexity.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to extract salient sentences and provide condensed summaries that can be easily viewed and understood.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a lengthy document, including researchers, students, and professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and improve comprehension of long documents. They can also be highlighted on the source material to facilitate viewing and sharing.'}",['method'],['Objective Function'],"['arXiv', 'PubMed', 'VideoLec']",['ROUGE'],"['Informativeness', 'Diversity']",https://github.com/tencent-ailab/Lodoss,https://aclanthology.org/2022.emnlp-main.8/,"{'Extractive summarization of lengthy documents is challenging, especially for spoken transcripts where there are no section boundaries.': 'The authors equip their summarizer with the ability to predict section boundaries and leverage this ability to improve long document summarization. They aim to leverage discourse cues to infer section boundaries, which help summarization of both spoken and written documents.', 'Ensuring that a summary covers a broad range of important topics is pivotal.': 'The authors design a new regularizer drawing on learned sentence representations and determinantal point process to ensure a set of representative and diverse sentences is selected for the summary.', 'It remains an open question as to whether spoken transcripts can be handled in a similar manner as written documents.': 'The authors train their model on written documents with known section boundaries, then adapt it to transcripts where such information is unavailable to exploit its transferability.', 'Text segmentation was previously studied as a standalone problem.': 'The authors enhance extractive summarization with a new addition of section segmentation, performing the two tasks of extractive summarization and section segmentation simultaneously, enhanced by an optimization-based framework to select important and diverse sentences.', 'It is inadequate for a summary to have a narrow information focus and miss the important points of the document.': 'The authors design a new regularizer drawing on learned sentence representations and determinantal point process to ensure a set of representative and diverse sentences is selected for the summary.', 'It is crucial to bring structure to a long document.': 'The authors equip their summarizer with the ability to predict section boundaries and leverage this ability to improve long document summarization. They also investigate a new architecture for extractive long document summarization that has demonstrated a reasonable degree of transferability from written documents to spoken transcripts.'}",supervised,"['Scholarly Documents', 'Lecture Transcripts']",['efficient-encoding-of-long-documents']
SP:043c950e7a00bf138cef5e40fab8703a9ed83120,Analyzing Multi-Task Learning for Abstractive Text Summarization,EMNLP,2022,"['Frederic Kirstein', 'Jan Philip Wahle', 'Terry Ruas', 'Bela Gipp']","Despite the recent success of multi-task learning and pre-finetuning for natural language understanding, few works have studied the effects of task families on abstractive text summarization. Task families are a form of task grouping during the pre-finetuning stage to learn common skills, such as reading comprehension. To close this gap, we analyze the influence of multi-task learning strategies using task families for the English abstractive text summarization task. We group tasks into one of three strategies, i.e., sequential, simultaneous, and continual multi-task learning, and evaluate trained models through two downstream tasks. We find that certain combinations of task families (e.g., advanced reading comprehension and natural language inference) positively impact downstream performance. Further, we find that choice and combinations of task families influence downstream performance more than the training scheme, supporting the use of task families for abstractive text summarization. Our code is publicly available 1.","The paper explores the effects of task families on abstractive text summarization, specifically analyzing the influence of multi-task learning strategies using task families for the English language. The authors group tasks into three strategies and evaluate trained models through two downstream tasks, finding that certain combinations of task families positively impact downstream performance. They also find that choice and combinations of task families influence downstream performance more than the training scheme, supporting the use of task families for abstractive text summarization. The code is publicly available.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to investigate the role of multi-task learning on English abstractive text summarization.', 'Who is the target audience?': 'It is not specified who the summaries are for in the paper.', 'How will the summaries be used?': 'It is not specified how the summaries will be used in the paper.'}",['analysis'],[],"['Reddit-TIFU', 'arXiv']","['METEOR', 'ROUGE', 'BERTScore', 'BLEU']",[],https://github.com/FKIRSTE/GEM_emnlp2022-TOASTS,https://aclanthology.org/2022.gem-1.5/,"{'Self-supervised learning can only learn intrinsic language features, but specific skills necessary for tasks like text summarization require labeled data.': 'The authors investigate the role of multi-task learning on English abstractive text summarization, which aims to acquire multiple skills simultaneously to succeed on downstream tasks.', 'Studies on the effects of multi-task learning on a large scale lack insight on the influence on abstractive text summarization, and multi-task learning approaches are diverse in their methods, hampering their comparison.': 'The authors organize 18 pre-selected training tasks into six higher-level, modular task families and compare three training schemes and their respective mixing strategies through changes of multiple scores.', 'The impact of family choice and co-training of different task families on text summarization is unclear.': 'The authors show that families’ choice significantly impacts text summarization, while pairing a text summarization task family with any other helps to stabilize the overall performance when transferring to unknown data. They also found that a text summarization task family can be substituted by other family pairs, e.g., advanced reading comprehension and classification.'}",,"['Social Media', 'Scholarly Documents']",[]
SP:13a7c64931db28bc061004e695f9bcb46b36bc8c,Don’t Say What You Don’t Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search,EMNLP,2022,"['Daniel King', 'Zejiang Shen', 'Nishant Subramani', 'Daniel S. Weld', 'Iz Beltagy', 'Doug Downey', '†MosaicML ‡MIT Allen']","Abstractive summarization systems today produce fluent and relevant output, but often “hallucinate” statements not supported by the source text. We analyze the connection between hallucinations and training data, and find evidence that models hallucinate because they train on target summaries that are unsupported by the source. Based on our findings, we present PINOCCHIO, a new decoding method that improves the consistency of a transformerbased abstractive summarizer by constraining beam search to avoid hallucinations. Given the model states and outputs at a given step, PINOCCHIO detects likely model hallucinations based on various measures of attribution to the source text. PINOCCHIO backtracks to find more consistent output, and can opt to produce no summary at all when no consistent generation can be found. In experiments, we find that PINOCCHIO improves the consistency of generation by an average of 68% on two abstractive summarization datasets, without hurting recall.ive summarization systems today produce fluent and relevant output, but often “hallucinate” statements not supported by the source text. We analyze the connection between hallucinations and training data, and find evidence that models hallucinate because they train on target summaries that are unsupported by the source. Based on our findings, we present PINOCCHIO, a new decoding method that improves the consistency of a transformerbased abstractive summarizer by constraining beam search to avoid hallucinations. Given the model states and outputs at a given step, PINOCCHIO detects likely model hallucinations based on various measures of attribution to the source text. PINOCCHIO backtracks to find more consistent output, and can opt to produce no summary at all when no consistent generation can be found. In experiments, we find that PINOCCHIO improves the consistency of generation by an average of 68% on two abstractive summarization datasets, without hurting recall.","The paper discusses the issue of ""hallucinations"" in abstractive summarization systems, where the system produces statements not supported by the source text. The authors analyze the connection between hallucinations and training data, and find that models hallucinate because they train on target summaries that are unsupported by the source. They present a new decoding method called PINOCCHIO, which improves the consistency of a transformer-based abstractive summarizer by constraining beam search to avoid hallucinations. PINOCCHIO detects likely model hallucinations based on various measures of attribution to the source text and can backtrack to find more consistent output or produce no summary at all when no consistent generation can be found. The experiments show that PINOCCHIO improves the consistency of generation by an average of 68% on two abstractive summarization datasets without hurting recall.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to compress lengthy source material into concise summaries that satisfy application or user needs.', 'Who is the target audience?': 'The target audience for the generated summaries is not specified in the paper.', 'How will the summaries be used?': 'The potential uses of the generated summaries are not specified in the paper.'}","['corpus', 'method']",['Controlled Generation'],"['SCD', 'CNN/DailyMail', 'XSum']",['ROUGE'],"['Consistency', 'Fluency', 'Relevance', 'Coherence']",https://github.com/allenai/pinocchio,https://aclanthology.org/2022.gem-1.51/,"{'Abstractive summarizers frequently hallucinate information that is inconsistent with the input.': 'The authors propose a new approach called PINOCCHIO, which is a decoding algorithm that constrains beam search to only consider predicted tokens that are likely to be supported by the source text. This significantly improves consistency on two abstractive summarization datasets with only a small decrease in fluency.', 'Training datasets for abstractive summarization are acquired from noisy ""silver"" sources, leading to target summaries that contain statements unsupported by the source text.': 'The authors propose that this disconnect between target and source text leads to a strong tendency to hallucinate information. They suggest that models optimized for likelihood and trained on target summaries containing unsupported statements should say something less ""likely,"" but supported instead.', 'Common automatic evaluation metrics like ROUGE reward lexical similarity significantly more than consistency, preferring hallucinated lexically similar summaries to completely consistent lexically different ones.': ""The authors propose that PINOCCHIO estimates which tokens are likely supported using simple but effective heuristics based on the model's confidence and attention distribution, and word frequency. When PINOCCHIO reaches a state where no supported token can be generated, it backtracks the search. It can also opt-out from generating a summary at all, rather than produce one expected to be hallucinated."", 'Existing methods to assess and improve the consistency of summarization systems tend to reduce the problem of generating consistent text to another difficult problem (e.g. information extraction or natural language inference).': ""The authors propose a different approach for generating more consistent summaries based on the observation that today's abstractive summarizers are often trained on target summaries that contain statements unsupported by the source text. They suggest that constraining beam search to focus on input-supported tokens can significantly improve consistency without relying on additional resources or difficult problems."", 'There is a lack of diverse datasets for abstractive summarization.': 'The authors introduce a new abstractive summarization dataset called Scientific Concept Description (SCD), which uses Wikipedia descriptions as the target summaries and the referenced papers as the source documents. SCD is motivated by the goal of automatically generating a high-quality encyclopedia for the long tail of scientific concepts described in papers, and presents a challenging workload for abstractive summarization.'}",,"['Scholarly Documents', 'News', 'Wikipedia']",['hallucinations-in-the-generated-summaries']
SP:8573c65a40ad837bc3213057a43d17148e6d9f97,HYDRASUM: Disentangling Style Features in Text Summarization with Multi-Decoder Models,EMNLP,2022,"['Tanya Goyal', 'Nazneen Rajani', 'Wenhao Liu', 'Wojciech Kryściński']","Summarization systems make numerous “decisions” about summary properties during inference, e.g. degree of copying, specificity and length of outputs, etc. However, these are implicitly encoded within model parameters and specific styles cannot be enforced. To address this, we introduce HYDRASUM, a new summarization architecture that extends the single decoder framework of current models to a mixture-of-experts version with multiple decoders. We show that HYDRASUM’s multiple decoders automatically learn contrasting summary styles when trained under the standard training objective without any extra supervision. Through experiments on three summarization datasets (CNN, NEWSROOM and XSUM), we show that HYDRASUM provides a simple mechanism to obtain stylistically-diverse summaries by sampling from either individual decoders or their mixtures, outperforming baseline models. Finally, we demonstrate that a small modification to the gating strategy during training can enforce an even stricter style partitioning, e.g. highvs low-abstractiveness or highvs low-specificity, allowing users to sample from a larger area in the generation space and vary summary styles along multiple dimensions.1","The paper introduces HYDRASUM, a new summarization architecture that uses multiple decoders to automatically learn contrasting summary styles without extra supervision. HYDRASUM provides a simple mechanism to obtain stylistically-diverse summaries by sampling from individual decoders or their mixtures, outperforming baseline models on three summarization datasets. A small modification to the gating strategy during training can enforce an even stricter style partitioning, allowing users to vary summary styles along multiple dimensions.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the stylistic diversity and quality of abstractive summarization systems.', 'Who is the target audience?': 'The summaries are for end users who want to specify their stylistic preferences for generated summaries.', 'How will the summaries be used?': 'The summaries will be used to provide a more diverse set of summaries with varying degrees of abstractiveness, readability, specificity, and length. They can be used for various applications such as news article summarization, document summarization, and more.'}",['method'],"['Objective Function', 'Controlled Generation']","['CNN/DailyMail', 'XSum', 'Newsroom']",['ROUGE'],"['Relevance', 'Coherence', 'Grammaticality', 'Factuality']",https://github.com/salesforce/hydra-sum,https://aclanthology.org/2022.emnlp-main.30/,"{'Current summarization systems implicitly encode stylistic decisions in their parameters, but provide no mechanism for end users to specify their stylistic preferences. Commonly used decoding methods tend to generate stylistically similar outputs, and cannot be queried for multiple diverse summaries without sacrificing quality.': 'The authors propose HYDRASUM - a new summarization architecture that disentangles the different stylistic decisions made by abstractive summarization models from the models weights into an explicit model component. This allows for multiple diverse summaries to be generated without sacrificing quality.', 'Prior work in style transfer targets styles that are not relevant to summarization and use explicit interventions to enforce style.': 'The authors propose to investigate what style combinations naturally occur in abstractive summarization datasets and whether models can automatically disentangle them.', 'Individual decoders cannot cover the range of stylistic variations in the dataset.': 'The authors propose a mixture-of-experts with multiple decoders for summary generation. At each time step of the generation phase, the next token’s probability distribution is computed by combining the output probabilities of all individual decoders. This allows for the distribution of diverse stylistic and lexical features encountered in the training data across the parameters of separate decoders.', 'There is a lack of stylistic diversity in baseline models.': 'The authors show that their proposed HYDRASUM model automatically assigns distinct summary “skills” to different decoders during training, which can be operationalized to obtain multiple summaries exhibiting better stylistic diversity and Top-K quality compared to baseline models.', 'There is no mechanism for multi-style variation in summary generation.': 'The authors demonstrate that a simple data preprocessing and gating strategy during training can be used to explicitly dictate which feature is partitioned across different decoders, providing a mechanism for multi-style variation in summary generation.'}",supervised,['News'],['controlled-and-tailored-summarization']
SP:00cc91d34fbd56d7ae70b2aaecd7c4004c251fb3,Improving Faithfulness by Augmenting Negative Summaries from Fake Documents,EMNLP,2022,"['Tianshu Wang', 'Faisal Ladhak', 'Esin Durmus', 'He He']","Current abstractive summarization systems tend to hallucinate content that is unfaithful to the source document, posing a risk of misinformation. To mitigate hallucination, we must teach the model to distinguish hallucinated summaries from faithful ones. However, the commonly used maximum likelihood training does not disentangle factual errors from other model errors. To address this issue, we propose a back-translation-style approach to augment negative samples that mimic factual errors made by the model. Specifically, we train an elaboration model that generates hallucinated documents given the reference summaries, and then generates negative summaries from the fake documents. We incorporate the negative samples into training through a controlled generator, which produces faithful/unfaithful summaries conditioned on the control codes. Additionally, we find that adding textual entailment data through multitasking further boosts the performance. Experiments on three datasets (XSum, GigaWord, and WikiHow) show that our method consistently improves faithfulness without sacrificing informativeness according to both human and automatic evaluation.1","The paper discusses the issue of current abstractive summarization systems producing summaries that are unfaithful to the source document, which can lead to misinformation. The authors propose a back-translation-style approach to augment negative samples that mimic factual errors made by the model, in order to teach the model to distinguish between faithful and unfaithful summaries. They also incorporate textual entailment data through multitasking to further improve performance. Experiments on three datasets show that their method consistently improves faithfulness without sacrificing informativeness.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to address the challenge of generated summaries being often unfaithful to the source document, containing hallucinated, non-factual content.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of the source document.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the content of the source document, without having to read the entire document.'}",['method'],['Data Augmentation'],"['XSum', 'Gigaword', 'WikiHow']","['ROUGE', 'BERTScore', 'QuestEval', 'Coverage', 'Density', 'Extractiveness']",['Faithfulness'],https://github.com/COFE2022/CoFE,https://aclanthology.org/2022.emnlp-main.816/,"{'The generated summaries by text summarization systems are often unfaithful to the source document, containing hallucinated, non-factual content.': 'The authors propose to explicitly teach the model to discriminate between positive (groundtruth) and negative (unfaithful) summaries. They generate unfaithful summaries using a simple method inspired by back-translation, where they first generate fake documents using an elaboration model that is trained to produce a document given the summary. They then generate summaries from the fake documents, which are assumed to be unfaithful since they are likely to contain hallucinated information in the fake documents.', 'The key challenge is to generate realistic negative samples.': 'The authors propose to generate unfaithful summaries using a simple method inspired by back-translation, where they first generate fake documents using an elaboration model that is trained to produce a document given the summary. They then generate summaries from the fake documents, which are assumed to be unfaithful since they are likely to contain hallucinated information in the fake documents.', 'Existing work on negative data augmentation mainly focuses on corrupting the reference or sampling low-probability model outputs, which often does not resemble actual hallucinations from the model and many methods rely on external tools such as NER taggers.': 'The authors propose a new method to generate unfaithful summaries using a simple method inspired by back-translation, which does not rely on external tools such as NER taggers and is assumed to be more realistic than existing methods.', 'Current summarization models are usually trained by maximum likelihood estimation (MLE), where unfaithful and faithful summaries are penalized equally if they both deviate from the reference. As a result, when the model fails to imitate the reference, it is likely to “over-generalize” and produce hallucinated content.': 'The authors propose a controlled generation model that generates either faithful or unfaithful summaries conditioned on a faithfulness control code. At inference time, they control the model to generate only faithful summaries.', 'The authors want to improve the result of their approach by incorporating additional data easily.': 'The authors use natural language inference (NLI) datasets to generate entailed (faithful) and non-entailed (unfaithful) hypotheses, which further improves the result of their approach.'}",,"['News', 'CQA']",['hallucinations-in-the-generated-summaries']
SP:0482b23683c2b8fa25a453f9bac117c680e21023,Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents,EMNLP,2022,"['Marcio Fonseca', 'Yftah Ziser', 'Shay B. Cohen']","We argue that disentangling content selection from the budget used to cover salient content improves the performance and applicability of abstractive summarizers. Our method, FACTORSUM1, does this disentanglement by factorizing summarization into two steps through an energy function: (1) generation of abstractive summary views covering salient information in subsets of the input document (document views) ; (2) combination of these views into a final summary, following a budget and content guidance. This guidance may come from different sources, including from an advisor model such as BART or BigBird, or in oracle mode – from the reference. This factorization achieves significantly higher ROUGE scores on multiple benchmarks for long document summarization, namely PubMed, arXiv, and GovReport. Notably, our model is effective for domain adaptation. When trained only on PubMed, it achieves a 46.29 ROUGE-1 score on arXiv, outperforming PEGASUS trained in domain by a large margin. Our experimental results indicate that the performance gains are due to more flexible budget adaptation and processing of shorter contexts provided by partial document views.","The paper proposes a method called FACTORSUM1 that disentangles content selection from the budget used to cover salient content, improving the performance and applicability of abstractive summarizers. This is achieved by factorizing summarization into two steps through an energy function: (1) generation of abstractive summary views covering salient information in subsets of the input document (document views); (2) combination of these views into a final summary, following a budget and content guidance. The model achieves significantly higher ROUGE scores on multiple benchmarks for long document summarization, and is effective for domain adaptation. The performance gains are due to more flexible budget adaptation and processing of shorter contexts provided by partial document views.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide a reductive transformation of the source text that keeps the important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries will be used as a quick reference to understand the main points of a long document, without having to read the entire text. They can also be used for information retrieval or to compare different documents on a similar topic.'}",['method'],"['Objective Function', 'External Knowledge']","['PubMed', 'arXiv', 'GovReport']",['ROUGE'],[],https://github.com/thefonseca/factorsum,https://aclanthology.org/2022.emnlp-main.426/,"{'The current framework for summarization conflates multiple steps of the decision-making process into a single feedforward step without taking into account contextual factors involved.': 'The authors propose to avoid budget information as a confounding factor as much as possible in sequence-to-sequence training. Instead, they treat budget decisions as extrinsic guidance during summary generation, that is, an objective that is unrelated to the content of the documents.', 'The quantity of information to be included in a summary depends on contextual factors, and current evaluation protocols based on n-gram overlap are sensitive to summary lengths.': 'The authors propose to formulate FACTORSUM, a factorized energy-based model aiming to find a summary that maximizes the total importance given a source document, a reference dataset, and contextual factors such as budget and content guidance. They also sample random document views to allow the abstractive model to focus on shorter summarization tasks with less influence of varying summary lengths.', 'Recent progress in summarization may be the effect of better length prediction and not the actual summarization desideratum.': 'The authors propose to optimize the model parameters so that summary views with important content (as informed by reference summaries) will have lower energies. They also use a greedy optimization algorithm during inference to find the combination of summary views that maximize the compatibility with the target budget and other types of guidance.', 'Truncation is a recurring problem in summarization.': 'The authors use the sampling procedure to allow the processing of long documents without truncation.', 'Models trained on one dataset may not perform well on out-of-domain data.': 'The authors perform domain adaptation experiments and show that FACTORSUM can adapt better to out-of-domain data, outperforming strong baselines trained in domain on both PubMed and arXiv.'}",supervised,"['Scholarly Documents', 'Govt. Reports']",['efficient-encoding-of-long-documents']
SP:83ff88febe427d47fde5fd14a4da2a026f09fd76,SQuALITY: Building a Long-Document Summarization Dataset the Hard Way,EMNLP,2022,"['Alex Wang', 'Richard Yuanzhe Pang', 'Angelica Chen', 'Jason Phang', 'Samuel R. Bowman']","Summarization datasets are often assembled either by scraping naturally occurring publicdomain summaries—which are nearly always in difcult-to-work-with technical domains— or by using approximate heuristics to extract them from everyday text—which frequently yields unfaithful summaries. In this work, we turn to a slower but more straightforward approach to developing summarization benchmark data: We hire highly-qualied contractors to read stories and write original summaries from scratch. To amortize reading time, we collect ve summaries per document, with the rst giving an overview and the subsequent four addressing specic questions. We use this protocol to collect SQuALITY, a dataset of question-focused summaries built on the same public-domain short stories as the multiple-choice dataset QuALITY (Pang et al., 2021b). Experiments with stateof-the-art summarization systems show that our dataset is challenging and that existing automatic evaluation metrics are weak indicators of quality. SQuALITY is available at https: //github.com/nyu-mll/SQuALITY.","The paper discusses the challenges of assembling summarization datasets and proposes a new approach of hiring contractors to write original summaries from scratch. The resulting dataset, SQuALITY, consists of question-focused summaries and is shown to be challenging for state-of-the-art summarization systems. The authors also note that existing automatic evaluation metrics are weak indicators of summary quality. SQuALITY is available for use at https://github.com/nyu-mll/SQuALITY.",{'Who is the target audience?': 'The summaries are for researchers and organizations interested in developing and evaluating automatic text summarization models.'},['corpus'],[],['SQuALITY'],"['ROUGE', 'BERTScore', 'METEOR']","['Correctness', 'Coverage', 'Overall Quality']",https://github.com/nyu-mll/SQuALITY,https://aclanthology.org/2022.emnlp-main.75/,"{'Existing datasets for automatic text summarization have issues that limit their usability, such as HTML artifacts, links to other news articles, and other types of noise.': 'The authors propose a crowdsourcing protocol for collecting original summaries that are free of these issues. They use short stories from Project Gutenberg to avoid domain and licensing issues.', 'Common approaches to creating summarization datasets, such as developing heuristics to extract pseudosummaries from existing texts or relying on serendipity in finding naturally occurring summaries, do not produce reliable data.': 'The authors propose a crowdsourcing protocol for collecting original summaries that is agnostic to the input documents used, so they are free to choose the input documents they want to summarize.', 'Found summarization data is often proprietary and not freely distributable, which can be a serious obstacle to reproducibility.': 'The authors propose a crowdsourcing protocol for collecting original summaries that is distributed with a CC BY license.', 'Crowdsourcing summaries is quite labor-intensive and can be costly.': 'The authors structure their crowdsourcing protocol in a way that makes the cost per summary more tractable (∼$6/summary) while also including incentives and checks to ensure the summaries are high-quality.', 'Automatic evaluation metrics for summarization are unreliable, and having multiple references when computing automatic evaluation metrics does not improve the correlation of the metric.': 'The authors conduct human evaluation experiments on their SQuALITY dataset and find that state-of-the-art summarization models produce summaries that are significantly worse than human-written summaries. They also identify the poor correlation between automatic evaluation metrics and human judgments of quality.'}",,['Short Stories'],[]
SP:6e5d4f71ef678f068c733b7a4429ab3bc7e03bc6,HEGEL: Hypergraph Transformer for Long Document Summarization,EMNLP,2022,"['Haopeng Zhang', 'Xiao Liu', 'Jiawei Zhang']","Extractive summarization for long documents is challenging due to the extended structured input context. The long-distance sentence dependency hinders cross-sentence relations modeling, the critical step of extractive summarization. This paper proposes HEGEL, a hypergraph neural network for long document summarization by capturing high-order crosssentence relations. HEGEL updates and learns effective sentence representations with hypergraph transformer layers and fuses different types of sentence dependencies, including latent topics, keywords coreference, and section structure. We validate HEGEL by conducting extensive experiments on two benchmark datasets, and experimental results demonstrate the effectiveness and efficiency of HEGEL.","The paper discusses the challenges of extractive summarization for long documents due to the extended structured input context and long-distance sentence dependency. It proposes HEGEL, a hypergraph neural network that captures high-order cross-sentence relations to improve summarization. HEGEL uses hypergraph transformer layers to update and learn effective sentence representations and fuses different types of sentence dependencies, including latent topics, keywords coreference, and section structure. The paper validates HEGEL through extensive experiments on two benchmark datasets, demonstrating its effectiveness and efficiency.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to create a shorter version of the original document while preserving the most important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a long scientific paper.', 'How will the summaries be used?': 'The summaries can be used to save time and help researchers quickly identify relevant papers for their work. They can also be used by non-experts who need to understand the main points of a scientific paper without reading the entire document.'}",['method'],"['Input Encoding', 'Unit Relationship']","['arXiv', 'PubMed']",['ROUGE'],[],https://github.com/hpzhang94/hegel_sum,https://aclanthology.org/2022.emnlp-main.692/,"{'Long structured input hinders sequential models like RNN from capturing sentence-level long-distance dependency and cross-sentence relations, which are essential for extractive summarization.': 'Researchers have turned to graph neural network (GNN) approaches to model cross-sentence relations. They generally represent a document with a sentence-level graph and turn extractive summarization into a node classification problem.', 'These methods only model the pairwise interaction between sentences, while sentence interactions could be triadic, tetradic, or of a higher-order in natural language. How to capture high-order cross-sentence relations for extractive summarization is still an open question.': 'To better model high-order cross-sentence relations, the authors propose HEGEL, a graph-based model designed for summarizing long documents with rich discourse information. They represent a document as a hypergraph, a generalization of graph structure, in which an edge can join any number of vertices.', 'Graph-based approaches rely on either semantic or discourses structure cross-sentence relation but are incapable of fusing sentence interactions from different perspectives.': 'The authors propose three types of hyperedges (section, topic, and keyword) that capture sentence dependency from different perspectives. Hypergraph transformer layers are then designed to update and learn effective sentence representations by message passing on the hypergraph.', 'The usability of existing graph-based approaches is limited by their inability to capture multi-type cross-sentence relations.': 'Capturing multi-type cross-sentence relations could benefit sentence representation learning and sentence salience modeling. The authors propose a model that can capture different types of sentence interactions, such as embedding similarity, keywords coreference, topical modeling from the semantic perspective, and section or rhetorical structure from the discourse perspective.', 'There is a lack of effective models for extractive summarization of long scientific documents.': 'The authors propose HEGEL, a hypergraph neural model for long document summarization. They validate HEGEL by conducting extensive experiments and analyses on two benchmark datasets, and experimental results demonstrate the effectiveness and efficiency of HEGEL.'}",supervised,['Scholarly Documents'],['efficient-encoding-of-long-documents']
SP:5444c051b379d13474b91e12edb0fa05a90bdf8d,Long Text and Multi-Table Summarization: Dataset and Method,EMNLP,2022,"['Shuaiqi Liu', 'Jiannong Cao', 'Ruosong Yang', 'Zhiyuan Wen']","Automatic document summarization aims to produce a concise summary covering the input document’s salient information. Within a report document, the salient information can be scattered in the textual and non-textual content. However, existing document summarization datasets and methods usually focus on the text and filter out the non-textual content. Missing tabular data can limit produced summaries’ informativeness, especially when summaries require covering quantitative descriptions of critical metrics in tables. Existing datasets and methods cannot meet the requirements of summarizing long text and multiple tables in each report. To deal with the scarcity of available data, we propose FINDSum, the first largescale dataset for long text and multi-table summarization. Built on 21,125 annual reports from 3,794 companies, it has two subsets for summarizing each company’s results of operations and liquidity. To summarize the long text and dozens of tables in each report, we present three types of summarization methods. Besides, we propose a set of evaluation metrics to assess the usage of numerical information in produced summaries. Dataset analyses and experimental results indicate the importance of jointly considering input textual and tabular data when summarizing report documents.","The paper discusses the limitations of existing document summarization methods that focus only on text and filter out non-textual content, such as tables. To address this, the authors propose FINDSum, a large-scale dataset for long text and multi-table summarization. The dataset is built on 21,125 annual reports from 3,794 companies and has two subsets for summarizing each company's results of operations and liquidity. The authors present three types of summarization methods and propose evaluation metrics to assess the usage of numerical information in produced summaries. The paper highlights the importance of jointly considering input textual and tabular data when summarizing report documents.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to support readers in quickly browsing salient information in report documents, which usually contain textual and tabular content.', 'Who is the target audience?': 'The summaries are for non-specialized readers who need to efficiently read and gather salient information from report documents, such as financial reports, investigative reports, and technical reports.', 'How will the summaries be used?': 'The summaries will be used to provide informative, fluent, and non-redundant summaries for the long text and multiple tables in each report, which can help readers analyze and make decisions based on the critical metrics recorded in tables.'}",['corpus'],[],['FINDSum'],"['ROUGE', 'BLEU']",[],https://github.com/StevenLau6/FINDSum,https://aclanthology.org/2022.findings-emnlp.145/,"{'Scarcity of available data for long text and multi-table summarization.': 'The authors propose FINDSum, the first large-scale dataset for long text and multi-table summarization, with two subsets named FINDSum-ROO and FINDSum-Liquidity.', 'Difficulty in identifying the salient information scattered in a large amount of input content.': 'The authors adopt the Maximum Marginal Recall Gain (MMRG) method to select salient text segments as a part of inputs and transform each table cell into a tuple and regard the salient tuple selection as a binary classification problem.', 'Incorporating different types of content when generating summaries.': 'The authors present three types of summarization methods: generate-and-combine (GC), combine-and-generate (CG), and generate-combine-and-generate (GCG).', 'Models’ efficiency in processing long inputs and outputs.': 'The authors employ content selection methods and sparse attention mechanisms to reduce the complexity and enable finetuning large pre-trained models over long inputs on an off-the-shelf GPU. They also employ a divide-and-conquer-based approach to generate summary segments in parallel and combine them as the final summary.', 'Difficulty in assessing the usage of numerical information in produced summaries.': 'The authors propose a set of evaluation metrics in addition to the commonly used ROUGE scores (Lin, 2004) to assess the usage of numerical information in produced summaries.'}",,['Financial Reports'],[]
SP:66bd5aba7a003315bc46cd95ea9e6e94704ba699,Improving Factual Consistency in Summarization with Compression-Based Post-Editing,EMNLP,2022,"['Alexander R. Fabbri', 'Prafulla Kumar Choubey', 'Jesse Vig', 'Chien-Sheng Wu', 'Caiming Xiong']","State-of-the-art summarization models still struggle to be factually consistent with the input text. A model-agnostic way to address this problem is post-editing the generated summaries. However, existing approaches typically fail to remove entity errors if a suitable input entity replacement is not available or may insert erroneous content. In our work, we focus on removing extrinsic entity errors, or entities not in the source, to improve consistency while retaining the summary’s essential information and form. We propose to use sentence-compression data to train the post-editing model to take a summary with extrinsic entity errors marked with special tokens and output a compressed, well-formed summary with those errors removed. We show that this model improves factual consistency while maintaining ROUGE, improving entity precision by up to 30% on XSum, and that this model can be applied on top of another post-editor, improving entity precision by up to a total of 38%. We perform an extensive comparison of post-editing approaches that demonstrate trade-offs between factual consistency, informativeness, and grammaticality, and we analyze settings where posteditors show the largest improvements.","The paper discusses the problem of factual inconsistency in summarization models and proposes a model-agnostic approach to address it through post-editing. The focus is on removing extrinsic entity errors, or entities not in the source, to improve consistency while retaining the summary's essential information and form. The proposed method uses sentence-compression data to train the post-editing model to remove errors marked with special tokens. The model improves factual consistency while maintaining ROUGE and can be applied on top of another post-editor, improving entity precision by up to a total of 38%. The paper also compares different post-editing approaches and analyzes settings where post-editors show the largest improvements.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to compress a long document(s) into a short and fluent form that preserves salient information.', 'Who is the target audience?': 'The target audience for the summaries is not specified in the given paper.', 'How will the summaries be used?': 'The usage of the summaries is not specified in the given paper.'}",['method'],['Post Processing'],['XSum'],"['ROUGE', 'BERTScore', 'DAE', 'QAFactEval', 'CoLA']",['Consistency'],https://github.com/salesforce/CompEdit,https://aclanthology.org/2022.emnlp-main.623/,"{'State-of-the-art text summarization models are often not factually consistent with the input they are conditioned on.': 'The authors propose a model-agnostic approach to post-edit the summaries, focusing on removing extrinsic entity errors. They propose a post-editing model that performs controlled compression, generating a compressed output with the specified entities removed.', 'Prior work in post-editing for factual consistency has focused on swapping inconsistent entities with those in the input, but a suitable entity replacement is often not available from the source.': 'The authors propose a perturber model that maps a compressed sentence and a list of entities to an uncompressed sentence containing those entities. They then apply the perturber model to insert entities on a subset of the target dataset whose summaries contain only named entities also found in the input.', 'There is a need to better understand the trade-offs between factual consistency, informativeness, and grammaticality in post-editing methods.': 'The authors perform an extensive comparison of prior post-editing methods across two datasets and six summarization models to better understand these trade-offs. They also make their models publicly available.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:27fc49ac783659aee5d3cd05517c06d19391adf0,Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature,EMNLP,2022,"['Tomas Goldsack', 'Zhihao Zhang', 'Chenghua Lin', 'Carolina Scarton']","Lay summarisation aims to jointly summarise and simplify a given text, thus making its content more comprehensible to non-experts. Automatic approaches for lay summarisation can provide significant value in broadening access to scientific literature, enabling a greater degree of both interdisciplinary knowledge sharing and public understanding when it comes to research findings. However, current corpora for this task are limited in their size and scope, hindering the development of broadly applicable data-driven approaches. Aiming to rectify these issues, we present two novel lay summarisation datasets, PLOS (large-scale) and eLife (medium-scale), each of which contains biomedical journal articles alongside expert-written lay summaries. We provide a thorough characterisation of our lay summaries, highlighting differing levels of readability and abstractiveness between datasets that can be leveraged to support the needs of different applications. Finally, we benchmark our datasets using mainstream summarisation approaches and perform a manual evaluation with domain experts, demonstrating their utility and casting light on the key challenges of this task. Our code and datasets are available at https://github.com/TGoldsack1/ Corpora_for_Lay_Summarisation.","The paper discusses the importance of lay summarisation in making scientific literature more accessible to non-experts. It highlights the limitations of current corpora for this task and presents two new datasets, PLOS and eLife, containing biomedical journal articles and expert-written lay summaries. The paper characterizes the lay summaries and benchmarks them using mainstream summarization approaches, demonstrating their utility and identifying key challenges. The datasets and code are available for use.","{'What is the purpose of the summaries?': 'The authors are generating summaries of scientific documents to make them more accessible to a wider audience, as scientific publications tend to be highly technical and difficult to comprehend for those lacking the required expertise.', 'Who is the target audience?': 'The summaries are for members of the public, journalists, and others who may not have the necessary background knowledge to understand the technical language used in scientific publications.', 'How will the summaries be used?': 'The summaries will be used to provide a clear and concise explanation of the context and significance of scientific articles using non-specialist language. They can be generated automatically using text summarization techniques, which can help to make scientific content more accessible to a wider audience.'}",['corpus'],[],"['PLOS Medicine', 'eLife']","['ROUGE', 'FKGL', 'DCRS']","['Comprehenesiveness', 'Layness', 'Factuality']",https://github.com/TGoldsack1/Corpora_for_Lay_Summarisation,https://aclanthology.org/2022.emnlp-main.724/,"{'Scientific publications are highly technical and use domain-specific language, making them difficult for lay people to understand, which limits the impact of research to only its direct community and can cause misinterpretation of research findings.': 'Some academic journals publish lay summaries that explain the context and significance of an article using non-specialist language. Automatic text summarisation can also provide significant value in generating scientific lay summaries.', 'Previous datasets for training supervised summarisation models for lay summarisation are relatively small and fragmented in terms of their framing of the task, hindering the development of usable models that can make scientific content accessible to a wider audience.': 'The authors introduce two new datasets derived from different academic journals within the biomedical domain - PLOS and eLife - that use the full journal article as the source, enabling the training of models that can be broadly applied to wider literature. The datasets cater to different audiences and applications, and the authors conduct an in-depth characterisation of the lay summaries within each dataset to quantify ways in which they differ from the technical abstract and from each other.', 'The utility of the new datasets and key challenges for the task of lay summarisation need to be evaluated.': 'The authors benchmark the datasets with popular summarisation approaches using automatic metrics and conduct an expert-based manual evaluation to highlight their utility and key challenges for the task of lay summarisation. The paper also includes a literature review, conclusions, and a discussion on its limitations.'}",,['Scholarly Documents'],[]
SP:04713930eb36756b7a1164e3433fdd722559a03c,Revisiting text decomposition methods for NLI-based factuality scoring of summaries,EMNLP,2022,"['John Glover', 'Federico Fancellu', 'Vasudevan Jagannathan', 'Matthew R. Gormley', 'Thomas Schaaf']","Scoring the factuality of a generated summary involves measuring the degree to which a target text contains factual information using the input document as support. Given the similarities in the problem formulation, previous work has shown that Natural Language Inference models can be effectively repurposed to perform this task. As these models are trained to score entailment at a sentence level, several recent studies have shown that decomposing either the input document or the summary into sentences helps with factuality scoring. But is fine-grained decomposition always a winning strategy? In this paper we systematically compare different granularities of decomposition – from document to sub-sentence level, and we show that the answer is no. Our results show that incorporating additional context can yield improvement, but that this does not necessarily apply to all datasets. We also show that small changes to previously proposed entailment-based scoring methods can result in better performance, highlighting the need for caution in model and methodology selection for downstream tasks.","The paper discusses the use of Natural Language Inference models to score the factuality of generated summaries. Previous studies have shown that decomposing either the input document or the summary into sentences can improve factuality scoring. However, the paper systematically compares different granularities of decomposition and shows that fine-grained decomposition is not always the best strategy. The results also suggest that incorporating additional context can improve performance, but this may not apply to all datasets. The paper highlights the importance of caution in model and methodology selection for downstream tasks.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the performance of abstractive summarization models.', 'Who is the target audience?': 'The summaries are for machine-generated output, and the authors are interested in accurately measuring the degree to which the output is non-factual.', 'How will the summaries be used?': 'The summaries will be used for factuality scoring and other closely related tasks such as fact verification, where the objective is to assess whether or to what degree the claims in a given text can be supported by other ""evidence"" texts. The authors propose repurposing Natural Language Inference (NLI) models for factuality scoring, and they perform a systematic comparison of input-summary decomposition methodologies at different levels of granularity to improve model performance.'}",['analysis'],[],['SummaC'],"['SummaC', 'FRANK']",[],,https://aclanthology.org/2022.gem-1.7/,"{'Machine-generated summaries are prone to generating non-factual statements.': 'Develop factuality scoring methods to accurately measure the degree to which machine-generated output is non-factual.', 'NLI models are usually trained with sentence pairs as input and can suffer performance degradation with longer contexts that arise in summarization.': 'Repurpose NLI models for factuality scoring by decomposing the input text into finer levels of granularity, followed by a later score aggregation step.', 'The majority of modern NLI models are based on architectures such as the Transformer that use fixed-length input sizes, and it may not be possible for a full document and summary pair to fit into this context.': 'Explore different levels of granularity for input-summary decomposition, from document to sub-sentence level.', 'Previous findings suggest that a more fine-grained decomposition approach is better for factuality scoring.': 'Show that adding more context to the premise (the source document) can sometimes outperform approaches based on a more fine-grained decomposition.', 'Small changes to the factuality scoring function can lead to a substantial increase in performance, but model performance does not necessarily generalize across benchmarks that use different metrics.': 'Highlight the need for caution and additional evaluation when selecting a model and methodology for downstream tasks.'}",,['News'],[]
SP:0897651719c89033a6687d8dfee76832acfaa3cf,Learning to Revise References for Faithful Summarization,EMNLP,2022,"['Griffin Adams', 'Han-Chin Shing', 'Qing Sun', 'Christopher Winestock', 'Kathleen McKeown', 'Noémie Elhadad']","In real-world scenarios with naturally occurring datasets, reference summaries are noisy and may contain information that cannot be inferred from the source text. On large news corpora, removing low quality samples has been shown to reduce model hallucinations. Yet, for smaller, and/or noisier corpora, filtering is detrimental to performance. To improve reference quality while retaining all data, we propose a new approach: to selectively rewrite unsupported reference sentences to better reflect source data. We automatically generate a synthetic dataset of positive and negative revisions by corrupting supported sentences and learn to revise reference sentences with contrastive learning. The intensity of revisions is treated as a controllable attribute so that, at inference, diverse candidates can be over-generated-then-rescored to balance faithfulness and abstraction. To test our methods, we extract noisy references from publicly available MIMIC-III discharge summaries for the task of hospital-course summarization, and vary the data on which models are trained. According to metrics and human evaluation, models trained on revised clinical references are much more faithful, informative, and fluent than models trained on original or filtered data.","The paper proposes a new approach to improve the quality of reference summaries while retaining all data. The approach involves selectively rewriting unsupported reference sentences to better reflect source data. A synthetic dataset of positive and negative revisions is automatically generated, and models are trained to revise reference sentences with contrastive learning. The intensity of revisions is treated as a controllable attribute to balance faithfulness and abstraction. The proposed method is tested on noisy references from publicly available MIMIC-III discharge summaries for hospital-course summarization, and models trained on revised clinical references are found to be more faithful, informative, and fluent than models trained on original or filtered data.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to address the issue of unfaithful summaries produced by abstractive systems. They propose a new approach to revise noisy reference content in order to retain faithful content, remove unfaithful content, and add relevant context.', 'Who is the target audience?': 'The summaries are for clinical summarization, specifically for summarizing a hospital admission using notes from the Electronic Health Record (EHR). The authors extract a corpus from a noisy source and propose a new method to address variable reference quality.', 'How will the summaries be used?': 'The summaries will be used to improve faithfulness, informativeness, and fluency in clinical summarization. The proposed method of reference revision can be used as a data preprocessing step, a post-hoc editor, and a pre-training objective for faithfulness. The authors provide code, pre-processed datasets, and models for alignment, corruption, revision, post-hoc editing, and generation of clinical summaries.'}",['method'],"['Data Augmentation', 'Post Processing']",['MIMIC-III'],"['Hallucination Rate', 'BERTScore', 'Entailment', 'Faithful-Adjusted Recall']","['Consistency', 'Relevance', 'Fluency', 'Coherence']", https://github.com/amazon-research/summary-reference-revision,https://aclanthology.org/2022.findings-emnlp.296/,"{'Many corpora used for training models are naturally occurring and noisy, which can lead to unfaithful summaries.': 'The authors propose a new approach called reference revision, which involves revising noisy reference content instead of removing it. They align each reference sentence to 1-5 sentences in the source text and classify it as supported or unsupported. Their objective is to revise all unsupported reference sentences in such a way that retains faithful content, removes unfaithful content, and adds relevant context as needed to preserve length.', 'Noisy data is detrimental to training faithful models.': 'The authors generate synthetic data to learn the revision task. They take each supported sentence, corrupt it to form a diverse set of unsupported alternatives, and use this mix of real and synthetic data to create examples of (un)faithful revisions for contrastive learning.', 'Data coverage is a huge issue in clinical summarization as only 60% of reference summary entities can be found in the source.': 'The authors experiment with the publicly available MIMIC-III dataset and treat the Brief Hospital Course (BHC) section of the discharge summary as a reference summary and all notes prior to discharge as source.', 'Filtering low quality text at the reference or span level is a common approach to deal with training noise, but it largely works because it is applied to clean, large-scale corpora.': 'The authors propose a new method that takes advantage of all available data while seeking to redress the underlying issue of noisy data.', 'Faithfulness is less studied for clinical summarization because most proposed methods are extractive.': 'The authors propose an abstractive approach to clinical summarization using their reference revision method. They show that training on revised references can improve faithfulness while also improving informativeness and fluency.'}",,['Medical Reports'],"['hallucinations-in-the-generated-summaries', 'controlled-and-tailored-summarization']"
SP:a900428d612e6b3bcd9f28c4489a2d1324c39430,Learning with Rejection for Abstractive Text Summarization,EMNLP,2022,"['Meng Cao', 'Yue Dong', 'Jingyi He', 'Jackie Chi', 'Kit Cheung']","State-of-the-art abstractive summarization systems frequently hallucinate content that is not supported by the source document, mainly due to noise in the training dataset. Existing methods opt to drop the noisy samples or tokens from the training set entirely, reducing the effective training set size and creating an artificial propensity to copy words from the source. In this work, we propose a training objective for abstractive summarization based on rejection learning, in which the model learns whether or not to reject potentially noisy tokens. We further propose a regularized decoding objective that penalizes non-factual candidate summaries during inference by using the rejection probability learned during training. We show that our method considerably improves the factuality of generated summaries in automatic and human evaluations when compared to five baseline models, and that it does so while increasing the abstractiveness of the generated summaries. 1","The paper proposes a new training objective for abstractive summarization that uses rejection learning to identify and reject potentially noisy tokens. They also propose a regularized decoding objective that penalizes non-factual candidate summaries during inference. The method improves the factuality of generated summaries while increasing their abstractiveness, as shown in evaluations compared to five baseline models. Existing methods drop noisy samples or tokens from the training set, reducing its size and creating an artificial propensity to copy words from the source.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve abstractive summarization systems, which are prone to producing non-factual summaries containing unsupported information.', 'Who is the target audience?': 'The summaries are for use in abstractive summarization systems, which are used to automatically generate summaries of documents.', 'How will the summaries be used?': 'The summaries will be used to train abstractive summarization models to recognize and reject unsupported target text spans, and to improve the factuality of generated summaries in automatic and human evaluations.'}",['method'],['Objective Function'],['XSum'],"['FactCC', 'ROUGE', 'DAE', 'EntFA', 'Novel n-grams']",['Faithfulness'],https://github.com/mcao516/rej-summ,https://aclanthology.org/2022.emnlp-main.663/,"{'Existing abstractive summarization systems are prone to produce non-factual summaries, which contain information that is not supported by the source.': 'The authors propose a training objective that enables the summarization model to recognize and reject unsupported target text spans. They introduce a new rejection class at training time that offers the model an option to reject confusing tokens rather than assigning high probability to all reference tokens. This rejection learning objective allows the summarization model to learn features that are indicative of unsupported information.', 'Noise in the reference summary can cause the summarization model to hallucinate and ""break"" the beam search process.': 'The authors propose a rejection learning objective that enables the summarization model to learn what information is unknown and reject contexts in which hallucination is likely to happen. They demonstrate that the rejection learning objective allows the model to correctly reject unsupported information.', 'Summarization models trained on noisy datasets containing erroneous references tend to imitate and even amplify undesired generations.': 'The authors propose a regularization term to the original decoding objective to penalize candidates using the rejection probability learned during training. This regularized decoding objective, combined with rejection training, can vastly improve the factuality of summarization models using both automatic and human evaluation.', 'Prior methods for improving faithfulness in summarization models have led to an increased level of extractiveness of the model outputs.': ""The authors demonstrate that their rejection learning objective and factuality-aware regularized decoding objective can improve model's factuality while simultaneously increasing the abstractiveness of the generated summaries.""}",supervised,['News'],['hallucinations-in-the-generated-summaries']
SP:3b6b1a09b65304e9b54af4cb207e4b7513b0268e,Abstractive Summarization Guided by Latent Hierarchical Document Structure,EMNLP,2022,"['Yifu Qiu', 'Shay B. Cohen']","Sequential abstractive neural summarizers often do not use the underlying structure in the input article or dependencies between the input sentences. This structure is essential to integrate and consolidate information from different parts of the text. To address this shortcoming, we propose a hierarchy-aware graph neural network (HierGNN) which captures such dependencies through three main steps: 1) learning a hierarchical document structure through a latent structure tree learned by a sparse matrixtree computation; 2) propagating sentence information over this structure using a novel message-passing node propagation mechanism to identify salient information; 3) using graphlevel attention to concentrate the decoder on salient information. Experiments confirm HierGNN improves strong sequence models such as BART, with a 0.55 and 0.75 margin in average ROUGE-1/2/L for CNN/DM and XSum. Further human evaluation demonstrates that summaries produced by our model are more relevant and less redundant than the baselines, into which HierGNN is incorporated. We also find HierGNN synthesizes summaries by fusing multiple source sentences more, rather than compressing a single source sentence, and that it processes long inputs more effectively.1","The paper proposes a new approach to summarizing scientific articles using a hierarchy-aware graph neural network (HierGNN). This approach captures the underlying structure and dependencies between sentences in the input article, which is essential for integrating and consolidating information from different parts of the text. The HierGNN model consists of three main steps: learning a hierarchical document structure, propagating sentence information over this structure, and using graph-level attention to concentrate the decoder on salient information. Experiments show that HierGNN improves upon strong sequence models such as BART, with a significant margin in average ROUGE-1/2/L for CNN/DM and XSum. Human evaluation also demonstrates that summaries produced by HierGNN are more relevant and less redundant than baselines. The model synthesizes summaries by fusing multiple source sentences, rather than compressing a single source sentence, and processes long inputs more effectively.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the quality of machine-produced summaries, which currently lag behind human-produced summaries.', 'Who is the target audience?': 'The intended audience for the summaries is not specified in the paper.', 'How will the summaries be used?': 'The paper does not specify how the summaries will be used, but they may be useful for quickly understanding the contents of a document or for generating a brief overview of a longer text.'}",['method'],['Unit Relationship'],"['CNN/DailyMail', 'XSum']","['ROUGE', 'BERTScore']","['Relevance', 'Informativeness', 'Redundancy', 'Overall Quality']",https://github.com/yfqiu-nlp/hiergnn,https://aclanthology.org/2022.emnlp-main.355/,"{'The quality of machine-produced summaries lags far behind the quality of human summaries.': 'The authors propose a document hierarchy-aware graph neural network (HierGNN) that can be effectively incorporated into any sequence-to-sequence (seq2seq) neural summarizer. HierGNN captures the hierarchical document structure via an adaptive sparse matrix-tree computation, with a new propagation rule for achieving intersentence reasoning.', 'Neural summarizers struggle to capture hierarchical and inter-sentential dependencies in the summarized document.': 'HierGNN formulates sentence-level reasoning as a graph propagation problem via a novel message passing mechanism. During decoding, a graph-selection attention mechanism serves as a source sentence selector, hierarchically indicating the attention module which tokens in the input sentences to focus on.', 'Summarizers tend to drop non-essential elements in an original sentence such as prepositional phrases and adjectives (sentence compression) instead of fusing information from multiple article sentences (sentence fusion).': 'HierGNN encourages the summarizers to favor sentence fusion more than sentence compression when generating summaries.', 'Summarizers struggle to process long sequence inputs effectively.': 'Modeling the hierarchical document structure via the sparse matrix-tree computation enables HierGNN to treat long sequences more effectively. The authors also propose a sparse adaptive variant of the matrix-tree computation that demonstrates a more powerful expressive ability over the original one.'}",supervised,['News'],['exploiting-the-structure-of-long-documents']
SP:62b91fb7445351dec64920e98ffbef96346293d7,Towards Summary Candidates Fusion,EMNLP,2022,"['Mathieu Ravaut', 'Shafiq Joty', 'Nancy F. Chen']","Sequence-to-sequence deep neural models fine-tuned for abstractive summarization can achieve great performance on datasets with enough human annotations. Yet, it has been shown that they have not reached their full potential, with a wide gap between the top beam search output and the oracle beam. Recently, re-ranking methods have been proposed, to learn to select a better summary candidate. However, such methods are limited by the summary quality aspects captured by the first-stage candidates. To bypass this limitation, we propose a new paradigm in secondstage abstractive summarization called SummaFusion that fuses several summary candiates to produce a novel abstractive secondstage summary. Our method works well on several summarization datasets, improving both the ROUGE scores and qualitative properties of fused summaries. It is especially good when the candidates to fuse are worse, such as in the few-shot setup where we set a new state-of-the-art. We will make our code and checkpoints available at https: //github.com/ntunlp/SummaFusion/.","The paper discusses the limitations of current abstractive summarization methods and proposes a new paradigm called SummaFusion, which fuses multiple summary candidates to produce a novel abstractive second-stage summary. This method improves both the ROUGE scores and qualitative properties of the summaries, especially in the few-shot setup where it sets a new state-of-the-art. The code and checkpoints for SummaFusion are available on GitHub.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to improve the performance of abstractive summarization methods.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries can be used in a variety of applications, such as search engines, news aggregation, and content recommendation systems.'}",['method'],['Objective Function'],"['XSum', 'Reddit-TIFU', 'SAMSUM']","['ROUGE', 'Novel n-grams']","['Overall Quality', 'Informativeness', 'Fluency', 'Grammaticality', 'Factual Consistency']",https://github.com/ntunlp/SummaFusion/,https://aclanthology.org/2022.emnlp-main.581/,"{'Leading abstractive summarization methods rely on transfer learning and the pre-train-then-finetune paradigm, which may not consider all potential good summary alternatives for a subjective task like summarization.': 'The authors propose SummaFusion, an abstractive second-stage summarization model that generates a new summary from scratch, re-using both the source and first-stage summary candidates to produce summary candidates that are closer to the ground-truth ones.', 'Decoding methods like beam search and nucleus sampling may not utilize models to their full capacity, leading to a wide gap between the top candidate and the oracle performance.': 'SummaFusion bypasses these limitations by learning to select a better candidate with access to a more global context, free from the autoregressive constraint which restricts access to only previous context.', 'Existing second-stage summarization methods may be bounded by the quality of the first-stage model, and alternative decoding methods to beam search may generate more diverse summaries but result in loss of performance in the output candidate.': 'SummaFusion is flexible and can adjust to varying number of summary candidates, and produces fused summaries that are abstractive with regards to both the source and the set of first-stage candidates, more fluent and more factually consistent. It performs well especially on lower-quality pools of summary candidates, where one needs a second-stage summarizer the most.'}",supervised,"['News', 'Social Media', 'Dialog']",['controlled-and-tailored-summarization']
SP:e583dd5e6149297ae3a271685eb4de1a016ad4b6,Questioning the Validity of Summarization Datasets and Improving Their Factual Consistency,EMNLP,2022,"['Yanzhu Guo', 'Chloé Clavel', 'Moussa Kamal Eddine', 'Michalis Vazirgiannis']","The topic of summarization evaluation has recently attracted a surge of attention due to the rapid development of abstractive summarization systems. However, the formulation of the task is rather ambiguous, neither the linguistic nor the natural language processing community has succeeded in giving a mutually agreed-upon definition. Due to this lack of well-defined formulation, a large number of popular abstractive summarization datasets are constructed in a manner that neither guarantees validity nor meets one of the most essential criteria of summarization: factual consistency. In this paper, we address this issue by combining state-of-the-art factual consistency models to identify the problematic instances present in popular summarization datasets. We release SummFC, a filtered summarization dataset with improved factual consistency, and demonstrate that models trained on this dataset achieve improved performance in nearly all quality aspects. We argue that our dataset should become a valid benchmark for developing and evaluating summarization systems.","The paper discusses the lack of a well-defined formulation for summarization evaluation, which has led to popular summarization datasets being constructed in a way that does not guarantee validity or factual consistency. The authors address this issue by combining factual consistency models to identify problematic instances and release a filtered summarization dataset called SummFC with improved factual consistency. They demonstrate that models trained on this dataset achieve improved performance in nearly all quality aspects and argue that it should become a valid benchmark for developing and evaluating summarization systems.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the performance of summarization models.', 'Who is the target audience?': 'The summaries are for users who need to quickly understand the most important content of a document.', 'How will the summaries be used?': 'The summaries will be used to present the most important content of a document in a concise form and in a manner sensitive to the user’s or application’s needs.'}","['corpus', 'analysis']",[],['SummFC'],"['BERTScore', 'BARTScore', 'DAE', 'BLANC', 'ROUGE']",[],https://github.com/YanzhuGuo/SummFC,https://aclanthology.org/2022.emnlp-main.386/,"{'Most research in automatic summarization has focused on improving performance metrics of summarization models on popular datasets, without considering if these datasets provide representative examples of high quality summaries.': 'The NLP community should take a step back, revisit the formulation of the summarization task, and reconsider the appropriateness of currently employed datasets.', 'The most widely employed summarization datasets (e.g. CNN/DailyMail and XSUM) have deficiencies, as they are composed of news articles automatically extracted from news websites, paired with a highlight or introduction sentence which serves as the summary. However, the qualities we seek in highlights and introductions are fundamentally different from the ones we seek in summaries.': 'The NLP community should reconsider the appropriateness of currently employed datasets and focus on identifying erroneous data samples by scoring them with factual consistency models.', 'Summaries constructed from highlights or introductions are not factually consistent with the source document, as they often contain information that are not mentioned in the main article or even exaggerate certain facts to achieve the goal of click baiting.': 'The models trained on these datasets perform the task of “pitch generation” rather than the intended summary generation. The authors aim to identify these erroneous data samples by scoring them with factual consistency models.', 'The authors aim to answer the research question of what kind of factual inconsistency can different factuality models capture and how can they be combined for better detection of erroneous samples.': 'This question is answered in Sections 3.2 and 5.1 of the paper.'}",,['News'],[]
SP:653a09f524f14387c827afdc5efa91473d619bcb,Generating Multiple-Length Summaries via Reinforcement Learning for Unsupervised Sentence Summarization,EMNLP,2022,"['Dongmin Hyun', 'Xiting Wang', 'Chanyoung Park', 'Xing Xie', 'Hwanjo Yu']","Sentence summarization shortens given texts while maintaining core contents of the texts. Unsupervised approaches have been studied to summarize texts without human-written summaries. However, recent unsupervised models are extractive, which remove words from texts and thus they are less flexible than abstractive summarization. In this work, we devise an abstractive model based on reinforcement learning without ground-truth summaries. We formulate the unsupervised summarization based on the Markov decision process with rewards representing the summary quality. To further enhance the summary quality, we develop a multi-summary learning mechanism that generates multiple summaries with varying lengths for a given text, while making the summaries mutually enhance each other. Experimental results show that the proposed model substantially outperforms both abstractive and extractive models, yet frequently generating new words not contained in input texts.","The paper discusses the development of an abstractive model for unsupervised summarization of texts, which is based on reinforcement learning and does not require human-written summaries. The model uses a Markov decision process with rewards to formulate the summarization process and a multi-summary learning mechanism to generate multiple summaries of varying lengths that enhance each other. Experimental results show that the proposed model outperforms both abstractive and extractive models and frequently generates new words not present in the input texts.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to enhance the readability of texts by reducing their lengths through word dropping, replacement, or paraphrasing.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a text, such as subtitle generation or email summarization.', 'How will the summaries be used?': 'The summaries will be used to save time and resources by providing a quick overview of a text without the need for human-written summaries. They can also be used to improve the accessibility and readability of texts for a wider audience.'}",['method'],['Objective Function'],"['Gigaword', 'DUC 2004']","['ROUGE', 'Fidelity', 'Fluency']","['Fidelity', 'Fluency']",https://github.com/dmhyun/MSRP,https://aclanthology.org/2022.findings-emnlp.214/,"{'The high cost of having human editors write summaries for each text.': 'Develop an unsupervised model that does not require any human-written summaries.', 'Existing extractive models cannot generate new words that can be effective for sentence summarization.': 'Devise an abstractive model that produces high-quality summaries with generating new words not contained in input texts.', 'Existing abstractive models fall short of reducing text lengths while maintaining the summary quality.': 'Employ reinforcement learning (RL) for unsupervised abstractive summarization that generates high-quality summaries with considering the semantic similarity between the generated summary and its corresponding input text, and fluency of the generated summaries.', 'The difficulty of summarization depends on the summary lengths.': 'Develop a multisummary learning mechanism that generates multiple summaries with varying lengths for a given text, while making the summaries mutually enhance each other.', 'The model needs well-initialized parameters for the RL training.': 'Devise a pretraining task to obtain well-initialized model parameters for the RL training by augmenting input texts with word-level perturbations and inserting length prompts, and training the model to reconstruct the original text from the augmented one.'}",reinforced,['News'],['controlled-and-tailored-summarization']
SP:88a0e8d58a2677bf9092105690a6ec2d9e6eb850,CTRLSUM: Towards Generic Controllable Text Summarization,EMNLP,2022,"['Junxian He', 'Wojciech Kryściński', 'Bryan McCann', 'Nazneen Rajani', 'Caiming Xiong']","Current summarization systems yield generic summaries that are disconnected from users’ preferences and expectations. To address this limitation, we present CTRLSUM, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLSUM features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models. We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLSUM on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLSUM is comparable or better than strong pretrained systems. 1","The paper introduces CTRLSUM, a framework for generating summaries that can be controlled through a set of keywords. The keywords are automatically extracted during training, and at test time, a control function maps control signals to keywords. The same trained model can be applied to control summaries on various dimensions without affecting the model training process or pretrained models. The framework is effective in entity-centric and length-controllable summarization, contribution summarization on scientific papers, invention purpose summarization on patent filings, and question-guided summarization on news articles. CTRLSUM is also comparable or better than strong pretrained systems in standard, unconstrained summarization settings.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to compress them into a short paragraph or sentence while preserving key information.', 'Who is the target audience?': 'The automatically generated summaries are for readers who want to quickly understand the content of a document without reading the entire text.', 'How will the summaries be used?': 'The summaries will be used to provide a quick overview of the content of a document, and can be used in various applications such as news articles, scientific papers, and patent documents.'}",['method'],['Controlled Generation'],"['CNN/DailyMail', 'arXiv', 'BigPatent']","['ROUGE', 'BERTScore']","['Control Accuracy', 'Control Relevance']",https://github.com/salesforce/ctrl-sum,https://aclanthology.org/2022.emnlp-main.396/,"{'Automatically generated summaries may not cover content considered important by readers.': 'The authors propose a controllable summarization framework called CTRLSUM, which allows users to control the generated summaries through a set of keywords. At training time, the model learns to predict summaries conditioned on both the source document and keywords, which are easily identified from training summaries. During inference, a control function is designed depending on the specific control aspect to map user preference to keywords to control the summary.', 'Typical controllable summarization methods require training a separate model for each control aspect and cannot generalize to new control aspects at test time.': 'The authors propose a generic controllable summarization framework with a single model that is agnostic to the specific control aspect. They use keywords to provide a clean separation of test-time user control and the training process, allowing different dimensions of the generated summary to be controlled through engineering the test-time control function, while the training process and pretrained model remain unchanged.', 'Keyword-guided summarization methods mainly focus on improving the summary quality in traditional, unconstrained summarization tasks or only study a specific control aspect like length control.': 'The authors generalize keyword-guided summarization as a generic controllable summarization framework and explore its novel applications to a wide range of control tasks, including entity-centric and length-controllable summarization, summarizing the contributions of scientific papers, summarizing the purpose of an invention, and summarizing answers to given questions in a zero-shot reading comprehension setting.', 'Personalized summarization systems are not well explored.': 'The authors expect the exploration in this paper to attract attention to the controllable summarization task and provide a springboard for future research on personalized summarization systems. They also release their trained CTRLSUM checkpoints to encourage others to try CTRLSUM for their own control of interest.'}",supervised,"['News', 'Scholarly Documents', 'Patents']",['controlled-and-tailored-summarization']
SP:7cd425f86c1468898d9f2693109308c8f41786b4,Active Learning for Abstractive Text Summarization,EMNLP,2022,"['Akim Tsvigun', 'Ivan Lysenko', 'Danila Sedashov', 'Ivan Lazichny', 'Eldar Damirov', 'Vladimir Karlov', 'Artemy Belousov', 'Leonid Sanochkin', 'Maxim Panov', 'Alexander Panchenko', 'Mikhail Burtsev', 'Artem Shelmanov']","Construction of human-curated annotated datasets for abstractive text summarization (ATS) is very time-consuming and expensive because creating each instance requires a human annotator to read a long document and compose a shorter summary that would preserve the key information relayed by the original document. Active Learning (AL) is a technique developed to reduce the amount of annotation required to achieve a certain level of machine learning model performance. In information extraction and text classification, AL can reduce the amount of labor up to multiple times. Despite its potential for aiding expensive annotation, as far as we know, there were no effective AL query strategies for ATS. This stems from the fact that many AL strategies rely on uncertainty estimation, while as we show in our work, uncertain instances are usually noisy, and selecting them can degrade the model performance compared to passive annotation. We address this problem by proposing the first effective query strategy for AL in ATS based on diversity principles. We show that given a certain annotation budget, using our strategy in AL annotation helps to improve the model performance in terms of ROUGE and consistency scores. Additionally, we analyze the effect of self-learning and show that it can further increase the performance of the model.","The paper discusses the challenges of creating human-curated annotated datasets for abstractive text summarization (ATS) and the potential of Active Learning (AL) to reduce the amount of annotation required. However, there were no effective AL query strategies for ATS due to the fact that uncertain instances are usually noisy and selecting them can degrade the model performance. The paper proposes the first effective query strategy for AL in ATS based on diversity principles, which improves the model performance in terms of ROUGE and consistency scores. The paper also analyzes the effect of self-learning and shows that it can further increase the performance of the model.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress them into a brief yet informative and readable summary that retains the key information of the original document.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the key information of a document without reading the entire document.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading long documents, and can be particularly useful in situations where time is limited or when a large number of documents need to be processed quickly.'}",['method'],['Objective Function'],"['AESLC', 'PubMed', 'WikiHow']","['ROUGE', 'SummaC']",[],https://github.com/AIRI-Institute/al_ats,https://aclanthology.org/2022.findings-emnlp.377/,"{'Manual composition of summaries for ATS is a tedious and time-consuming task, resulting in expensive construction of annotated corpora for text summarization.': 'Active Learning (AL) technique is proposed to substantially reduce the amount of annotation required to achieve a certain level of machine learning model performance. AL works iteratively, where a model is trained on the annotated dataset, used to select informative instances from a large unlabeled pool using a query strategy, presented to human experts for gold-standard annotations, and added to the labeled dataset for a new iteration.', 'Traditional AL query strategies based on uncertainty estimation techniques cannot be straightforwardly adapted to AL in text summarization as uncertain predictions of ATS models (uncertain summaries) are not more useful than randomly selected instances and usually introduce more noise and detriment to the performance of summarization models.': 'The authors propose the first effective query strategy for AL in ATS, called in-domain diversity sampling (IDDS), based on the selection of diverse instances that are semantically dissimilar from already annotated documents but at the same time similar to the core documents of the considered domain. The empirical investigation shows that while techniques based on uncertainty cannot overcome the random sampling baseline, IDDS substantially increases the performance of summarization models.', 'The effect of self-learning in conjunction with AL for ATS has not been investigated.': 'The authors experiment with the self-learning technique that leverages a training dataset expanded with summaries automatically generated by an ATS model trained only on the human-annotated dataset. This approach shows improvements when one needs to generate short summaries.'}",supervised,"['Emails', 'Scholarly Documents', 'CQA']","['pretraining-and-sample-efficiency', 'lack-of-suitable-training-data']"
SP:c0c2c7260c218404d3c1950755596297e3a65f27,SNAC: Coherence Error Detection for Narrative Summarization,EMNLP,2022,"['Tanya Goyal', 'Junyi Jessy Li', 'Greg Durrett']","Progress in summarizing long texts is inhibited by the lack of appropriate evaluation frameworks. A long summary that appropriately covers the facets of that text must also present a coherent narrative, but current automatic and human evaluation methods fail to identify gaps in coherence. In this work, we introduce SNAC, a narrative coherence evaluation framework for fine-grained annotations of long summaries. We develop a taxonomy of coherence errors in generated narrative summaries and collect spanlevel annotations for 6.6k sentences across 150 book and movie summaries. Our work provides the first characterization of coherence errors generated by state-of-the-art summarization models and a protocol for eliciting coherence judgments from crowdworkers. Furthermore, we show that the collected annotations allow us to benchmark past work in coherence modeling and train a strong classifier for automatically localizing coherence errors in generated summaries. Finally, our SNAC framework can support future work in long document summarization and coherence evaluation, including improved summarization modeling and posthoc summary correction.1","The paper discusses the lack of appropriate evaluation frameworks for summarizing long texts, which inhibits progress in this field. The authors introduce SNAC, a narrative coherence evaluation framework for fine-grained annotations of long summaries. They develop a taxonomy of coherence errors in generated narrative summaries and collect annotations for 6.6k sentences across 150 book and movie summaries. The collected annotations allow them to benchmark past work in coherence modeling and train a strong classifier for automatically localizing coherence errors in generated summaries. The SNAC framework can support future work in long document summarization and coherence evaluation, including improved summarization modeling and posthoc summary correction.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to tackle increasingly challenging settings, particularly long document summarization and generation of longer summaries.', 'Who is the target audience?': 'The summaries are for evaluating different modeling approaches and measuring progress in the field of summarization.', 'How will the summaries be used?': 'The summaries will be used for downstream applications such as better long summary evaluation, coherence-aware generation, and post-correction of summaries.'}",['analysis'],[],[],[],[],https://github.com/tagoyal/snac,https://aclanthology.org/2022.emnlp-main.29/,"{'The shift towards long document summarization and generation of longer summaries requires a reexamination of the summarization evaluation framework.': 'Establishing human evaluation protocols is critical for comparing different modeling approaches and measuring progress. The authors introduce SNAC, a framework for collecting fine-grained annotations to evaluate Summary Narrative Coherence.', 'Current summarization models generate summaries that lack coherent discourse structure.': 'The authors develop an error schema with 7 narrative error types grounded in actual errors made by current summarization models. They enlist crowdworkers to collect a large-scale dataset of 9.6k span-level error annotations in narrative summaries generated by current state-of-the-art summarization models on two datasets: movie screenplays and books.', 'Automated metrics are inadequate for evaluating coherence in summaries, and human evaluation is rarely done for longer summaries due to the associated labor costs of reading and evaluating long text.': 'The authors show that a fine-grained annotation framework is better suited for collecting crowd annotations than a Likert scale-based holistic evaluation of coherence. They also evaluate the performance of automatic coherence models, comparing synthetic data generation techniques against SNAC annotations as training sources.', 'There is a lack of understanding of specific errors made by current summarization models and gaps that exist with human-written coherent summaries.': ""The authors' work is the first to characterize specific errors made by these systems and gaps that exist with human-written coherent summaries. Their collected dataset and analysis provides a foundation for downstream applications such as better long summary evaluation, coherence-aware generation, and post-correction of summaries.""}",,"['Books', 'Movie Scripts']",[]
SP:c2f42ed7a42be6f37cf77a90193e48144a975ef9,Universal Evasion Attacks on Summarization Scoring,EMNLP,2022,"['Wenchuan Mu Kwan', 'Hui Lim']","The automatic scoring of summaries is important as it guides the development of summarizers. Scoring is also complex, as it involves multiple aspects such as fluency, grammar, and even textual entailment with the source text. However, summary scoring has not been considered a machine learning task to study its accuracy and robustness. In this study, we place automatic scoring in the context of regression machine learning tasks and perform evasion attacks to explore its robustness. Attack systems predict a non-summary string from each input, and these non-summary strings achieve competitive scores with good summarizers on the most popular metrics: ROUGE, METEOR, and BERTScore. Attack systems also ""outperform"" state-of-the-art summarization methods on ROUGE-1 and ROUGE-L, and score the second-highest on METEOR. Furthermore, a BERTScore backdoor is observed: a simple trigger can score higher than any automatic summarization method. The evasion attacks in this work indicate the low robustness of current scoring systems at the system level. We hope that our highlighting of these proposed attacks will facilitate the development of summary scores.","The paper discusses the importance of automatic scoring of summaries in guiding the development of summarizers, but notes that summary scoring has not been studied as a machine learning task to assess its accuracy and robustness. The authors perform evasion attacks to explore the robustness of summary scoring systems and find that non-summary strings can achieve competitive scores with good summarizers on popular metrics such as ROUGE, METEOR, and BERTScore. The attacks also outperform state-of-the-art summarization methods on ROUGE-1 and ROUGE-L, and score the second-highest on METEOR. The authors observe a BERTScore backdoor where a simple trigger can score higher than any automatic summarization method. The low robustness of current scoring systems at the system level is highlighted, and the authors hope that their proposed attacks will facilitate the development of summary scores.","{'What is the purpose of the summaries?': 'The authors are discussing the paradox of automatic summarization, where automatic scoring methods are often used to endorse summarizers as state-of-the-art, but these methods have been found to be insufficient, oversimplified, and difficult to interpret.', 'Who is the target audience?': 'The discussion is relevant for researchers and developers working on automatic summarization systems.', 'How will the summaries be used?': 'The authors argue that automatic scoring is not just a sub-module of automatic summarization, but a stand-alone system that needs to be studied for its own accuracy and robustness. They propose performing evasion attacks to expose the weaknesses of current automatic scoring systems and suggest that emerging scoring systems should be tested using the same approach.'}",['analysis'],[],['CNN/DailyMail'],"['ROUGE', 'BERTScore', 'METEOR']",[],,https://aclanthology.org/2022.blackboxnlp-1.9/,"{'The paradox of automatic summarization - the lack of automatic scoring available to demonstrate summary quality, while contemporaneous research relies on automatic scores to endorse a summarizer as state-of-the-art.': 'The authors argue that automatic scoring itself is not just a sub-module of automatic summarization, but a stand-alone system that needs to be studied for its own accuracy and robustness. They suggest that NLU is required to characterize summary quality, and that recent advances in automatic scoring are transitioning from well-established metrics to emerging metrics aimed at computing semantic similarity through pre-trained neural models.', 'The fallacy of the justification process for potentially useful summarizers.': 'The authors suggest that there are three mainstream speculations that are not mutually exclusive: (1) the transition from extractive to abstractive summarization could have been underestimated, (2) many metrics, while flawed in judging individual summaries, often make sense at the system level, and (3) researchers have not figured out how humans interpret or understand texts. They argue that automatic scoring is a challenging NLU task that needs to be studied for its own accuracy and robustness.', 'The need to test the accuracy and robustness of current representative automatic scoring systems.': 'The authors treat automatic summarization scoring as an NLU regression task and perform evasion attacks. They are the first to perform a universal, targeted attack on NLP regression models and their evasion attacks support that it is not difficult to deceive the three most popular automatic scoring systems simultaneously. The proposed attacks can be directly applied to test emerging scoring systems.'}",,['News'],[]
SP:e028aee05de2d913c6dcf9d4ae274645ad1d295c,Salience Allocation as Guidance for Abstractive Summarization,EMNLP,2022,"['Fei Wang', 'Kaiqiang Song', 'Hongming Zhang', 'Lifeng Jin', 'Sangwoo Cho', 'Wenlin Yao', 'Xiaoyang Wang', 'Muhao Chen', 'Dong Yu']","Abstractive summarization models typically learn to capture the salient information from scratch implicitly. Recent literature adds extractive summaries as guidance for abstractive summarization models to provide hints of salient content and achieves better performance. However, extractive summaries as guidance could be over strict, leading to information loss or noisy signals. Furthermore, it cannot easily adapt to documents with various abstractiveness. As the number and allocation of salience content pieces vary, it is hard to find a fixed threshold deciding which content should be included in the guidance. In this paper, we propose a novel summarization approach with a flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as Guidance for Abstractive SummarizatiON). SEASON utilizes the allocation of salience expectation to guide abstractive summarization and adapts well to articles in different abstractiveness. Automatic and human evaluations on two benchmark datasets show that the proposed method is effective and reliable. Empirical results on more than one million news articles demonstrate a natural fifteen-fifty salience split for news article sentences, providing a useful insight for composing news articles.1ive summarization models typically learn to capture the salient information from scratch implicitly. Recent literature adds extractive summaries as guidance for abstractive summarization models to provide hints of salient content and achieves better performance. However, extractive summaries as guidance could be over strict, leading to information loss or noisy signals. Furthermore, it cannot easily adapt to documents with various abstractiveness. As the number and allocation of salience content pieces vary, it is hard to find a fixed threshold deciding which content should be included in the guidance. In this paper, we propose a novel summarization approach with a flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as Guidance for Abstractive SummarizatiON). SEASON utilizes the allocation of salience expectation to guide abstractive summarization and adapts well to articles in different abstractiveness. Automatic and human evaluations on two benchmark datasets show that the proposed method is effective and reliable. Empirical results on more than one million news articles demonstrate a natural fifteen-fifty salience split for news article sentences, providing a useful insight for composing news articles.1","The paper proposes a new summarization approach called SEASON (SaliencE Allocation as Guidance for Abstractive SummarizatiON) that uses salience expectation to guide abstractive summarization and adapts well to articles with different levels of abstractiveness. The paper argues that extractive summaries as guidance can be too strict and lead to information loss or noisy signals. SEASON is shown to be effective and reliable in automatic and human evaluations on two benchmark datasets, and empirical results on more than one million news articles demonstrate a natural fifteen-fifty salience split for news article sentences, providing useful insights for composing news articles.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to provide users with improved dissemination and acquisition of more readable content in long documents.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the main points of a longer document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used for enhanced selection, compression, and retrieval of Web-scale textual information that benefits other NLP tasks, such as machine reading comprehension, mention linking, claim verification, and information extraction.'}",['method'],"['Objective Function', 'Unit Selection']","['CNN/DailyMail', 'Newsroom']",['ROUGE'],"['Informativeness', 'Faithfulness', 'Fluency']",https://github.com/tencent-ailab/season,https://aclanthology.org/2022.emnlp-main.409/,"{'Extractive summaries are not reliable guidance for abstractive summarization models.': 'The authors propose a novel summarization approach with a flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as Guidance for Abstractive SummarizatiON). Salience is the degree to which a sentence contributes to the central idea of a document, and its allocation means how salience is distributed among all sentences in a document. To estimate the salience allocation, a linear classifier is trained on top of the encoder. This estimation is incorporated into the decoder with Salience-Aware CrossAttention (SACA). It provides the flexibility to decide how much signal to accept from the salience guidance to supervise the abstractive summarization.', 'Extractive summaries are not flexible to adapt to different cases.': 'The authors propose a flexible guidance that selects salient content based on document properties. The ground-truth salience label is assigned to each sentence based on its similarity with the ground-truth summary. Meanwhile, the number of salience degrees and their cut-off thresholds are decided based on the corpus to balance informativeness and prediction accuracy.', 'An imperfect selection process may lead to further model biases.': 'The authors apply label smoothing between adjacent salience degrees during training, and use the expectation of salience as a more robust salience estimation to improve the robustness of the summarization model.'}",supervised,['News'],"['information-loss-and-incoherence-in-extractive-summarization', 'identifying-important-contents-from-the-document']"
SP:6b350e3f7930c7d98276017d015c08294b2a291f,R-TeaFor: Regularized Teacher-Forcing for Abstractive Summarization,EMNLP,2022,"['Guan-Yu Lin', 'Pu-Jen Cheng']","Teacher-forcing is widely used in training sequence generation models to improve sampling efficiency and to stabilize training. However, teacher-forcing is vulnerable to the exposure bias problem. Previous works have attempted to address exposure bias by modifying the training data to simulate model-generated results. Nevertheless, they do not consider the pairwise relationship between the original training data and the modified ones, which provides more information during training. Hence, we propose Regularized Teacher-Forcing (R-TeaFor) to utilize this relationship for better regularization. Empirically, our experiments show that R-TeaFor outperforms previous summarization state-of-the-art models, and the results can be generalized to different pre-trained models.",System: The paper proposes a new method called Regularized Teacher-Forcing (R-TeaFor) to address the exposure bias problem in training sequence generation models. R-TeaFor utilizes the pairwise relationship between the original training data and the modified ones for better regularization. The experiments show that R-TeaFor outperforms previous state-of-the-art models in summarization and can be generalized to different pre-trained models.,"{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to evaluate the effectiveness of their proposed approach for solving the exposure bias problem in sequence generation tasks.', 'Who is the target audience?': 'The summaries are for researchers and practitioners in the field of natural language processing who are interested in improving the performance of encoder-decoder models in sequence generation tasks.', 'How will the summaries be used?': 'The summaries will be used to understand the background and motivation for the proposed approach, as well as the related work and experimental results presented in the paper. They may also be used to compare the proposed approach with other methods for solving the exposure bias problem.'}",['method'],"['Objective Function', 'Data Augmentation']","['CNN/DailyMail', 'XSum']",['ROUGE'],[],,https://aclanthology.org/2022.emnlp-main.423/,"{'Encoder-decoder models trained with teacher-forcing suffer from exposure bias, as they are only exposed to the training data distribution rather than their prediction distribution.': 'Regularization methods such as dropout and perturbation can alleviate exposure bias, but their ability to do so is limited. R-TeaFor introduces a symmetric KL-divergence loss to force consistency between the token distribution generated with the ground-truth sequence and the distribution generated with an augmented sequence modified from the same ground-truth. This augmented sequence serves as a regularizer to prevent exposure bias, while the model can still learn from the original ground-truth sequences.', 'Contrastive learning can provide more information inside the training data, but finding a suitable contrastive pair that is neither too easy to distinguish nor too hard to learn is a challenge.': 'For summarization tasks, both extractive-based and abstractive-based approaches can be combined with contrastive learning. This can entail an additional contrastive loss or using contrastive data to learn an additional model for reranking.', 'Reinforcement learning requires a warm start phase or regularization powered by traditional teacher-forcing.': 'Pang and He formulate the sequence generation learning problem as an off-line reinforcement learning with expert demonstrations that addresses exposure bias by training the model on its state/history distribution.', 'Sampling-based approaches can simulate the data distribution in the inference stage during training, but the modified training data might deviate from the original one, leading to learning from noisy training data.': 'Zhang et al. propose refining the sampling rate with beam search, while Liu et al. suggest scheduling the sampling rate according to the decoding steps.'}",supervised,['News'],['pretraining-and-sample-efficiency']
SP:1cecb7be515358c158d3ab6d445fa2f3c06c304c,How Far are We from Robust Long Abstractive Summarization?,EMNLP,2022,"['Huan Yee Koh', 'Jiaxin Ju', 'He Zhang', 'Ming Liu', 'Shirui Pan']","Abstractive summarization has made tremendous progress in recent years. In this work, we perform fine-grained human annotations to evaluate long document abstractive summarization systems (i.e., models and metrics) with the aim of implementing them to generate reliable summaries. For long document abstractive models, we show that the constant strive for state-of-the-art ROUGE results can lead us to generate more relevant summaries but not factual ones. For long document evaluation metrics, human evaluation results show that ROUGE remains the best at evaluating the relevancy of a summary. It also reveals important limitations of factuality metrics in detecting different types of factual errors and the reasons behind the effectiveness of BARTScore. We then suggest promising directions in the endeavor of developing factual consistency metrics. Finally, we release our annotated long document dataset with the hope that it can contribute to the development of metrics across a broader range of summarization settings.ive summarization has made tremendous progress in recent years. In this work, we perform fine-grained human annotations to evaluate long document abstractive summarization systems (i.e., models and metrics) with the aim of implementing them to generate reliable summaries. For long document abstractive models, we show that the constant strive for state-of-the-art ROUGE results can lead us to generate more relevant summaries but not factual ones. For long document evaluation metrics, human evaluation results show that ROUGE remains the best at evaluating the relevancy of a summary. It also reveals important limitations of factuality metrics in detecting different types of factual errors and the reasons behind the effectiveness of BARTScore. We then suggest promising directions in the endeavor of developing factual consistency metrics. Finally, we release our annotated long document dataset with the hope that it can contribute to the development of metrics across a broader range of summarization settings.","The paper discusses the evaluation of long document abstractive summarization systems using fine-grained human annotations. It highlights the trade-off between generating relevant summaries and factual ones, and suggests promising directions for developing factual consistency metrics. The study also reveals the limitations of factuality metrics in detecting different types of factual errors and the effectiveness of ROUGE and BARTScore in evaluating the relevancy of a summary. The authors release their annotated long document dataset to contribute to the development of metrics across a broader range of summarization settings.","{'What is the purpose of the summaries?': 'The authors are generating summaries of long documents to analyze the quality of current state-of-the-art long document abstractive models and evaluation metrics.', 'Who is the target audience?': 'The summaries are for researchers and developers working on abstractive summarization systems for long documents.', 'How will the summaries be used?': 'The summaries will be used to encourage a rethinking of architectural designs under long document settings and to further research in human-correlated evaluation metrics across a broader setting. They will also be used to investigate summarization metrics and provide promising directions for the future development of evaluation metrics.'}",['analysis'],[],"['arXiv', 'GovReport']",['ROUGE'],"['Relevance', 'Factual Consistency']",https://github.com/huankoh/How-Far-are-We-from-Robust-Long-Abstractive-Summarization,https://aclanthology.org/2022.emnlp-main.172/,"{'Transformer-based abstractive models often generate summaries that are repetitive, ungrammatical, and factually inconsistent with the source, even under a short document setting.': 'The authors aim to fill the gap by systematically analyzing abstractive models and evaluation metrics under the long document setting. They implement different variants of Longformer-based BART and PEGASUS to obtain a diverse set of summaries and perform fine-grained human analysis on the model outputs by three human annotators to qualitatively assess whether long document abstractive models can generate relevant and factually consistent summaries.', 'Current pre-trained Transformers have an input length limit that restricts them to be directly adapted to long document summarization as it would lead to a significant loss of salient information in the remaining text.': 'The authors closely follow prior works in extending the pre-trained models using sparse attention and reduce-then-summarize mechanism to implement different variants of Longformer-based BART and PEGASUS to obtain a diverse set of summaries.', 'Research on analysis and critiques of models and metrics mainly focus on the short document or long dialogue.': 'The authors aim to fill the gap by systematically analyzing abstractive models and evaluation metrics under the long document setting.', 'Effective evaluation metrics are paramount as they can critically assess the model performance before releasing it to target users.': 'The authors adapt recently proposed metrics to long document settings and thoroughly analyze their strength and weaknesses to measure the relevance and factual consistency on their annotated dataset.', 'There is a lack of a set of model-generated summaries with sufficient diversity under long document settings.': 'The authors implement BART and PEGASUS models under arXiv and GovReport as they have been found to be the most effective pre-trained Transformer in a large-scale evaluation of summarization models to obtain a diverse set of summaries.', 'There is a need to encourage a rethinking of architectural designs under long document settings.': 'The authors analyze pre-trained Transformer summarizers to encourage a rethinking of architectural designs under long document settings.', 'There is a need to further research in human-correlated evaluation metrics across a broader setting.': 'The authors release human-annotated long document abstractive model outputs to further research in human-correlated evaluation metrics across a broader setting.', 'There is a need to expose the limitation of metrics and provide promising directions for the future development of evaluation metrics.': 'The authors investigate summarization metrics using their annotated long document datasets to expose the limitation of metrics and provide promising directions for the future development of evaluation metrics.'}",,"['Scholarly Documents', 'Govt. Reports']",[]
SP:e96c111ace74e77fe22e005ab9a9d98c28218274,Summarizing Procedural Text: Data and Approach,EMNLP,2022,"['Shen Gao', 'Haotong Zhang', 'Xiuying Chen', 'Dongyan Zhao', 'Rui Yan']","Procedural text is a widely used genre that contains many steps of instructions of how to cook a dish or how to conduct a chemical experiment and analyzing the procedural text has become a popular task in the NLP field. Since the procedural text can be very long and contains many details, summarizing the whole procedural text or giving an overview for each complicated procedure step can save time for readers and help the reader to capture the core action in the procedure. In this paper, we propose the procedural text summarization task with two summarization granularity: step-view and globalview, which summarizes each step in procedural text separately or gives an overall summary for all steps respectively. To tackle this task, we propose an Entity-State Graph-based Summarizer (ESGS) which is based on stateof-the-art entity state tracking methods and constructs a heterogeneous graph to aggregate contextual information for each procedure. In order to help the summarization model focus on the salient entity, we propose to use the contextualized procedure graph representation to predict the salient entity. Experiments conducted on two datasets verify the effectiveness of our proposed model, and the code and datasets will be released on https://github. com/gsh199449/procedural-summ.","The paper proposes a procedural text summarization task with two summarization granularity: step-view and globalview, which summarizes each step in procedural text separately or gives an overall summary for all steps respectively. To tackle this task, the authors propose an Entity-State Graph-based Summarizer (ESGS) which is based on state-of-the-art entity state tracking methods and constructs a heterogeneous graph to aggregate contextual information for each procedure. The authors also propose to use the contextualized procedure graph representation to predict the salient entity. Experiments conducted on two datasets verify the effectiveness of the proposed model.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to save time for readers when they want to quickly locate the useful step or take an overview of the procedural text.', 'Who is the target audience?': 'The summaries are for readers who want to quickly locate the useful step or take an overview of the procedural text.', 'How will the summaries be used?': 'The summaries will be used to quickly locate the useful step or take an overview of the procedural text.'}","['corpus', 'method']","['Unit Selection', 'Objective Function']","['PsyStory', 'WikiHow']","['ROUGE', 'BLEU']",[],https://github.com/gsh199449/procedural-summ,https://aclanthology.org/2022.findings-emnlp.162/,"{'The authors note that while procedural texts are widely used, there has been limited research on how to summarize them effectively. They propose a new summarization task: Procedural Text Summarization, which has two sub-tasks: (1) summarizing each procedure (Step-View) and (2) summarizing all procedures into a comprehensive summary (GlobalView).': 'The authors propose a new summarization task that aims to generate two granularity of summaries for each procedure and all procedural text.', 'The authors note that the core of the procedural text summarization model is to capture the salient entity and describe the trace of entity state changes. However, plain text summarization methods cannot model the relationship between contextual procedures.': 'The authors propose to leverage the entity state tracking method to explicitly construct the relationship between procedures by employing the trace of entity state changes.', 'The authors note that identifying the salient entity for the procedure is a challenge.': 'The authors propose an entity selection module by using the graph representation of procedure to identify the salient entity.', 'The authors note that there is a need to verify the effectiveness of their proposed method.': 'The authors conduct experiments on two datasets, WikiHowproc and PsyStory, to demonstrate that their Entity-State Graph-based Summarizer (ESGS) method outperforms all baselines, including the state-of-the-art summarization model.'}",supervised,['CQA'],['exploiting-the-structure-of-long-documents']
SP:e96e9949af76fc1111b18ef8450861809b3917d6,Few-shot Query-Focused Summarization with Prefix-Merging,EMNLP,2022,"['Ruifeng Yuan', 'Zili Wang', 'Ziqiang Cao', 'Wenjie Li']","Query-focused summarization has been considered as an important extension for text summarization. It aims to generate a concise highlight for a given query. Different from text summarization, query-focused summarization has long been plagued by the problem of lacking high-quality large-scale datasets. In this paper, we investigate the idea that whether we can integrate and transfer the knowledge of text summarization and question answering to assist the few-shot learning in query-focused summarization. Here, we propose prefix-merging, a prefix-based pretraining strategy for fewshot learning in query-focused summarization. Drawn inspiration from prefix-tuning, we are allowed to integrate the task knowledge from text summarization and question answering into a properly designed prefix and apply the merged prefix to query-focused summarization. With only a small amount of trainable parameters, prefix-merging outperforms fine-tuning on query-focused summarization. We further discuss the influence of different prefix designs and propose a visualized explanation for how prefix-merging works.","The paper proposes a new approach called prefix-merging for few-shot learning in query-focused summarization. The approach integrates the knowledge of text summarization and question answering into a properly designed prefix and applies it to query-focused summarization. With only a small amount of trainable parameters, prefix-merging outperforms fine-tuning on query-focused summarization. The paper also discusses the influence of different prefix designs and proposes a visualized explanation for how prefix-merging works.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to compress the source document(s) into a shorter version that contains its important information.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the important information in a document, such as researchers, students, or professionals.', 'How will the summaries be used?': 'The summaries can be used to save time and effort in reading and understanding long documents, and can also be used as a reference for further research or analysis.'}",['method'],"['Auxiliary Tasks', 'Objective Function']","['PubMedQA', 'DUC 2006', 'DUC 2007']",['ROUGE'],[],,https://aclanthology.org/2022.emnlp-main.243/,"{'Lack of generalized large-scale datasets for query-focused summarization.': 'Decouple query-focused summarization into two basic tasks, text summarization and question answering, and transfer knowledge from these tasks to query-focused summarization using few-shot learning techniques.', 'Previous parameter-based knowledge learning methods are usually one-to-one or one-to-many, and seldom focus on many-to-one (integrating basic tasks to a complex one).': 'Propose prefix-merging, a pre-trained strategy for few-shot learning in query-focused summarization, that integrates task-specific knowledge from text summarization and question answering into a properly designed prefix and applies it to the more complex task of query-focused summarization.', 'Difficulty in merging knowledge from multiple tasks into a prefix.': 'Use a flexible prefix design composed of both task-specific and shared parts, and propose a self-adaptive prefix merging that allows basic tasks to decide the prefix design using Fisher Information to calculate importance scores of prefix embeddings for each task.', 'Limited applicability of prompt-based approaches.': 'Benefit from the universality of prompt-based approaches and apply prefix-merging to both autoregressive LM and encoder-decoder based LM, expanding the application of prompt-based approaches to multi-task situations and exploring the interaction between different task knowledge through prefix.'}",supervised,"['CQA', 'News']",['pretraining-and-sample-efficiency']
SP:aa0ae35e0864188f9997cd4080cb729b2d5e2d98,Opinion Summarization by Weak-Supervision from Mix-structured Data,EMNLP,2022,"['Yizhu Liu', 'Qi Jia', 'Kenny Q. Zhu', 'Shanghai Jiao Tong']","Opinion summarization of multiple reviews suffers from the lack of reference summaries for training. Most previous approaches construct multiple reviews and their summary based on textual similarities between reviews, resulting in information mismatch between the review input and the summary. In this paper, we convert each review into a mix of structured and unstructured data, which we call opinion-aspect pairs (OAs) and implicit sentences (ISs). We propose a new method to synthesize training pairs of such mix-structured data as input and the textual summary as output, and design a summarization model with OA encoder and IS encoder. Experiments show that our approach outperforms previous methods on Yelp, Amazon and RottenTomatos datasets.","The paper discusses the challenges of opinion summarization of multiple reviews and proposes a new method to address the issue. The authors convert each review into a mix of structured and unstructured data, called opinion-aspect pairs (OAs) and implicit sentences (ISs), and synthesize training pairs of such mix-structured data as input and the textual summary as output. They design a summarization model with OA encoder and IS encoder and show that their approach outperforms previous methods on Yelp, Amazon and RottenTomatos datasets.","{'What is the purpose of the summaries?': 'The authors are generating summaries of subjective user reviews about an entity (such as a product, service, or movie) in order to help users quickly understand the entity.', 'Who is the target audience?': 'The summaries are for users who want to quickly understand the opinions and aspects of an entity based on multiple reviews.', 'How will the summaries be used?': 'The summaries can be used by users to make informed decisions about whether to purchase a product or use a service, based on the opinions and aspects highlighted in the reviews.'}",['method'],['External Knowledge'],"['Yelp', 'Amazon Product Reviews', 'RottenTomatoes']","['ROUGE', 'Diversity', 'Aspect Coverage']","['Fluency', 'Non-redundancy', 'Opinion Consistency', 'Overall Quality']",https://github.com/YizhuLiu/Opinion-Summarization,https://aclanthology.org/2022.emnlp-main.201/,"{'Opinion summarization lacks training pairs with reviews as input and summary as output, making it difficult and costly for annotators to write summaries for multiple reviews on a large scale.': 'Some approaches adopt unsupervised learning, while others focus on creating synthetic (multireview, summary) pairs for training. The authors propose a new data creation method to construct mix-structured synthetic training pairs by sampling a review as summary and then sampling opinion-aspect pairs (OAs) and implicit sentences (ISs) from other reviews as input.', 'Existing approaches use either textual or structured information to create the input, but they face challenges such as semantic misalignment between the input and output, resulting in problems when training a summarization model.': 'The authors use a mix of structured and unstructured information as the input of their synthetic training data, which can cover more information in output than all previous methods. They also propose a summarization model with OA encoder and IS encoder to capture explicit and implicit opinions at the same time.', 'Some sentences may not produce any OA pairs at all, and information in these sentences is ignored in previous works.': 'The authors not only make use of the structured opinion-aspect data but also those sentences that do not produce explicit OA pairs. They call the latter implicit sentences (IS) and use a mix of structured and unstructured information as the input of their synthetic training data.'}",supervised,"['Opinions', 'Reviews']",['lack-of-suitable-training-data']
SP:d23b15df94ad9b07749d701e562a577e7a15ffa6,Are Abstractive Summarization Models truly ‘Abstractive’? An Empirical Study to Compare the two Forms of Summarization,EMNLP,2022,"['Vinayshekhar Bannihatti Kumar', 'Rashmi Gangadharaiah']","Automatic Text Summarization has seen a large paradigm shift from extractive methods to abstractive (or generation-based) methods in the last few years. This can be attributed to the availability of large autoregressive language models (Lewis et al., 2019; Zhang et al., 2019a) that have been shown to outperform extractive methods. In this work, we revisit extractive methods and study their performance against state of the art(SOTA) abstractive models. Through extensive studies, we notice that abstractive methods are not yet completely abstractive in their generated summaries. In addition to this finding, we propose an evaluation metric that could benefit the summarization research community to measure the degree of abstractiveness of a summary in comparison to their extractive counterparts. To confirm the generalizability of our findings, we conduct experiments on two summarization datasets using five powerful techniques in extractive and abstractive summarization and study their levels of abstraction.","The paper discusses the shift from extractive to abstractive methods in automatic text summarization, and how large autoregressive language models have contributed to this shift. The authors revisit extractive methods and compare their performance to state-of-the-art abstractive models, finding that abstractive methods are not completely abstract in their generated summaries. They propose an evaluation metric to measure the degree of abstractiveness of a summary compared to extractive methods. The authors conduct experiments on two summarization datasets using five techniques in extractive and abstractive summarization to confirm their findings.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to alleviate the issue of information overload caused by the exponential growth of data on the internet.', 'Who is the target audience?': 'The summaries are for users who need to consume information quickly and efficiently.', 'How will the summaries be used?': 'The summaries will be used to capture the essence of the long source text and provide a shorter and concise version of the information.'}","['metric', 'analysis']",[],"['CNN/DailyMail', 'XSum']","['BLEU', 'AbsExtScore', 'Overlap']",['Similarity'],,https://aclanthology.org/2022.gem-1.17/,"{'Abstractive summarization models are not introducing enough novelty words and are simply copying over the words from the source text.': 'The authors propose to analyze the extent of this issue in abstractive summarization models and make observations on the lack of novelty words introduced by these models.', 'There is a large overlap between the extractive and abstractive summaries which questions the abstractiveness of the summaries generated by abstractive summarization models.': 'The authors propose to differentiate summaries generated by abstractive summarization models from their extractive counterparts by proposing an evaluation metric called AbsExtScore.', 'Evaluation methods like BLEU and ROUGE are not geared towards measuring abstractiveness of summaries.': 'The authors propose to use the AbsExtScore evaluation metric to better measure the quality of summaries in terms of abstractiveness.', 'The observations on the lack of abstractiveness in abstractive summarization models have previously been unnoticed largely due to the evaluation methods that have been employed.': 'The authors propose to conduct a human subject study on a sample of summaries to show the correlation between human judgements and the AbsExtScore evaluation metric.'}",,['News'],[]
SP:20138efdf2161aee14d7820fe2a6e7d7c3c46fa0,X-FACTOR: A Cross-metric Evaluation of Factual Correctness in Abstractive Summarization,EMNLP,2022,"['Subhajit Chaudhury', 'Sarathkrishna Swaminathan', 'Chulaka Gunasekara', 'Maxwell Crouse', 'Srinivas Ravishankar', 'Daiki Kimura', 'Keerthiram Murugesan', 'Ramón Fernandez Astudillo', 'Tahira Naseem', 'Pavan Kapanipathi', 'Alexander Gray']","Abstractive summarization models often produce factually inconsistent summaries that are not supported by the original article. Recently, a number of fact-consistent evaluation techniques have been proposed to address this issue; however, a detailed analysis of how these metrics agree with one another has yet to be conducted. In this paper, we present X-FACTOR, a cross-evaluation of three high-performing fact-aware abstractive summarization methods. First, we show that summarization models are often fine-tuned on datasets that contain factually inconsistent summaries and propose a factaware filtering mechanism that improves the quality of training data and, consequently, the factuality of these models. Second, we propose a corrector module that can be used to improve the factual consistency of generated summaries. Third, we present a re-ranking technique that samples summary instances from the output distribution of a summarization model and reranks the sampled instances based on their factuality. Finally, we provide a detailed crossmetric agreement analysis that shows how tuning a model to output summaries based on a particular factuality metric influences factuality as determined by the other metrics. Our goal in this work is to facilitate research that improves the factuality and faithfulness of abstractive summarization models.ive summarization models often produce factually inconsistent summaries that are not supported by the original article. Recently, a number of fact-consistent evaluation techniques have been proposed to address this issue; however, a detailed analysis of how these metrics agree with one another has yet to be conducted. In this paper, we present X-FACTOR, a cross-evaluation of three high-performing fact-aware abstractive summarization methods. First, we show that summarization models are often fine-tuned on datasets that contain factually inconsistent summaries and propose a factaware filtering mechanism that improves the quality of training data and, consequently, the factuality of these models. Second, we propose a corrector module that can be used to improve the factual consistency of generated summaries. Third, we present a re-ranking technique that samples summary instances from the output distribution of a summarization model and reranks the sampled instances based on their factuality. Finally, we provide a detailed crossmetric agreement analysis that shows how tuning a model to output summaries based on a particular factuality metric influences factuality as determined by the other metrics. Our goal in this work is to facilitate research that improves the factuality and faithfulness of abstractive summarization models.","The paper discusses the issue of factually inconsistent summaries produced by abstractive summarization models and proposes X-FACTOR, a cross-evaluation of three high-performing fact-aware abstractive summarization methods. The authors propose a fact-aware filtering mechanism to improve the quality of training data, a corrector module to improve the factual consistency of generated summaries, and a re-ranking technique to sample summary instances and rerank them based on their factuality. The paper also provides a detailed crossmetric agreement analysis to show how tuning a model to output summaries based on a particular factuality metric influences factuality as determined by other metrics. The goal of the work is to facilitate research that improves the factuality and faithfulness of abstractive summarization models.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents for the task of automatic text summarization, which involves generating a concise summary of a given document that preserves its most salient information.', 'Who is the target audience?': 'The summaries can be applied across a variety of contexts and domains, such as the summarization of legal documents, automatic news summarization, and summarization of dialog between agents and clients.', 'How will the summaries be used?': 'The summaries can be used to provide a quick overview of the main points of a document, saving time and effort for readers who need to quickly understand the content.'}","['method', 'analysis']",['Data Augmentation'],"['CNN/DailyMail', 'XSum']",[],[],,https://aclanthology.org/2022.emnlp-main.478/,"{'Abstractive summarization models struggle with generating factual summaries.': 'The authors propose using factuality metrics to evaluate and improve the factuality of abstractive summarization. They perform a comprehensive analysis of seven recent factuality metrics and leverage three different strategies for fact-aware summarization: fact-aware training, posthoc reranking, and fact-aware corrector.', 'Lexical overlap metrics used to evaluate and tune abstractive summarization models do not explicitly measure for factual correctness.': 'The authors propose using factuality metrics specifically targeted towards evaluating and improving the factuality of abstractive summarization.', 'It is unclear how the factuality metrics introduced by recent works agree with each other and how tuning summary generation with a particular metric influences how the summary is scored by other metrics.': 'The authors perform a comprehensive and unified analysis of how these metrics can be used to improve factual consistency and how they interact with each other.', 'Previous works have performed fact-aware methods usually on a single metric.': 'The authors provide an extensive and unified analysis of these methods optimized for various factuality metrics.', 'It is unclear how optimizing fact-aware summarization methods for each of these metrics affects the performance of other lexical and factual evaluation metrics.': 'The authors aim to understand how optimizing fact-aware summarization methods for each of these metrics affects the performance of other lexical and factual evaluation metrics and how that can be used to design an abstractive summarization pipeline that outperforms recent fact-aware summarization baselines.'}",,['News'],['hallucinations-in-the-generated-summaries']
SP:76e42711b2da74431de06b9b2e372ac5a7100b18,Human Guided Exploitation of Interpretable Attention Patterns in Summarization and Topic Segmentation,EMNLP,2022,"['Raymond Li', 'Wen Xiao', 'Linzi Xing', 'Lanjun Wang', 'Gabriel Murray', 'Giuseppe Carenini']","The multi-head self-attention mechanism of the transformer model has been thoroughly investigated recently. In one vein of study, researchers are interested in understanding why and how transformers work. In another vein, researchers propose new attention augmentation methods to make transformers more accurate, efficient and interpretable. In this paper, we combine these two lines of research in a human-in-the-loop pipeline to first discover important task-specific attention patterns. Then those patterns are injected, not only to smaller models, but also to the original model. The benefits of our pipeline and discovered patterns are demonstrated in two case studies with extractive summarization and topic segmentation. After discovering interpretable patterns in BERT-based models fine-tuned for the two downstream tasks, experiments indicate that when we inject the patterns into attention heads, the models show considerable improvements in accuracy and efficiency.","The paper discusses the combination of two lines of research on the multi-head self-attention mechanism of the transformer model. The first line of research aims to understand why and how transformers work, while the second proposes new attention augmentation methods to make transformers more accurate, efficient, and interpretable. The authors present a human-in-the-loop pipeline to discover task-specific attention patterns, which are then injected into smaller and original models. The benefits of this approach are demonstrated in two case studies on extractive summarization and topic segmentation, where the models show considerable improvements in accuracy and efficiency after injecting the discovered patterns into attention heads.","{'What is the purpose of the summaries?': 'The authors are generating summaries of documents to improve the efficiency and accuracy of transformer-based models for NLP tasks such as summarization, topic segmentation, and sentiment analysis.', 'Who is the target audience?': 'The summaries are for researchers and practitioners working in the field of NLP who are interested in improving the interpretability and performance of transformer-based models.', 'How will the summaries be used?': 'The summaries will be used to inform and guide future research on transformer-based models for NLP tasks, particularly in the areas of analyzing self-attention and injecting patterns into attention matrices to improve efficiency and accuracy.'}",['analysis'],['Input Encoding'],['CNN/DailyMail'],['ROUGE'],[],https://github.com/raymondzmc/Attention-Pattern-Exploitation,https://aclanthology.org/2022.emnlp-main.694/,"{'The run-time complexity of self-attention in transformer-based models is high.': 'Inject predefined patterns into attention matrices of transformers to reduce run-time complexity while maintaining competitive accuracy. This can be done by either replacing the attention weights with a fixed matrix or guiding the attention weights through more flexible masking strategies.', 'Lack of interpretability in transformer-based models.': 'Propose a human-in-the-loop pipeline that combines research on analyzing self-attention with work on injecting patterns into attention matrices. Human users visually explore the attention matrices of transformers to identify task-specific patterns that could be formalized as a predicate. Injecting human-interpretable patterns into the model increases the model’s descriptive accuracy by explicitly encoding useful relationships between input tokens in the attention weights while simultaneously improving the predictive accuracy in task performance.', 'Lack of efficiency in transformer-based models.': 'Inject discovered patterns into attention heads of transformer models to simultaneously improve task accuracy and make the model more efficient by sparsifying the attention matrices.', 'Lack of feasibility and potential benefits of the proposed approach.': 'Run two case studies on the tasks of extractive summarization and topic segmentation using BERT-based models to test the feasibility and potential benefits of the proposed approach. Find that some of the important heads do have patterns with interpretable meaning, and when the discovered patterns are injected to the attention heads of transformer models, both the task accuracy and efficiency of the model can be significantly improved. Additionally, propose a strategy to improve the performance of pretrained transformer models by injecting patterns through PALs.'}",supervised,['News'],['efficient-encoding-of-long-documents']
SP:baf0e0fe6d1b44388f6771dd740ce4f4f8d71ba1,Unsupervised Token-level Hallucination Detection from Summary Generation By-products,EMNLP,2022,"['Andreas Marfurt', 'James Henderson']","Hallucinations in abstractive summarization are model generations that are unfaithful to the source document. Current methods for detecting hallucinations operate mostly on noun phrases and named entities, and restrict themselves to the XSum dataset, which is known to have hallucinations in 3 out of 4 training examples (Maynez et al., 2020). We instead consider the CNN/DailyMail dataset where the summarization model has not seen abnormally many hallucinations during training. We automatically detect candidate hallucinations at the token level, irrespective of its part of speech. Our detection comes essentially for free, as we only use information the model already produces during generation of the summary. This enables practitioners to jointly generate a summary and identify possible hallucinations, with minimal overhead. We repurpose an existing factuality dataset and create our own token-level annotations. The evaluation on these two datasets shows that our model achieves better precisionrecall tradeoffs than its competitors, which additionally require a model forward pass.","The paper discusses the issue of hallucinations in abstractive summarization, which are model generations that are not faithful to the source document. Current methods for detecting hallucinations are limited to certain datasets and focus on noun phrases and named entities. The authors propose a new method that detects candidate hallucinations at the token level, regardless of its part of speech, using information already produced during summary generation. They evaluate their method on the CNN/DailyMail dataset and show that it achieves better precision-recall tradeoffs than existing methods. The authors also repurpose an existing factuality dataset and create their own token-level annotations. Overall, their method enables practitioners to generate summaries and identify possible hallucinations with minimal overhead.","{'What is the purpose of the summaries?': 'The authors are generating summaries of the documents to advance the state of the art in abstractive summarization.', 'Who is the target audience?': 'The summaries are for anyone who needs to quickly understand the content of a document.', 'How will the summaries be used?': 'The summaries can be used to quickly understand the content of a document without having to read the entire document.'}","['analysis', 'metric']",[],['CNN/DailyMail'],[],[],https://github.com/idiap/hallucination-detection,https://aclanthology.org/2022.gem-1.21/,"{'Model hallucinations are a prominent failure mode of large pretrained Transformers in abstractive summarization.': ""The authors propose an unsupervised method to detect hallucinations in segments of aligned and unaligned tokens by computing statistics from the encoder's self-attentions and the decoder's next-word probabilities."", 'Current work on hallucination detection focuses on noun phrases and named entities, with some attention to dates and numbers, but not on other parts of speech such as predicates.': 'The authors expand the current line of research to a different dataset and remove the restriction to entities, detecting hallucinations in all parts of speech.', 'XSum, the dataset predominantly used in recent work on hallucination detection, contains a high percentage of reference summaries with hallucinations, making models trained on this dataset prone to hallucinations themselves.': 'The authors evaluate their approach on two datasets, including one they created themselves, to avoid the bias towards hallucinations in XSum.', 'Hallucination detection proves to be a difficult task, particularly on intrinsic hallucinations.': 'The authors acknowledge the difficulty of detecting intrinsic hallucinations and propose their method as a competitive solution compared to existing methods.'}",unsupervised,['News'],['hallucinations-in-the-generated-summaries']
SP:59432e2459cefefac413e4e48bc516727ec1c3d8,Unsupervised Multi-Granularity Summarization,EMNLP,2022,"['Ming Zhong', 'Yang Liu', 'Suyu Ge', 'Yuning Mao', 'Yizhu Jiao', 'Xingxing Zhang', 'Yichong Xu', 'Chenguang Zhu', 'Michael Zeng', 'Jiawei Han']","Text summarization is a user-preference based task, i.e., for one document, users often have different priorities for summary. As a key aspect of customization in summarization, granularity is used to measure the semantic coverage between summary and source document. However, developing systems that can generate summaries with customizable semantic coverage is still an under-explored topic. In this paper, we propose the first unsupervised multi-granularity summarization framework, GRANUSUM. We take events as the basic semantic units of the source documents and propose to rank these events by their salience. We also develop a model to summarize input documents with given events as anchors and hints. By inputting different numbers of events, GRANUSUM is capable of producing multi-granular summaries in an unsupervised manner. Meanwhile, we annotate a new benchmark GranuDUC that contains multiple summaries at different granularities for each document cluster. Experimental results confirm the substantial superiority of GRANUSUM on multi-granularity summarization over strong baselines. Furthermore, by exploiting the event information, GRANUSUM also exhibits state-of-the-art performance under conventional unsupervised abstractive setting.1","The paper proposes an unsupervised multi-granularity summarization framework called GRANUSUM, which can generate summaries with customizable semantic coverage. The framework uses events as the basic semantic units of the source documents and ranks them by their salience. A model is developed to summarize input documents with given events as anchors and hints, producing multi-granular summaries in an unsupervised manner. The paper also introduces a new benchmark called GranuDUC, which contains multiple summaries at different granularities for each document cluster. Experimental results show that GRANUSUM outperforms strong baselines in multi-granularity summarization and exhibits state-of-the-art performance under conventional unsupervised abstractive setting by exploiting event information.","{'What is the purpose of the summaries?': 'The authors are generating the summaries of the documents to condense and summarize long documents into a concise paragraph containing the essential points of the original texts.', 'Who is the target audience?': 'The summaries are highly customized and personalized for different users, so they are for anyone who needs to quickly grasp the overall picture of the input documents or acquire additional details.', 'How will the summaries be used?': 'The summaries can be used in real-world applications to meet the intent of different users and are more versatile than single-granularity summaries. They can also be used to evaluate the performance of multi-granularity summarization systems.'}",['method'],['Unit Selection'],"['Mullti-News', 'arXiv', 'DUC 2004']",['ROUGE'],"['Fluency', 'Relevance', 'Faithfulness']",https://github.com/maszhongming/GranuDUC,https://aclanthology.org/2022.findings-emnlp.366/,"{'Most existing summarization models and benchmarks focus solely on single-granularity summarization, limiting the ability of these systems to adapt to different user preferences and generalize to a wider range of granularity scenarios.': 'The authors propose an unsupervised multi-granularity summarization framework called GRANUSUM, which can generate summaries at different levels of granularity to meet the diverse needs of readers. The system consists of two event-related components: Event-aware Summarizer and Event Selector. The Summarizer can recover event-related passages, and the Selector selects events with high salience from the original text. By selecting different numbers of anchor events, the Summarizer can generate summaries containing different events, thus covering different numbers of semantic units of the original text.', 'Length limit is a surface-level feature of the summary and does not equate to a higher degree of semantic coverage.': 'The authors propose a granularity-based approach to measure the degree of semantic coverage between summary and source documents. They regard events as the basic semantic units of the input texts and create summaries at different levels of granularity to cater to the diverse needs of readers.', 'Query/aspect-based and interactive summarization require a user to provide a query, implying that the user must have prior knowledge of the topic of the source text.': 'The authors propose an automatic granularity-aware summarization model that does not rely on any manually labeled data. Their unsupervised multi-granularity summarization framework can generate summaries at different levels of granularity without requiring a user to provide a query.', 'There is a lack of benchmark datasets for multi-granularity summarization.': 'The authors re-annotate DUC2004 as the first benchmark in this direction (denoted as GranuDUC) and propose to divide several large-scale summarization datasets into buckets with summaries at different granularity levels to further evaluate the model performance. They experimentally show that GRANUSUM surpasses strong summarization systems on all the multi-granularity evaluations and substantially improves the previous state-of-the-art model under the traditional setting.'}",unsupervised,"['News', 'Scholarly Documents']",['controlled-and-tailored-summarization']
